- [[#Informieren und Beraten von Kunden und Kundinnen|Informieren und Beraten von Kunden und Kundinnen]]
- [[#Aktives Zuhören, Kommunikationsmodelle (z.B. Telefonkonferenzen, Chat, virtuelle Teambesprechungen), Verkaufsgespräche (Anfrage, Angebot, Auftrag), Analyse der Kundenbedürfnisse (nicht Bestandteil der schriftlichen Prüfung)|Aktives Zuhören, Kommunikationsmodelle (z.B. Telefonkonferenzen, Chat, virtuelle Teambesprechungen), Verkaufsgespräche (Anfrage, Angebot, Auftrag), Analyse der Kundenbedürfnisse (nicht Bestandteil der schriftlichen Prüfung)]]
	- [[#Aktives Zuhören, Kommunikationsmodelle (z.B. Telefonkonferenzen, Chat, virtuelle Teambesprechungen), Verkaufsgespräche (Anfrage, Angebot, Auftrag), Analyse der Kundenbedürfnisse (nicht Bestandteil der schriftlichen Prüfung)#Kundenbeziehungen unter Beachtung rechtlicher Regelungen und betrieblicher Grundsätze gestalten|Kundenbeziehungen unter Beachtung rechtlicher Regelungen und betrieblicher Grundsätze gestalten]]
	- [[#Aktives Zuhören, Kommunikationsmodelle (z.B. Telefonkonferenzen, Chat, virtuelle Teambesprechungen), Verkaufsgespräche (Anfrage, Angebot, Auftrag), Analyse der Kundenbedürfnisse (nicht Bestandteil der schriftlichen Prüfung)#Instrumente zur Datenauswertung kennen und bedarfsgerecht auswählen sowie Ergebnisse interpretieren können|Instrumente zur Datenauswertung kennen und bedarfsgerecht auswählen sowie Ergebnisse interpretieren können]]
- [[#Beurteilen marktgängiger IT-Systeme und kundenspezifischer Lösungen|Beurteilen marktgängiger IT-Systeme und kundenspezifischer Lösungen]]
	- [[#Beurteilen marktgängiger IT-Systeme und kundenspezifischer Lösungen#Chancen und Risiken der technischen Entwicklungen kennen und identifizieren können|Chancen und Risiken der technischen Entwicklungen kennen und identifizieren können]]
	- [[#Beurteilen marktgängiger IT-Systeme und kundenspezifischer Lösungen#Veränderungen von Einsatzfeldern kennen und beurteilen können|Veränderungen von Einsatzfeldern kennen und beurteilen können]]
- [[#Entwickeln, Erstellen und Betreuen von IT-Lösungen|Entwickeln, Erstellen und Betreuen von IT-Lösungen]]
	- [[#Entwickeln, Erstellen und Betreuen von IT-Lösungen#Fehler erkennen, analysieren und beheben|Fehler erkennen, analysieren und beheben]]
	- [[#Entwickeln, Erstellen und Betreuen von IT-Lösungen#Algorithmen formulieren und Programme entwickeln|Algorithmen formulieren und Programme entwickeln]]
	- [[#Entwickeln, Erstellen und Betreuen von IT-Lösungen#Datenbanken modellieren und erstellen|Datenbanken modellieren und erstellen]]
- [[#Durchführen und Dokumentieren von qualitätssichernden Maßnahmen|Durchführen und Dokumentieren von qualitätssichernden Maßnahmen]]
	- [[#Durchführen und Dokumentieren von qualitätssichernden Maßnahmen#Methoden der Qualitätslenkung anwenden|Methoden der Qualitätslenkung anwenden]]
	- [[#Durchführen und Dokumentieren von qualitätssichernden Maßnahmen#Methoden zur Messung der Zielerreichung im QM-Prozess kennen und anwenden|Methoden zur Messung der Zielerreichung im QM-Prozess kennen und anwenden]]
- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz|Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz]]
	- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz#Für jede Anwendung, die verwendeten IT-Systeme und die verarbeiteten Informationen gilt: Betrachtung zu erwartender Schäden, die bei einer Beeinträchtigung von Vertraulichkeit, Integrität oder Verfügbarkeit entstehen könnten!|Für jede Anwendung, die verwendeten IT-Systeme und die verarbeiteten Informationen gilt: Betrachtung zu erwartender Schäden, die bei einer Beeinträchtigung von Vertraulichkeit, Integrität oder Verfügbarkeit entstehen könnten!]]
	- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz#[[Schadenspotenziale von IT-Sicherheitsvorfällen ]]einschätzen und Schäden verhindern können, z.B.|[[Schadenspotenziale von IT-Sicherheitsvorfällen ]]einschätzen und Schäden verhindern können, z.B.]]
	- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz#[[Präventive IT-Sicherheitsmaßnahmen]] für verschiedene Bedrohungsszenarien planen und umsetzen, z.B.|[[Präventive IT-Sicherheitsmaßnahmen]] für verschiedene Bedrohungsszenarien planen und umsetzen, z.B.]]
	- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz#Ziele zur Entwicklung von IT-Sicherheitskriterien definieren, z.B.|Ziele zur Entwicklung von IT-Sicherheitskriterien definieren, z.B.]]
	- [[#Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz#Kunden zur IT-Sicherheit beraten|Kunden zur IT-Sicherheit beraten]]
- [[#IT-Sicherheitsmaßnahmen mit verschiedenen Tools überprüfen, z.B.|IT-Sicherheitsmaßnahmen mit verschiedenen Tools überprüfen, z.B.]]
- [[#Technische organisatorische Maßnahmen ([[TOM]]) kontrollieren|Technische organisatorische Maßnahmen ([[TOM]]) kontrollieren]]
- [[#Betreiben von IT-Systemen|Betreiben von IT-Systemen]]
	- [[#Betreiben von IT-Systemen#Schichtenmodelle, z.B. [[OSI-Modell|OSI]], [[TCP-IP-Modell|TCP/IP]] benennen und zuordnen können|Schichtenmodelle, z.B. [[OSI-Modell|OSI]], [[TCP-IP-Modell|TCP/IP]] benennen und zuordnen können]]
	- [[#Betreiben von IT-Systemen#Netzwerkkomponenten vergleichen und analysieren können|Netzwerkkomponenten vergleichen und analysieren können]]
	- [[#Betreiben von IT-Systemen#[[Netzwerkkonzepte]] (-topologien, -infrastrukturen) benennen und charakterisieren|[[Netzwerkkonzepte]] (-topologien, -infrastrukturen) benennen und charakterisieren]]
	- [[#Betreiben von IT-Systemen#[[Peer-To-Peer]] bzw. [[Client-Server]]-Konzepte vergleichen und hinsichtlich ihres Einsatzes bewerten können|[[Peer-To-Peer]] bzw. [[Client-Server]]-Konzepte vergleichen und hinsichtlich ihres Einsatzes bewerten können]]
	- [[#Betreiben von IT-Systemen#Übertragungsprotokolle erläutern und zielgerichtet einsetzen können|Übertragungsprotokolle erläutern und zielgerichtet einsetzen können]]
	- [[#Betreiben von IT-Systemen#Standortübergreifende und -unabhängige Kommunikation situationsgerecht auswählen und einrichten können|Standortübergreifende und -unabhängige Kommunikation situationsgerecht auswählen und einrichten können]]
	- [[#Betreiben von IT-Systemen#Netzwerkrelevante Dienste administrieren|Netzwerkrelevante Dienste administrieren]]
	- [[#Betreiben von IT-Systemen#Anwendungsdienste sicherstellen können|Anwendungsdienste sicherstellen können]]
	- [[#Betreiben von IT-Systemen#Risiken identifizieren, Maßnahmen planen und Ausfallwahrscheinlichkeiten berücksichtigen|Risiken identifizieren, Maßnahmen planen und Ausfallwahrscheinlichkeiten berücksichtigen]]
	- [[#Betreiben von IT-Systemen#Maßnahmen zur Sicherstellung des Betriebes beurteilen können|Maßnahmen zur Sicherstellung des Betriebes beurteilen können]]
	- [[#Betreiben von IT-Systemen#Monitoringsysteme anwenden und Ergebnisse interpretieren können|Monitoringsysteme anwenden und Ergebnisse interpretieren können]]
	- [[#Betreiben von IT-Systemen#Monitoringergebnisse analyseiren und korrektive Maßnahmen bestimmen können|Monitoringergebnisse analyseiren und korrektive Maßnahmen bestimmen können]]
	- [[#Betreiben von IT-Systemen#Erstellen und Erweitern von Handbüchern für Benutzer und Systembetreuer|Erstellen und Erweitern von Handbüchern für Benutzer und Systembetreuer]]
- [[#Inbetriebnehmen von [[Speicherlösungen]]|Inbetriebnehmen von [[Speicherlösungen]]]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Technische und organisatorische Maßnahmen ([[TOM]])|Technische und organisatorische Maßnahmen ([[TOM]])]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Möglichkeiten der [[Hardwaretechnischen Absicherung]] benennen|Möglichkeiten der [[Hardwaretechnischen Absicherung]] benennen]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Möglichkeiten der [[Softwaretechnischen Absicherung]] implementieren können|Möglichkeiten der [[Softwaretechnischen Absicherung]] implementieren können]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Verschiedene Service- und Liefermodelle benennen und bedarfsorientiert auswählen können|Verschiedene Service- und Liefermodelle benennen und bedarfsorientiert auswählen können]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Daten heterogener Quellen zusammenführen|Daten heterogener Quellen zusammenführen]]
	- [[#Inbetriebnehmen von [[Speicherlösungen]]#Netzwerkkomponenten und -protokolle beschreiben können, z.B.|Netzwerkkomponenten und -protokolle beschreiben können, z.B.]]
- [[#Programmieren von Softwarelösungen|Programmieren von Softwarelösungen]]
	- [[#Programmieren von Softwarelösungen#[[Software-Anforderungen|Anforderungen]] kundengerecht erfassen|[[Software-Anforderungen|Anforderungen]] kundengerecht erfassen]]
	- [[#Programmieren von Softwarelösungen#Planen mit geeigneten Modellen|Planen mit geeigneten Modellen]]
	- [[#Programmieren von Softwarelösungen#Festlegen von Schnittstellen und vorhandene Schnittstellen nutzen|Festlegen von Schnittstellen und vorhandene Schnittstellen nutzen]]
	- [[#Programmieren von Softwarelösungen#Situationsgerechte Auswahl einer passenden [[Programmiersprachen|Programmiersprache]] begründen können|Situationsgerechte Auswahl einer passenden [[Programmiersprachen|Programmiersprache]] begründen können]]
	- [[#Programmieren von Softwarelösungen#Algorithmen in einer Programmiersprache darstellen|Algorithmen in einer Programmiersprache darstellen]]
	- [[#Programmieren von Softwarelösungen#[[Wiederkehrende Systemabläufe mithilfe von Skripten automatisieren und überwachen können]]|[[Wiederkehrende Systemabläufe mithilfe von Skripten automatisieren und überwachen können]]]]
- [[#Analysieren von Arbeits- und Geschäftsprozessen|Analysieren von Arbeits- und Geschäftsprozessen]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse identifzieren|Prozesse identifzieren]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse im Unternehmen einordnen können|Prozesse im Unternehmen einordnen können]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse beschreiben können z.B.|Prozesse beschreiben können z.B.]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse bewerten|Prozesse bewerten]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse modifizieren können|Prozesse modifizieren können]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse einführen können|Prozesse einführen können]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Prozesse steuern können aufgrund von|Prozesse steuern können aufgrund von]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Managementansätze, die die Prozessorientierung unterstützen, in ihren Auswirkungen beschreiben können|Managementansätze, die die Prozessorientierung unterstützen, in ihren Auswirkungen beschreiben können]]
	- [[#Analysieren von Arbeits- und Geschäftsprozessen#Konzepte zur Prozessoptimierung anwenden können|Konzepte zur Prozessoptimierung anwenden können]]
- [[#Analysieren von Datenquellen und Bereitstellen von Daten|Analysieren von Datenquellen und Bereitstellen von Daten]]
	- [[#Analysieren von Datenquellen und Bereitstellen von Daten#Für einen Prozess relevante Daten identifizieren können|Für einen Prozess relevante Daten identifizieren können]]
	- [[#Analysieren von Datenquellen und Bereitstellen von Daten#Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können|Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können]]
- [[#Daten in einer Datenbank speichern und verarbeiten können|Daten in einer Datenbank speichern und verarbeiten können]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#Daten klassifizieren können|Daten klassifizieren können]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#Rechtliche Grundlagen erkennen können|Rechtliche Grundlagen erkennen können]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#Einbinden unterschiedlicher interner/externer Stellen/Ansprechpartner bei Zweifelsfällen|Einbinden unterschiedlicher interner/externer Stellen/Ansprechpartner bei Zweifelsfällen]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#Ethische Konsequenzen aus der Nutzung und Verknüpfung von Daten diskutieren können|Ethische Konsequenzen aus der Nutzung und Verknüpfung von Daten diskutieren können]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#[[Technische Verfügbarkeit von Daten]] realisieren können|[[Technische Verfügbarkeit von Daten]] realisieren können]]
	- [[#Daten in einer Datenbank speichern und verarbeiten können#Daten auf einer einheitlichen Plattform speichern|Daten auf einer einheitlichen Plattform speichern]]
- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle|Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Daten zur Feststellung des Istzustandes aufbereiten, Reproduzierbarkeit/Wiederholbarkeit von Daten|Daten zur Feststellung des Istzustandes aufbereiten, Reproduzierbarkeit/Wiederholbarkeit von Daten]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Defizite gegenüber dem Sollzustand in der [[Datenqualität]] anhand von Merkmalen feststellen|Defizite gegenüber dem Sollzustand in der [[Datenqualität]] anhand von Merkmalen feststellen]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Maßnahmen zur Verbesserung der Datenqualität ableiten|Maßnahmen zur Verbesserung der Datenqualität ableiten]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Angemessene grafische Repräsentation für Analyseergebnisse auswählen z.B.|Angemessene grafische Repräsentation für Analyseergebnisse auswählen z.B.]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Mathematische Vorhersagemodelle anwenden|Mathematische Vorhersagemodelle anwenden]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Grundlagen des maschinellen Lernens anwenden können|Grundlagen des maschinellen Lernens anwenden können]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Verfahren einordnen und weitere Konzepte kennen|Verfahren einordnen und weitere Konzepte kennen]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Format für zielgruppengerechte Berichterstattung erarbeiten|Format für zielgruppengerechte Berichterstattung erarbeiten]]
	- [[#Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle#Kennzahlen ableiten und für ein Monitoringsystem vorschlagen|Kennzahlen ableiten und für ein Monitoringsystem vorschlagen]]
- [[#Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]|Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]]]
	- [[#Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]#Akteure/Rollen im [[Datenschutz]] erkennen und ihre Beziehung untereinander zuordnen können|Akteure/Rollen im [[Datenschutz]] erkennen und ihre Beziehung untereinander zuordnen können]]
	- [[#Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]#Grundlegende [[Schutz- und Gewährleistungsziele der Informationssicherheit]] beschreiben können|Grundlegende [[Schutz- und Gewährleistungsziele der Informationssicherheit]] beschreiben können]]
	- [[#Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]#Auswahl von Datenfeldern, die für eine Zweckerreichung zwingend benötigt werden|Auswahl von Datenfeldern, die für eine Zweckerreichung zwingend benötigt werden]]
	- [[#Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]#Verfahren zur Datenverschlüsselung auswählen und nutzen|Verfahren zur Datenverschlüsselung auswählen und nutzen]]
- [[#Berufsausbildung sowie Arbeits- und Tarifrecht|Berufsausbildung sowie Arbeits- und Tarifrecht]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Rechte und Pflichten des Auszubildenden und des Ausbildenden|Rechte und Pflichten des Auszubildenden und des Ausbildenden]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Vorteile der Ausbildung im dualen System der Berufsbildung|Vorteile der Ausbildung im dualen System der Berufsbildung]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Aufgaben von Ausbildungsbetrieb, Berufsschule und Kammern im Rahmen der Berufsausbildung|Aufgaben von Ausbildungsbetrieb, Berufsschule und Kammern im Rahmen der Berufsausbildung]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Ausbildungsrahmenplan, sachliche und zeitliche Gliederung|Ausbildungsrahmenplan, sachliche und zeitliche Gliederung]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Grundsätze des Individual- und Kollektivarbeitsrechtes|Grundsätze des Individual- und Kollektivarbeitsrechtes]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Arbeitgeberorganisationen|Arbeitgeberorganisationen]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Arbeitnehmerorganisationen|Arbeitnehmerorganisationen]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Tarifrecht|Tarifrecht]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Lohn- und Gehaltsformen|Lohn- und Gehaltsformen]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Lebensbegleitendes lernen|Lebensbegleitendes lernen]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Lerntechniken|Lerntechniken]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Arbeitstechniken|Arbeitstechniken]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Berufliche Fortbildung und Umschulung|Berufliche Fortbildung und Umschulung]]
	- [[#Berufsausbildung sowie Arbeits- und Tarifrecht#Lebensplanung|Lebensplanung]]
- [[#Aufbau und Organisation des Ausbildungsbetriebes|Aufbau und Organisation des Ausbildungsbetriebes]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Der Betrieb|Der Betrieb]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Rechtsformen|Rechtsformen]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Unternehmensstruktur und Organisationsform|Unternehmensstruktur und Organisationsform]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Wirtschaftliche Verflechtung|Wirtschaftliche Verflechtung]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Ziele von Betrieben und Unternehmen|Ziele von Betrieben und Unternehmen]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Betriebliche und gesamtwirtschaftliche Arbeitsteilung|Betriebliche und gesamtwirtschaftliche Arbeitsteilung]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Ziele und Aufgaben von Arbeitgeber- und Arbeitnehmerverbänden|Ziele und Aufgaben von Arbeitgeber- und Arbeitnehmerverbänden]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Ziele und Aufgaben von Behörden und Verwaltungen|Ziele und Aufgaben von Behörden und Verwaltungen]]
	- [[#Aufbau und Organisation des Ausbildungsbetriebes#Grundsatz der vertrauensvollen Zusammenarbeit zwischen Arbeitgeber- und Arbeitnehmervertretern|Grundsatz der vertrauensvollen Zusammenarbeit zwischen Arbeitgeber- und Arbeitnehmervertretern]]
- [[#Sicherheit und Gesundheitsschutz bei der Arbeit|Sicherheit und Gesundheitsschutz bei der Arbeit]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Gesundheits- und Arbeitsschutzvorschriften|Gesundheits- und Arbeitsschutzvorschriften]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Gefährdung und Beanspruchungen wahrnehmen und einschätzen|Gefährdung und Beanspruchungen wahrnehmen und einschätzen]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Vorsorgeuntersuchungen|Vorsorgeuntersuchungen]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Aufgaben der Sicherheitsbeauftragten|Aufgaben der Sicherheitsbeauftragten]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Vorschriften im betrieblichen und persönlichen Arbeitsablauf|Vorschriften im betrieblichen und persönlichen Arbeitsablauf]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Verhaltensweisen bei Unfällen|Verhaltensweisen bei Unfällen]]
	- [[#Sicherheit und Gesundheitsschutz bei der Arbeit#Verhaltensweisen im Brandfall sowie verbeugender Brandschutz|Verhaltensweisen im Brandfall sowie verbeugender Brandschutz]]
- [[#Umweltschutz|Umweltschutz]]
	- [[#Umweltschutz#Umweltbelastungen wahrnehmen und vermeiden helfen|Umweltbelastungen wahrnehmen und vermeiden helfen]]
	- [[#Umweltschutz#Umgang mit Abfällen|Umgang mit Abfällen]]
	- [[#Umweltschutz#Öffentliche Systeme und Verordnungen/Gesetze|Öffentliche Systeme und Verordnungen/Gesetze]]
	- [[#Umweltschutz#Externe Auswirkungen|Externe Auswirkungen]]
	- [[#Umweltschutz#Umweltschonende Ressourcennutzung|Umweltschonende Ressourcennutzung]]
	- [[#Umweltschutz#Abfallvermeidung und -reduzierung|Abfallvermeidung und -reduzierung]]
	- [[#Umweltschutz#Rechtsfolgen bei Nichteinhaltung|Rechtsfolgen bei Nichteinhaltung]]
- [[#Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien|Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien]]
	- [[#Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien#Wertschätzende Zusammenarbeit|Wertschätzende Zusammenarbeit]]
	- [[#Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien#Informationstechnische Schutzziele: Integrität, Vertraulichkeit und Authentizität berücksichtigen|Informationstechnische Schutzziele: Integrität, Vertraulichkeit und Authentizität berücksichtigen]]
	- [[#Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien#Ethische Aspekte und Compliance-Regelungen|Ethische Aspekte und Compliance-Regelungen]]
		- [[#Ethische Aspekte und Compliance-Regelungen#Funktionen|Funktionen]]
		- [[#Ethische Aspekte und Compliance-Regelungen#Typen von APIs|Typen von APIs]]
		- [[#Ethische Aspekte und Compliance-Regelungen#Entwicklungsstufen|Entwicklungsstufen]]
		- [[#Ethische Aspekte und Compliance-Regelungen#Bedeutung|Bedeutung]]
- [[#Quellen|Quellen]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Formel|Formel]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Grundbegriffe|Grundbegriffe]]
- [[#Apriori Algorithmus|Apriori Algorithmus]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
- [[#Aufgabenanalyse|Aufgabenanalyse]]
- [[#Aufgabensynthese|Aufgabensynthese]]
- [[#Organisationsformen|Organisationsformen]]
	- [[#Organisationsformen#Einliniensystem|Einliniensystem]]
	- [[#Organisationsformen#Mehrliniensystem|Mehrliniensystem]]
- [[#Matrixorganisation|Matrixorganisation]]
	- [[#Matrixorganisation#Stabliniensystem|Stabliniensystem]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Funktionsweise von Augmented Reality|Funktionsweise von Augmented Reality]]
	- [[#Quellen#Arten von Augmented Reality|Arten von Augmented Reality]]
	- [[#Quellen#Anwendungsbereiche von Augmented Reality|Anwendungsbereiche von Augmented Reality]]
	- [[#Quellen#Vorteile von Augmented Reality|Vorteile von Augmented Reality]]
	- [[#Quellen#Herausforderungen und Einschränkungen|Herausforderungen und Einschränkungen]]
	- [[#Quellen#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#1. Definition|1. Definition]]
- [[#2. Ziele der Automatisierung|2. Ziele der Automatisierung]]
- [[#3. Vorteile der Automatisierung|3. Vorteile der Automatisierung]]
- [[#4. Herausforderungen der Automatisierung|4. Herausforderungen der Automatisierung]]
- [[#5. Schritte zur Implementierung|5. Schritte zur Implementierung]]
- [[#6. Beispiele für automatisierte Prozesse|6. Beispiele für automatisierte Prozesse]]
- [[#Veränderungen von Einsatzfeldern|Veränderungen von Einsatzfeldern]]
	- [[#Veränderungen von Einsatzfeldern#Einsatzfelder autonomer Systeme|Einsatzfelder autonomer Systeme]]
	- [[#Veränderungen von Einsatzfeldern#Technologische Trends|Technologische Trends]]
	- [[#Veränderungen von Einsatzfeldern#Herausforderungen und Risiken|Herausforderungen und Risiken]]
	- [[#Veränderungen von Einsatzfeldern#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Gründe für Backups|Gründe für Backups]]
- [[#Backup-Arten|Backup-Arten]]
- [[#Backup-Strategien|Backup-Strategien]]
- [[#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Definition|Definition]]
- [[#Zielgruppen|Zielgruppen]]
- [[#Wichtige Standards und Richtlinien|Wichtige Standards und Richtlinien]]
- [[#Technische Maßnahmen|Technische Maßnahmen]]
- [[#Testing und Evaluation|Testing und Evaluation]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Grundlagen von Bash|Grundlagen von Bash]]
- [[#Wichtige Befehle|Wichtige Befehle]]
- [[#Variablen|Variablen]]
- [[#Kontrollstrukturen|Kontrollstrukturen]]
- [[#Funktionen|Funktionen]]
- [[#Skripterstellung|Skripterstellung]]
- [[#Nützliche Tipps|Nützliche Tipps]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Arten des Benchmarking|Arten des Benchmarking]]
- [[#Benchmarking-Prozess|Benchmarking-Prozess]]
- [[#Vorteile|Vorteile]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices für erfolgreiches Benchmarking|Best Practices für erfolgreiches Benchmarking]]
- [[#Grundprinzipien|Grundprinzipien]]
	- [[#Grundprinzipien#Volumen|Volumen]]
	- [[#Grundprinzipien#Velocity|Velocity]]
	- [[#Grundprinzipien#Variety|Variety]]
	- [[#Grundprinzipien#Value|Value]]
	- [[#Grundprinzipien#Veracity *(Richtigkeit)*|Veracity *(Richtigkeit)*]]
	- [[#Grundprinzipien#Weitere Aspekte|Weitere Aspekte]]
- [[#Anwendungsfälle|Anwendungsfälle]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Quellen|Quellen]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
- [[#Quellen|Quellen]]
		- [[#Weitere Aspekte#Ziele von BPMN|Ziele von BPMN]]
		- [[#Weitere Aspekte#Vorteile von BPMN|Vorteile von BPMN]]
		- [[#Weitere Aspekte#Grundelemente von BPMN|Grundelemente von BPMN]]
		- [[#Weitere Aspekte#Anwendungsbereiche von BPMN|Anwendungsbereiche von BPMN]]
		- [[#Weitere Aspekte#Herausforderungen bei der Verwendung von BPMN|Herausforderungen bei der Verwendung von BPMN]]
- [[#Arten von Breakpoints|Arten von Breakpoints]]
- [[#Verwendung von Breakpoints|Verwendung von Breakpoints]]
- [[#Vorteile von Breakpoints|Vorteile von Breakpoints]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Formel|Formel]]
	- [[#Formel#Beispiel|Beispiel]]
- [[#Zielsetzung|Zielsetzung]]
- [[#Wann ist BPR sinnvoll?|Wann ist BPR sinnvoll?]]
- [[#Methoden und Phasen des BPR|Methoden und Phasen des BPR]]
- [[#Historische Perspektive|Historische Perspektive]]
- [[#Vor- und Nachteile von BPR|Vor- und Nachteile von BPR]]
- [[#Fazit|Fazit]]
- [[#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Tipps für die Umsetzung|Tipps für die Umsetzung]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Arten|Arten]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#SaaS|SaaS]]
- [[#IaaS|IaaS]]
- [[#PaaS|PaaS]]
- [[#XaaS|XaaS]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#K-Means Clusteranalyse|K-Means Clusteranalyse]]
	- [[#K-Means Clusteranalyse#Algorithmus|Algorithmus]]
	- [[#K-Means Clusteranalyse#Wichtige Aspekte|Wichtige Aspekte]]
	- [[#K-Means Clusteranalyse#Vor- und Nachteile|Vor- und Nachteile]]
	- [[#K-Means Clusteranalyse#Anwendungen|Anwendungen]]
- [[#Hierarchische Clusteranalyse|Hierarchische Clusteranalyse]]
	- [[#Hierarchische Clusteranalyse#Hauptmerkmale|Hauptmerkmale]]
	- [[#Hierarchische Clusteranalyse#Arten|Arten]]
	- [[#Hierarchische Clusteranalyse#Algorithmus (agglomerativ)|Algorithmus (agglomerativ)]]
	- [[#Hierarchische Clusteranalyse#Distanzmaße|Distanzmaße]]
	- [[#Hierarchische Clusteranalyse#Fusionsmethoden|Fusionsmethoden]]
	- [[#Hierarchische Clusteranalyse#Vorteile|Vorteile]]
	- [[#Hierarchische Clusteranalyse#Nachteile|Nachteile]]
	- [[#Hierarchische Clusteranalyse#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Arten von Compliance|Arten von Compliance]]
- [[#Anforderungen|Anforderungen]]
- [[#Vorteile|Vorteile]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Quellen|Quellen]]
- [[#Elemente der Corporate Identity|Elemente der Corporate Identity]]
- [[#Ziele der Corporate Identity|Ziele der Corporate Identity]]
- [[#Vorteile der Corporate Identity|Vorteile der Corporate Identity]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Phasen|Phasen]]
	- [[#Phasen#1. Business Understanding|1. Business Understanding]]
	- [[#Phasen#2. Data Understanding|2. Data Understanding]]
- [[#3. Data Preparation|3. Data Preparation]]
- [[#4. Modeling|4. Modeling]]
- [[#5. Evaluation|5. Evaluation]]
- [[#6. Deployment|6. Deployment]]
- [[#Wichtige Aspekte von CRM|Wichtige Aspekte von CRM]]
- [[#Funktionen von CRM-Systemen|Funktionen von CRM-Systemen]]
- [[#Vorteile von CRM|Vorteile von CRM]]
- [[#Herausforderungen bei der Implementierung von CRM|Herausforderungen bei der Implementierung von CRM]]
- [[#Quellen|Quellen]]
- [[#Definition|Definition]]
- [[#Merkmale|Merkmale]]
- [[#ETL-Prozess|ETL-Prozess]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Prozess|Prozess]]
- [[#Techniken|Techniken]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Definition|Definition]]
- [[#Merkmale|Merkmale]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Arten von Daten|Arten von Daten]]
- [[#Herausforderungen bei der Datenanalyse|Herausforderungen bei der Datenanalyse]]
- [[#Methoden zur Datenverarbeitung|Methoden zur Datenverarbeitung]]
- [[#Praktische Anwendungen der Datenanalyse|Praktische Anwendungen der Datenanalyse]]
- [[#Strukturierte Daten|Strukturierte Daten]]
	- [[#Strukturierte Daten#Merkmale|Merkmale]]
	- [[#Strukturierte Daten#Beispiele|Beispiele]]
	- [[#Strukturierte Daten#Anwendungen|Anwendungen]]
- [[#Unstrukturierte Daten|Unstrukturierte Daten]]
	- [[#Unstrukturierte Daten#Merkmale|Merkmale]]
	- [[#Unstrukturierte Daten#Beispiele|Beispiele]]
	- [[#Unstrukturierte Daten#Anwendungen:|Anwendungen:]]
- [[#Halbstrukturierte Daten|Halbstrukturierte Daten]]
	- [[#Halbstrukturierte Daten#Definition|Definition]]
	- [[#Halbstrukturierte Daten#Merkmale|Merkmale]]
	- [[#Halbstrukturierte Daten#Beispiele|Beispiele]]
	- [[#Halbstrukturierte Daten#Anwendungen|Anwendungen]]
- [[#XML (eXtensible Markup Language)|XML (eXtensible Markup Language)]]
- [[#JSON (JavaScript Object Notation)|JSON (JavaScript Object Notation)]]
- [[#CSV (Comma-Separated Values)|CSV (Comma-Separated Values)]]
- [[#Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können|Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können]]
- [[#Quellen|Quellen]]
- [[#Stand-Alone-Datenbanksystem|Stand-Alone-Datenbanksystem]]
- [[#Multi-User-Datenbanksystem|Multi-User-Datenbanksystem]]
	- [[#Multi-User-Datenbanksystem#Konkurrenzverwaltung in Multi-User-Systemen:|Konkurrenzverwaltung in Multi-User-Systemen:]]
- [[#Komponenten einer Datenbankarchitektur|Komponenten einer Datenbankarchitektur]]
- [[#Wichtige Aspekte des Datendiebstahls|Wichtige Aspekte des Datendiebstahls]]
- [[#Methoden des Datendiebstahls|Methoden des Datendiebstahls]]
- [[#Auswirkungen des Datendiebstahls|Auswirkungen des Datendiebstahls]]
- [[#Präventionsmaßnahmen|Präventionsmaßnahmen]]
- [[#Reaktion auf Datendiebstahl|Reaktion auf Datendiebstahl]]
- [[#Quellen|Quellen]]
- [[#Formel|Formel]]
- [[#Quellen|Quellen]]
- [[#Merkmale der Datenqualität|Merkmale der Datenqualität]]
	- [[#Merkmale der Datenqualität#Messung der Datenqualität|Messung der Datenqualität]]
- [[#Prozess|Prozess]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte des Datenschutzes|Wichtige Aspekte des Datenschutzes]]
- [[#Grundprinzipien des Datenschutzes|Grundprinzipien des Datenschutzes]]
- [[#Maßnahmen zur Gewährleistung des Datenschutzes|Maßnahmen zur Gewährleistung des Datenschutzes]]
- [[#Aktuelle Trends und Entwicklungen|Aktuelle Trends und Entwicklungen]]
- [[#Strategien zur Erkennung von Anforderungen|Strategien zur Erkennung von Anforderungen]]
- [[#Rechte der betroffenen Personen|Rechte der betroffenen Personen]]
- [[#Regelwerke und Normen|Regelwerke und Normen]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte der Datensicherheit|Wichtige Aspekte der Datensicherheit]]
- [[#Maßnahmen zur Gewährleistung der Datensicherheit|Maßnahmen zur Gewährleistung der Datensicherheit]]
- [[#Risiken für die Datensicherheit|Risiken für die Datensicherheit]]
- [[#Aktuelle Trends und Entwicklungen|Aktuelle Trends und Entwicklungen]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte der Datensorgfalt|Wichtige Aspekte der Datensorgfalt]]
	- [[#Wichtige Aspekte der Datensorgfalt#Datenqualität|Datenqualität]]
	- [[#Wichtige Aspekte der Datensorgfalt#Datenschutz|Datenschutz]]
	- [[#Wichtige Aspekte der Datensorgfalt#Datenminimierung|Datenminimierung]]
	- [[#Wichtige Aspekte der Datensorgfalt#Dokumentation und Nachverfolgbarkeit|Dokumentation und Nachverfolgbarkeit]]
	- [[#Wichtige Aspekte der Datensorgfalt#Schulung und Sensibilisierung|Schulung und Sensibilisierung]]
- [[#Vorteile der Datensorgfalt|Vorteile der Datensorgfalt]]
- [[#Herausforderungen bei der Umsetzung der Datensorgfalt|Herausforderungen bei der Umsetzung der Datensorgfalt]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Wichtige Aspekte der Datensparsamkeit|Wichtige Aspekte der Datensparsamkeit]]
	- [[#Quellen#Minimierung der Datenerhebung|Minimierung der Datenerhebung]]
	- [[#Quellen#Zweckbindung|Zweckbindung]]
	- [[#Quellen#Datenlöschung|Datenlöschung]]
	- [[#Quellen#Transparenz|Transparenz]]
- [[#Vorteile der Datensparsamkeit|Vorteile der Datensparsamkeit]]
- [[#Herausforderungen bei der Umsetzung der Datensparsamkeit|Herausforderungen bei der Umsetzung der Datensparsamkeit]]
- [[#Quellen|Quellen]]
- [[#Kernfunktionen|Kernfunktionen]]
- [[#Architektur und Komponenten|Architektur und Komponenten]]
- [[#Datenmodelle und Abfragesprachen|Datenmodelle und Abfragesprachen]]
- [[#Transaktionsmanagement|Transaktionsmanagement]]
	- [[#Transaktionsmanagement#Concurrency Control Methoden|Concurrency Control Methoden]]
- [[#Datensicherheit und -integrität|Datensicherheit und -integrität]]
	- [[#Datensicherheit und -integrität#Sicherheitsmechanismen|Sicherheitsmechanismen]]
	- [[#Datensicherheit und -integrität#Integritätsbedingungen|Integritätsbedingungen]]
- [[#Verteilte Datenbanksysteme|Verteilte Datenbanksysteme]]
- [[#Moderne Entwicklungen|Moderne Entwicklungen]]
	- [[#Moderne Entwicklungen#Arten von Bugs|Arten von Bugs]]
	- [[#Moderne Entwicklungen#Debugging-Methoden|Debugging-Methoden]]
	- [[#Moderne Entwicklungen#Debugging-Strategien|Debugging-Strategien]]
	- [[#Moderne Entwicklungen#Best Practices|Best Practices]]
	- [[#Moderne Entwicklungen#Tools und Ressourcen|Tools und Ressourcen]]
	- [[#Moderne Entwicklungen#Tipps für effektives Debugging|Tipps für effektives Debugging]]
- [[#Quellen|Quellen]]
- [[#Wichtige Komponenten|Wichtige Komponenten]]
- [[#Tools und Techniken|Tools und Techniken]]
	- [[#Tools und Techniken#Gerätemanagement|Gerätemanagement]]
	- [[#Tools und Techniken#Endpoint Protection|Endpoint Protection]]
	- [[#Tools und Techniken#Netzwerksicherheit|Netzwerksicherheit]]
	- [[#Tools und Techniken#Sicherheitsüberprüfung|Sicherheitsüberprüfung]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
	- [[#Vor- und Nachteile#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile#Nachteile|Nachteile]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Grundlagen von DHCP|Grundlagen von DHCP]]
- [[#Funktionsweise von DHCP|Funktionsweise von DHCP]]
- [[#DHCP-Prozess|DHCP-Prozess]]
- [[#DHCP-Optionen|DHCP-Optionen]]
- [[#Vorteile von DHCP|Vorteile von DHCP]]
- [[#DHCP-Reservierungen|DHCP-Reservierungen]]
- [[#DHCP-Sicherheit|DHCP-Sicherheit]]
- [[#Relevanz in Netzwerken|Relevanz in Netzwerken]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Balkendiagramm|Balkendiagramm]]
- [[#Liniendiagramm|Liniendiagramm]]
- [[#Diagramm Fläche|Diagramm Fläche]]
- [[#Streudiagramm|Streudiagramm]]
- [[#Kreisdiagramm|Kreisdiagramm]]
- [[#Piktogramm|Piktogramm]]
- [[#Säulendiagramm|Säulendiagramm]]
- [[#Blasendiagramm|Blasendiagramm]]
- [[#Pegelkarte|Pegelkarte]]
- [[#Gestapeltes Venn|Gestapeltes Venn]]
- [[#Mosaik-Plot|Mosaik-Plot]]
- [[#Gantt-Diagramm|Gantt-Diagramm]]
- [[#Radarkarte|Radarkarte]]
- [[#Wasserfall-Diagramm|Wasserfall-Diagramm]]
- [[#Wärmekarte|Wärmekarte]]
- [[#Trichterdiagramm|Trichterdiagramm]]
- [[#Pareto-Diagramm|Pareto-Diagramm]]
- [[#Gestapeltes Balkendiagramm|Gestapeltes Balkendiagramm]]
- [[#Flussdiagramm|Flussdiagramm]]
- [[#Boxplot|Boxplot]]
- [[#Quellen|Quellen]]
- [[#Notwendigkeit einer digitalen Signatur (Zertifikate)|Notwendigkeit einer digitalen Signatur (Zertifikate)]]
- [[#Praktische Umsetzung|Praktische Umsetzung]]
- [[#Quellen|Quellen]]
- [[#1. Disaster-Recovery-Planung|1. Disaster-Recovery-Planung]]
- [[#2. Wichtige Konzepte|2. Wichtige Konzepte]]
- [[#3. Business-Continuity-Planung|3. Business-Continuity-Planung]]
- [[#4. Business-Impact-Analyse|4. Business-Impact-Analyse]]
- [[#5. Risikoanalyse|5. Risikoanalyse]]
- [[#6. Priorisierung von Anwendungen|6. Priorisierung von Anwendungen]]
- [[#7. Dokumentation von Abhängigkeiten|7. Dokumentation von Abhängigkeiten]]
- [[#8. Wiederherstellungsziele|8. Wiederherstellungsziele]]
- [[#9. Einhaltung gesetzlicher Vorschriften|9. Einhaltung gesetzlicher Vorschriften]]
- [[#10. Auswahl von Technologien|10. Auswahl von Technologien]]
- [[#11. Auswahl von Recovery-Standorten|11. Auswahl von Recovery-Standorten]]
- [[#12. Kontinuierliche Tests und Überprüfung|12. Kontinuierliche Tests und Überprüfung]]
- [[#13. Disaster-Recovery as a Service (DRaaS)|13. Disaster-Recovery as a Service (DRaaS)]]
	- [[#13. Disaster-Recovery as a Service (DRaaS)#Hauptmerkmale:|Hauptmerkmale:]]
	- [[#13. Disaster-Recovery as a Service (DRaaS)#Anwendungsgebiete:|Anwendungsgebiete:]]
- [[#Struktur des DNS|Struktur des DNS]]
	- [[#Struktur des DNS#Beispiel für DNS-Einträge:|Beispiel für DNS-Einträge:]]
- [[#Vorteile und Herausforderungen|Vorteile und Herausforderungen]]
	- [[#Vorteile und Herausforderungen#Vorteile:|Vorteile:]]
	- [[#Vorteile und Herausforderungen#Herausforderungen:|Herausforderungen:]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Beispiele|Beispiele]]
	- [[#Beispiele#Merkmale von Embedded Systems|Merkmale von Embedded Systems]]
	- [[#Beispiele#Anwendungsbereiche von Embedded Systems|Anwendungsbereiche von Embedded Systems]]
	- [[#Beispiele#Komponenten von Embedded Systems|Komponenten von Embedded Systems]]
	- [[#Beispiele#Entwicklungsprozess von Embedded Systems|Entwicklungsprozess von Embedded Systems]]
	- [[#Beispiele#Herausforderungen bei Embedded Systems|Herausforderungen bei Embedded Systems]]
	- [[#Beispiele#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Beziehungen|Beziehungen]]
- [[#Entropie|Entropie]]
	- [[#Entropie#Formel|Formel]]
		- [[#Formel#Allgemein|Allgemein]]
		- [[#Formel#IHK|IHK]]
			- [[#IHK#Beispiel|Beispiel]]
	- [[#Entropie#Berechnung|Berechnung]]
- [[#Informationsgewinn|Informationsgewinn]]
	- [[#Informationsgewinn#Formel|Formel]]
- [[#Quellen|Quellen]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Arten von Entscheidungsbäumen|Arten von Entscheidungsbäumen]]
- [[#Terminologie|Terminologie]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Warum ist Entropie wichtig?|Warum ist Entropie wichtig?]]
- [[#Quellen|Quellen]]
- [[#Prognose|Prognose]]
- [[#Diskrete Zufallsvariable|Diskrete Zufallsvariable]]
	- [[#Diskrete Zufallsvariable#Beispiel|Beispiel]]
- [[#Stetige Zufallsvariable|Stetige Zufallsvariable]]
- [[#Zusammenfassung|Zusammenfassung]]
- [[#Einordnung|Einordnung]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Extraktion|Extraktion]]
- [[#Transformation|Transformation]]
- [[#Load|Load]]
- [[#Quellen|Quellen]]
- [[#Allgemeine Formel|Allgemeine Formel]]
- [[#Algorithmus|Algorithmus]]
- [[#Beispiel|Beispiel]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Grundbegriffe|Grundbegriffe]]
- [[#Grundalgorithmus|Grundalgorithmus]]
	- [[#Grundalgorithmus#Darstellungsform 1|Darstellungsform 1]]
	- [[#Grundalgorithmus#Darstellungsform 2|Darstellungsform 2]]
- [[#Genetische Operatoren|Genetische Operatoren]]
	- [[#Genetische Operatoren#Mutationen|Mutationen]]
	- [[#Genetische Operatoren#Rekombination|Rekombination]]
	- [[#Genetische Operatoren#Selektion|Selektion]]
		- [[#Selektion#Inselmodell *(häufig bevorzugt)*|Inselmodell *(häufig bevorzugt)*]]
		- [[#Selektion#Einfache Menge|Einfache Menge]]
		- [[#Selektion#Nachbarschaft|Nachbarschaft]]
		- [[#Selektion#Fitness Based Selection|Fitness Based Selection]]
		- [[#Selektion#Ranking Based Selection|Ranking Based Selection]]
		- [[#Selektion#Tournament Selection|Tournament Selection]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Ablauf|Ablauf]]
- [[#Teilnehmer|Teilnehmer]]
- [[#Arten|Arten]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Nutzen für Unternehmen|Nutzen für Unternehmen]]
	- [[#Nutzen für Unternehmen#1. Früherkennung von Fehlern|1. Früherkennung von Fehlern]]
	- [[#Nutzen für Unternehmen#2. Risikominimierung|2. Risikominimierung]]
	- [[#Nutzen für Unternehmen#3. Verbesserung der Produkt- und Prozessqualität|3. Verbesserung der Produkt- und Prozessqualität]]
	- [[#Nutzen für Unternehmen#4. Kosteneinsparungen|4. Kosteneinsparungen]]
	- [[#Nutzen für Unternehmen#5. Erhöhung der Kundenzufriedenheit|5. Erhöhung der Kundenzufriedenheit]]
	- [[#Nutzen für Unternehmen#6. Förderung der Teamarbeit und Kommunikation|6. Förderung der Teamarbeit und Kommunikation]]
	- [[#Nutzen für Unternehmen#7. Dokumentation und Nachverfolgbarkeit|7. Dokumentation und Nachverfolgbarkeit]]
	- [[#Nutzen für Unternehmen#8. Compliance und Normen|8. Compliance und Normen]]
- [[#Quellen|Quellen]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Funktionale Anforderungen|Funktionale Anforderungen]]
- [[#Nicht-funktionale Anforderungen (NFAs)|Nicht-funktionale Anforderungen (NFAs)]]
- [[#Wichtige Punkte|Wichtige Punkte]]
- [[#Best Practices für NFAs|Best Practices für NFAs]]
- [[#Formel|Formel]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Wichtige Geräteklassen|Wichtige Geräteklassen]]
	- [[#Wichtige Geräteklassen#Embedded Systems|Embedded Systems]]
	- [[#Wichtige Geräteklassen#Mobile Geräte|Mobile Geräte]]
	- [[#Wichtige Geräteklassen#Desktop-Computer|Desktop-Computer]]
	- [[#Wichtige Geräteklassen#Server|Server]]
	- [[#Wichtige Geräteklassen#IoT-Geräte (Internet of Things)|IoT-Geräte (Internet of Things)]]
	- [[#Wichtige Geräteklassen#Wearables|Wearables]]
- [[#Anwendungsbereiche von Geräteklassen|Anwendungsbereiche von Geräteklassen]]
- [[#Herausforderungen bei Geräteklassen|Herausforderungen bei Geräteklassen]]
	- [[#Herausforderungen bei Geräteklassen#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Bewertung von Risiken bei Änderungen an Geschäftsprozessen|Bewertung von Risiken bei Änderungen an Geschäftsprozessen]]
- [[#Quellen|Quellen]]
- [[#Einführung in das UWG|Einführung in das UWG]]
- [[#Relevante Aspekte für die Fachinformatik|Relevante Aspekte für die Fachinformatik]]
- [[#Verbotene Handlungen|Verbotene Handlungen]]
- [[#Rechtsfolgen|Rechtsfolgen]]
- [[#Praktische Anwendung in der Fachinformatik|Praktische Anwendung in der Fachinformatik]]
- [[#Quellen|Quellen]]
- [[#Grundlagen von Groupware|Grundlagen von Groupware]]
- [[#Wichtige Funktionen|Wichtige Funktionen]]
- [[#Beispiele für Groupware|Beispiele für Groupware]]
- [[#Vorteile von Groupware|Vorteile von Groupware]]
- [[#Sicherheit|Sicherheit]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Arten von Redundanzen|Arten von Redundanzen]]
	- [[#Arten von Redundanzen#Failover|Failover]]
	- [[#Arten von Redundanzen#Switchover|Switchover]]
	- [[#Arten von Redundanzen#N+1 Redundanz|N+1 Redundanz]]
	- [[#Arten von Redundanzen#N+2, N+M Redundanz|N+2, N+M Redundanz]]
	- [[#Arten von Redundanzen#[[RAID]]|[[RAID]]]]
	- [[#Arten von Redundanzen#Cluster-Redundanz|Cluster-Redundanz]]
- [[#Netzwerk-Redundanzen|Netzwerk-Redundanzen]]
	- [[#Netzwerk-Redundanzen#Link Aggregation (LACP)|Link Aggregation (LACP)]]
	- [[#Netzwerk-Redundanzen#Spanning Tree Protocol (STP)|Spanning Tree Protocol (STP)]]
	- [[#Netzwerk-Redundanzen#Hot Standby Router Protocol (HSRP) / Virtual Router Redundancy Protocol (VRRP)|Hot Standby Router Protocol (HSRP) / Virtual Router Redundancy Protocol (VRRP)]]
	- [[#Netzwerk-Redundanzen#Multipathing|Multipathing]]
	- [[#Netzwerk-Redundanzen#Dual-Homed|Dual-Homed]]
- [[#Vorteile von Hardware- und Netzwerk-Redundanzen|Vorteile von Hardware- und Netzwerk-Redundanzen]]
- [[#Best Practices für Redundanzen|Best Practices für Redundanzen]]
- [[#Quellen|Quellen]]
- [[#Zugangskontrolle|Zugangskontrolle]]
- [[#Videoüberwachung|Videoüberwachung]]
- [[#Physische Barrieren|Physische Barrieren]]
- [[#Alarmanlagen|Alarmanlagen]]
- [[#Sicherheitsbewusstsein und Schulung|Sicherheitsbewusstsein und Schulung]]
- [[#Physische Sicherheit von Hardware|Physische Sicherheit von Hardware]]
- [[#Notfallpläne|Notfallpläne]]
- [[#Quellen|Quellen]]
- [[#Arten von Hardwaretests|Arten von Hardwaretests]]
- [[#Wichtige Prüfmethoden|Wichtige Prüfmethoden]]
- [[#Dokumentation und Nachverfolgbarkeit|Dokumentation und Nachverfolgbarkeit]]
- [[#Bedeutung von Hardwaretests|Bedeutung von Hardwaretests]]
- [[#[[Hashing]]|[[Hashing]]]]
	- [[#[[Hashing]]#Auswahl des Hashing-Verfahrens|Auswahl des Hashing-Verfahrens]]
- [[#Verschlüsselungsverfahren|Verschlüsselungsverfahren]]
	- [[#Verschlüsselungsverfahren#Auswahl des Verschlüsselungsverfahrens|Auswahl des Verschlüsselungsverfahrens]]
- [[#Zusammenfassung der Auswahl|Zusammenfassung der Auswahl]]
- [[#Quellen|Quellen]]
- [[#Charakteristische Eigenschaften|Charakteristische Eigenschaften]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Digitale Signaturen und Prüfsummen|Digitale Signaturen und Prüfsummen]]
- [[#Vorteile|Vorteile]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Algorithmus|Algorithmus]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Wichtige Komponenten|Wichtige Komponenten]]
- [[#Tools und Techniken|Tools und Techniken]]
	- [[#Tools und Techniken#Authentifizierungstools|Authentifizierungstools]]
	- [[#Tools und Techniken#Zugriffsmanagement|Zugriffsmanagement]]
	- [[#Tools und Techniken#Sicherheitsüberprüfung|Sicherheitsüberprüfung]]
- [[#Best Practices|Best Practices]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
	- [[#Vor- und Nachteile#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Ziele des Incident Managements|Ziele des Incident Managements]]
- [[#Komponenten eines Ticketsystems|Komponenten eines Ticketsystems]]
- [[#Prozess des Incident Managements|Prozess des Incident Managements]]
- [[#Vorteile eines Ticketsystems|Vorteile eines Ticketsystems]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Technologien und Konzepte|Technologien und Konzepte]]
- [[#Quellen|Quellen]]
- [[#1. Grundformel für Information|1. Grundformel für Information]]
- [[#2. Wichtige Eigenschaften|2. Wichtige Eigenschaften]]
- [[#3. Interpretation der Bits|3. Interpretation der Bits]]
- [[#4. Beispiele|4. Beispiele]]
- [[#5. Anwendungen|5. Anwendungen]]
- [[#6. Merksätze|6. Merksätze]]
- [[#Begriffsdefinitionen|Begriffsdefinitionen]]
- [[#Ziele der Modularisierung|Ziele der Modularisierung]]
- [[#Methoden der Modularisierung|Methoden der Modularisierung]]
- [[#Integrationstechniken|Integrationstechniken]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Vorteile der Integration|Vorteile der Integration]]
- [[#Nachteile der Integration|Nachteile der Integration]]
- [[#Vorteile der Modularisierung|Vorteile der Modularisierung]]
- [[#Nachteile der Modularisierung|Nachteile der Modularisierung]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Architektur von IoT-Systemen|Architektur von IoT-Systemen]]
- [[#Komponenten eines IoT-Systems|Komponenten eines IoT-Systems]]
- [[#Anwendungsbereiche von IoT|Anwendungsbereiche von IoT]]
- [[#IoT-Protokolle|IoT-Protokolle]]
- [[#Herausforderungen und Risiken von IoT|Herausforderungen und Risiken von IoT]]
- [[#Schritte zur Entwicklung eines IoT-Systems|Schritte zur Entwicklung eines IoT-Systems]]
- [[#Edge Computing vs. Cloud Computing in IoT|Edge Computing vs. Cloud Computing in IoT]]
- [[#Relevante Begriffe|Relevante Begriffe]]
- [[#Quellen|Quellen]]
- [[#Adressierung|Adressierung]]
	- [[#Adressierung#IPv4|IPv4]]
	- [[#Adressierung#IPv6|IPv6]]
	- [[#Adressierung#Subnetzmaske|Subnetzmaske]]
	- [[#Adressierung#Adressraum|Adressraum]]
	- [[#Adressierung#Adresstypen|Adresstypen]]
	- [[#Adressierung#Klassen|Klassen]]
- [[#Quellen|Quellen]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Protokolle|Protokolle]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Aktoren|Aktoren]]
- [[#Funktionswiese|Funktionswiese]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
- [[#Quellen|Quellen]]
- [[#Bereiche|Bereiche]]
	- [[#Bereiche#1. Menschen|1. Menschen]]
	- [[#Bereiche#2. Maschinen|2. Maschinen]]
	- [[#Bereiche#3. Material|3. Material]]
	- [[#Bereiche#4. Methoden|4. Methoden]]
	- [[#Bereiche#5. Mitwelt / Milieu|5. Mitwelt / Milieu]]
	- [[#Bereiche#6. Messung|6. Messung]]
	- [[#Bereiche#7. Management|7. Management]]
- [[#Auswertung|Auswertung]]
- [[#Ziele des Ishikawa-Diagramms|Ziele des Ishikawa-Diagramms]]
- [[#Quellen|Quellen]]
- [[#Methoden zur Datensammlung|Methoden zur Datensammlung]]
	- [[#Methoden zur Datensammlung#Stakeholder|Stakeholder]]
	- [[#Methoden zur Datensammlung#Analysemethoden|Analysemethoden]]
- [[#Checkliste möglicher Schwachstellen|Checkliste möglicher Schwachstellen]]
- [[#Quellen|Quellen]]
- [[#Komponenten|Komponenten]]
- [[#Prozess des ITSM|Prozess des ITSM]]
- [[#Vorgehensweisen|Vorgehensweisen]]
- [[#Vorteile|Vorteile]]
- [[#[[Kontinuierlicher Verbesserungsprozess]]|[[Kontinuierlicher Verbesserungsprozess]]]]
- [[#Zentrale Prinzipien|Zentrale Prinzipien]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Fazit|Fazit]]
- [[#Teilgebiete der KI|Teilgebiete der KI]]
- [[#[[Neural Network|Künstliche neuronale Netze (KNN)  ]]|[[Neural Network|Künstliche neuronale Netze (KNN)  ]]]]
- [[#[[Support Vector Machine|Support Vector Machines (SVM)  ]]|[[Support Vector Machine|Support Vector Machines (SVM)  ]]]]
- [[#Anwendungsgebiete der KI|Anwendungsgebiete der KI]]
- [[#Schritte zur Entwicklung eines KI-Modells|Schritte zur Entwicklung eines KI-Modells]]
- [[#Ethik und Herausforderungen der KI|Ethik und Herausforderungen der KI]]
- [[#Relevante Begriffe|Relevante Begriffe]]
- [[#Quellen|Quellen]]
- [[#Zweck|Zweck]]
- [[#Arten der Klassifikation|Arten der Klassifikation]]
- [[#Wichtige Algorithmen|Wichtige Algorithmen]]
- [[#Vorgehen|Vorgehen]]
- [[#Evaluationsmetriken|Evaluationsmetriken]]
	- [[#Evaluationsmetriken#Fachbuch|Fachbuch]]
	- [[#Evaluationsmetriken#IHK|IHK]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
- [[#Funktionsweise|Funktionsweise]]
	- [[#Funktionsweise#Klassifikationsprozess|Klassifikationsprozess]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Abstandsmetriken|Abstandsmetriken]]
- [[#Variabilität und Verzerrung|Variabilität und Verzerrung]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Kostenarten im Detail|Kostenarten im Detail]]
	- [[#Kostenarten im Detail#Softwarekosten|Softwarekosten]]
	- [[#Kostenarten im Detail#Hardwarekosten|Hardwarekosten]]
	- [[#Kostenarten im Detail#Personalkosten|Personalkosten]]
	- [[#Kostenarten im Detail#Kommunikationskosten|Kommunikationskosten]]
	- [[#Kostenarten im Detail#Qualifizierungskosten|Qualifizierungskosten]]
- [[#Ziel|Ziel]]
- [[#Schritte der Kosten-Nutzen-Analyse|Schritte der Kosten-Nutzen-Analyse]]
	- [[#Schritte der Kosten-Nutzen-Analyse#1. Problemdefinition|1. Problemdefinition]]
	- [[#Schritte der Kosten-Nutzen-Analyse#2. Identifikation von Kosten und Nutzen|2. Identifikation von Kosten und Nutzen]]
	- [[#Schritte der Kosten-Nutzen-Analyse#3. Quantifizierung|3. Quantifizierung]]
	- [[#Schritte der Kosten-Nutzen-Analyse#4. Diskontierung|4. Diskontierung]]
	- [[#Schritte der Kosten-Nutzen-Analyse#5. Vergleich|5. Vergleich]]
- [[#Entscheidungsfindung|Entscheidungsfindung]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Nicht-monetäre Nutzenfaktoren|Nicht-monetäre Nutzenfaktoren]]
- [[#Beispiel zur Anwendung|Beispiel zur Anwendung]]
	- [[#Beispiel zur Anwendung#Weiterbildung von Mitarbeitern|Weiterbildung von Mitarbeitern]]
- [[#Checkliste für die KNA|Checkliste für die KNA]]
- [[#Fazit|Fazit]]
- [[#Wichtige Aspekte von KPIs in der Qualitätslenkung|Wichtige Aspekte von KPIs in der Qualitätslenkung]]
- [[#Beispiele für KPIs in der Qualitätslenkung|Beispiele für KPIs in der Qualitätslenkung]]
- [[#Vorteile der Verwendung von KPIs in der Qualitätslenkung|Vorteile der Verwendung von KPIs in der Qualitätslenkung]]
- [[#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Wichtige Lagemaße|Wichtige Lagemaße]]
- [[#Bedeutung der Lagemaße|Bedeutung der Lagemaße]]
- [[#Anwendung|Anwendung]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Leitlinien|Leitlinien]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Bedeutung des lebenslangen Lernens|Bedeutung des lebenslangen Lernens]]
	- [[#Quellen#Formen des lebenslangen Lernens|Formen des lebenslangen Lernens]]
	- [[#Quellen#Methoden und Ansätze|Methoden und Ansätze]]
	- [[#Quellen#Herausforderungen des lebenslangen Lernens|Herausforderungen des lebenslangen Lernens]]
	- [[#Quellen#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Kernmerkmale|Kernmerkmale]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Beispiel|Beispiel]]
		- [[#Wichtige Begriffe#Funktion:|Funktion:]]
		- [[#Wichtige Begriffe#Parameter:|Parameter:]]
		- [[#Wichtige Begriffe#Zusammenfassung:|Zusammenfassung:]]
- [[#Funktionsweise|Funktionsweise]]
	- [[#Funktionsweise#statische Algorithmen|statische Algorithmen]]
	- [[#Funktionsweise#dynamische Algorithmen|dynamische Algorithmen]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Aspekte|Aspekte]]
	- [[#Aspekte#Wirtschaftliche Aspekte|Wirtschaftliche Aspekte]]
	- [[#Aspekte#Technische Aspekte|Technische Aspekte]]
	- [[#Aspekte#Rechtliche Aspekte|Rechtliche Aspekte]]
- [[#Durchführung|Durchführung]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Grundlagen von Mailservern|Grundlagen von Mailservern]]
- [[#Wichtige Protokolle|Wichtige Protokolle]]
- [[#Komponenten eines Mailservers|Komponenten eines Mailservers]]
- [[#Sicherheit|Sicherheit]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Schritte|Schritte]]
- [[#Arten des maschinellen Lernens|Arten des maschinellen Lernens]]
- [[#Algorithmen des maschinellen Lernens|Algorithmen des maschinellen Lernens]]
- [[#Anwendungen des maschinellen Lernens|Anwendungen des maschinellen Lernens]]
- [[#Vorteile des maschinellen Lernens|Vorteile des maschinellen Lernens]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Quelle|Quelle]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Formel|Formel]]
- [[#Vorteile|Vorteile]]
- [[#Quellen|Quellen]]
- [[#Mitbestimmungsrechte des Betriebsrats|Mitbestimmungsrechte des Betriebsrats]]
- [[#Rechte des Betriebsrats im Einzelnen|Rechte des Betriebsrats im Einzelnen]]
	- [[#Rechte des Betriebsrats im Einzelnen#Informationsrechte|Informationsrechte]]
	- [[#Rechte des Betriebsrats im Einzelnen#Mitwirkungsrechte (Beratungsrechte)|Mitwirkungsrechte (Beratungsrechte)]]
	- [[#Rechte des Betriebsrats im Einzelnen#Mitbestimmungsrechte (Zustimmungsrechte)|Mitbestimmungsrechte (Zustimmungsrechte)]]
	- [[#Rechte des Betriebsrats im Einzelnen#Wirtschaftliche Mitbestimmung|Wirtschaftliche Mitbestimmung]]
- [[#Besondere Mitbestimmungsrechte|Besondere Mitbestimmungsrechte]]
	- [[#Besondere Mitbestimmungsrechte#Soziale Angelegenheiten (§ 87 BetrVG)|Soziale Angelegenheiten (§ 87 BetrVG)]]
	- [[#Besondere Mitbestimmungsrechte#Personelle Angelegenheiten|Personelle Angelegenheiten]]
	- [[#Besondere Mitbestimmungsrechte#Gesundheitsschutz (§ 89 BetrVG)|Gesundheitsschutz (§ 89 BetrVG)]]
- [[#Vor- und Nachteile der Mitbestimmung|Vor- und Nachteile der Mitbestimmung]]
	- [[#Vor- und Nachteile der Mitbestimmung#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile der Mitbestimmung#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#MTBF|MTBF]]
- [[#MTTR|MTTR]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Wichtige Kennzahlen|Wichtige Kennzahlen]]
- [[#Methoden der Netzwerkanalyse|Methoden der Netzwerkanalyse]]
- [[#Werkzeuge zur Netzwerkanalyse|Werkzeuge zur Netzwerkanalyse]]
- [[#Best Practices|Best Practices]]
- [[#Netzwerktypen|Netzwerktypen]]
	- [[#Netzwerktypen#PAN|PAN]]
	- [[#Netzwerktypen#LAN|LAN]]
		- [[#LAN#WLAN|WLAN]]
		- [[#LAN#VLAN|VLAN]]
	- [[#Netzwerktypen#MAN|MAN]]
	- [[#Netzwerktypen#WAN|WAN]]
	- [[#Netzwerktypen#GAN|GAN]]
- [[#Sicherheitskonzepte und -risiken|Sicherheitskonzepte und -risiken]]
	- [[#Sicherheitskonzepte und -risiken#Verschlüsselungstechnologien|Verschlüsselungstechnologien]]
	- [[#Sicherheitskonzepte und -risiken#Sicherheitsrisiken|Sicherheitsrisiken]]
	- [[#Sicherheitskonzepte und -risiken#Sicherheitsmaßnahmen|Sicherheitsmaßnahmen]]
- [[#Netzwerktopologien|Netzwerktopologien]]
	- [[#Netzwerktopologien#Bustopologie|Bustopologie]]
	- [[#Netzwerktopologien#Sterntopologie|Sterntopologie]]
	- [[#Netzwerktopologien#Ringtopologie|Ringtopologie]]
	- [[#Netzwerktopologien#Vermaschte Topologie (Mesh)|Vermaschte Topologie (Mesh)]]
	- [[#Netzwerktopologien#Baumtopologie|Baumtopologie]]
- [[#Quellen|Quellen]]
- [[#Wichtige Elemente eines Netzwerkplans|Wichtige Elemente eines Netzwerkplans]]
- [[#Point-to-Point|Point-to-Point]]
- [[#Point-to-Multipoint|Point-to-Multipoint]]
- [[#Line / Chain / Linien-Topologie|Line / Chain / Linien-Topologie]]
- [[#Bus-Topologie|Bus-Topologie]]
- [[#Ring-Topologie|Ring-Topologie]]
- [[#Stern-Topologie|Stern-Topologie]]
- [[#Baum-Topologie|Baum-Topologie]]
- [[#Mesh / Maschen-Topologie|Mesh / Maschen-Topologie]]
- [[#Aufbau eines Neuronalen Netzes|Aufbau eines Neuronalen Netzes]]
	- [[#Aufbau eines Neuronalen Netzes#Struktur|Struktur]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Wichtige Konzepte|Wichtige Konzepte]]
	- [[#Wichtige Konzepte#Aktivierungsfunktionen|Aktivierungsfunktionen]]
- [[#Regularisierungstechniken|Regularisierungstechniken]]
- [[#Lernprozess|Lernprozess]]
	- [[#Lernprozess#Optimierungsalgorithmen|Optimierungsalgorithmen]]
	- [[#Lernprozess#Lernratenanpassung|Lernratenanpassung]]
		- [[#Lernratenanpassung#Adaptive Lernraten|Adaptive Lernraten]]
- [[#Beispielberechnung|Beispielberechnung]]
- [[#Architekturen|Architekturen]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Vor- und Nachteile|Vor- und Nachteile]]
	- [[#Vor- und Nachteile#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile#Nachteile|Nachteile]]
- [[#Vorteile von NFS|Vorteile von NFS]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Normalformen|Normalformen]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Charakteristika|Charakteristika]]
- [[#NoSQL-Datenbanktypen|NoSQL-Datenbanktypen]]
	- [[#NoSQL-Datenbanktypen#1. Dokumentenorientierte Datenbanken|1. Dokumentenorientierte Datenbanken]]
	- [[#NoSQL-Datenbanktypen#2. Spaltenorientierte Datenbanken|2. Spaltenorientierte Datenbanken]]
	- [[#NoSQL-Datenbanktypen#3. Key-Value Stores|3. Key-Value Stores]]
	- [[#NoSQL-Datenbanktypen#4. Graphdatenbanken|4. Graphdatenbanken]]
- [[#CAP-Theorem|CAP-Theorem]]
- [[#Vergleich zu relationalen Datenbanken|Vergleich zu relationalen Datenbanken]]
- [[#Vor- und Nachteile von NoSQL-Datenbanken|Vor- und Nachteile von NoSQL-Datenbanken]]
	- [[#Vor- und Nachteile von NoSQL-Datenbanken#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile von NoSQL-Datenbanken#Nachteile|Nachteile]]
- [[#Anwendungsfälle|Anwendungsfälle]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Praxisrelevante Konzepte|Praxisrelevante Konzepte]]
	- [[#Praxisrelevante Konzepte#Map/Reduce|Map/Reduce]]
	- [[#Praxisrelevante Konzepte#Sharding|Sharding]]
	- [[#Praxisrelevante Konzepte#Replikation|Replikation]]
- [[#Vorteile relationaler Datenbanken|Vorteile relationaler Datenbanken]]
- [[#Vorteile NoSQL-Datenbanken|Vorteile NoSQL-Datenbanken]]
- [[#Schritte|Schritte]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Beispiele|Beispiele]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Schichten|Schichten]]
	- [[#Schichten#Merksätze|Merksätze]]
- [[#Quellen|Quellen]]
- [[#Grundlagen des Patentrechts|Grundlagen des Patentrechts]]
- [[#Voraussetzungen für die Patentierbarkeit|Voraussetzungen für die Patentierbarkeit]]
- [[#Patentarten|Patentarten]]
- [[#Antragsverfahren|Antragsverfahren]]
- [[#Rechte des Patentinhabers|Rechte des Patentinhabers]]
- [[#Dauer des Patents|Dauer des Patents]]
- [[#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Relevanz für Fachinformatiker|Relevanz für Fachinformatiker]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Schritte|Schritte]]
- [[#PDSA|PDSA]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Arten von Penetration Tests|Arten von Penetration Tests]]
- [[#Phasen eines Penetration Tests|Phasen eines Penetration Tests]]
- [[#Tools für Penetration Testing|Tools für Penetration Testing]]
- [[#Best Practices für Penetration Testing|Best Practices für Penetration Testing]]
- [[#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Arten von Phishing|Arten von Phishing]]
- [[#Methoden|Methoden]]
- [[#Vorbeugung|Vorbeugung]]
- [[#Auswirkungen|Auswirkungen]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Zweck|Zweck]]
- [[#Arten von Plausibilitätskontrollen|Arten von Plausibilitätskontrollen]]
- [[#Implementierung|Implementierung]]
- [[#Vorteile|Vorteile]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices|Best Practices]]
- [[#Erstellung eines Polaritätsprofils|Erstellung eines Polaritätsprofils]]
- [[#Arten der Skalen|Arten der Skalen]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Boston Matrix|Boston Matrix]]
- [[#Schritte|Schritte]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Grundlagen von PowerShell|Grundlagen von PowerShell]]
- [[#Wichtige Befehle|Wichtige Befehle]]
- [[#Variablen|Variablen]]
- [[#Kontrollstrukturen|Kontrollstrukturen]]
- [[#Funktionen|Funktionen]]
- [[#Skripterstellung|Skripterstellung]]
- [[#Nützliche Tipps|Nützliche Tipps]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Netzwerksegmentierung|Netzwerksegmentierung]]
- [[#Firewall-Konfiguration|Firewall-Konfiguration]]
- [[#Intrusion Detection/Prevention Systeme (IDS/IPS)|Intrusion Detection/Prevention Systeme (IDS/IPS)]]
- [[#Systemhärtung|Systemhärtung]]
	- [[#Systemhärtung#Deaktivierung unnötiger Dienste und Ports|Deaktivierung unnötiger Dienste und Ports]]
	- [[#Systemhärtung#Sichere Konfiguration von Betriebssystemen|Sichere Konfiguration von Betriebssystemen]]
	- [[#Systemhärtung#Application Whitelisting|Application Whitelisting]]
- [[#Zugriffskontrolle|Zugriffskontrolle]]
	- [[#Zugriffskontrolle#Starke Authentifizierung|Starke Authentifizierung]]
	- [[#Zugriffskontrolle#Privileged Access Management (PAM)|Privileged Access Management (PAM)]]
	- [[#Zugriffskontrolle#Rollenbasierte Zugriffskontrolle (RBAC)|Rollenbasierte Zugriffskontrolle (RBAC)]]
- [[#Datensicherheit|Datensicherheit]]
	- [[#Datensicherheit#Datenverschlüsselung|Datenverschlüsselung]]
	- [[#Datensicherheit#Regelmäßige Backups|Regelmäßige Backups]]
	- [[#Datensicherheit#Data Loss Prevention (DLP)|Data Loss Prevention (DLP)]]
- [[#Schulung und Sensibilisierung|Schulung und Sensibilisierung]]
	- [[#Schulung und Sensibilisierung#Mitarbeiterschulungen|Mitarbeiterschulungen]]
	- [[#Schulung und Sensibilisierung#Sicherheitsrichtlinien|Sicherheitsrichtlinien]]
- [[#Schwachstellenmanagement|Schwachstellenmanagement]]
	- [[#Schwachstellenmanagement#Regelmäßige Sicherheitsaudits|Regelmäßige Sicherheitsaudits]]
	- [[#Schwachstellenmanagement#Patch-Management|Patch-Management]]
- [[#Netzwerküberwachung|Netzwerküberwachung]]
	- [[#Netzwerküberwachung#Security Information and Event Management (SIEM)|Security Information and Event Management (SIEM)]]
	- [[#Netzwerküberwachung#Netzwerk-Monitoring|Netzwerk-Monitoring]]
- [[#Definition|Definition]]
- [[#Wichtige Konzepte|Wichtige Konzepte]]
- [[#Vorteile|Vorteile]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Technologien|Technologien]]
- [[#Quellen|Quellen]]
- [[#7 Prinzipien|7 Prinzipien]]
- [[#7 Themen|7 Themen]]
- [[#7 Prozesse|7 Prozesse]]
- [[#Stärken|Stärken]]
- [[#Schwächen|Schwächen]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Performance und Speicherverbrauch|Performance und Speicherverbrauch]]
- [[#Portabilität|Portabilität]]
- [[#Frameworks/Bibliotheken|Frameworks/Bibliotheken]]
- [[#Einsatz von integrierten Entwicklungsumgebungen (IDEs)|Einsatz von integrierten Entwicklungsumgebungen (IDEs)]]
- [[#Aufwand|Aufwand]]
- [[#Know-how/Fachkenntnis|Know-how/Fachkenntnis]]
- [[#Definition eines Projekts|Definition eines Projekts]]
- [[#Projektphasen|Projektphasen]]
- [[#Sachebene vs. Beziehungsebene|Sachebene vs. Beziehungsebene]]
	- [[#Sachebene vs. Beziehungsebene#Sachebene|Sachebene]]
	- [[#Sachebene vs. Beziehungsebene#Beziehungsebene|Beziehungsebene]]
- [[#Befugnisse des Projektleiters|Befugnisse des Projektleiters]]
- [[#Projektmanagement|Projektmanagement]]
- [[#Werkzeuge und Methoden|Werkzeuge und Methoden]]
- [[#Ressourcenmanagement|Ressourcenmanagement]]
- [[#Kommunikation im Projekt|Kommunikation im Projekt]]
- [[#Risiken im Projekt|Risiken im Projekt]]
- [[#Erfolgskriterien|Erfolgskriterien]]
- [[#Arten von Proxy-Technologien|Arten von Proxy-Technologien]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Quantitative Bewertungsmethoden|Quantitative Bewertungsmethoden]]
	- [[#Quantitative Bewertungsmethoden#Kennzahlen und Metriken|Kennzahlen und Metriken]]
	- [[#Quantitative Bewertungsmethoden#Statistische Verfahren|Statistische Verfahren]]
- [[#Qualitative Bewertungsmethoden|Qualitative Bewertungsmethoden]]
	- [[#Qualitative Bewertungsmethoden#Beschreibende Techniken|Beschreibende Techniken]]
	- [[#Qualitative Bewertungsmethoden#Bewertende Techniken|Bewertende Techniken]]
- [[#Kombinierte Ansätze|Kombinierte Ansätze]]
	- [[#Kombinierte Ansätze#Nutzwertanalyse|Nutzwertanalyse]]
	- [[#Kombinierte Ansätze#Prozess-Benchmarking|Prozess-Benchmarking]]
- [[#Anwendung in der Praxis|Anwendung in der Praxis]]
- [[#Bedeutung von Prozessindikatoren|Bedeutung von Prozessindikatoren]]
- [[#Arten von Prozessindikatoren|Arten von Prozessindikatoren]]
- [[#Merkmale guter Prozessindikatoren|Merkmale guter Prozessindikatoren]]
- [[#Beispiele für spezifische Prozessindikatoren|Beispiele für spezifische Prozessindikatoren]]
- [[#Anwendung von Prozessindikatoren|Anwendung von Prozessindikatoren]]
- [[#Gliederung|Gliederung]]
- [[#Quellen|Quellen]]
- [[#Arten|Arten]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices|Best Practices]]
- [[#Analyse von Prozessschnittstellen|Analyse von Prozessschnittstellen]]
- [[#Werkzeuge für Schnittstellenmanagement|Werkzeuge für Schnittstellenmanagement]]
- [[#Parität|Parität]]
	- [[#Parität#Anwendung von Parität|Anwendung von Parität]]
	- [[#Parität#Vorgehensweise|Vorgehensweise]]
	- [[#Parität#Vorteile der Parität|Vorteile der Parität]]
	- [[#Parität#Beispiele für Parität|Beispiele für Parität]]
	- [[#Parität#Herausforderungen|Herausforderungen]]
- [[#Redundanz|Redundanz]]
	- [[#Redundanz#Anwendung von Redundanz|Anwendung von Redundanz]]
	- [[#Redundanz#Vorgehensweise|Vorgehensweise]]
	- [[#Redundanz#Vorteile der Redundanz|Vorteile der Redundanz]]
	- [[#Redundanz#Beispiele für Redundanz|Beispiele für Redundanz]]
	- [[#Redundanz#Herausforderungen|Herausforderungen]]
- [[#Grundlagen von Pseudocode|Grundlagen von Pseudocode]]
- [[#Wichtige Merkmale|Wichtige Merkmale]]
- [[#Grundlegende Strukturen|Grundlegende Strukturen]]
- [[#Beispiel eines Pseudocodes|Beispiel eines Pseudocodes]]
- [[#Vorteile von Pseudocode|Vorteile von Pseudocode]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Merkmale von Python|Merkmale von Python]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Grundlegende Syntax|Grundlegende Syntax]]
- [[#Vorteile von Python|Vorteile von Python]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Formel|Formel]]
	- [[#Quellen#Anwendung|Anwendung]]
	- [[#Quellen#Eigenschaften|Eigenschaften]]
	- [[#Quellen#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Qualitätskontrolle von Daten|Qualitätskontrolle von Daten]]
	- [[#Qualitätskontrolle von Daten#Hauptmerkmale|Hauptmerkmale]]
	- [[#Qualitätskontrolle von Daten#Inhalte der Qualitätskontrolle|Inhalte der Qualitätskontrolle]]
	- [[#Qualitätskontrolle von Daten#Methoden|Methoden]]
	- [[#Qualitätskontrolle von Daten#Maßnahmen|Maßnahmen]]
- [[#Qualitätssicherung von Daten|Qualitätssicherung von Daten]]
	- [[#Qualitätssicherung von Daten#Hauptmerkmale|Hauptmerkmale]]
	- [[#Qualitätssicherung von Daten#Aufgaben der Qualitätssicherung|Aufgaben der Qualitätssicherung]]
		- [[#Aufgaben der Qualitätssicherung#Organisatorisch|Organisatorisch]]
		- [[#Aufgaben der Qualitätssicherung#Technisch|Technisch]]
		- [[#Aufgaben der Qualitätssicherung#Methoden|Methoden]]
- [[#Unterschiede|Unterschiede]]
- [[#Wirtschaftliche Aspekte bei der Auswahl von Datenqualitätsmaßnahmen|Wirtschaftliche Aspekte bei der Auswahl von Datenqualitätsmaßnahmen]]
- [[#RAID 0|RAID 0]]
- [[#RAID 1|RAID 1]]
- [[#RAID 5|RAID 5]]
- [[#RAID und Redundanzkonzepte|RAID und Redundanzkonzepte]]
	- [[#RAID und Redundanzkonzepte#Hot-Spare|Hot-Spare]]
	- [[#RAID und Redundanzkonzepte#Cold-Standby|Cold-Standby]]
- [[#Quellen|Quellen]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Vorteile|Vorteile]]
- [[#Wichtige Hyperparameter|Wichtige Hyperparameter]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Feature Importance|Feature Importance]]
- [[#Arten von Ransomware|Arten von Ransomware]]
- [[#Verbreitungswege|Verbreitungswege]]
- [[#Auswirkungen|Auswirkungen]]
- [[#Vorbeugung|Vorbeugung]]
- [[#Reaktion auf einen Ransomware-Angriff|Reaktion auf einen Ransomware-Angriff]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte redundanter Systeme|Wichtige Aspekte redundanter Systeme]]
- [[#Arten von Redundanz|Arten von Redundanz]]
- [[#Implementierung redundanter Systeme|Implementierung redundanter Systeme]]
- [[#Vorteile redundanter Systeme|Vorteile redundanter Systeme]]
- [[#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Bedeutung|Bedeutung]]
- [[#Bereiche der Regelkonformität|Bereiche der Regelkonformität]]
- [[#Faktoren, die Regelkonformität beeinflussen|Faktoren, die Regelkonformität beeinflussen]]
- [[#Maßnahmen zur Förderung der Regelkonformität|Maßnahmen zur Förderung der Regelkonformität]]
- [[#Quellen|Quellen]]
- [[#Formen|Formen]]
	- [[#Formen#**Einfache lineare** / **Univariate** Regression|**Einfache lineare** / **Univariate** Regression]]
	- [[#Formen#**Multiple lineare** / **Multivariate** Regression|**Multiple lineare** / **Multivariate** Regression]]
	- [[#Formen#**Logistische** Regression|**Logistische** Regression]]
- [[#Kostenfunktion|Kostenfunktion]]
	- [[#Kostenfunktion#Univariate Regression|Univariate Regression]]
	- [[#Kostenfunktion#Multivariate Regression|Multivariate Regression]]
- [[#Berechnung|Berechnung]]
	- [[#Berechnung#Nullstellen der Kostenfunktionsableitung|Nullstellen der Kostenfunktionsableitung]]
	- [[#Berechnung#Gradientabstiegsverfahren|Gradientabstiegsverfahren]]
		- [[#Gradientabstiegsverfahren#Ableitungen der Kostenfunktion|Ableitungen der Kostenfunktion]]
		- [[#Gradientabstiegsverfahren#Update-Regeln für die Parameter|Update-Regeln für die Parameter]]
		- [[#Gradientabstiegsverfahren#Code-Äquivalent|Code-Äquivalent]]
		- [[#Gradientabstiegsverfahren#Pseudocode für den Gradientenabstieg|Pseudocode für den Gradientenabstieg]]
- [[#Feature-Skalierung|Feature-Skalierung]]
- [[#Vergleich ERM und RM|Vergleich ERM und RM]]
- [[#Darstellung im Relationenmodell|Darstellung im Relationenmodell]]
- [[#Wichtige Merkmale|Wichtige Merkmale]]
- [[#Quellen|Quellen]]
- [[#Berechnung des ROI|Berechnung des ROI]]
	- [[#Berechnung des ROI#Beispiel:|Beispiel:]]
- [[#Bedeutung des ROI|Bedeutung des ROI]]
- [[#Vorteile des ROI|Vorteile des ROI]]
- [[#Nachteile des ROI|Nachteile des ROI]]
- [[#Anwendung des ROI in der Praxis|Anwendung des ROI in der Praxis]]
- [[#Ziele des Prozess-Roll-outs|Ziele des Prozess-Roll-outs]]
- [[#Phasen des Roll-outs|Phasen des Roll-outs]]
- [[#Wichtige Elemente zur Unterstützung des Roll-outs|Wichtige Elemente zur Unterstützung des Roll-outs]]
- [[#Erfolgsfaktoren für den Roll-out|Erfolgsfaktoren für den Roll-out]]
- [[#Herausforderungen beim Roll-out|Herausforderungen beim Roll-out]]
- [[#Best Practices für einen erfolgreichen Roll-out|Best Practices für einen erfolgreichen Roll-out]]
	- [[#Best Practices für einen erfolgreichen Roll-out#Messung des Roll-out-Erfolgs|Messung des Roll-out-Erfolgs]]
	- [[#Best Practices für einen erfolgreichen Roll-out#Nachbereitung und kontinuierliche Verbesserung|Nachbereitung und kontinuierliche Verbesserung]]
- [[#Parameter|Parameter]]
- [[#Quellen|Quellen]]
- [[#Wichtige Schadenspotenziale|Wichtige Schadenspotenziale]]
	- [[#Wichtige Schadenspotenziale#Imageschaden|Imageschaden]]
	- [[#Wichtige Schadenspotenziale#Wirtschaftlicher Schaden|Wirtschaftlicher Schaden]]
	- [[#Wichtige Schadenspotenziale#Datenverlust|Datenverlust]]
- [[#Weitere Schadenspotenziale|Weitere Schadenspotenziale]]
- [[#Quellen|Quellen]]
- [[#Verfügbarkeit|Verfügbarkeit]]
- [[#Integrität|Integrität]]
- [[#Vertraulichkeit|Vertraulichkeit]]
- [[#Datenminimierung|Datenminimierung]]
- [[#Transparenz|Transparenz]]
- [[#Intervenierbarkeit|Intervenierbarkeit]]
- [[#Nichtverkettung|Nichtverkettung]]
- [[#Bedeutung der Schwachstellenanalyse|Bedeutung der Schwachstellenanalyse]]
- [[#Schritte der Schwachstellenanalyse|Schritte der Schwachstellenanalyse]]
- [[#IT-Sicherheitsmaßnahmen|IT-Sicherheitsmaßnahmen]]
- [[#Tools zur Überprüfung von IT-Sicherheitsmaßnahmen|Tools zur Überprüfung von IT-Sicherheitsmaßnahmen]]
- [[#Best Practices zur Durchführung einer Schwachstellenanalyse|Best Practices zur Durchführung einer Schwachstellenanalyse]]
- [[#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Rollen|Rollen]]
- [[#Artefakte|Artefakte]]
- [[#Scrum Ablauf|Scrum Ablauf]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Grundprinzipien|Grundprinzipien]]
- [[#Vorbeugung|Vorbeugung]]
- [[#Vorteile|Vorteile]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte selbstkonfigurierender Systeme|Wichtige Aspekte selbstkonfigurierender Systeme]]
- [[#Technologien und Methoden|Technologien und Methoden]]
- [[#Vorteile selbstkonfigurierender Systeme|Vorteile selbstkonfigurierender Systeme]]
- [[#Anwendungsbereiche|Anwendungsbereiche]]
- [[#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Einführung in die Shellprogrammierung|Einführung in die Shellprogrammierung]]
- [[#Typen von Shells|Typen von Shells]]
- [[#Grundlagen der Shell-Skripterstellung|Grundlagen der Shell-Skripterstellung]]
- [[#Wichtige Shell-Befehle|Wichtige Shell-Befehle]]
- [[#Eingabe und Ausgabe|Eingabe und Ausgabe]]
- [[#Dateioperationen|Dateioperationen]]
- [[#Nützliche Tipps|Nützliche Tipps]]
- [[#Praktische Anwendungen|Praktische Anwendungen]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Vorteile|Vorteile]]
- [[#Anwendung|Anwendung]]
	- [[#Anwendung#DMAIC-Zyklus|DMAIC-Zyklus]]
- [[#Rollen|Rollen]]
- [[#Quellen|Quellen]]
- [[#Merkmale von Skriptsprachen|Merkmale von Skriptsprachen]]
- [[#Beliebte Skriptsprachen|Beliebte Skriptsprachen]]
- [[#Anwendungen der Skriptprogrammierung|Anwendungen der Skriptprogrammierung]]
- [[#Vorteile der Skriptprogrammierung|Vorteile der Skriptprogrammierung]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Best Practices|Best Practices]]
- [[#Quellen|Quellen]]
- [[#Wichtige Bestandteile eines SLA:|Wichtige Bestandteile eines SLA:]]
- [[#Verschiedene Arten von SLAs|Verschiedene Arten von SLAs]]
- [[#Supportlevel|Supportlevel]]
	- [[#Supportlevel#Level 1 Support|Level 1 Support]]
	- [[#Supportlevel#Level 2 Support|Level 2 Support]]
	- [[#Supportlevel#Level 3 Support|Level 3 Support]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Komponenten des Smart Grid|Komponenten des Smart Grid]]
- [[#Vorteile des Smart Grid|Vorteile des Smart Grid]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Anwendungen des Smart Grid|Anwendungen des Smart Grid]]
- [[#Quellen|Quellen]]
- [[#Quellen|Quellen]]
- [[#Protokollarchitektur|Protokollarchitektur]]
- [[#Hauptaufgaben|Hauptaufgaben]]
- [[#Nachrichtenarten|Nachrichtenarten]]
- [[#Versionen|Versionen]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Einsatzbereiche|Einsatzbereiche]]
- [[#Quellen|Quellen]]
- [[#Änderbarkeit|Änderbarkeit]]
- [[#Benutzbarkeit|Benutzbarkeit]]
- [[#Effizienz|Effizienz]]
- [[#Funktionalität|Funktionalität]]
- [[#Übertragbarkeit|Übertragbarkeit]]
- [[#Zuverlässigkeit|Zuverlässigkeit]]
- [[#Normen anwenden|Normen anwenden]]
	- [[#Normen anwenden#Grundprinzipien der Softwareergonomie|Grundprinzipien der Softwareergonomie]]
	- [[#Normen anwenden#Anwendungsbereiche der Softwareergonomie|Anwendungsbereiche der Softwareergonomie]]
	- [[#Normen anwenden#Methoden zur Verbesserung der Softwareergonomie|Methoden zur Verbesserung der Softwareergonomie]]
	- [[#Normen anwenden#Herausforderungen in der Softwareergonomie|Herausforderungen in der Softwareergonomie]]
	- [[#Normen anwenden#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#User-Management|User-Management]]
- [[#Firewall/Webfilter|Firewall/Webfilter]]
- [[#Port-Security|Port-Security]]
- [[#Verschlüsselung (TPM)|Verschlüsselung (TPM)]]
- [[#Quellen|Quellen]]
- [[#Definition|Definition]]
- [[#Komponenten|Komponenten]]
- [[#Kennzahlen|Kennzahlen]]
- [[#Analyse|Analyse]]
- [[#Ziel|Ziel]]
- [[#Zweck von SOPs|Zweck von SOPs]]
- [[#Bestandteile einer SOP|Bestandteile einer SOP]]
- [[#Arten von SOPs|Arten von SOPs]]
- [[#Erstellung von SOPs|Erstellung von SOPs]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Wichtige Aspekte der sozialen Stabilität|Wichtige Aspekte der sozialen Stabilität]]
	- [[#Quellen#Bedeutung der sozialen Stabilität in der IT|Bedeutung der sozialen Stabilität in der IT]]
	- [[#Quellen#Maßnahmen zur Förderung der sozialen Stabilität|Maßnahmen zur Förderung der sozialen Stabilität]]
	- [[#Quellen#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Definition|Definition]]
- [[#Formel|Formel]]
- [[#Quellen|Quellen]]
- [[#Speichersysteme|Speichersysteme]]
	- [[#Speichersysteme#Direct Attached Storage (DAS)|Direct Attached Storage (DAS)]]
	- [[#Speichersysteme#Storage Area Network (SAN)|Storage Area Network (SAN)]]
	- [[#Speichersysteme#Network Attached Storage (NAS)|Network Attached Storage (NAS)]]
- [[#Speichertechniken|Speichertechniken]]
	- [[#Speichertechniken#File Storage|File Storage]]
	- [[#Speichertechniken#Block Storage|Block Storage]]
	- [[#Speichertechniken#Object Storage|Object Storage]]
- [[#Quellen|Quellen]]
- [[#Datentypen in SQL|Datentypen in SQL]]
- [[#Integrität und Schlüssel|Integrität und Schlüssel]]
- [[#Datenbankoperationen|Datenbankoperationen]]
- [[#Komplexe Abfragen|Komplexe Abfragen]]
	- [[#Komplexe Abfragen#INNER JOIN|INNER JOIN]]
	- [[#Komplexe Abfragen#LEFT JOIN (oder LEFT OUTER JOIN)|LEFT JOIN (oder LEFT OUTER JOIN)]]
	- [[#Komplexe Abfragen#RIGHT JOIN (oder RIGHT OUTER JOIN)|RIGHT JOIN (oder RIGHT OUTER JOIN)]]
	- [[#Komplexe Abfragen#FULL JOIN (oder FULL OUTER JOIN)|FULL JOIN (oder FULL OUTER JOIN)]]
	- [[#Komplexe Abfragen#CROSS JOIN|CROSS JOIN]]
- [[#Ausdrücke und Bedingungen|Ausdrücke und Bedingungen]]
- [[#Aggregatfunktionen|Aggregatfunktionen]]
	- [[#Aggregatfunktionen#SUM()|SUM()]]
	- [[#Aggregatfunktionen#AVG()|AVG()]]
	- [[#Aggregatfunktionen#COUNT()|COUNT()]]
	- [[#Aggregatfunktionen#MAX()|MAX()]]
	- [[#Aggregatfunktionen#MIN()|MIN()]]
	- [[#Aggregatfunktionen#Weitere Beispiele und Kombinationen|Weitere Beispiele und Kombinationen]]
- [[#Charakteristika|Charakteristika]]
- [[#SQL-Datenbanktypen|SQL-Datenbanktypen]]
	- [[#SQL-Datenbanktypen#1. Traditionelle relationale Datenbanken|1. Traditionelle relationale Datenbanken]]
	- [[#SQL-Datenbanktypen#2. NewSQL-Datenbanken|2. NewSQL-Datenbanken]]
- [[#ACID-Eigenschaften|ACID-Eigenschaften]]
- [[#Vergleich zu NoSQL-Datenbanken|Vergleich zu NoSQL-Datenbanken]]
- [[#Vor- und Nachteile von SQL-Datenbanken|Vor- und Nachteile von SQL-Datenbanken]]
	- [[#Vor- und Nachteile von SQL-Datenbanken#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile von SQL-Datenbanken#Nachteile|Nachteile]]
- [[#Anwendungsfälle|Anwendungsfälle]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Praxisrelevante Konzepte|Praxisrelevante Konzepte]]
	- [[#Praxisrelevante Konzepte#Normalisierung|Normalisierung]]
	- [[#Praxisrelevante Konzepte#Indexierung|Indexierung]]
	- [[#Praxisrelevante Konzepte#Transaktionen|Transaktionen]]
- [[#Formel|Formel]]
	- [[#Formel#Gesamtheit|Gesamtheit]]
	- [[#Formel#Stichprobe|Stichprobe]]
- [[#Vergleich zwischen Standardabweichung und Varianz|Vergleich zwischen Standardabweichung und Varianz]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Wichtige Streumaße|Wichtige Streumaße]]
- [[#Gemeinsamkeiten mit Lagemaße|Gemeinsamkeiten mit Lagemaße]]
- [[#Unterschiede mit Lagemaße|Unterschiede mit Lagemaße]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Quellen|Quellen]]
	- [[#Quellen#Vorteile|Vorteile]]
	- [[#Quellen#Nachteile|Nachteile]]
- [[#Funktionsweise|Funktionsweise]]
	- [[#Funktionsweise#Lineare Klassifikation|Lineare Klassifikation]]
		- [[#Lineare Klassifikation#Begriffe:|Begriffe:]]
	- [[#Funktionsweise#Nicht-lineare Klassifikation|Nicht-lineare Klassifikation]]
- [[#Kernel-Trick|Kernel-Trick]]
		- [[#Nicht-lineare Klassifikation#Häufig verwendete Kernel-Funktionen:|Häufig verwendete Kernel-Funktionen:]]
	- [[#Kernel-Trick#Vorteile des Kernel-Tricks:|Vorteile des Kernel-Tricks:]]
	- [[#Kernel-Trick#Nachteile des Kernel-Tricks:|Nachteile des Kernel-Tricks:]]
- [[#Zusammenfassung|Zusammenfassung]]
- [[#Quellen|Quellen]]
- [[#Ablauf|Ablauf]]
- [[#Quellen|Quellen]]
- [[#Kategorien|Kategorien]]
- [[#Kombinationen entwickeln|Kombinationen entwickeln]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#Ziele der Systemlastanalyse|Ziele der Systemlastanalyse]]
- [[#Anwendung von Monitoringsystemen|Anwendung von Monitoringsystemen]]
- [[#Durchführung der Systemlastanalyse|Durchführung der Systemlastanalyse]]
- [[#Interpretation der Ergebnisse|Interpretation der Ergebnisse]]
- [[#Quellen|Quellen]]
- [[#Aufgaben|Aufgaben]]
- [[#Schichten|Schichten]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#TCP|TCP]]
- [[#UDP|UDP]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte der technischen Verfügbarkeit von Daten|Wichtige Aspekte der technischen Verfügbarkeit von Daten]]
- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten|Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten]]
	- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten#Redundante Systeme|Redundante Systeme]]
	- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten#Backup-Strategien|Backup-Strategien]]
	- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten#Lastverteilung|Lastverteilung]]
	- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten#Monitoring und Alarmierung|Monitoring und Alarmierung]]
	- [[#Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten#Cloud-Lösungen|Cloud-Lösungen]]
- [[#Herausforderungen bei der Sicherstellung der technischen Verfügbarkeit von Daten|Herausforderungen bei der Sicherstellung der technischen Verfügbarkeit von Daten]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte der Teilhabe|Wichtige Aspekte der Teilhabe]]
- [[#Bedeutung der Teilhabe in der IT|Bedeutung der Teilhabe in der IT]]
- [[#Maßnahmen zur Förderung der Teilhabe|Maßnahmen zur Förderung der Teilhabe]]
- [[#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Zweck|Zweck]]
- [[#Arten von Testdatengeneratoren|Arten von Testdatengeneratoren]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Zweck|Zweck]]
- [[#Inhalte eines Testprotokolls|Inhalte eines Testprotokolls]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Testverfahren|Testverfahren]]
	- [[#Testverfahren#Statische Testverfahren|Statische Testverfahren]]
	- [[#Testverfahren#Dynamische Testverfahren|Dynamische Testverfahren]]
	- [[#Testverfahren#Übersicht|Übersicht]]
	- [[#Testverfahren#1. Black-Box-Testing|1. Black-Box-Testing]]
	- [[#Testverfahren#2. White-Box-Testing|2. White-Box-Testing]]
	- [[#Testverfahren#3. Graue-Box-Testing|3. Graue-Box-Testing]]
- [[#Testarten|Testarten]]
	- [[#Testarten#1. Unit-Tests|1. Unit-Tests]]
	- [[#Testarten#2. Komponenten-Tests|2. Komponenten-Tests]]
	- [[#Testarten#3. Integrationstests|3. Integrationstests]]
	- [[#Testarten#4. Systemtests|4. Systemtests]]
	- [[#Testarten#5. Akzeptanztests|5. Akzeptanztests]]
	- [[#Testarten#6. Extremwerttest|6. Extremwerttest]]
- [[#Test-Pyramide|Test-Pyramide]]
- [[#Technische Maßnahmen|Technische Maßnahmen]]
- [[#Organisatorische Maßnahmen|Organisatorische Maßnahmen]]
- [[#Quellen|Quellen]]
- [[#Merkmale|Merkmale]]
- [[#Warum ist TQM wichtig?|Warum ist TQM wichtig?]]
- [[#Prinzipien von TQM|Prinzipien von TQM]]
- [[#Vor- und Nachteile von TQM|Vor- und Nachteile von TQM]]
	- [[#Vor- und Nachteile von TQM#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile von TQM#Nachteile|Nachteile]]
- [[#Funktionsweise der Einkapselung von Paketen|Funktionsweise der Einkapselung von Paketen]]
- [[#Vorteile der Einkapselung|Vorteile der Einkapselung]]
- [[#Was ist ein VPN-Tunnel?|Was ist ein VPN-Tunnel?]]
- [[#Was ist Split Tunneling?|Was ist Split Tunneling?]]
- [[#Tunneling-Protokolle|Tunneling-Protokolle]]
- [[#Quellen|Quellen]]
- [[#Überwachtes Lernen|Überwachtes Lernen]]
- [[#Definition|Definition]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Unüberwachtes Lernen|Unüberwachtes Lernen]]
- [[#Definition|Definition]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Algorithmen|Algorithmen]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Herausforderungen|Herausforderungen]]
- [[#Vergleich|Vergleich]]
- [[#Quellen|Quellen]]
- [[#Arten|Arten]]
- [[#Elemente|Elemente]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Einsatzgebiete|Einsatzgebiete]]
- [[#Elemente|Elemente]]
- [[#Beziehungen|Beziehungen]]
- [[#Elemente|Elemente]]
- [[#Quellen|Quellen]]
- [[#Elemente|Elemente]]
- [[#Beispiel|Beispiel]]
- [[#Quellen|Quellen]]
- [[#Diagrammstruktur|Diagrammstruktur]]
- [[#Zustände|Zustände]]
- [[#Ereignisse|Ereignisse]]
- [[#Transitionen|Transitionen]]
- [[#Elemente|Elemente]]
- [[#Beispiele|Beispiele]]
- [[#Quellen|Quellen]]
- [[#Einführung in das Urheberrecht|Einführung in das Urheberrecht]]
- [[#Relevante Aspekte für die Fachinformatik|Relevante Aspekte für die Fachinformatik]]
- [[#Rechte des Urhebers|Rechte des Urhebers]]
- [[#Nutzungsrechte|Nutzungsrechte]]
- [[#Verletzungen des Urheberrechts|Verletzungen des Urheberrechts]]
- [[#Praktische Anwendung in der Fachinformatik|Praktische Anwendung in der Fachinformatik]]
- [[#Quellen|Quellen]]
- [[#USV-Arten|USV-Arten]]
	- [[#USV-Arten#Offline / Standby-USV|Offline / Standby-USV]]
	- [[#USV-Arten#Line-Interactive-USV|Line-Interactive-USV]]
	- [[#USV-Arten#Online / Doppelwandler-USV|Online / Doppelwandler-USV]]
- [[#Quellen|Quellen]]
- [[#Formel|Formel]]
	- [[#Formel#Gesamtheit|Gesamtheit]]
	- [[#Formel#Stichprobe|Stichprobe]]
- [[#Vor- und Nachteile der Varianz|Vor- und Nachteile der Varianz]]
	- [[#Vor- und Nachteile der Varianz#Vorteile|Vorteile]]
	- [[#Vor- und Nachteile der Varianz#Nachteile|Nachteile]]
- [[#Vergleich zwischen Standardabweichung und Varianz|Vergleich zwischen Standardabweichung und Varianz]]
- [[#Quellen|Quellen]]
- [[#Begriffsdefinitionen|Begriffsdefinitionen]]
- [[#Arten der Vernetzung|Arten der Vernetzung]]
- [[#Vernetzungstechnologien|Vernetzungstechnologien]]
- [[#Vorteile der Vernetzung|Vorteile der Vernetzung]]
- [[#Nachteile der Vernetzung|Nachteile der Vernetzung]]
- [[#Best Practices für die Vernetzung|Best Practices für die Vernetzung]]
- [[#Quellen|Quellen]]
- [[#Symmetrische Verschlüsselung|Symmetrische Verschlüsselung]]
- [[#Asymmetrische Verschlüsselung|Asymmetrische Verschlüsselung]]
- [[#Auswahl der Verschlüsselungsart|Auswahl der Verschlüsselungsart]]
- [[#Quellen|Quellen]]
- [[#Wichtige Aspekte des Versionsmanagements|Wichtige Aspekte des Versionsmanagements]]
- [[#Beliebte Versionsmanagement-Systeme|Beliebte Versionsmanagement-Systeme]]
- [[#Grundlegende Konzepte|Grundlegende Konzepte]]
- [[#Vorteile des Versionsmanagements|Vorteile des Versionsmanagements]]
- [[#Herausforderungen und Risiken|Herausforderungen und Risiken]]
- [[#Quellen|Quellen]]
- [[#Normalverteilung|Normalverteilung]]
- [[#Diskrete Gleichverteilung|Diskrete Gleichverteilung]]
- [[#T-Verteilung|T-Verteilung]]
- [[#Chi-Quadrat-Verteilung|Chi-Quadrat-Verteilung]]
- [[#F-Verteilung|F-Verteilung]]
- [[#Quellen|Quellen]]
	- [[#Quellen#1. Kaufen|1. Kaufen]]
	- [[#Quellen#2. Leasing|2. Leasing]]
	- [[#Quellen#3. Mieten|3. Mieten]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Protokolle|Protokolle]]
- [[#Modelle|Modelle]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Anwendungsgebiete|Anwendungsgebiete]]
- [[#Rechtliche Aspekte|Rechtliche Aspekte]]
- [[#Quellen|Quellen]]
- [[#Grundbegriffe|Grundbegriffe]]
- [[#Mengen und Ereignisse|Mengen und Ereignisse]]
- [[#Berechnung von Wahrscheinlichkeiten|Berechnung von Wahrscheinlichkeiten]]
- [[#Abhängigkeit und Unabhängigkeit|Abhängigkeit und Unabhängigkeit]]
- [[#Bedingte Wahrscheinlichkeit|Bedingte Wahrscheinlichkeit]]
- [[#Grundlagen von Webservern|Grundlagen von Webservern]]
- [[#Wichtige Protokolle|Wichtige Protokolle]]
- [[#Komponenten eines Webservers|Komponenten eines Webservers]]
- [[#Funktionsweise|Funktionsweise]]
- [[#Sicherheit|Sicherheit]]
- [[#Fazit|Fazit]]
- [[#Quellen|Quellen]]
- [[#Anwendung der Wertschöpfungskettenanalyse|Anwendung der Wertschöpfungskettenanalyse]]
- [[#Skripting-Sprachen|Skripting-Sprachen]]
- [[#Wichtige Konzepte|Wichtige Konzepte]]
- [[#Überwachung von Skripten|Überwachung von Skripten]]
- [[#Best Practices|Best Practices]]
- [[#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Quellen|Quellen]]
- [[#Ziele|Ziele]]
- [[#Kernprozesse des Wissensmanagements|Kernprozesse des Wissensmanagements]]
- [[#Arten von Wissen|Arten von Wissen]]
- [[#Wissensmanagement-Methoden und -Tools|Wissensmanagement-Methoden und -Tools]]
- [[#Barrieren im Wissensmanagement|Barrieren im Wissensmanagement]]
- [[#Erfolgsfaktoren|Erfolgsfaktoren]]
- [[#Trends im Wissensmanagement|Trends im Wissensmanagement]]
- [[#Best Practices|Best Practices]]
		- [[#3. Mieten#Ziele von Workshops|Ziele von Workshops]]
		- [[#3. Mieten#Struktur eines Workshops|Struktur eines Workshops]]
		- [[#3. Mieten#Methoden und Techniken|Methoden und Techniken]]
		- [[#3. Mieten#Vorteile von Workshops|Vorteile von Workshops]]
		- [[#3. Mieten#Herausforderungen|Herausforderungen]]
	- [[#Best Practices#Wichtige Merkmale|Wichtige Merkmale]]
		- [[#Wichtige Merkmale#Zentralisierung in der IT|Zentralisierung in der IT]]
		- [[#Wichtige Merkmale#Dezentralisierung in der IT|Dezentralisierung in der IT]]
	- [[#Best Practices#Anwendungsbereiche|Anwendungsbereiche]]
		- [[#Anwendungsbereiche#Zentralisierung|Zentralisierung]]
		- [[#Anwendungsbereiche#Dezentralisierung|Dezentralisierung]]
	- [[#Best Practices#Vor- und Nachteile|Vor- und Nachteile]]
		- [[#Vor- und Nachteile#Zentralisierung in der IT|Zentralisierung in der IT]]
		- [[#Vor- und Nachteile#Dezentralisierung in der IT|Dezentralisierung in der IT]]
	- [[#Best Practices#Wichtige Begriffe|Wichtige Begriffe]]
- [[#Quellen|Quellen]]
- [[#Diskrete Zufallsvariable|Diskrete Zufallsvariable]]
- [[#Stetige Zufallsvariable|Stetige Zufallsvariable]]
- [[#Klassifizierung|Klassifizierung]]
- [[#Vorteile|Vorteile]]
- [[#Nachteile|Nachteile]]
- [[#Quellen|Quellen]]
- [[#(Un-)abhängige Variablen|(Un-)abhängige Variablen]]
- [[#Unabhängige Daten|Unabhängige Daten]]
- [[#Abhängige Daten|Abhängige Daten]]
- [[#Warum ist die Unterscheidung wichtig?|Warum ist die Unterscheidung wichtig?]]
	- [[#Warum ist die Unterscheidung wichtig?#Visuelle Darstellung|Visuelle Darstellung]]
	- [[#Warum ist die Unterscheidung wichtig?#Anwendungsbeispiele|Anwendungsbeispiele]]
- [[#Arbeitsanalyse|Arbeitsanalyse]]
- [[#Arbeitssynthese|Arbeitssynthese]]
- [[#Darstellung|Darstellung]]
- [[#Quellen|Quellen]]
- [[#Bedeutung|Bedeutung]]
- [[#Methoden|Methoden]]
- [[#Best Practices|Best Practices]]
- [[#Tools und Technologien|Tools und Technologien]]
	- [[#Tools und Technologien#Inhalt eines Abnahmeprotokolls|Inhalt eines Abnahmeprotokolls]]
	- [[#Tools und Technologien#Bedeutung für das Projektmanagement|Bedeutung für das Projektmanagement]]
	- [[#Tools und Technologien#Arten der Abnahme|Arten der Abnahme]]
	- [[#Tools und Technologien#Best Practices|Best Practices]]
	- [[#Tools und Technologien#Rechtliche Aspekte|Rechtliche Aspekte]]
- [[#Quellen|Quellen]]
- [[#Rechtsgrundlagen|Rechtsgrundlagen]]
- [[#Voraussetzungen für die Gültigkeit|Voraussetzungen für die Gültigkeit]]
- [[#Unwirksamkeit von Klauseln|Unwirksamkeit von Klauseln]]
- [[#Besondere Regelungen|Besondere Regelungen]]
- [[#Quellen|Quellen]]
- [[#Bedeutung im Risikomanagement|Bedeutung im Risikomanagement]]
- [[#Zusammenhang mit anderen Konzepten|Zusammenhang mit anderen Konzepten]]
- [[#Anwendung|Anwendung]]
- [[#Berechnung|Berechnung]]
- [[#Vorteile|Vorteile]]
- [[#Beachtung bei der Anwendung|Beachtung bei der Anwendung]]
- [[#Ebenen|Ebenen]]
- [[#Vorteile|Vorteile]]
- [[#Quellen|Quellen]]

# Fachrichtungsübergreifende berufsprofilgebende Fertigkeiten, Kenntnisse und Fähigkeiten
## Informieren und Beraten von Kunden und Kundinnen

## Aktives Zuhören, Kommunikationsmodelle (z.B. Telefonkonferenzen, Chat, virtuelle Teambesprechungen), Verkaufsgespräche (Anfrage, Angebot, Auftrag), Analyse der Kundenbedürfnisse (nicht Bestandteil der schriftlichen Prüfung)

### Kundenbeziehungen unter Beachtung rechtlicher Regelungen und betrieblicher Grundsätze gestalten
- [[Customer Relationship Management]]
- [[Gesetz gegen unlauteren Wettbewerb]]
- [[AGB-Gesetz]]
- [[Compliance]]
- [[Regelkonformität]]

### Instrumente zur Datenauswertung kennen und bedarfsgerecht auswählen sowie Ergebnisse interpretieren können
- Präsentationstechniken
- Grafische Darstellung ([[Diagrammarten]], Bilderbearbeitung, Videos, multimediale Aufbereitung)
- Tabellenkalkulation
- Präsentationsprogramme
- Programme zum Erstellen multimedialer Inhalte
- [[Corporate Identity ]](CI)

## Beurteilen marktgängiger IT-Systeme und kundenspezifischer Lösungen

### Chancen und Risiken der technischen Entwicklungen kennen und identifizieren können
- [[Datensicherheit]], [[Datenschutz]]
- Ausfallsicherheit, bspw. [[redundante Systeme]], [[selbstkonfigurierende System]]
- [[Lebenslanges Lernen]]
- [[Teilhabe]], [[soziale Stabiliät]]

### Veränderungen von Einsatzfeldern kennen und beurteilen können
- [[Geräteklassen]]
- [[Vernetzung]], [[Integration und Modularisierung]], [[Zentralisierung und Dezentralisierung|Zentralisierung/Dezentralisierung]], [[Embedded Systems]]
- [[Smart Grid]]
- [[IoT]], [[Industrie 4.0]]
- [[KI]], [[Autonome Systeme]]
- [[Big Data]]
- [[Cloud-Computing|Cloud]]
- [[Block Chain]], [[Smart Contracts]]
- [[Augmented Reality]]

## Entwickeln, Erstellen und Betreuen von IT-Lösungen

### Fehler erkennen, analysieren und beheben
- [[Debugging]], [[Break Point]]
- Software-Test, dynamische und statische [[Testverfahren]] (z.B. Black Box, White Box, Review, Extremwertetest)
- Testdaten
- Komponententest, Funktionstest, Integrationstest
- [[Versionsmanagement]] des Quellcodes

### Algorithmen formulieren und Programme entwickeln
- Abbildung der Kontrollstrukturen mittels [[Struktogramm]], [[Programmablaufplan|PAP]] oder [[Pseudocode]] als didaktisches Hilfsmittel
- UML ([[UML-Anwendungsfalldiagramm|Use Case]], [[UML-Klassendiagramm|Klassendiagramm]])
- Entwurf der Bildschirmausgabemasken ([[Softwareergonomie]], [[Barrierefreiheit]])

### Datenbanken modellieren und erstellen
- Relationale und nicht-relationale Datenbanken, NoSQL Datenbanken
- Datentypen: Boolesche Werte, Ganzzahl, Gleitkommawerte, Währung, Datumswerte, Texte fester und variabler Länge, BLO, Geokoordinaten
- [[Normalisierung|Normalisieren, 1. bis 3. Normalform]]
- [[Entity Relationship Model|ER-Diagramm, Attribute, Beziehungen, Kardinalitäten]], referenzielle Integrität, Aktualisierungsweitergabe, Löschweitergabe, Primärschlüssel, Fremdschlüssel
- Datenbankabfrage, Datenpflege
- Tabellenstruktur (CREATE TABLE, ALTER TABLE), Index (CREATE INDEX), Manipulation (INSERT, UPDATE, DELETE), Projektion (SELECT FROM), Selektion (SELECT FROM ... WHERE) und (SELECT ... (SELECT ...)), Sortieren (ORDER BY), Gruppieren (GROUP BY, HAVING)
- Abfrage über mehrere Tabellen (JOIN)
- Ausdrücke und Bedingungen
- Aggregat-Funktionen, z.B. SUM
- [[OpenData]], [[API-Schnittstellen]]

## Durchführen und Dokumentieren von qualitätssichernden Maßnahmen

### Methoden der Qualitätslenkung anwenden
- [[Prüfverfahren|Verschiedene Prüfverfahren, z.B. Parität, Redundanz]]
- Software-Test, dynamische und statische Testverfahren (z.B. Black Box, White Box, Review, Extremwertetest, Testdaten)
- [[Debugging]], [[Ablaufverfolgung]]
- [[Netzwerkanalyse]], Bandbreite, Reaktionszeiten

### Methoden zur Messung der Zielerreichung im QM-Prozess kennen und anwenden
- Verbesserungsprozess, [[PDCA|PDCA-Zyklus]], [[Kontinuierlicher Verbesserungsprozess|KVP]], [[KPI|Kennzahlen]]
- Kontrollverfahren
	- [[Hardwaretest]], z.B. Wareneingangskontrolle, mangelhafte Lieferung, Warenausgangskontrolle, [[Abnahmeprotokoll]]
	- SW-Test, z.B. [[Testverfahren]], [[Abnahmeprotokoll]]
- [[Soll-Ist-Vergleich]], Abweichungen erkennen und berechnen
- [[Testdatengeneratoren]]
- [[Testprotokolle]]

## Umsetzen, Integrieren und Prüfen von Maßnahmen zur IT-Sicherheit und zum Datenschutz

### Für jede Anwendung, die verwendeten IT-Systeme und die verarbeiteten Informationen gilt: Betrachtung zu erwartender Schäden, die bei einer Beeinträchtigung von Vertraulichkeit, Integrität oder Verfügbarkeit entstehen könnten!

### [[Schadenspotenziale von IT-Sicherheitsvorfällen ]]einschätzen und Schäden verhindern können, z.B.
- Imageschaden
- Wirtschaftlicher Schaden
- Datenverlust

### [[Präventive IT-Sicherheitsmaßnahmen]] für verschiedene Bedrohungsszenarien planen und umsetzen, z.B.
- [[Datendiebstahl]]
- Digitale Erpressung ([[Ransomware]])
- Identitätsdiebstahl ([[Phishing]])

### Ziele zur Entwicklung von IT-Sicherheitskriterien definieren, z.B.
- Richtschnur für Entwickler
- Objektive Bewertung der Systeme ([[IT-Grundschutzmodell|IT-Grundschutzmodellierung]])
- Anwender/Benutzer bei der Auswahl eines geeigneten IT-Sicherheitsproduktes unterstützen ([[Security by Design]])

### Kunden zur IT-Sicherheit beraten
- Private Haushalte
- Unternehmen (intern, extern)
- Öffentliche Hand
- Funktionale Anforderungen
- Qualitätsanforderungen Anforderungen
- Rahmenbedingungen
	- Technologisch
	- Organisatorisch
	- Rechtlich
	- Ethisch
- Risikoanalyse

## IT-Sicherheitsmaßnahmen mit verschiedenen Tools überprüfen, z.B.
- [[Penetrations-Test]]
- [[Device Security Check]]
- [[Identity & Access Management]]
- [[Schwachstellenanalyse]] (z.B. Ende-zu-Ende-Verschlüsselung)

## Technische organisatorische Maßnahmen ([[TOM]]) kontrollieren
- Zutrittskontrolle, z.B.
	- Alarmanlage
	- Videoüberwachung
	- Besucherausweise
- Zugangskontrolle, z.B.
	- Bildschirmschoner mit Passwortschutz
	- Biometrische Verfahren
	- Magnet- oder Chipkarte
- Zugriffskontrolle, z.B.
	- Verschlüsselung von Datenträgern
	- Löschung von Datenträgern
	- User/Rollenkonzept
- Log management
- Compliance Reports

# Daten- und Prozessanalyse
## Betreiben von IT-Systemen

### Schichtenmodelle, z.B. [[OSI-Modell|OSI]], [[TCP-IP-Modell|TCP/IP]] benennen und zuordnen können
- [[IP|IPv4, IPv6]]
- [[MAC]]
- [[TCP-IP-Modell#^b4a03f|Routing]]
- [[Switching]]
- [[ARP]]

### Netzwerkkomponenten vergleichen und analysieren können

### [[Netzwerkkonzepte]] (-topologien, -infrastrukturen) benennen und charakterisieren
- Ausdehnung
- Datenübertragungsrate
- Verschlüsselung (preshared key, RADIUS, ...)
- LAN/WAN/MAN/GAN
- Strukturierte Verkabelung
- VLAN
- Drahtlos: PAN/WLAN
- Sicherheitskonzepte und -risiken
- Bluetooth

### [[Peer-To-Peer]] bzw. [[Client-Server]]-Konzepte vergleichen und hinsichtlich ihres Einsatzes bewerten können
- ([[Netzwerktopologie]] (FI DV/SI))
- [[Netzwerkplan]]

### Übertragungsprotokolle erläutern und zielgerichtet einsetzen können
- [[TCP-UDP|TCP/UDP]]
- [[HTTPS]]

### Standortübergreifende und -unabhängige Kommunikation situationsgerecht auswählen und einrichten können
- [[VPN-Modelle]]
- [[Tunneling]]
- [[IPsec]]

### Netzwerkrelevante Dienste administrieren
- [[DNS]]
- [[DHCP]]
- [[Proxy]]

### Anwendungsdienste sicherstellen können
- Echtzeitkommunikation sicherstellen können
- [[Mailserver]]
- [[Webserver]]
- [[Groupware]]
- [[DBMS|Datenbanken]]

### Risiken identifizieren, Maßnahmen planen und Ausfallwahrscheinlichkeiten berücksichtigen
- [[PDCA|PDCA-Zyklus]]
- [[MTBF]]
- [[ANR]]
- [[Disaster Recovery|Notfallkonzept]]

### Maßnahmen zur Sicherstellung des Betriebes beurteilen können
- Elektrotechnisch ([[USV]])
- Hardwaretechnisch ([[Hardware-Redundanzen|Redundanzen]]), [[RAID]]
- Softwaretechnisch ([[Backup]], ...)

### Monitoringsysteme anwenden und Ergebnisse interpretieren können
- [[SNMP]], [[S.M.A.R.T.]] u. Ä.
- [[Systemlastanalyse]]
- [[Predictive Maintenance]]
- [[Load Balancing]]
- [[Incident Management]] (Ticketsystem)

### Monitoringergebnisse analyseiren und korrektive Maßnahmen bestimmen können
- Standard Operation Procedures ([[SOP]])
- Service Level Agreement ([[SLA]]), Service Level 1 -3

### Erstellen und Erweitern von Handbüchern für Benutzer und Systembetreuer 
(Schwerpunkt der praktischen Prüfung)

## Inbetriebnehmen von [[Speicherlösungen]]

### Technische und organisatorische Maßnahmen ([[TOM]])
- Berechtigungskonzepte, Organisationsstrukturen (Zugang, Zutritt, Zugriff)

### Möglichkeiten der [[Hardwaretechnischen Absicherung]] benennen
- Zugangskontrolle (z.B. Gebäude, Serverraum, Schrank, ...)

### Möglichkeiten der [[Softwaretechnischen Absicherung]] implementieren können
- User-Management
- Firewall/Webfilter
- Port-Security
- Verschlüsselung (TPM)

### Verschiedene Service- und Liefermodelle benennen und bedarfsorientiert auswählen können
- [[Fog-Computing]], [[Cloud-Computing|Cloud]], ...
- [[Cloud-Dienste|SaaS, XaaS]], ...

### Daten heterogener Quellen zusammenführen
- [[Data Warehouse]]
- [[Data Lake]]
### Netzwerkkomponenten und -protokolle beschreiben können, z.B.
- [[iSCSI]]
- [[SMB]]
- [[NFS]]
- [[Ethernet]], [[Fibre Channel]]

## Programmieren von Softwarelösungen

### [[Software-Anforderungen|Anforderungen]] kundengerecht erfassen
- Änderbarkeit
- Benutzbarkeit
- Effizienz
- Funktionalität
- Übertragbarkeit
- Zuverlässigkeit
- Normen anwenden

### Planen mit geeigneten Modellen
- [[Entity Relationship Model|ERM]]
- [[UML-Klassendiagramm]]
- [[Mock-up]]
- [[UML-Aktivitätsdiagramm]]
- [[UML-Anwendungsfalldiagramm]] (FI AE, DP)
- [[UML-Sequenzdiagramm ]](FI AE, DP)
- [[UML-Zustandsdiagramm]] (FI AE, DP)

### Festlegen von Schnittstellen und vorhandene Schnittstellen nutzen
- [[Datenaustauschformate]] (xml, json, ...)
- Datenbankverbindung implementieren
- [[SQL]]
- [[API-Schnittstellen|API]]

### Situationsgerechte Auswahl einer passenden [[Programmiersprachen|Programmiersprache]] begründen können
- Performance, Speicherverbrauch
- Portabilität
- Framework/Bibliotheken
- Einsatz von integrierten Entwicklungsumgebungen
- Aufwand
- Know-how/Fachkenntnis

### Algorithmen in einer Programmiersprache darstellen
Die Darstellung soll in allgemein verständlich verständlichen Programm- oder [[Pseudocode]] erfolgen. Der Code soll für Dritte, ohne Kenntnis der verwendeten Programmiersprache, lesbar sein. Der Code muss nicht in der geschriebenen Sprache kompilierbar bzw. ausführbar sein.

### [[Wiederkehrende Systemabläufe mithilfe von Skripten automatisieren und überwachen können]]
- [[Shellprogrammierung]] (z.B. [[PowerShell]], [[Bash]])
- [[Skriptprogrammierung]] (z.B. [[Python]], ...)

## Analysieren von Arbeits- und Geschäftsprozessen

### Prozesse identifzieren
- Mit Kunden, Lieferanten, beteiligten Bereichen, Mitarbeitern
- [[Prozessschnittstellen|Schnittstellen zu anderen Prozessen]]
- [[KPI|Leistungs-]], [[Prozessindikatoren]]
- Verfahren: [[Ist-Analyse|Methoden der Ist-Analyse]]

### Prozesse im Unternehmen einordnen können
- [[Aufbauorganisation]]
- [[Ablauforganisation]]

### Prozesse beschreiben können z.B.
- [[Prozesslandkarten]]
- [[Flussdiagramm|Flussdiagramme]]
- [[eEPK]]
- [[UML-Aktivitätsdiagramm]]
- [[Flussdiagramm|Prozessablaufdiagramm]]

### Prozesse bewerten
- [[Schwachstellenanalyse]] zur Identifizierung und Strukturierung von Problemen, z.B.
	- [[FMEA|FMEA (Fehlermöglichkeits- und Einflussanalyse]] 
	- [[Ishikawa-Diagramm|Ursache-Wirkungsdiagramm (Ishikawa-Diagramm = Fischgräten-Diagramm)]]
- [[ABC-Analyse|ABC-Analyse zur Priorisierung von Schwerpunkten]]
- [[Nutzwertanalyse|Nutzwertanalyse zum Vergleich mehrerer Varianten]]
- [[Polaritätsprofil|Polaritätsprofil zum Vergleichen mehrerer Varianten]]
- [[Wertschöpfungskette]]

### Prozesse modifizieren können
- Programmiertechnische Umsetzung

### Prozesse einführen können
- Unterstützung des [[Roll-out des Sollprozesses]]

### Prozesse steuern können aufgrund von
- [[KPI|Kennzahlen]] 
- [[Benchmarking]]
- [[Wissensmanagement]]

### Managementansätze, die die Prozessorientierung unterstützen, in ihren Auswirkungen beschreiben können
- [[Kaizen]]/[[Kontinuierlicher Verbesserungsprozess]]
- [[Lean Management]]
- [[Total Quality Management|Total Quality Management (TQM)]]

### Konzepte zur Prozessoptimierung anwenden können
- Basiswissen zu
	- [[Six Sigma]] mit
		- [[Six Sigma#DMAIC-Zyklus|DMAIC (Define, Measure, Analyze, Improve, Control)]]
	- Agile und hybride Konzepte, z.B.
		- [[SCRUM]]
		- [[PRINCE2]]

## Analysieren von Datenquellen und Bereitstellen von Daten

### Für einen Prozess relevante Daten identifizieren können
- [[Data Mining]] ([[CRISP-DM]])

### Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können
- [[API-Schnittstellen|Schnittstellenentwicklung]]
- Formate, z.B.
	- [[Datenaustauschformate|XML]]
	- [[Datenaustauschformate|JSON]]
	- [[Datenaustauschformate|CSV]]

## Daten in einer Datenbank speichern und verarbeiten können
- [[Datenbankarchitektur]], [[ANSI-SPARC-Architektur|3-Ebenen-Modell]]
- Auswahl eines geeigneten [[DBMS]]: [[No-SQL]] vs. [[SQL]]
- Datenmodellierung, z.B. [[Entity Relationship Model]], [[UML-Klassendiagramm]], [[Relationenmodell]]
- SQL-Befehle anwenden können

### Daten klassifizieren können

### Rechtliche Grundlagen erkennen können
- [[Urheberrecht]]
- [[Datenschutz]]
- [[Mitbestimmungsrechte laut Betriebsverfassungsgesetz]]
- [[Patentrecht]]

### Einbinden unterschiedlicher interner/externer Stellen/Ansprechpartner bei Zweifelsfällen

### Ethische Konsequenzen aus der Nutzung und Verknüpfung von Daten diskutieren können

### [[Technische Verfügbarkeit von Daten]] realisieren können

### Daten auf einer einheitlichen Plattform speichern

## Nutzen der Daten zur Optimierung von Arbeits- und Geschäftsprozessen sowie zur Optimierung digitaler Geschäftsmodelle

### Daten zur Feststellung des Istzustandes aufbereiten, Reproduzierbarkeit/Wiederholbarkeit von Daten
- Vollständigkeit überprüfen
- Datenmengen im Hinblick auf die Verwendung beurteilen (Stichprobengröße)

### Defizite gegenüber dem Sollzustand in der [[Datenqualität]] anhand von Merkmalen feststellen
- Messung auf Vollständigkeit, Korrektheit, Aktualität, Historisierung, Widerspruchsfreiheit, z.B. defect per million opportunities

### Maßnahmen zur Verbesserung der Datenqualität ableiten
- [[Normalisierung|Normalisierung durchführen]]
- [[Plausibilitätskontrollen]]
- Merkmale verschiedener [[DBMS|Datenbanksysteme]] kennen
- [[DBMS|Datenbanksysteme]] (z.B. relationale DB, No-SQL DB)
- [[Data Warehouse]]
- [[Lagemaße]] und [[Streumaße]] berechnen können
- [[Arithmetisches Mittel]]
- [[Median]]
- [[Standardabweichung]]
- [[Verteilung]]

### Angemessene grafische Repräsentation für Analyseergebnisse auswählen z.B.
- Tabellen, Texte
- [[Diagrammarten|Diagramme]]
- Dashboards
- [[Verteilung#Normalverteilung|Normalverteilung]]

### Mathematische Vorhersagemodelle anwenden
- [[Wahrscheinlichkeiten]]/[[Erwartungswerte]]
- [[Clustering]]/[[Assoziation]]/[[Regression]]/[[Klassifikation]]

### Grundlagen des maschinellen Lernens anwenden können
- [[K-Nearest Neighbor]]/[[Entscheidungsbaum|Decision Tree]] (z.B. [[ID3]])
- [[Evolutionäre Algorithmen]]
- [[Entropie und Informationsgewinn|Entropy, Information gain]]

### Verfahren einordnen und weitere Konzepte kennen
- [[Neural Network|Neuronales Netz]]
- [[Support Vector Machine]]
- [[Überwachtes und nicht-überwachtes Lernen]]
### Format für zielgruppengerechte Berichterstattung erarbeiten
- Zielgruppen, Stakeholder

### Kennzahlen ableiten und für ein Monitoringsystem vorschlagen


## Umsetzen des Datenschutzes und der [[Schutz- und Gewährleistungsziele der Informationssicherheit|Schutzziele der Datensicherheit]]

### Akteure/Rollen im [[Datenschutz]] erkennen und ihre Beziehung untereinander zuordnen können
- Betroffene Personen
- Verantwortliche
- Auftragsverarbeitende
- Empfänger
- Dritte
- Aufsichtsbehörnde

### Grundlegende [[Schutz- und Gewährleistungsziele der Informationssicherheit]] beschreiben können
- Verfügbarkeit
- Integrität
- Vertraulichkeit
- Datenminimierung
- Transparenz
- Intervenierbarkeit
- Nichtverkettung

### Auswahl von Datenfeldern, die für eine Zweckerreichung zwingend benötigt werden
- [[Datensparsamkeit]]
- [[Datensorgfalt]]

### Verfahren zur Datenverschlüsselung auswählen und nutzen
- Auswahl der [[Verschlüsselungsart]] (synchron, asynchron, hybrid) in Abhängigkeit von Datenmenge und Schutzbedarf
- Auswahl des konkreten [[Hashing- und Verschlüsselungsverfahren]] (z.B. MD5, SHA256, ...)
- Notwendigkeit einer [[Digitale Signatur|Signierung]] und praktische Umsetzung
- Anwendungsszenarien für [[Hashing]]

# Wirtschafts- und Sozialkunde

## Berufsausbildung sowie Arbeits- und Tarifrecht

### Rechte und Pflichten des Auszubildenden und des Ausbildenden
- Inhalte des Ausbildungsvertrages
	- Vertragspartner
	- Dauer der täglichen Arbeitszeit
	- Probezeit
	- Vergütungs- und Urlaubsregelungen
	- Kündigungsbedingungen
	- Folgen bei Nichteinhaltung der Rechte und Pflichten
	- Geltungsbereich
	- Beendigung
	- Arbeitszeugnis
	- Prüfungen, Abschluss

### Vorteile der Ausbildung im dualen System der Berufsbildung
- Unterschiedliche Lernorte, auf regionaler Ebene
- Zusammenwirken von Betrieb und Berufsschule

### Aufgaben von Ausbildungsbetrieb, Berufsschule und Kammern im Rahmen der Berufsausbildung
- Berufsbildungsgesetz, Ausbildungsordnung
- Aufgaben der Berufsschule, Berufsschulpflicht
- Aufgaben der Kammern

### Ausbildungsrahmenplan, sachliche und zeitliche Gliederung
- Rahmenlehrplan
- Betrieblicher Ausbildungsplan
- Zuordnung der Lernziele des Ausbildungsrahmenplans zu den Inhalten des betrieblichen Ausbildungsplans unter Berücksichtigung betrieblicher Besonderheiten
- Einsatz und Versetzungsplan im Betrieb
- Rahmenplan für die berufsschulische Ausbildung

### Grundsätze des Individual- und Kollektivarbeitsrechtes
- Kenntnis der Arbeitnehmerrechte und -pflichten im Betrieb
- Kenntnis der wesentlichen Bestimmungen aus den relevanten Rechtsgebieten
	- Berufsbildungsgesetz
	- Arbeitsschutzgesetz
	- Bundeselterngeld- und Elternzeitgesetz
	- Allgemeines Gleichbehandlungsgesetz
	- Kündigungsschutzgesetz
	- Jugendarbeitsschutzgesetz
	- Arbeitsstättenverodnung
	- Arbeitszeitgesetz
	- Betriebsverfassungsgesetz
	- Betriebsvereinbarungen (z.B. betriebliche Arbeitszeitregelung, betriebliches Beurteilungsverfahren)
	- Sozialversicherung
	- Lohnsteuer
	- Mutterschutzgesetz
	- Schwerbehindertengesetz

### Arbeitgeberorganisationen
- Arbeitgeberverbände
- Industrie- und Handelskammern
- Wirtschaftsverbände

### Arbeitnehmerorganisationen
- Gewerkschaften
- Betriebsräte
	- Wahl und Zusammensetzung
	- Mitbestimmungs- und Mitwirkungsrechte
	- Betriebsversamlung
	- Einigungsstelle
	- Jugend- und Auszubildendenvertretung
### Tarifrecht
- Tarifverträge (z.B. Entgelttarifvertrag, Manteltarifvertrag)
- Tarifautonomie, Tarifverhandlung, Tarifbindung, Tarifkonflikt (Arbeitskampf)
- Geltungsbereich
- Laufzeit
### Lohn- und Gehaltsformen
- Brutto/Netto-Entgelt
- Lohnsteuer, Kirchensteuer
- Sozialabgaben: Krankenversicherung, Arbeitslosenversicherung, Rentenversicherung, Pflegeversicherung
- Vermögenswirksame Leistungen
- Steuerklassen

### Lebensbegleitendes lernen
- Regelungen und Möglichkeiten für interne und externe Weiterbildung in Betrieb und Branche, evtl. tarifvertragliche Regelungen
- Berufliche Fortbildung und Umschulung
- Innerbetriebliche Fortbildung
- Staatliche Fördermaßnahmen

### Lerntechniken
- Visuelles Lernen, z.B. Lernposter mit Mindmaps, Schaubilder, Grafiken erstellen, Videos ansehen, eigene Zusammenfassungen und Lernkarteien schreiben
- Auditives Lernen, z.B. Lerngruppen bilden, Vorträge anhören, Lerninhalte aufnahmen und abspielen
- Kommunikatives Lernen, z.B. Dialoge, Diskussionen, Lerngruppen, Frage-Antwort-Spiele
- Motorisches Lernen, z.B. Learning by Doing, Rollenspiele, Gruppenaktivitäten

### Arbeitstechniken
- Zeitmanagementtechniken, flexible Arbeitszeiten
- Moderations- und Präsentationstechniken
- Arbeitsplanung- und Projektplanungstechniken
- Verschiedene Arbeitstechnik erlernen
- Gestaltung eines lernförderlichen und das Lernen integrierenden Arbeitsplatzes
- Beschaffung, Auswahl und Auswertung von Fachinformationen
- Digitale Lernmedien nutzen und individuell bewerten
	- Internet
	- Apps
	- Plattformen (Kommunikation, Information, Videos, Austausch)
	- Netzwerke
	- Computer Based Training (CBT)
	- Web Based Training (WBT)
	- Umgang mit mobilen Endgeräten

### Berufliche Fortbildung und Umschulung
- IT-Weiterbildung ergänzend zur Ausbildung in den IT-Berufen
- Staatliche Fördermaßnahmen
- Innerbetriebliche Fortbildung
- Umschulungen

### Lebensplanung
- Regelungen und Möglichkeiten für interne und externe Weiterbildung in Betrieb und Branche, evtl. tarifvertragliche Regelungen
- Bildungseinrichtungen
- Auslandsaufenthalte, z.B. mithilfe von EU-Förderprogrammen
- Persönliche Weiterbildung
	- Studium von Fachliteratur
	- Selbstlernmaterialien
	- Fachmessen
- Entwicklung bezüglich
	- Eigenständigkeit
	- Verantwortung
	- Reflexivität
	- Lernkompetenz
	- Team- und Führungsfähigkeit
	- Mitgestaltung
	- Kommunikation
- Überbetriebliche Fortbildung
- Europass
- Mobilitätsprogramme
- Europäische Sozialcharta
- Potenzialanalyse
- Karriereplanung
- Möglichkeiten und Grenzen einer Existenzgründung
- Altersvorsorge

## Aufbau und Organisation des Ausbildungsbetriebes

### Der Betrieb
- Branchenzugehörigkeit
- Gesamtwirtschaft, z.B. primärer, sekundärer, tertiärer Sektor, erwerbswirtschaftliche Betriebe
- Produktpalette und Märkte

### Rechtsformen
- Gesellschaft bürgerlichen Rechts
- Personengesellschaften, z.B. Einzelunternehmen, KG, OHG, GmbH & Co. KG
- Kapitalgesellschaften, z.B. GMBH, AG
- Staatliche order kommunale Unternehmen, Unternehmendes öffentlichen Rechts
- Gemeinnützige Organisationen

### Unternehmensstruktur und Organisationsform
- Unternehmenszentrale, Filialunternehmen, Niederlassung, Außenstelle
- Einlinien- bzw. Mehrlinien-, Stabliniensystem
- Spartenorganisation
- Matrixorganisation
- Arbeitsabläufe und Aufgabenteilung

### Wirtschaftliche Verflechtung
- Konzern
- Kartell
- Fusion

### Ziele von Betrieben und Unternehmen
- Produktivität
- Wirtschaftlichkeit
- Rentabilität

### Betriebliche und gesamtwirtschaftliche Arbeitsteilung
- Internationale Spezialisierung, Globalisierung
- Betriebliche und gesamtwirtschaftliche Arbeitsteilung
- Möglichkeiten und Grenzen der sozialen Marktwirtschaft

### Ziele und Aufgaben von Arbeitgeber- und Arbeitnehmerverbänden
- Branchenspezifische Gewerkschaften und Arbeitgeberverbände
- Wirtschaftsorganisationen
- Berufsständische Vertretungen und Organisationen
- Ehrenamtliche Mitwirkung, z.B. Prüfungsausschuss
### Ziele und Aufgaben von Behörden und Verwaltungen
- Vertretung gesamtgesellschaftlicher Interessen

### Grundsatz der vertrauensvollen Zusammenarbeit zwischen Arbeitgeber- und Arbeitnehmervertretern
- Betriebsverfassungsgesetz
- Arbeitnehmervertretung, Betriebsrat
- Jugend- und Auszubildendenvertreter und deren Informations-, Beratungs- und Mitbestimmungsrechte
- Betriebsvereinbarungen bzw. Personalvertretung auf Grundlage des Personalvertretungsgesetzes


## Sicherheit und Gesundheitsschutz bei der Arbeit

### Gesundheits- und Arbeitsschutzvorschriften
- Arbeitsschutzgesetz
- Arbeitssicherheitsgesetz
- Arbeitszeitgesetz
- Betriebssicherheitsverordnung
- Arbeitsstättenverordnung
- Unfallverhütungsvorschriften (UVV)
- Berufsgenossenschaften
- Arbeitsplatzergonomie
- Bildschirmarbeitsplatzverordnung
- Aufsichtsbehörde für Arbeitsschutz (Gewerbeaufsicht)
- Jugendarbeitsschutzgesetz

### Gefährdung und Beanspruchungen wahrnehmen und einschätzen
- Mechanische, elektrische, thermische und chemische Gefahren
- Ergonomische, akustische und psychische Gefahren
- Gefahren beachten und ggf. melden
- Sicherheitshinweise, Vorschriften und Anweisungen beachten
- Besondere Fürsorgepflicht des Arbeitgebers
- Ersthelfer am Arbeitsplatz
- Ergonomische Arbeitsplatzgestaltung

### Vorsorgeuntersuchungen
- Augenuntersuchung für Bildschirmarbeitsplätze
- Psychische Gefährdungsbeurteilung
### Aufgaben der Sicherheitsbeauftragten

### Vorschriften im betrieblichen und persönlichen Arbeitsablauf
- Sachgerechter Umgang mit Gefahrenpotenzialen
- Allgemeine und betriebliche Verhaltensregeln
- Notausgänge (Kennzeichnung), Fluchtwege im Gebäude/am Arbeitsplatz
- Schutzarten elektrischer Betriebsmittel
- Schutzklassen
- Prüfzeichen, z.B. CE-Zeichen
- Schriften, Farben und Zeichen des Arbeitsschutzes

### Verhaltensweisen bei Unfällen
- Erste-Hilfe-Maßnahmen
- Ersthelfer, Notruf- und Notfallnummern
- Meldeketten
- Fluchtwege und Sammelplätze
- Evakuierung und Dokumentation
- Meldepflicht von Unfällen

### Verhaltensweisen im Brandfall sowie verbeugender Brandschutz
- Brandursachen durch brennbare Stoffe und Hitzeentwicklung
- Brandschutzordnung z.B. Verbot zur Fahrstuhlnutzung, Schließen von Türen und Fenstern im Gebäude/am Arbeitsplatz
- Brandschutzmittel
	- Feuerlöscher (Arten, Standort, Bedienungsanleitung, Wirkungsweise)
	- Löschdecken
- Verhalten in Brandfällen, z.B. Verbot zur Fahrstuhlnutzung, Schließen von Türen und Fenstern im Gebäude/am Arbeitsplatz
- Sammelplätze
- Flucht und Rettungswege
- Sicherheitszeichen
- Brandschutzklassen (A, B, C, D)
- Brandmeldung
- Schulung

## Umweltschutz

### Umweltbelastungen wahrnehmen und vermeiden helfen
- Spezifische Risiken der IT-Prozesse, sowie von IT beteiligten Prozessen z.B. USV-Anlagen
- Rationelle Energie- und Ressourcenverwendung
	- unnötige Gerätelaufzeiten vermeiden
	- Umgang mit Speicher- und Printmedien
- Green IT
- Wiederverwertung (Recycling)
- Abfalltrennung und -vermeidung

### Umgang mit Abfällen
- Branchenspezifische Abfälle
	- Erfassung
	- Lagerung und Entsorgung von z.B. Datenträgern oder Kabeln

### Öffentliche Systeme und Verordnungen/Gesetze
- Teilnahme am Dualen System im Hinblick auf Verpackungsentsorgung
- Immsionsschutzgestz, technische Anleitungen, z.B. zu Lärm, Luft, Abfall

### Externe Auswirkungen
- Im Rahmen von Nachhaltigkeit sind auch Auswirkungen auf Umwelt, Pflanzen, Tiere, Lebensräume zu reflektieren

### Umweltschonende Ressourcennutzung
- Berücksichtigen wirtschaftlicher Nachhaltigkeit bereits bei Einkauf und Lieferantenauswahl
- Sparsamer und effektiver Umgang mit Roh-, Hilfs- und Betriebsstoffen (ggf. erforderliche Kennzeichnung und getrennte Lagerung beachten)
- Ressourcenverbrauch und Umweltschutz in Kombination bedenken, z.B. Nutzung von Strom aus regenerativen Quellen
### Abfallvermeidung und -reduzierung
- Kreislaufwirtschaftsgesetz 
- Papierloses Büro
### Rechtsfolgen bei Nichteinhaltung
- Verursacherprinzip

## Vernetztes Zusammenarbeiten unter Nutzung digitaler Medien

### Wertschätzende Zusammenarbeit
- Interdisziplinarität, Interkulturarität
- Fähigkeit, effektive, integer und respektvoll mit verschiedenen Teams zusammenzuarbeiten
- Übernahme gemeinsamer Verantwortung für die Zusammenarbeit und Wertschätzung der einzelnen Beiträge jedes Teammitglieds
- Unternehmenswerte beachten und betriebliche Ethikregeln anwenden
- (Un-)bewusste Vorurteile erkennen und beseitigen
- Compliance-Regeln kennen und beachten

### Informationstechnische Schutzziele: Integrität, Vertraulichkeit und Authentizität berücksichtigen
- Standards des BSI beachten und einhalten
- betriebliche Regelungen kennen und beachten
- Reflexion von Erfahrungen in virtuellen Räumen
- Im Umgang mit Kommunikation und Information Zuständigkeitsabgrenzung verdeutlichen
- Nachrichten und Inhalte auch aus Sicht der Empfänger betrachten
- Sensibler Umgang mit Adressatenlisten in der digitalen Kommunikation
- Die möglichen (auch juristischen) Konsequenzen von Äußerungen über den eigenen Arbeitgeber in sozialen Netzwerken berücksichtigen

### Ethische Aspekte und Compliance-Regelungen
- "Diversity" gewährleisten und unterschiedliche Perspektiven berücksichtigen
- Aus der Verschiedenheit Vorteile für das Unternehmen ziehen
- Gender-Neutralität gewährleisten, aber auch z.B. das dritte Geschlecht berücksichtigen
- Im Zentrum ethischer Aspekte steht die Würde aller menschen sowie deren Integrität. Diese ist für alle direkt und indirekt Betroffenen der IT-Lösungen kurz-, mittel- und langfristig zu gewährleisten
- Im Rahmen von Nachhaltigkeit sind auch Auswirkungen auf alles Lebendige (Umwelt, Pflanzen, Tiere, Lebensräume) zu reflektieren
- Ergänzend dazu sind auch allgemeine und betriebliche Compliance-Regelungen zu berücksichtigen.

- **API**: Anwendungsschnittstelle, ermöglicht Anbindung von Programmen an Softwaresysteme.
- **Unterschied zu ABI** *(Application Binary Interface)*: API definiert Programmanbindung auf Quelltext-Ebene.

#### Funktionen
- Zugriff auf Datenbanken, Hardware, GUI-Komponenten.
- Beispiel: Windows API für Softwareentwicklung auf Windows.

#### Typen von APIs
1. **Funktionsorientierte APIs**
   - Kommunikation über Funktionen (z. B. Dynamic Link Library).
   - Verwendung von Handles.

2. **Dateiorientierte APIs**
   - Zugriff über Dateisystemaufrufe (open, read, write, close).
   - Verbreitet bei Gerätetreibern unter UNIX.

3. **Objektorientierte APIs**
   - Verwendung von Schnittstellenzeigern, flexibler als funktionsorientierte APIs.

4. **Protokollorientierte APIs**
   - Unabhängig von Betriebssystem und Hardware.
   - Kapselung durch funktions- oder interfaceorientierte Schnittstellen (z. B. SOAP, SMTP).

#### Entwicklungsstufen
- **Evolving API**: Entwickelt sich weiter, kann Änderungen erfordern.
- **Stable API**: Stabil, keine Änderungen in Anwenderprogrammen nötig.
- **Refactoring**: Fortentwicklung ohne Änderungen für Anwender.

#### Bedeutung
- Gut dokumentierte APIs bieten Wettbewerbsvorteile.
- Erhöhen Attraktivität des Systems durch Drittanbieter-Software.
- Langzeitstabilität wichtig für Kosten- und Aufwandseffizienz.

## Quellen
> Seite „Binärschnittstelle“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 14. Juli 2024, 21:30 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Bin%C3%A4rschnittstelle&oldid=246763634](https://de.wikipedia.org/w/index.php?title=Bin%C3%A4rschnittstelle&oldid=246763634) (Abgerufen: 16. September 2024, 10:20 UTC)
> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- auch als **Durchschnittswert** bezeichnet, repräsentiert den zentralen Wert einer Datenmenge

## Anwendungsbereiche
- bei [[Kardinalskala|intervall- und verhältnisskalierten]] Daten
- nicht für [[Ordinalskala|ordinal skalierte Variablen]] und [[Nominalskala|nominal skalierte Variablen]]

## Formel

$$
\bar{x} = \dfrac{1}{n} \sum^{n}_{i=1}x_i = \dfrac{x_1+x_2+x_3+...+x_n}{n}
$$

## Vorteile
- einfach zu **berechnen** und zu **interpretieren**
- berücksichtigt alle Werte der Datenmenge

## Nachteile
- empfindlich gegenüber **Ausreißern**, die den Durchschnitt stark beeinflussen können
- benötigt ein **Intervallskalenniveau**

## Quellen

> Arithmetisches Mittel. (2019, October 09). Retrieved from https://studyflix.de/statistik/arithmetisches-mittel-1508  
> AI Chat. (2024, September 16). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


- **A**ddress **R**esolution **P**rotocol
- Netzwerkprotokoll auf [[TCP-IP-Modell|Netzzugangsschicht]] bzw. [[OSI-Modell|Sicherungsschicht]]

- dient zur Übersetzung von [[IP|IPv4]]-Adressen zu [[MAC]]-Adressen 
- Zuordnung wird ggf. in *ARP-Tabellen* der beteiligten Rechnern hinterlegt
- equivalent für [[IP|IPv6]] wäre das *Neighbor Discovery Protocol*

## Quellen

> Seite „Address Resolution Protocol“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 26. Januar 2024, 11:22 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Address_Resolution_Protocol&oldid=241562255](https://de.wikipedia.org/w/index.php?title=Address_Resolution_Protocol&oldid=241562255) (Abgerufen: 17. September 2024, 08:29 UTC)

- die **Assoziationsanalyse** sucht nach **häufig auftretenden Mustern**, **Korrelationen** oder **kausalen Strukturen** zwischen Datenelementen in großen Datenbanken
	- *wenn **X** dann wahrscheinlich auch **Y***

## Grundbegriffe
- **Itemset**, Menge bestehend aus mindestens zwei Elementen
- **Support**, Häufigkeit wie oft ein Produkt relativ gekauft wird
	- $Support(A)=\dfrac{Transkationen \space mit \space A}{Alle \space Transaktionen}$ ![[Pasted image 20241002155440.png]]
- **Konfidenz**, misst Support aller Transaktionen, die A und B enthalten
	- $Konfidenz(A + B) = \dfrac{Support(A \cup B)}{Support(A)} = \dfrac{Transaktionen \space mit \space A \space und \space B}{Transaktionen \space mit \space A}$ ![[Pasted image 20241002155500.png]]
- **Assoziationsregel**, sucht Regelmäßigkeiten zwischen zwei oder mehr Elementen
- **Frequent Itemset**, Menge von Elementen die häufig zusammen auftreten, die vorher definiertes Level an Support und Konfidenz

## Apriori Algorithmus
- Methode zur Findung von **Frequent Itemsets**
- **iterative Durchführung der Schritte**:
	- **Join**, Bildung von Itemsets der Menge $K$ ($K$ ist der aktuelle Wiederholungsschritt)
	- **Prune**, Entfernen von allen Itemsets, die **Supportschwelle** nicht erreichen und deshalb als selten gesehen werden
	- **->** sofern keine neuen Itemsets mehr gefunden werden, ist Algorithmus terminiert

## Vor- und Nachteile
- **Vorteile**
	- gute Möglichkeit um Assoziationsregeln zu finden
	- Einfach zu implementieren
- **Nachteile**
	- bei großen Datenbanken sehr rechenintensiv


- **hierarchisches Grundgerüst** wie ein Unternehmen aufgebaut ist
- Wer übernimmt *Führung*? Wer übernimmt *Verantwortung*? Welche *Abteilungen* gibt es?
- **Organigramm**, strukturiert Aufgaben- und Verantwortungsbereiche

## Aufgabenanalyse
- analyse aller Aufgaben im Unternehmen
1. **Hauptaufgaben** zur Erfüllung des **Unternehmensziels** identifizieren 
2. In Teilaufgaben anhand von: *Objekten*, *Funktionen*, *Phasen* und *Rangstufen* aufteilen
	1. Objekte: Kühlschränke, Mikrowellen
	2. Funktionen: Produktion (Montagearbeiten -> Verkabelung, ...), Vertrieb, Forschung & Entwicklung, Marketing
	3. Phasen: Planung, Durchführung, Kontrolle

## Aufgabensynthese
- Haupt- und Teilaufgaben **zusammensetzen**, gruppieren
- -> **Organisationsform** erstellen

## Organisationsformen

### Einliniensystem
![[Pasted image 20240913102344.png]]
- **einfacher** hierarchischer Aufbau
- legt **Delegations-** und **Rechtswege** klar fest
- einen **direkten** Vorgesetzten
- **Vorteile**
	- *übersichtlich*
	- klar *verteilte Anordnungsbefugnis*
	- eindeutige *Dienst-, Informations- und Kommunikationswege*
	- Vermeidung von Kompetenzüberschneidungen
- **Nachteile**
	- lange Dienstwege
	- unnötige Belastung von Zwischeninstanzen
	- Überlastung der Vorgesetzten
	- fehlende Flexibilität

### Mehrliniensystem
![[Pasted image 20240913102929.png]]
- **Mehrfachunterstellung**
- jeder Mitarbeiter kann **mehrere Vorgesetzte** haben
- **Vorteile**
	- direkte Kommunikationswege
	- erleichterte Mitarbeiterkontrolle
	- **Spezialisten** in Fachgebieten
	- **Entlastung** ranghoher Instanzen
- **Nachteile**
	- Probleme bei Abgrenzung der **Zuständigkeit** und **Verantwortung**
	- Kompetenzüberschneidung mit Konfliktpotential
	- **Widersprüchliche** Arbeitsanweisungen

## Matrixorganisation
![[Pasted image 20240913103127.png]] 
- Umsetzung eines mehrdimensionalens **Mehrliniensystems**
- Zuordnung nach **Fach-** und **Geschäftsbereich** 


### Stabliniensystem
![[Pasted image 20240913102536.png]]
- sind bestimmten Abteilungen zugeordnet
- haben **unterstützende** Funktion

## Quellen

> Aufbauorganisation. (2019, June 21). Retrieved from https://studyflix.de/wirtschaft/aufbauorganisation-1346
> Einliniensystem. (2019, June 21). Retrieved from https://studyflix.de/wirtschaft/einliniensystem-1344
> Mehrliniensystem. (2019, June 21). Retrieved from https://studyflix.de/wirtschaft/mehrliniensystem-1345

- **Technologie**, die digitale Informationen und **Objekte in die reale Welt integriert**, um die Wahrnehmung der Umgebung zu erweitern.
- **Ziel**: Verbesserung der Benutzererfahrung durch die Überlagerung von virtuellen Inhalten auf die reale Welt.

### Funktionsweise von Augmented Reality
- **Hardware**: AR-Systeme nutzen Geräte wie Smartphones, Tablets, Smart Glasses oder Headsets, um digitale Inhalte anzuzeigen.
- **Software**: AR-Anwendungen verwenden Computer Vision, Sensoren und Algorithmen, um die reale Umgebung zu analysieren und digitale Inhalte präzise zu platzieren.
- **Tracking**: AR-Technologien verwenden GPS, Beschleunigungssensoren, Gyroskope und Kameras, um die Position und Orientierung des Geräts in der realen Welt zu bestimmen.

### Arten von Augmented Reality
- **Markerbasierte AR**: Nutzt visuelle Marker (z.B. QR-Codes), um digitale Inhalte zu aktivieren und anzuzeigen.
- **Markerlose AR**: Verwendet GPS und andere Sensoren, um digitale Inhalte ohne spezifische Marker in der Umgebung zu platzieren.
- **Projection-based AR**: Projektiert digitale Informationen auf reale Oberflächen, um interaktive Erlebnisse zu schaffen.
- **Superimposition-based AR**: Überlagert digitale Informationen auf reale Objekte, um zusätzliche Informationen bereitzustellen.

### Anwendungsbereiche von Augmented Reality
- **Bildung**: Interaktive Lernumgebungen, die komplexe Konzepte visuell darstellen.
- **Medizin**: Unterstützung bei chirurgischen Eingriffen durch Überlagerung von Informationen auf den Patienten.
- **Einzelhandel**: Virtuelle Anprobe von Kleidung oder Möbeln in der eigenen Umgebung.
- **Gaming**: Spiele, die die reale Umgebung einbeziehen, wie Pokémon GO.
- **Industrie**: Wartung und Reparatur durch Bereitstellung von Anleitungen und Informationen in Echtzeit.

### Vorteile von Augmented Reality
- **Verbesserte Benutzererfahrung**: Interaktive und immersive Erlebnisse, die das Lernen und die Interaktion fördern.
- **Effizienzsteigerung**: Schnellere Entscheidungsfindung durch sofortige Informationen und visuelle Unterstützung.
- **Zugänglichkeit**: Erleichterter Zugang zu Informationen und Schulungen in verschiedenen Bereichen.

### Herausforderungen und Einschränkungen
- **Technologische Limitierungen**: Abhängigkeit von Hardware und Software, die möglicherweise nicht immer verfügbar oder leistungsfähig sind.
- **Datenschutz**: Bedenken hinsichtlich der Erfassung und Nutzung von Benutzerdaten.
- **Benutzerakzeptanz**: Notwendigkeit, Benutzer an neue Technologien und Interaktionsmethoden heranzuführen.

### Wichtige Begriffe
- **AR-Toolkit**: Software-Frameworks zur Entwicklung von AR-Anwendungen.
- **Computer Vision**: Technologie, die es Computern ermöglicht, die reale Welt zu erkennen und zu interpretieren.
- **Interaktive Inhalte**: Digitale Informationen, die Benutzer aktiv einbeziehen und mit denen sie interagieren können.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## 1. Definition
- **Automatisierung von Geschäftsprozessen**: Der Einsatz von Technologien, um manuelle Aufgaben und Abläufe in Unternehmen zu optimieren, zu beschleunigen und zu vereinfachen.

## 2. Ziele der Automatisierung
- **Effizienzsteigerung**: Reduzierung der Bearbeitungszeiten und Optimierung der Ressourcennutzung.
- **Fehlerreduktion**: Minimierung menschlicher Fehler durch automatisierte Systeme.
- **Kostensenkung**: Langfristige Einsparungen durch reduzierte Betriebskosten und weniger Nacharbeiten.
- **Verbesserung der Qualität**: Höhere Konsistenz und Zuverlässigkeit der Ergebnisse.
- **Wettbewerbsvorteil**: Schnelleres Reagieren auf Marktveränderungen und Verbesserung der Kundenbindung.

## 3. Vorteile der Automatisierung
- **Produktivitätssteigerung**: Mitarbeiter können sich auf wertschöpfende Tätigkeiten konzentrieren.
- **Skalierbarkeit**: Automatisierte Prozesse können leichter an wachsende Anforderungen angepasst werden.
- **Transparenz**: Bessere Nachverfolgbarkeit von Prozessen und Ergebnissen.
- **Kundenzufriedenheit**: Schnellere und fehlerfreie Dienstleistungen führen zu höherer Kundenzufriedenheit.

## 4. Herausforderungen der Automatisierung
- **Hohe Anfangsinvestitionen**: Kosten für Softwareentwicklung und Implementierung.
- **Widerstand gegen Veränderungen**: Mitarbeiter könnten Bedenken hinsichtlich Arbeitsplatzsicherheit haben.
- **Technologische Abhängigkeit**: Abhängigkeit von Software und Technologie kann Risiken bergen.
- **Schulungsbedarf**: Notwendigkeit, Mitarbeiter im Umgang mit neuen Systemen zu schulen.

## 5. Schritte zur Implementierung
1. **Bedarfsanalyse**: Identifikation der Prozesse, die automatisiert werden sollen.
2. **Auswahl der Technologie**: Entscheidung für geeignete Softwarelösungen oder externe Dienstleister.
3. **Planung und Design**: Entwicklung eines detaillierten Plans für die Automatisierung.
4. **Implementierung**: Durchführung der Automatisierung und Integration in bestehende Systeme.
5. **Schulung**: Training der Mitarbeiter im Umgang mit den neuen Prozessen und Technologien.
6. **Monitoring und Optimierung**: Kontinuierliche Überwachung der automatisierten Prozesse und Anpassungen bei Bedarf.

## 6. Beispiele für automatisierte Prozesse
- **Rechnungsstellung**: Automatisierte Erstellung und Versendung von Rechnungen.
- **Kundenservice**: Einsatz von Chatbots zur Beantwortung häufig gestellter Fragen.
- **Lagerverwaltung**: Automatisierte Bestandsüberwachung und Nachbestellung.
- **Personalverwaltung**: Automatisierung von Urlaubsanträgen und Zeiterfassung.


- Autonome Systeme sind Technologien, die in der Lage sind, s**elbstständig Entscheidungen** zu treffen und Aktionen auszuführen, **ohne menschliches Eingreifen**. Sie nutzen **Sensoren**, **Algorithmen** und **Aktuatoren**, um ihre Umgebung zu analysieren und darauf zu reagieren.

## Veränderungen von Einsatzfeldern

### Einsatzfelder autonomer Systeme
- **Transport und Logistik**: 
  - **Beispiele**: Autonome Fahrzeuge, Drohnen für Lieferungen.
  - **Veränderungen**: Effizienzsteigerung, Reduzierung von Transportkosten, Verbesserung der Sicherheit im Straßenverkehr.
- **Industrie und Fertigung**: 
  - **Beispiele**: Roboter in der Produktion, autonome Fertigungssysteme.
  - **Veränderungen**: Erhöhung der Produktionsgeschwindigkeit, Flexibilität in der Fertigung, Reduzierung von menschlichen Fehlern.
- **Landwirtschaft**: 
  - **Beispiele**: Autonome Traktoren, Drohnen zur Überwachung von Feldern.
  - **Veränderungen**: Präzisere Bewirtschaftung, Erhöhung der Ernteerträge, Reduzierung des Ressourcenverbrauchs.
- **Gesundheitswesen**: 
  - **Beispiele**: Roboterassistenten, autonome chirurgische Systeme.
  - **Veränderungen**: Verbesserung der Patientenversorgung, Unterstützung von medizinischem Personal, Erhöhung der Präzision bei Eingriffen.

### Technologische Trends
- **Vernetzung**: 
  - Autonome Systeme sind oft Teil eines vernetzten Ökosystems (z.B. IoT), was den Austausch von Daten und die Zusammenarbeit zwischen Systemen ermöglicht.
- **Integration von KI**: 
  - Künstliche Intelligenz ermöglicht es autonomen Systemen, aus Erfahrungen zu lernen und ihre Entscheidungen zu optimieren.
- **Big Data**: 
  - Die Analyse großer Datenmengen verbessert die Entscheidungsfindung und die Anpassungsfähigkeit autonomer Systeme.
- **Cloud-Computing**: 
  - Bereitstellung von Rechenleistung und Speicherplatz in der Cloud ermöglicht komplexe Berechnungen und Datenanalysen in Echtzeit.

### Herausforderungen und Risiken
- **Sicherheit**: 
  - Autonome Systeme müssen gegen Cyberangriffe geschützt werden, um ihre Integrität und Funktionalität zu gewährleisten.
- **Regulierung**: 
  - Die rechtlichen Rahmenbedingungen für den Einsatz autonomer Systeme sind oft unklar und müssen weiterentwickelt werden.
- **Akzeptanz**: 
  - Die Akzeptanz von autonomen Systemen in der Gesellschaft ist entscheidend für deren Erfolg. Bedenken hinsichtlich Sicherheit und Arbeitsplatzverlust müssen adressiert werden.

### Wichtige Begriffe
- **Autonome Systeme**: Technologien, die selbstständig Entscheidungen treffen und handeln.
- **[[IoT]] (Internet of Things)**: Vernetzung von Geräten, die Daten austauschen und miteinander kommunizieren.
- **Künstliche Intelligenz ([[KI]])**: Technologien, die es Maschinen ermöglichen, menschenähnliche Entscheidungen zu treffen.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Kopie** von Daten, die an einem **anderen Ort** aufbewahrt wird um **Datenverlust** durch **Hardware-**, **Softwarefehler** und **menschliches Versagen**, **Hackerangriffe** oder **Naturkatastrophe** zu **vermeiden**

## Gründe für Backups
- **Datenwiederherstellung**: Ermöglicht die Wiederherstellung verlorener oder beschädigter Daten.
- **Sicherheit**: Schutz vor Ransomware oder Malware-Angriffen.
- **Gesetzliche Vorgaben**: Unternehmen müssen oft bestimmte Daten über Jahre aufbewahren.
- **Kontinuität**: Sicherstellung des Geschäftsbetriebs bei IT-Problemen.

## Backup-Arten
- **Vollbackup**
	- **Vollständige** Sicherung der Daten
	- **Vorteil**, alle Daten stehen bei einem Verlust zur Verfügung
	- **Nachteil**, Zeitaufwendig und benötigt viel Speicherplatz
- **Inkrementelles Backup**
	- Sichert nur Daten die sich **seit letztem Backup** (egal ob Voll- oder inkrementell) **geändert** haben
	- **Vorteil**, spart Speicherplatz und Zeit
	- **Nachteil**, langsame Wiederherstellung -> Kombination mehrer Backups
- **Differenzielles Backup**
	- **Alle Änderungen** seit **letzten Vollbackup**
	- **Vorteil**, schneller als inkrementell bei Wiederherstellung
	- **Nachteil**, wird mit Zeit größer je nachdem wie lange seit letztem Vollbackup
- **Spiegelung (Mirroring)**
	- **Echtzeit-Kopie** von Daten auf externen Speicher
	- **Vorteil**, Permanente Verfügbarkeit der neusten Datne
	- **Nachteil**, kein Schutz vor versehentlichem Löschen, Änderungen werden sofort übernommen

## Backup-Strategien
- **3-2-1-Strategie**
	- **3 Kopien** (Produktivdaten + 2 Backups)
	- **2 verschiedene Medien** (z.B. Festplatte und Cloud)
	- **1 Kopie extern** (Offsite-Backup, z.B. andere geographische Lage, in der Cloud)
- **Grandfather-Father-Son (GFS)**
	- **Kombination** aus täglichen, wöchentlichen und monatlichen Backups
		- **Täglich (Son)**, Inkrementelle oder differenzielles Backup
		- **Wöchentlich (Father)**, Differenzielles Backup
		- **Monatlich (Grandfather)**, Vollbackup
	- **Vorteil**: Langfristig und flexible Datensicherung
- **Towers of Hanoi**
	- komplexere Methode mit weniger Backups, jedoch **intelligentem Rotationsprinzip**
	- **Vorteil**, spart Speicherplatz, ausgeklügelte Zeitplanung
	- **Nachteil**, Schwierig umzusetzen und weniger verbreitet

## Wichtige Begriffe

- **RPO (Recovery Point Objective)**: Maximale Menge an Daten, die verloren gehen kann (Zeitraum zwischen den Backups).
- **RTO (Recovery Time Objective)**: Maximale Zeitspanne, die für die Wiederherstellung der Daten benötigt wird.
- **Backup-Fenster**: Zeitraum, in dem das Backup durchgeführt wird. Optimalerweise außerhalb der Arbeitszeiten.
- **Hot/Cold/Offline Backup**:
    - **Hot Backup**: Backup während der Betriebszeit (Datenbank läuft weiter).
    - **Cold Backup**: Backup bei ausgeschaltetem System.
    - **Offline Backup**: Backup auf nicht verbundene Systeme (z.B. externe Festplatten, die vom Netzwerk getrennt sind).

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed14f7-2ab8-800b-be61-aa7b9d421115

## Definition
- **Barrierefreiheit**: Gestaltung von IT-Systemen, Websites und Anwendungen, die es **Menschen mit unterschiedlichen Fähigkeiten** ermöglicht, diese **ohne Einschränkungen** zu nutzen.

## Zielgruppen
- Menschen mit:
  - **Sehbehinderungen** (z.B. Blinde, Farbblinde)
  - **Hörbehinderungen** (z.B. Gehörlose)
  - **Körperlichen Einschränkungen** (z.B. motorische Einschränkungen)
  - **Kognitiven Beeinträchtigungen** (z.B. Lernschwierigkeiten)

## Wichtige Standards und Richtlinien
- **WCAG (Web Content Accessibility Guidelines)**: Richtlinien zur Verbesserung der Zugänglichkeit von Webinhalten.
  - **Prinzipien**: Wahrnehmbar, Bedienbar, Verständlich, Robust.
- **BITV (Barrierefreie-Informationstechnik-Verordnung)**: Deutsche Verordnung zur Barrierefreiheit von Websites öffentlicher Stellen.

## Technische Maßnahmen
- **Semantisches HTML**: Verwendung von HTML-Elementen, die die Struktur und Bedeutung des Inhalts klar definieren.
- **Alt-Texte**: Beschreibungen für Bilder, die von Screenreadern vorgelesen werden.
- **Tastatur-Navigation**: Sicherstellen, dass alle Funktionen auch ohne Maus zugänglich sind.
- **Kontraste und Schriftgrößen**: Ausreichende Farbkontraste und anpassbare Schriftgrößen für bessere Lesbarkeit.

## Testing und Evaluation
- **Usability-Tests**: Einbeziehung von Menschen mit Behinderungen in den Testprozess.
- **Automatisierte Tools**: Verwendung von Tools zur Überprüfung der Barrierefreiheit (z.B. WAVE, Axe).

## Best Practices
- **Inklusive Design-Prinzipien**: Berücksichtigung der Vielfalt der Nutzer von Anfang an.
- **Schulung**: Sensibilisierung von Entwicklern und Designern für Barrierefreiheit.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Grundlagen von Bash
- **Definition**: Bash ist eine **Unix-Shell** und Kommandozeilen-Interpreter, die als Standard-Shell in vielen Linux-Distributionen und macOS verwendet wird.
- **Zweck**: Ermöglicht die **Ausführung von Befehlen**, **Skripten** und die **Automatisierung von Aufgaben**.

## Wichtige Befehle
- **`ls`**: Listet Dateien und Verzeichnisse auf.
- **`cd`**: Wechselt das Verzeichnis.
- **`pwd`**: Zeigt das aktuelle Verzeichnis an.
- **`cp`**: Kopiert Dateien oder Verzeichnisse.
- **`mv`**: Verschiebt oder benennt Dateien oder Verzeichnisse um.
- **`rm`**: Löscht Dateien oder Verzeichnisse.
- **`echo`**: Gibt Text oder Variablen aus.
- **`cat`**: Zeigt den Inhalt von Dateien an.

## Variablen
- **Definition**: Variablen speichern Daten, die in Skripten verwendet werden können.
- **Deklaration**: `variable_name=value` (z. B. `name="Welt"`).
- **Zugriff**: Mit `$variable_name` (z. B. `echo "Hallo, $name"`).

## Kontrollstrukturen
- **Bedingte Anweisungen**: 
  - `if [ condition ]; then ... fi`
  - `case`-Anweisung für mehrere Bedingungen.
  
- **Schleifen**:
  - `for`-Schleife: `for i in {1..5}; do ... done`
  - `while`-Schleife: `while [ condition ]; do ... done`

## Funktionen
- **Definition**: Funktionen gruppieren Befehle zur Wiederverwendung.
- **Syntax**: 
  ```bash
  function_name() {
      # Befehle
  }
  ```

## Skripterstellung
- **Shebang**: `#!/bin/bash` am Anfang eines Skripts, um die Bash-Shell zu definieren.
- **Ausführbar machen**: `chmod +x script.sh` zur Erteilung von Ausführungsrechten.
- **Ausführen**: `./script.sh` oder `bash script.sh`.

## Nützliche Tipps
- **Tab-Vervollständigung**: Automatisches Vervollständigen von Befehlen und Dateinamen durch Drücken der Tab-Taste.
- **Verlauf**: Mit den Pfeiltasten durch die Befehlsverlauf navigieren.
- **Hilfe**: `man command` für die Handbuchseite eines Befehls.

## Fazit
Bash ist ein leistungsfähiges Werkzeug zur Automatisierung und Verwaltung von Systemaufgaben. Ein grundlegendes Verständnis der Befehle, Variablen und Kontrollstrukturen ist entscheidend für die effektive Nutzung von Bash in der Systemadministration und Programmierung.


## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- systematischer Prozess des **Vergleichens und Messens** der eigenen Produkte, Dienstleistungen oder Prozesse mit den besten Praktiken anderer Unternehmen oder Organisationen.

## Ziele
- Leistungsverbesserung
- Identifizierung von Best Practices
- Wettbewerbsvorteile erzielen
- Innovationen fördern

## Arten des Benchmarking
1. **Internes Benchmarking**
	- Vergleich innerhalb der eigenen Organisation
2. **Wettbewerbsorientiertes Benchmarking**
	- Vergleich mit direkten Konkurrenten
3. **Funktionales Benchmarking**
	- Vergleich ähnlicher Prozesse in unterschiedlichen Branchen
4. **Generisches Benchmarking**
	- Vergleich mit branchenfremden Unternehmen
## Benchmarking-Prozess
1. Planung und Vorbereitung
2. Datensammlung
3. Analyse der Daten
4. Ableitung von Maßnahmen
5. Umsetzung und Kontrolle

## Vorteile
- Objektive Bewertung der eigenen Leistung
- Identifikation von Verbesserungspotentialen
- Förderung von kontinuierlicher Verbesserung
- Steigerung der Wettbewerbsfähigkeit

## Herausforderungen
- Datenverfügbarkeit und -qualität
- Vergleichbarkeit der Daten
- Zeitaufwand und Kosten
- Akzeptanz und Umsetzung der Ergebnisse

## Best Practices für erfolgreiches Benchmarking
- Klare Zielsetzung definieren
- Geeignete Benchmarking-Partner auswählen
- Ethische Richtlinien beachten
- Regelmäßige Durchführung für kontinuierliche Verbesserung


- Daten die in **großer Vielfalt**, **großen Mengen** und mit **hoher Geschwindigkeit**
	- *Variety*, *Volume*, *Velocity*
- Möglichkeit **geschäftliche Probleme anzugehen**


## Grundprinzipien

### Volumen
- **Unstrukturierte Daten**: Daten, die nicht in einem festen Format vorliegen.
- **Beispiele**: 
  - Datenfeeds (z.B. von sozialen Medien)
  - Clickstreams (Nutzerverhalten auf Webseiten)
  - Sensorgestützte Geräte (IoT-Daten)
- **Herausforderung**: Speicherung und Verarbeitung großer Datenmengen.

### Velocity
- **Schnelligkeitsrate**: Geschwindigkeit, mit der Daten generiert und verarbeitet werden.
- **Echtzeitauswertung**: Analyse von Daten in dem Moment, in dem sie erzeugt werden.
- **Technologien**: Stream Processing, In-Memory Computing.
- **Anwendungen**: Finanztransaktionen, Online-Überwachung.

### Variety
- **Traditionelle Datentypen**: Strukturierte Daten (z.B. Datenbanken).
- **Neue Datentypen**: Unstrukturierte (z.B. Texte, Bilder) und semi-strukturierte Daten (z.B. XML, JSON).
- **Integration**: Herausforderung der Datenintegration aus verschiedenen Quellen.

### Value
- **Wert in Big Data finden**: Identifikation von Mustern, Trends und Erkenntnissen.
- **Datenanalyse**: Nutzung von Analysetools und Algorithmen zur Wertschöpfung.
- **Business Intelligence**: Entscheidungsfindung basierend auf Datenanalysen.

### Veracity *(Richtigkeit)*
- **Datenqualität**: Überprüfung der Genauigkeit und Zuverlässigkeit von Daten.
- **Herausforderungen**: Inkonsistenzen, Fehlerquellen, Datenverzerrungen.
- **Vertrauenswürdigkeit**: Methoden zur Validierung und Verifizierung von Daten.

### Weitere Aspekte
- **Datenethik**: Verantwortung im Umgang mit Daten.
- **Datensicherheit**: Schutz von sensiblen Informationen.
- **Datenvisualisierung**: Darstellung von Daten zur besseren Verständlichkeit.
- **Machine Learning**: Einsatz von Algorithmen zur Mustererkennung in großen Datensätzen. 

## Anwendungsfälle
- **Produktentwicklung**, Kundennachfrage vorhersagen, Produkte entwickeln
- **Prädiktive Wartung**, mechanische Fehler prognostizieren
- **Betrug und Compliance**, Betrugsmuster erkennen, regulatorische Reportings beschleunigen
- **Maschinelles Lernen**, Big Data ist Grundlage

## Herausforderungen
- **große** und **schnelllebigkeit** der Daten
- Daten müssen kuratiert werden

## Funktionsweise
1. **Integration**, *Erfassung* und *Verarbeitung der Daten*, formatieren der Daten um Format für Geschäftsanalysen vorliegen
2. **Verwalten**, Speicherlösung in Cloud, On-Premise oder hybrid Lösung
3. **Analysieren**, Grundlage für Entscheidungen, ...


## Quellen

> Tiao, S. (2024). What is Big Data? Oracle. Retrieved from https://www.oracle.com/de/big-data/what-is-big-data/#value

- dezentrale **Datenbank**: Datenspeicherung auf allen Rechnern in der **Blockkette**
- **Blöcke**: enthalten Datensätze von Transaktionen o. Ä.
- jeder Nutzer speichert eine Kopie
- fehlerhafte Kopien können von Teilnehmern aussortiert werden

## Funktionsweise
- bestimmte **Informationen** werden als Datensatz in einem Block **verpackt**. Ein Block enthält:
  - Daten
  - [[Hashing|Hash]] der Daten
  - [[Hashing|Hash]] des vorherigen Blocks
- durch Referenzierung des vorherigen Blocks haben Änderungen **hohen Rechenaufwand**
- der erste Block in einer Blockchain wird als **Genesis Block** bezeichnet
- **Proof of Work**: Aufgabe, die erfüllt werden muss, um einen Block zu generieren; verlangsamt die Block-Kalkulation
- **Konsens** über Blöcke, die zur Chain hinzugefügt werden

## Anwendungsgebiete
- **Finanzwesen**: Kryptowährungen, internationale Überweisungen, Smart Contracts
- **Lieferkettenmanagement**: Verfolgung von Produkten, Transparenz, Betrugsbekämpfung
- **Gesundheitswesen**: Sichere Speicherung von Patientendaten, Interoperabilität, Datenintegrität
- **Identitätsmanagement**: Digitale Identitäten, Verifizierung, Datenschutz
- **Energie**: Peer-to-Peer-Energiehandel, dezentrale Energieversorgung
- **Immobilien**: Eigentumsnachweise, Smart Contracts für Transaktionen
- **Wahlen**: Sichere und transparente Abstimmungen, Verhinderung von Wahlbetrug
- **Urheberrecht**: Schutz von geistigem Eigentum, Lizenzierung, Verteilung von Einnahmen
- **Gaming**: Digitale Sammlerstücke (NFTs), In-Game-Transaktionen, dezentrale Spiele
- **Öffentliche Verwaltung**: Transparente Aufzeichnungen, Bürgerdienste, Betrugsbekämpfung

## Vor- und Nachteile
- **Vorteile**
	- langfristige Dokumentation, hohe Transparenz
	- dezentrale Speicherung
	- Manipulation fast unmöglich
- **Nachteile**
	- massiver Speicheraufwand
	- Geschwindigkeit der Transaktionen niedrig
	- kostenintensiv durch hohen Energieverbrauch

## Quellen

> Blockchain einfach erklärt. (2023, November 10). Retrieved from https://studyflix.de/informatik/blockchain-einfach-erklaert-7344  
> Explained, S. (2017, November 13). Wie funktioniert eine Blockchain - Einfach erklärt. YouTube. Retrieved from https://www.youtube.com/watch?v=SSo_EIwHSd4  
> https://duck.ai. (2024, September 18). Generierte Informationen über Blockchain. DuckDuckGo AI Chat.



| **Kriterium**              | **BPMN (Business Process Modelling Notation)**                         | **EPK (Ereignisgesteuerte Prozesskette)**           | **UML (Unified Modeling Language)**                                     |
| -------------------------- | ---------------------------------------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------------- |
| **Zweck**                  | Modellierung von Geschäftsprozessen                                    | Modellierung von Geschäftsprozessen                 | Modellierung von Software- und Systemdesign                             |
| **Darstellung**            | Umfassende Notation mit Ereignissen, Aktivitäten, Gateways und Flüssen | Einfache Darstellung von Ereignissen und Funktionen | Vielfältige Diagrammtypen (z. B. Aktivitätsdiagramme, Klassendiagramme) |
| **Komplexität**            | Hohe Flexibilität und Detailtiefe                                      | Einfachere, lineare Struktur                        | Breite der Modellierung, kann komplex sein                              |
| **Fokus**                  | Geschäftsprozessoptimierung und -automatisierung                       | Prozessabläufe und -steuerung                       | Softwarearchitektur und -design                                         |
| **Zielgruppe**             | Geschäftsanalysten, Prozessmanager                                     | Prozessmanager, Unternehmensberater                 | Softwareentwickler, Architekten                                         |
| **Unterscheidungsmerkmal** | Detaillierte Notation für komplexe Prozesse                            | Fokus auf Ereignisse und Funktionen                 | Breiter gefasst, nicht speziell auf Geschäftsprozesse ausgerichtet      |


BPMN (Business Process Modelling Notation) ist eine **grafische Notation** zur **Modellierung von Geschäftsprozessen**. Sie bietet eine standardisierte Methode, um Abläufe in Unternehmen zu visualisieren, zu analysieren und zu dokumentieren.

#### Ziele von BPMN
- **Visualisierung von Geschäftsprozessen**: Komplexe Abläufe werden verständlich und nachvollziehbar dargestellt.
- **Kommunikation zwischen Stakeholdern**: Einheitliche Sprache für Fachabteilungen, IT-Teams und Management.
- **Unterstützung der Prozessautomatisierung**: Modelle können direkt in IT-Systeme integriert werden.

#### Vorteile von BPMN
1. **Standardisierte Darstellung**:
   - Einheitliche Notation fördert das Verständnis und die Zusammenarbeit.
   - Reduziert Missverständnisse zwischen verschiedenen Abteilungen.
2. **Integration und Automatisierung**:
   - Modelle können leicht in Workflow-Management-Systeme integriert werden.
   - Effiziente Umsetzung von Prozessen durch Automatisierung.

#### Grundelemente von BPMN
![[Pasted image 20241008082632.png]]
1. **Ereignisse**:
   - **Start-Ereignis**: Kennzeichnet den Beginn eines Prozesses.
   - **End-Ereignis**: Kennzeichnet das Ende eines Prozesses.
   - **Zwischenereignisse**: Treten während des Prozesses auf und können verschiedene Auswirkungen haben.
2. **Aktivitäten**:
   - **Tasks**: Einzelne Arbeitsschritte innerhalb eines Prozesses.
   - **Sub-Prozesse**: Komplexere Aufgaben, die in einem eigenen Prozessmodell dargestellt werden können.
3. **Gateways**:
   - Steuern den Fluss des Prozesses und ermöglichen Entscheidungen (z. B. XOR, AND, OR).
4. **Verbindungen**:
   - **Sequenzflüsse**: Zeigen die Reihenfolge der Aktivitäten.
   - **Nachrichtenflüsse**: Stellen die Kommunikation zwischen verschiedenen Prozessen dar.
5. **Pools und Lanes**:
   - **Pools**: Repräsentieren verschiedene Organisationen oder Teilnehmer.
   - **Lanes**: Unterteilen Pools in spezifische Rollen oder Abteilungen.

#### Anwendungsbereiche von BPMN
- **Prozessdokumentation**: Erfassung und Visualisierung bestehender Prozesse.
- **Prozessoptimierung**: Identifikation von Schwachstellen und Verbesserungspotenzialen.
- **Schulung und Training**: Unterstützung bei der Einarbeitung neuer Mitarbeiter in Geschäftsprozesse.
- **Automatisierung**: Grundlage für die Implementierung in Workflow-Management-Systeme.

#### Herausforderungen bei der Verwendung von BPMN
- **Komplexität**: Bei sehr komplexen Prozessen kann die Modellierung unübersichtlich werden.
- **Schulungsbedarf**: Mitarbeiter müssen im Umgang mit BPMN geschult werden, um die Notation effektiv nutzen zu können.


- spezieller Punkt im Quellcode eines Programms, an dem der **Debugger die Ausführung des Programms anhält**. Dies ermöglicht Entwicklern, den aktuellen **Zustand des Programms zu untersuchen und Fehler zu identifizieren**.

## Arten von Breakpoints
- **Einfacher Breakpoint**: Hält die Ausführung an einer bestimmten Zeile im Code an.
- **Bedingter Breakpoint**: Hält die Ausführung nur an, wenn eine bestimmte Bedingung erfüllt ist (z.B. eine Variable hat einen bestimmten Wert).
- **Funktions-Breakpoint**: Hält die Ausführung an, wenn eine bestimmte Funktion aufgerufen wird, unabhängig von der Stelle im Code.
- **Hit Count Breakpoint**: Hält die Ausführung an, nachdem ein bestimmter Codeabschnitt eine festgelegte Anzahl von Malen erreicht wurde.

## Verwendung von Breakpoints
- **Fehlerdiagnose**: Entwicklern hilft, den Programmfluss zu verstehen und Fehlerquellen zu identifizieren.
- **Variableninspektion**: Ermöglicht das Überprüfen von Variablenwerten und deren Änderungen während der Programmausführung.
- **Schrittweises Debugging**: Entwickler können den Code Schritt für Schritt durchlaufen, um das Verhalten des Programms zu analysieren.

## Vorteile von Breakpoints
- **Effizienz**: Erleichtert das Auffinden und Beheben von Fehlern, was die Entwicklungszeit verkürzt.
- **Flexibilität**: Entwickler können Breakpoints nach Bedarf setzen und entfernen, um verschiedene Teile des Codes zu testen.
- **Verbesserte Fehleranalyse**: Detaillierte Einblicke in den Programmzustand zur besseren Analyse von Problemen.

## Herausforderungen
- **Übermäßiger Einsatz**: Zu viele Breakpoints können die Debugging-Sitzung unübersichtlich machen und die Leistung des Debuggers beeinträchtigen.
- **Bedingungen**: Komplexe Bedingungen für bedingte Breakpoints können schwer zu formulieren und zu verstehen sein.
- **Performance-Einfluss**: Das Setzen von Breakpoints kann die Ausführungsgeschwindigkeit des Programms beeinträchtigen, insbesondere in zeitkritischen Anwendungen.

## Best Practices
- **Strategische Platzierung**: Breakpoints an Schlüsselstellen im Code setzen, um die Analyse zu fokussieren.
- **Dokumentation**: Notieren, warum ein Breakpoint gesetzt wurde, um die Nachverfolgbarkeit zu verbessern.
- **Regelmäßige Überprüfung**: Überprüfen und Entfernen nicht mehr benötigter Breakpoints, um die Übersichtlichkeit zu wahren.

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Die **Wirtschaftlichkeit einer Investition**, eines **neuen Produktes** oder einer **neuen Dienstleistungen** untersucht. Der **Zeitpunkt** wird errechnet, ab dem eine Investition einen **Gewinn erzielen** wird bzw. die **Kosten amortisiert** sind.

## Formel
- **Investitionskosten**: Einmalige Kosten, die für die Einführung eines neuen Produktes oder einer Dienstleistung anfallen.
- **Alte Kosten**: Die laufenden Kosten, die vor der Einführung des neuen Produktes oder der Dienstleistung anfallen.
- **Neue Kosten**: Die laufenden Kosten, die nach der Einführung des neuen Produktes oder der Dienstleistung anfallen.
 
$\text{Break-even} \space Dauer=\dfrac{Investitionskosten}{Alte \space Kosten - Neue \space Kosten}$


### Beispiel
- Einführung neuer Software
- Jährliche Kosten von **10.000 EUR**
- Mitarbeiter, welcher nach einem Jahr der Softwareeinführung in Ruhestand geht, **15.000 EUR**

$$
\text{Break-even} \space \text{Dauer} = \dfrac{15.000^{1)}}{15.000 - 10.000} = 3 
$$

$^{i)}$ Da die *15.000 EUR* nur im ersten Jahr auftreten, werden diese als Investitionskosten erfasst

![[Pasted image 20241007104533.png]]

![[Pasted image 20240924082826.png]]
- **Business Process Reengineering (BPR)**: Radikale Neugestaltung von Geschäftsprozessen zur Steigerung der Qualität und Effizienz.
- Auch bekannt als „Radikalkur für das Unternehmen“.

## Zielsetzung
- Steigerung der Qualität, Senkung der Kosten und Verbesserung der Kundenzufriedenheit.
- Minimierung organisatorischer Schnittstellen.
- Fokussierung auf Kernprozesse, die Wert für Kunden schaffen.

## Wann ist BPR sinnvoll?
- In Notlagen, z.B. zur Vermeidung von Insolvenzen.
- Wenn radikale Maßnahmen zur Optimierung des Kerngeschäfts erforderlich sind.
- Überprüfung und ggf. Optimierung oder Auslagerung anderer Unternehmensprozesse.

## Methoden und Phasen des BPR
- **Vier R** (nach Michael Hammer und James Champy):
  1. **Erneuerung (Renewing)**: Wissen der Mitarbeiter fördern und einbinden.
  2. **Belebung (Revitalizing)**: Analyse der bestehenden Prozesse.
  3. **Einstellungsänderungen (Reframing)**: Fundamentales Umdenken und Aufbrechen von Denkmustern.
  4. **Neugestaltung (Restructuring)**: Etablierung neuer Prozessansätze im Unternehmen.

## Historische Perspektive
- BPR war in den 80er und 90er Jahren ein wichtiges Managementkonzept.
- Entwickelt von Michael Hammer und Thomas Davenport.
- Technologiefirmen wie SAP und Oracle förderten BPR als Lösung für Prozessneugestaltung.
- Kritiken: Hoher Fokus auf Technologie und Kostenreduzierung, Vernachlässigung der Auswirkungen auf Mitarbeiter und Unternehmenskultur.

## Vor- und Nachteile von BPR
- **Vorteile**:
  - Gesteigerte Kundenorientierung.
  - Nutzung neuer Informations- und Kommunikationstechniken.
  - Ganzheitliche Betrachtung der Prozesse.
  - Senkung der Kosten bei gleichzeitiger Qualitätssteigerung.
  - Berücksichtigung der Mitarbeiterperspektive.

- **Nachteile**:
  - Mögliche Auflösung etablierter Strukturen.
  - Personalabbau und Unzufriedenheit unter Mitarbeitern.
  - Langwieriger Prozess mit verzögerten Erfolgen.
  - Nicht für jedes Unternehmen geeignet.

## Fazit
- BPR ist ein bedeutender, aber herausfordernder Schritt zur Prozessoptimierung.
- Erfordert sorgfältige Überlegung und Planung, bietet jedoch großes Potenzial für Unternehmen.

## Wichtige Begriffe
- **Lean Management**: Ansatz zur Minimierung von Verschwendung und Maximierung von Wertschöpfung.
- **Kernprozess**: Zentrale Abläufe, die direkt zur Wertschöpfung für den Kunden beitragen.

## Tipps für die Umsetzung
- Führen Sie eine gründliche Analyse der bestehenden Prozesse durch.
- Binden Sie Mitarbeiter in den Veränderungsprozess ein.
- Setzen Sie auf technologische Unterstützung zur Prozessoptimierung.
- Kommunizieren Sie transparent über Veränderungen und deren Auswirkungen.

## Quellen

> https://der-prozessmanager.de/aktuell/wissensdatenbank/business-process-reengineering-bpr

- **gängigstes** Architekturkonzept
- klare **Verteilung von Aufgaben** zwischen Clients und Server
- **Server**, Bereitstellung von Daten und Diensten
- **Client**, Konsument von Daten und Diensten
- Ein Server bedient mehrere Clients
- Ein Computer kann sowohl Server als auch Client sein
- **Vorteile**
	- **vereinfachte** Administration und Wartung durch **Zentralisierung**
	- sicheres und globales Management von **Zugriffsrechten**
- **Nachteile**
	- Ausfall des Servers führt zum **Gesamtausfall des Systems**
	- schlechtere **Skalierbarkeit** als [[Peer-To-Peer]]
	- **zeitlicher Aufwand**
- **Anwendungsgebiete**
	- Webserver
	- E-Mail Server
	- FTP-Server
	- -> Großteil des Internet
## Quellen

> https://www.ionos.de/digitalguide/server/knowhow/client-server-modell/

- **On-Demand**-Zugriff auf **Rechenressourcen** (*physische/virtuelle Server, Datenspeicher, Netzwerkkapazitäten, Analysetools, ...*)
- **nutzungsabhängige** Bezahlung
- Cloud-Service-Provider **(CSP)** verwaltet Technologieservices in einem RZ[^1]
	- Rechenzentren, Sicherheit (Zugangskontrollen, Firewall, Feuerschutz)
	- Hardware, Redundanz, ...
	- Software, Backups, Firewall, ...

## Arten
- **Public Cloud**, CSP stellt Rechenressourcen über **öffentliches Internet** zur Verfügung (SAAS, XAAS, ...)
- **Hybrid Cloud**, Verbindung aus Public und Private Cloud, sensible Daten und Anwendungen in Private Cloud, andere in Public Cloud, Softwareseitig trotzdem nur ein Überblick
- **Multicloud**, Verwendung mehrer Cloud-Provider, weniger **Abhängigkeit** (Politik, Ausfall, ...)
- **Private Cloud**, Cloud-Infrastruktur steht nur **einem Kunden** zur Verfügung, meist lokal im RZ[^1] des Kunden

## Vorteile
- mehr **Flexibilität** und **Skalierbarkeit**
- höhere **Wirtschaftlichkeit**, Kapazitäten können geteilt werden -> keine **Investionskosten**
- geringerer **Wartungsbedarf** -> automatische Updates, bereitgestellte Infrastruktur (Feuerschutz-System), automatische Backups, ...

## Nachteile
- nicht in jedem Anwendungsfall kostengünstiger bei **hoher Nutzung**
- **Datenschutzbedenken**, Daten sind in der Hand eines Dritten
- **Abhängigkeit vom Anbieter**, bei Produkteinstellungen, Politikänderungen ...

[^1:] Rechenzentrum
## Quellen

> Was ist Cloud Computing? | IBM. (2024, September 11). Retrieved from https://www.ibm.com/de-de/topics/cloud-computing

- **Lizenz- und Vertriebsmodell**

## SaaS
- **S**oftware **a**s **a** **S**ervice
- **Software-Anwendungen** werden **über das Internet** als Service angeboten
## IaaS
- **I**nfrastructure **a**s **a** **S**ervice 
- Anbieter stellt **Hard-**, **Software**, **Speicherplatz** und weitere **Infrastruktur-Komponenten** bereit
## PaaS
- **P**latform **a**s **a** **S**ervice
- **Entwicklungsumgebung** und -**tools**, DevOps Integrationen, Monitoring und Analytics, ...
## XaaS
 - **X** *(Everything)* **a**s **a** **S**ervice
 - weitere Beispiele
	 - **D**esktop **a**s **a** **S**ervice *(DaaS)*, virtuelle Desktop-Infrastruktur
	 - **D**ata**b**ase **a**s **a** **S**ervice *(DBaaS)*, Datenbank bereitgestellt als Dienst
	 - **Sec**urity **a**s **a** **S**ervice *(SECaaS)*, Abonnement für Nutzung von Sicherheitsdiensten

## Vorteile
- geringere **Konfigurations-** und **Infrastrukturkosten**, Investionskosten etc. werden vermieden
- Zugriff **ohne räumliche Einschränkungen**
- **Skalierbarkeit** falls neue Mitarbeiter dazukommen, mehr Datenbankzugriffe erfolgen als üblich, ...

## Nachteile
- eingeschränkte **Kontrolle** und **Anpassbarkeit**, spezifische Anforderungen oder interne Anpassungen nicht immer möglich
- Abhängigkeit vom **Internet**, bei Ausfällen, etc. kein Zugriff auf Dienste
- Herausforderungen bei **Datenportabilität**, Daten gehören nicht einem sondern Service-Provider

## Quellen

> Salesforce. (2024, September 10). Retrieved from https://www.salesforce.com/de/learning-centre/tech/saas/#saas
> Redaktion, I. (2023). PaaS: Platform as a Service im Überblick. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/server/knowhow/paas-platform-as-a-service
> OpenAI. (2024). Antwort auf die Frage zu Beispielen von PaaS. Abgerufen am 11. September 2024, von [https://www.duckduckgo.com](https://www.duckduckgo.com)

- Methode zur **Gruppierung ähnlicher Datenpunkte** in Cluster.
- Ziel: Daten in **homogene Gruppen (Cluster)** einteilen, die intern möglichst ähnlich und extern möglichst unterschiedlich sind[
- Anwendung: Häufig im Marketing zur Kundensegmentierung eingesetzt[
- Vorgehen:
    1. Ähnlichkeits-/Distanzmaß definieren
    2. Clustering-Algorithmus auswählen und anwenden
    3. Optimale Clusterzahl bestimmen
    4. Ergebnisse interpretieren und validieren
- Beispiel-Algorithmen: K-Means, hierarchisches Clustering

Hier ist eine verbesserte Version Ihres Lernzettels zur K-Means Clusteranalyse:

## K-Means Clusteranalyse
K-Means ist eines der **einfachsten** und **gängigsten** Verfahren zur Clusteranalyse. Es ist ein [[Überwachtes und nicht-überwachtes Lernen|unüberwachter Lernalgorithmus]], der Datenpunkte in K vordefinierten Clustern gruppiert.
### Algorithmus
1. **Initialisierung**: Definiere die Anzahl K der Cluster und wähle K zufällige Datenpunkte als initiale Cluster-Zentren aus.
2. **Zuordnung**: Ordne jeden Datenpunkt dem nächstgelegenen Cluster-Zentrum zu, basierend auf der euklidischen Distanz.
3. **Aktualisierung**: Berechne die neuen Cluster-Zentren als Mittelwert aller Datenpunkte im jeweiligen Cluster.
4. **Iteration**: Wiederhole Schritte 2 und 3, bis die Cluster-Zentren sich nicht mehr signifikant verändern oder eine maximale Anzahl von Iterationen erreicht ist.
### Wichtige Aspekte
- **Distanzmaß**: In der Regel wird die [[Euklidische Distanz|euklidische Distanz]] verwendet, insbesondere für zweidimensionale Daten.
- **Qualitätsbewertung**: Die Qualität des Clusterings kann anhand der Varianz innerhalb der Cluster beurteilt werden. Ein Clustering mit geringerer Varianz gilt als besser.
- **Wahl von K**: Die optimale Anzahl der Cluster K kann mithilfe des "Elbow-Plots" bestimmt werden. Dieser zeigt, ab welchem Punkt die Reduktion der Varianz nicht mehr signifikant ist. (Allgemeine Varianz bestimmen, dann halt gucken ab wann Varianz nicht mehr so stark abnimmt)
### Vor- und Nachteile
- **Vorteile**:
	- Einfach zu implementieren und zu verstehen
	- Effizient bei großen Datensätzen
- **Nachteile**:
	- Ergebnis kann von der zufälligen Initialisierung abhängen
	- Vorherige Festlegung von K erforderlich
	- Kann Probleme mit nicht-konvexen Clustern haben
### Anwendungen
- Marktsegmentierung
- Dokumentenklassifizierung
- Bildkompression
- Anomalieerkennung

## Hierarchische Clusteranalyse
- Statistisches Verfahren zur Gruppierung **ähnlicher Objekte in Cluster**
- Erstellt eine hierarchische Struktur (Baum) der Cluster, genannt Dendrogramm
- Zeigt Beziehungen zwischen Objekten und wie sie auf verschiedenen Ebenen gruppiert werden

### Hauptmerkmale
- **Keine vorherige Festlegung** der Clusterzahl erforderlich
- Ermöglicht die Analyse von Clustern auf verschiedenen Detailebenen
- Ergebnis ist visuell als Baumdiagramm darstellbar

### Arten
1. Agglomerativ (bottom-up):
    - Startet mit einzelnen Datenpunkten als separate Cluster
    - Fusioniert schrittweise die ähnlichsten Cluster
2. Divisiv (top-down):
    - Beginnt mit allen Datenpunkten in einem Cluster
    - Teilt schrittweise in kleinere Cluster auf

### Algorithmus (agglomerativ)
1. Jeder Datenpunkt bildet zunächst ein eigenes Cluster
2. Berechnung der Distanzen zwischen allen Clustern
3. Fusion der zwei ähnlichsten Cluster
4. Wiederholung der Schritte 2-3 bis alle Objekte in einem Cluster sind

### Distanzmaße
- [[Euklidische Distanz]]
- Manhattan-Distanz
	- Summe der absoluten Differenzen der Koordinaten zweier Punkte
	- Auch bekannt als "Cityblock-Distanz" oder "L1-Norm"
	- Misst Entfernung entlang rechtwinkliger Achsen
	- z.B. $P_1(4,5), P_2(20, 2) = \vec{P_1P_2}= |20-4| + |2-5| = 16 + 3 = 19$

### Fusionsmethoden
![[Pasted image 20241002144231.png]]
- Single-Linkage: Kleinste Distanz zwischen Clustern
![[Pasted image 20241002144239.png]]
- Complete-Linkage: Größte Distanz zwischen Clustern
![[Pasted image 20241002144248.png]]
- Average-Linkage: Durchschnittliche Distanz zwischen Clustern

### Vorteile
- Flexibel in der Clusterzahl
- Hierarchische Struktur ermöglicht detaillierte Analyse
- Gut für kleine bis mittlere Datensätze geeignet

### Nachteile
- Rechenintensiv für große Datensätze
- Einmal getroffene Entscheidungen sind nicht revidierbar
- Anfällig für Ausreißer

### Anwendungsgebiete
- Bioinformatik (z.B. Genexpressionsanalyse)
- Marktforschung (Kundensegmentierung)
- Dokumentenklassifikation
- Sozialwissenschaften (Gruppenbildung)

- **Einhaltung** von **Gesetzen, Vorschriften, Standards** und **internen Richtlinien**, die für eine Organisation relevant sind. Ziel ist es, **rechtliche und ethische Standards** einzuhalten, um Risiken zu minimieren und das **Vertrauen** von Stakeholdern zu gewinnen.

## Arten von Compliance
- **Regulatorische Compliance**: Einhaltung von gesetzlichen Vorschriften und Auflagen, die von staatlichen oder internationalen Behörden festgelegt werden.
- **Normen-Compliance**: Einhaltung von branchenspezifischen Standards, wie ISO-Normen oder PCI-DSS (Payment Card Industry Data Security Standard).
- **Interne Compliance**: Einhaltung interner Richtlinien und Verfahren, die von der Organisation selbst festgelegt werden.
- **Ethik-Compliance**: Sicherstellung, dass die Geschäftspraktiken ethischen Standards entsprechen und die Unternehmenswerte widerspiegeln.

## Anforderungen
- **Dokumentation**: Erstellung und Pflege von Dokumenten, die die Einhaltung von Vorschriften und Standards nachweisen.
- **Schulung**: Regelmäßige Schulungen für Mitarbeiter, um das Bewusstsein für Compliance-Anforderungen zu schärfen.
- **Überwachung und Audits**: Durchführung von regelmäßigen Überprüfungen und Audits, um die Einhaltung zu gewährleisten und Schwachstellen zu identifizieren.
- **Berichterstattung**: Transparente Berichterstattung über Compliance-Aktivitäten und -Ergebnisse an das Management und relevante Behörden.

## Vorteile
- **Risikominimierung**: Reduzierung von rechtlichen und finanziellen Risiken durch die Einhaltung von Vorschriften.
- **Vertrauen und Reputation**: Stärkung des Vertrauens von Kunden, Partnern und Investoren durch transparente und ethische Geschäftspraktiken.
- **Wettbewerbsvorteil**: Unternehmen, die Compliance ernst nehmen, können sich von Wettbewerbern abheben und neue Geschäftsmöglichkeiten erschließen.
- **Effizienzsteigerung**: Klare Richtlinien und Verfahren können die Effizienz und Produktivität innerhalb der Organisation verbessern.

## Herausforderungen
- **Komplexität**: Die Vielzahl an Vorschriften und Standards kann überwältigend sein und erfordert ständige Aktualisierung.
- **Ressourcenaufwand**: Compliance-Programme erfordern Zeit, Geld und personelle Ressourcen, die möglicherweise nicht immer verfügbar sind.
- **Kulturelle Barrieren**: Widerstand gegen Veränderungen in der Unternehmenskultur kann die Implementierung von Compliance-Maßnahmen erschweren.
- **Technologische Entwicklungen**: Die schnelle Entwicklung neuer Technologien kann die Einhaltung bestehender Vorschriften komplizieren.

## Quellen
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **einheitliche Erscheinungsbild** und die **Identität** eines Unternehmens. Sie umfasst alle visuellen, kommunikativen und verhaltensbezogenen Aspekte, die das Unternehmen nach außen und innen repräsentieren.

## Elemente der Corporate Identity
- **Corporate Design**: Das visuelle Erscheinungsbild des Unternehmens, einschließlich Logo, Farben, Schriftarten und Gestaltungselementen.
- **Corporate Communication**: Die Art und Weise, wie das Unternehmen mit seinen Stakeholdern kommuniziert, einschließlich Werbung, PR und interne Kommunikation.
- **Corporate Behavior**: Das Verhalten und die Werte, die das Unternehmen verkörpert, einschließlich der Unternehmenskultur und des Verhaltens der Mitarbeiter.

## Ziele der Corporate Identity
- **Wiedererkennung**: Schaffung eines einheitlichen und wiedererkennbaren Erscheinungsbildes, das das Unternehmen von Wettbewerbern abhebt.
- **Vertrauen und Glaubwürdigkeit**: Aufbau von Vertrauen bei Kunden, Partnern und Mitarbeitern durch konsistente Kommunikation und Verhalten.
- **Markenidentität**: Stärkung der Markenidentität und -wahrnehmung, um eine emotionale Bindung zu den Kunden aufzubauen.
- **Mitarbeiterbindung**: Förderung einer positiven Unternehmenskultur, die Mitarbeiter motiviert und an das Unternehmen bindet.

## Vorteile der Corporate Identity
- **Konsistenz**: Einheitliche Darstellung des Unternehmens in allen Kommunikationskanälen, was zu einem klaren und professionellen Image führt.
- **Wettbewerbsvorteil**: Differenzierung von Wettbewerbern durch ein starkes und einzigartiges Markenimage.
- **Kundenzufriedenheit**: Verbesserung der Kundenzufriedenheit durch klare Werte und Botschaften, die die Erwartungen der Kunden erfüllen.
- **Langfristiger Erfolg**: Stärkung der Marktposition und des langfristigen Erfolgs durch eine starke und konsistente Corporate Identity.

## Herausforderungen
- **Ressourcenzuweisung**: Notwendigkeit, Ressourcen für die Entwicklung und Pflege der Corporate Identity bereitzustellen.
- **Anpassungsfähigkeit**: Die CI muss an sich ändernde Marktbedingungen und Kundenbedürfnisse angepasst werden.
- **Interne Akzeptanz**: Sicherstellung, dass alle Mitarbeiter die CI verstehen und leben, um eine konsistente Umsetzung zu gewährleisten.
- **Krisenmanagement**: Umgang mit Krisen, die das Image des Unternehmens beeinträchtigen können, und die Notwendigkeit, die CI entsprechend anzupassen.

## Quellen
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Modell für einheitliches Data Mining

![[Pasted image 20241008092942.png]]

## Ziele
- Schaffung eines einheitlichen Prozesses-und Vorgehensmodell
- Übergreifende Nutzung in verschiedenen Branchen

## Phasen

### 1. Business Understanding
- konkrete Beschreibung der **betriebswirtschaftlichen Problemstellung**
- **Situationsbewertung**: Software- und Personalressourcen bestimmen, mögliche Risiken identifizieren
- ausgehend von **betriebswirtschaftlicher Problemstellung** werden **Datenanalyseaufgaben** bestimmt (z.B. Kundensegmentierung, Scoring-Verfahren, etc.). **Erfolgskriterien** werden festgelegt (z.B. Steigerung der Antwortquote von Kampagnen um 3%) 
- **Projektplan** erstellen
	- Auflistung einzelner *Schritte mit Zeitspanne*
	- Beurteilung möglicher *Risiken* (Verzögerungen, Ursachen für Scheitern des Projektes)
	- Prüfung der zur *Verfügung stehender Ressourcen* (Mitarbeiter, Hardware, Software, ...)
### 2. Data Understanding
- **Daten sammeln**: Beschaffung der Daten, wenn erforderlich Integration der Daten in eine bestehende Datenmenge. Dokumentation von Problemen. 
- **Daten beschreiben**: Quantität der Daten, Formateigenschaften, Anzahl der Einträge und Felder, Eigenschaften der Felder. *Reichen vorliegende Daten für Projekterfolg?*
- **Untersuchung der Daten**: erste Analysen (z.b. Produktgruppen identifizieren). Erstellung von Reports, Erkenntnisse und Hypothesen visualisieren
- **Bewertung der Daten**: Bewertung der Qualität, Datenmenge ausreichend für Analyse, auf fehlende Attributwerte achten

## 3. Data Preparation
- **Auswahl** der Daten: hängt stark von den Zielen ab, Selektion von Daten wird vorgenommen (z.B. Kunden mit Umsatz > 100€/Monat), Eindeutig welche Datenmengen(-Sets) in Analyse aufgenommen/ausgeschlossen werden
- **Bereinigung** der Daten: sauberere Datenmenge auswählen oder Bereinigung der Daten um gewünschtes Ergebnis für Modellierung zu erreichen
- **Transform** und **Integration** der Daten: Kodierung der Daten, Aggregation/Disaggregation. Erstellung von wichtigen Kennzahlen (Durchschnittsgehalt, ...)
- Daten **formatieren**: Anpassung des Datentyps für Model

## 4. Modeling
- Auswahl der **Modellierungstechnik**
- **Testmodell** erstellen: Qualität und Genauigkeit des Modells überprüfen, bei überwachten Verfahren (z.B. Klassifikation) Fehlerraten als Qualitätsmaß
- Modell **bewerten**: auf definierte Data Mining Ziele und betriebswirtschaftliche Fragestellung hin bewerten  

## 5. Evaluation
- **Ergebnisse bewerten**: inwieweit hat Modell *Projektziele* erreicht, bei Nicht-Erreichung Gründe
- **Prozess bewerten**: Projekt wird rückblickend bewertet, alle wichtigen Faktoren berücksichtigt? Inwieweit Attribute für zukünftige Projekte nutzbar?
- **Nächsten Schritte festlegen**: Projektleiter entscheidet ob Projekt abgeschlossen und umgesetzt wird

## 6. Deployment
- **letzte Phase**
- gewonnene **Erkenntnisse** werden **aufbereitet**, z.B. mögliche Implementierungsstrategie
- Überprüfung der **Gültigkeit der Modelle**
- **zusammenfassender Bericht** und Präsentation

# Quellen

> Wuttke, L. (2024). CRISP-DM: das Standard-Vorgehensmodell für Data Mining. Datasolut GmbH. Retrieved from https://datasolut.com/crisp-dm-standard

Customer Relationship Management (CRM) bezeichnet **Strategien, Technologien und Praktiken**, die Unternehmen einsetzen, um ihre **Interaktionen und Beziehungen zu bestehenden und potenziellen Kunden zu verwalten**. Ziel von CRM ist es, die Kundenzufriedenheit zu erhöhen, die Kundenbindung zu stärken und den Umsatz zu steigern.

## Wichtige Aspekte von CRM
- **Datenmanagement**: CRM-Systeme sammeln und speichern umfangreiche Daten über Kunden, einschließlich Kontaktdaten, Kaufhistorie, Vorlieben und Interaktionen.
- **Kundensegmentierung**: Kunden werden in Gruppen eingeteilt, um gezielte Marketingstrategien und personalisierte Angebote zu entwickeln.
- **Interaktionsmanagement**: CRM ermöglicht die Nachverfolgung aller Interaktionen mit Kunden über verschiedene Kanäle, einschließlich E-Mail, Telefon, Social Media und persönliche Treffen.

## Funktionen von CRM-Systemen
- **Vertrieb**: Unterstützung des Vertriebsteams bei der Verwaltung von Leads, Opportunities und Verkaufsprozessen. CRM-Systeme bieten Tools zur Prognose von Verkaufszahlen und zur Analyse von Verkaufsdaten.
- **Marketing**: Automatisierung von Marketingkampagnen, Segmentierung von Zielgruppen und Analyse der Kampagnenleistung. CRM-Systeme helfen, personalisierte Marketingbotschaften zu erstellen.
- **Kundenservice**: Verwaltung von Kundenanfragen, Beschwerden und Support-Tickets. CRM-Systeme ermöglichen eine schnelle und effiziente Bearbeitung von Kundenanliegen.
- **Berichterstattung und Analyse**: Bereitstellung von Dashboards und Berichten zur Analyse von Kundenverhalten, Verkaufszahlen und Marketingeffektivität.

## Vorteile von CRM
- **Verbesserte Kundenzufriedenheit**: Durch personalisierte Kommunikation und schnellen Zugriff auf Kundeninformationen können Unternehmen besser auf die Bedürfnisse ihrer Kunden eingehen.
- **Erhöhte Effizienz**: Automatisierung von Prozessen und zentralisierte Datenverwaltung führen zu einer effizienteren Arbeitsweise und weniger Fehlern.
- **Bessere Kundenbindung**: Durch gezielte Marketingstrategien und einen proaktiven Kundenservice können Unternehmen die Loyalität ihrer Kunden erhöhen.
- **Datenbasierte Entscheidungen**: CRM-Systeme liefern wertvolle Einblicke in Kundenverhalten und Markttrends, die als Grundlage für strategische Entscheidungen dienen.

## Herausforderungen bei der Implementierung von CRM
- **Datenqualität**: Die Effektivität eines CRM-Systems hängt von der Qualität der gesammelten Daten ab. Ungenaue oder veraltete Daten können zu falschen Entscheidungen führen.
- **Benutzerakzeptanz**: Mitarbeiter müssen geschult werden, um das CRM-System effektiv zu nutzen. Widerstand gegen Veränderungen kann die Implementierung erschweren.
- **Integration mit bestehenden Systemen**: Die Integration von CRM mit anderen Unternehmenssystemen (z. B. ERP, Marketing-Automation) kann komplex sein und erfordert sorgfältige Planung.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


## Definition
Ein **Data Lake** ist ein zentraler Speicherort, der große Mengen an **unstrukturierten** und **strukturieren Rohdaten** in ihrem ursprünglichen Format speichert. Er ermöglicht die Speicherung und Analyse von Daten aus verschiedenen Quellen.

## Merkmale
- **Unstrukturierter Daten-Pool**: Data Lakes speichern Daten in ihrem Rohformat, ohne vorherige Strukturierung oder Verarbeitung.
- **Einziger Speicher für Unternehmensdaten**: Sie dienen als zentrale Anlaufstelle für alle Unternehmensdaten, unabhängig von deren Herkunft.
- **Anwendungsbereiche**:
  - **Berichterstellung**: Erleichtert die Erstellung von Berichten durch den Zugriff auf umfassende Datenbestände.
  - **Visualisierung**: Unterstützt die Datenvisualisierung, um Muster und Trends zu erkennen.
  - **Erweiterte Analysen**: Ermöglicht tiefere Analysen, um wertvolle Erkenntnisse zu gewinnen.
  - **Maschinelles Lernen**: Bietet die Grundlage für Machine-Learning-Modelle, die auf großen Datenmengen trainiert werden.

## ETL-Prozess
- **Kein ETL-Prozess**: Im Gegensatz zu traditionellen Datenbanken erfolgt kein ETL (Extract, Transform, Load)-Prozess. Daten werden einfach in den Data Lake geladen, ohne sie vorher zu transformieren.

## Vorteile
- **Flexibilität**: Daten können in ihrem ursprünglichen Format gespeichert werden, was eine hohe Flexibilität bei der Datennutzung ermöglicht.
- **Skalierbarkeit**: Data Lakes können große Datenmengen speichern und sind oft kostengünstiger als traditionelle Datenbanken.

## Nachteile
- **Datenqualität**: Da Daten unstrukturiert und ohne vorherige Verarbeitung gespeichert werden, kann die Datenqualität variieren.
- **Komplexität**: Die Analyse von Rohdaten kann komplexer sein und erfordert oft spezialisierte Kenntnisse.

## Quellen
> Autoren der Wikimedia-Projekte. (2020, February 20). Data Lake – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Data_Lake&oldid=244405639

---

Diese überarbeitete Version bietet eine umfassendere Übersicht über Data Lakes, einschließlich Definition, Merkmale, Vorteile und Nachteile, was das Verständnis des Themas vertieft.

- Prozess der **Erkennung von Mustern** und anderen **wertvollen Informationen** in **großen Datenbeständen**

## Prozess
1. Festlegen von **Zielen**, Geschäftsproblem definieren, relevante Fragen festhalten
2. **Datenaufbereitung**, Daten sammeln und bereinigen, Rauschen und irrelevante Informationen entfernen
3. **Modellerstellung** und **Pattern Mining**, Untersuchung on **Datenbeziehungen**, Algorithmen zur Klassifizierung oder Clustering
4. **Auswertung** der Ergebnisse, Interpretation, erstellen von Reports

## Techniken
- **[[CRISP-DM]]**
- **Assoziationsregeln**, *Beziehungen* zwischen Variablen
- **Neuronale Netze**, *Deep-Learning-Algorithmen*, bilden menschliches Gehirn nach
- **Entscheidungsbaum**, *Klassifizierung/Vorhersage* auf Reihe von *Entscheidungen*
- **K-Nearest Neighbor (KNN)**, Klassifizierung von *Datenpunkten* basierend auf *Nähe zu anderen Punkten*

## Vorteile
- **Entscheidungsunterstützung**, wertvolle Einblicke, die Entscheidungsfindung verbessern
- **Frühzeitige Problemerkennung**, Anomalien und Trends können frühzeitig erkannt werden
- **Effizienzsteigerung**, Automatisierung von Datenanalysen spart Zeit und Ressourcen

## Nachteile
- **Datenschutzbedenken**, Erhebung und Analyse großer Datenmengen können zu Bedenken hinsichtlich Privatsphäre führen
- **Fehlinterpretation von Daten**, falsche Analysen können zu schlechten Entscheidungen führen
- **Abhängigkeit von Datenqualität**, Ergebnisse sind stark von Qualität der Daten abhängig

## Quellen

> Was ist Data-Mining? | IBM. (2024, September 11). Retrieved from https://www.ibm.com/de-de/topics/data-mining
> OpenAI. (2024). Data Mining. Retrieved from [OpenAI ChatGPT](https://www.openai.com)

## Definition
Ein **Data Warehouse** ist eine zentrale Datenbank, die speziell für **Analysezwecke** optimiert ist. Es dient als Repository für strukturierte Daten und ermöglicht eine effiziente Datenanalyse und -berichterstattung.

## Merkmale
- **Strukturierte Daten**: Data Warehouses speichern Daten in einem strukturierten Format, was die Analyse erleichtert.
- **Bestandteile**:
  - **Zentrale Datenbank**: Speichert sowohl **aktuelle** als auch **historische Daten** für umfassende Analysen.
  - **Daten-Integration**: Führt Daten aus **heterogenen Quellen** zusammen, indem sie kopiert und aufbereitet werden (siehe [[ETL|ETL-Prozess]]).
  - **Meta-Daten**: Informationen über die Daten selbst, die den Kontext (Merkmale, Quelle) beschreiben und die Datenverwaltung erleichtern.
  - **Zugriffs-Tools**: API-Schnittstellen und Integrationen mit anderen Systemen ermöglichen den Zugriff auf die Daten.

## Vorteile
- **Globale Sicht auf Datenbestände**: Data Warehouses bieten eine umfassende Sicht auf alle Unternehmensdaten, was die Entscheidungsfindung unterstützt.
- **Ausgangsbasis für Analysen**: Sie dienen als Grundlage für **Data Mining** und die Aggregation betrieblicher Kennzahlen sowie für darauf aufbauende Analysen und Berichte.

## Nachteile
- **Kosten**: Die Implementierung und Wartung eines Data Warehouses kann kostspielig sein.
- **Komplexität**: Die Datenintegration und -aufbereitung erfordert oft spezialisierte Kenntnisse und Ressourcen.

## Quellen
> Autoren der Wikimedia-Projekte. (2003, June 26). Data Warehouse – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Data_Warehouse&oldid=247290071


- **Definition**: Datenanalyse ist der Prozess der Inspektion, Bereinigung und Modellierung von Daten, um nützliche Informationen zu gewinnen, Schlussfolgerungen zu ziehen und Entscheidungsfindung zu unterstützen.
- **Ziele**: 
  - Muster und Trends erkennen
  - Vorhersagen treffen
  - Entscheidungsprozesse optimieren

## Arten von Daten
- **Rohdaten**: Unverarbeitete, unstrukturierte Daten, die direkt aus einer Quelle stammen (z.B. Nutzerinteraktionen, Sensoren).
- **Strukturierte Daten**: Daten, die in einem festen Format organisiert sind (z.B. Tabellen in Datenbanken).
- **Unstrukturierte Daten**: Daten, die nicht in einem vorgegebenen Format vorliegen (z.B. Texte, Bilder).

## Herausforderungen bei der Datenanalyse
- **Unstrukturierte Daten**: 
	- Schwierigkeit bei der Verarbeitung und Analyse.
- **Variabilität**: 
	- Unterschiedliche Bedeutungen und Interpretationen von Datenpunkten.
- **Fehlende Kontextinformationen**: 
	- Unklarheit über die Ursachen von Datenwerten.
- **Ausreißer**: 
	- Extreme Werte, die das Gesamtbild verzerren können.
- **Aggregationsproblematik**: 
	- Einfache Zählungen oder Durchschnittswerte können irreführend sein.

## Methoden zur Datenverarbeitung
- **Datenbereinigung**: 
	- Identifikation und Entfernung von Ausreißern, Standardisierung inkonsistenter Daten.
- **Aggregation**: 
	- Berechnung nützlicher Metriken (z.B. Gesamtanzahl der Aufrufe, durchschnittliche Betrachtungsdauer).
- **Segmentierung**: 
	- Analyse von Nutzergruppen oder Zeiträumen zur Erkennung von Mustern.
- **Kontextualisierung**: 
	- Sammlung zusätzlicher Informationen (z.B. Nutzerfeedback, Inhaltsbeliebtheit).
- **Visualisierung**: 
	- Einsatz von Diagrammen und Grafiken zur Darstellung von Mustern und Trends.
- **Statistische Analyse**: 
	- Anwendung statistischer Methoden zur Gewinnung tieferer Einblicke (z.B. Korrelationen, Vorhersagemodelle).

## Praktische Anwendungen der Datenanalyse
- **Marketing**: 
	- Analyse von Nutzerverhalten zur Optimierung von Kampagnen.
- **Forschung**: 
	- Auswertung von Umfragedaten zur Identifikation von Trends.
- **Webanalyse**: 
	- Bewertung der Nutzerinteraktion auf Webseiten zur Verbesserung der Benutzererfahrung.
- **Finanzanalyse**: 
	- Analyse von Finanzdaten zur Risikobewertung und Entscheidungsfindung.


## Strukturierte Daten
- Strukturierte Daten sind Daten, die in einem klar definierten Format organisiert sind, meist in Form von Tabellen mit Zeilen und Spalten.

### Merkmale
- **Eindeutige Struktur**: Daten sind klar definiert und organisiert.
- **Datentypen**: Jedes Feld hat einen festgelegten Datentyp (z.B. integer, string, date).
- **Einfache Abfragen**: Daten können leicht abgerufen und bearbeitet werden, oft mit SQL oder ähnlichen Abfragesprachen.

### Beispiele
- **Tabellen**: Kunden- und Bestelldaten in einer Datenbank.
- **Datenbanken**: Relationale Datenbanken wie MySQL, PostgreSQL.

### Anwendungen
- Ideal für Business Intelligence, Datenanalysen und maschinelles Lernen, bei dem strukturierte Daten verarbeitet werden (z.B. Klassifikation, Regression).

## Unstrukturierte Daten
- Unstrukturierte Daten sind Daten, die **keine vordefinierte Struktur** oder Organisation aufweisen und daher schwer zu kategorisieren und zu analysieren sind.

### Merkmale
- **Vielfalt der Formate**: Daten können aus unterschiedlichsten Quellen stammen (z.B. Texte, Bilder, Videos).
- **Hohe Variabilität**: Inhalte sind in verschiedenen Längen und Formaten vorhanden, was die Verarbeitung erschwert.

### Beispiele
- **Texte**: Social-Media-Beiträge, E-Mails, Blogartikel.
- **Medien**: Bilder (JPEG, PNG), Videos (MP4, AVI).

### Anwendungen:
- Verarbeitung natürlicher Sprache (NLP), Bild- und Videoanalyse, Sentiment-Analyse.

## Halbstrukturierte Daten
### Definition
- Halbstrukturierte Daten weisen eine gewisse Struktur auf, sind aber nicht so starr wie strukturierte Daten. Sie enthalten Marker oder Tags, um Daten zu organisieren.

### Merkmale
- **Flexibilität**: Daten können in unterschiedlichen Formaten vorliegen, jedoch mit einer gewissen hierarchischen Struktur.
- **Teilsystematisierung**: Die Struktur ist nicht festgelegt, was eine flexible Datenhaltung ermöglicht.

### Beispiele
- **XML-Daten**: Strukturierte Textdateien mit Tags zur Kennzeichnung von Daten.
- **JSON-Daten**: Häufig in Webanwendungen verwendet, um Daten zwischen Client und Server auszutauschen.

### Anwendungen
- Web-APIs, Datenübertragung zwischen verschiedenen Systemen, Textanalyse.



## XML (eXtensible Markup Language)
- **Definition**: Ein textbasiertes Format zur Darstellung strukturierter Daten in einer hierarchischen Form.
- **Einsatzbereich**: Häufig verwendet in Webdiensten, Konfigurationsdateien und zur Speicherung von Daten.
- **Vorteile**:
  - Flexibel und erweiterbar.
  - Unterstützt komplexe Datenstrukturen.
- **Nachteile**:
  - Größerer Speicherbedarf im Vergleich zu JSON.
  - Komplexere Syntax, die schwerer zu lesen sein kann.

```xml
<root>
	<sub-element attr="120">test</sub-element>
</root>
```

## JSON (JavaScript Object Notation)
- **Definition**: Ein leichtgewichtiges, textbasiertes Format zur Darstellung von Datenobjekten.
- **Einsatzbereich**: Weit verbreitet in Webanwendungen, APIs und zur Datenübertragung zwischen Client und Server.
- **Vorteile**:
  - Einfach zu lesen und zu schreiben.
  - Geringerer Speicherbedarf als XML.
  - Native Unterstützung in JavaScript.
- **Nachteile**:
  - Weniger geeignet für sehr komplexe Datenstrukturen.

```json
{
	"element": [
		false
	],
	"test": {},
	no: 0
}
```

## CSV (Comma-Separated Values)
- **Definition**: Ein einfaches, textbasiertes Format zur Speicherung tabellarischer Daten, bei dem Werte durch Kommas getrennt sind.
- **Einsatzbereich**: Häufig verwendet für den Import und Export von Daten in Tabellenkalkulationsprogrammen und Datenbanken.
- **Vorteile**:
  - Sehr einfach und leichtgewichtig.
  - Breite Unterstützung in verschiedenen Anwendungen.
- **Nachteile**:
  - Keine Unterstützung für komplexe Datenstrukturen.
  - Probleme mit der Handhabung von Sonderzeichen und Zeilenumbrüchen.

```csv
col1,col2,col3,col4
data,is,0,"even spaces"
```
## Daten aus unterschiedlichen Systemen und unterschiedlichen Formaten zusammenführen können
- **Schnittstellenentwicklung**: Entwicklung von [[API-Schnittstellen|API]]s oder Middleware, um Daten zwischen verschiedenen Systemen auszutauschen und zu konvertieren.
- **Formate, z.B.**:
	- [[Datenaustauschformate|XML]]: Ideal für **komplexe** Datenstrukturen und **hierarchische** Daten.
	- [[Datenaustauschformate|JSON]]: Optimal für **Webanwendungen** und **einfache Datenübertragungen**.
	- [[Datenaustauschformate|CSV]]: Praktisch für **tabellarische Daten** und **einfache Datenimporte/-exporte**.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Stand-Alone-Datenbanksystem
- Für Einzelplatzanwendungen oder kleine Projekte
- Effektiv für kleine Datenmengen
- Keine Berücksichtigung von Konkurrenzsituationen nötig

## Multi-User-Datenbanksystem
- Komplexer als Stand-Alone-Systeme
- Meist als Client-Server-Anwendung realisiert
- Erfordert effektive Berechtigungsvergabe und Konkurrenzverwaltung

### Konkurrenzverwaltung in Multi-User-Systemen:
1. **Optimistic Locking**: 
   - Alle Benutzer können alle Aktionen ausführen
   - DBMS entscheidet anhand einer Unique ID über Datenverfügbarkeit
   - Hohe Produktivität, aber komplexe Implementierung
2. **Pessimistic Locking**:
   - DBMS sperrt Datensätze beim Zugriff
   - Geringere Produktivität durch Wartezeiten
   - Einfachere Implementierung
3. **Release Lock**:
   - Entwickler implementiert Restriktionen im Quellcode
   - Flexible, aber aufwändige Lösung

## Komponenten einer Datenbankarchitektur

1. **Benutzeroberfläche**: 
   - Meist in separatem Formular
   - Kann Datenmodule für Wiederverwendbarkeit nutzen
2. **Datenmodul**:
   - Enthält Komponenten zur Datenanzeige und -verbindung
   - Beinhaltet Datenquellen als Verbindung zwischen UI und Datenmenge
3. **Datenquelle**:
   - Verbindet UI-Elemente mit Datenmengen
   - Ermöglicht Synchronisation mehrerer datensensitiver Steuerelemente
4. **Datenmenge**:
   - Repräsentiert Gruppe von Datensätzen aus der Datenbank
   - Abstrahiert physische Datenbankstruktur
5. **Datenverbindung**:
   - Stellt Verbindung zur Datenquelle her
   - Verschiedene Mechanismen: 
     - Direkte Verbindung zum Datenbankserver
     - Verwendung dedizierter Dateien
     - Verbindungen zu anderen Datenmengen
     - Nutzung von Anwendungsservern

Datendiebstahl bezeichnet den **unbefugten Zugriff** auf, die **Entwendung oder die unrechtmäßige Nutzung von sensiblen oder vertraulichen Daten**. Dies kann durch verschiedene Methoden geschehen, einschließlich Cyberangriffe, Phishing, Malware oder durch interne Bedrohungen.

## Wichtige Aspekte des Datendiebstahls
- **Arten von Daten**: Betroffene Daten können persönliche Informationen (z. B. Namen, Adressen, Sozialversicherungsnummern), Finanzdaten (z. B. Kreditkarteninformationen), Unternehmensgeheimnisse oder vertrauliche Geschäftsdaten sein.
- **Ziele von Datendiebstahl**: Die Motive hinter Datendiebstahl können finanzieller Gewinn, Identitätsdiebstahl, Industriespionage oder die Schädigung des Rufs eines Unternehmens sein.

## Methoden des Datendiebstahls
- **Phishing**: Betrügerische E-Mails oder Nachrichten, die darauf abzielen, Benutzer zur Preisgabe sensibler Informationen zu verleiten.
- **Malware**: Schadsoftware, die auf einem Computer installiert wird, um Daten zu stehlen oder zu überwachen.
- **Social Engineering**: Manipulation von Personen, um vertrauliche Informationen zu erhalten, oft durch Täuschung oder Vertrauensmissbrauch.
- **Hacking**: Unbefugter Zugriff auf Systeme oder Netzwerke, um Daten zu stehlen oder zu manipulieren.

## Auswirkungen des Datendiebstahls
- **Finanzielle Verluste**: Unternehmen können durch den Verlust von Geld, Kunden und Marktanteilen erheblich geschädigt werden.
- **Rechtliche Konsequenzen**: Nichteinhaltung von Datenschutzgesetzen kann zu hohen Geldstrafen und rechtlichen Auseinandersetzungen führen.
- **Rufschädigung**: Der Verlust von Kundendaten kann das Vertrauen in ein Unternehmen beeinträchtigen und zu einem langfristigen Imageschaden führen.
- **Betriebsunterbrechungen**: Die Reaktion auf einen Datendiebstahl kann erhebliche Ressourcen in Anspruch nehmen und den Betrieb stören.

## Präventionsmaßnahmen
- **Zugriffskontrollen**: Implementierung von strengen Zugriffskontrollen, um sicherzustellen, dass nur autorisierte Personen Zugang zu sensiblen Daten haben.
- **Verschlüsselung**: Verschlüsselung von Daten sowohl im Ruhezustand als auch während der Übertragung, um sie vor unbefugtem Zugriff zu schützen.
- **Schulung der Mitarbeiter**: Sensibilisierung der Mitarbeiter für Sicherheitsrisiken und Schulung im Umgang mit verdächtigen E-Mails oder Anfragen.
- **Regelmäßige Sicherheitsüberprüfungen**: Durchführung von Audits und Penetrationstests, um Schwachstellen in der IT-Infrastruktur zu identifizieren und zu beheben.

## Reaktion auf Datendiebstahl
- **Sofortige Maßnahmen**: Schnelle Identifizierung und Eindämmung des Vorfalls, um weiteren Schaden zu verhindern.
- **Benachrichtigung der Betroffenen**: Informieren der betroffenen Personen über den Vorfall und die möglichen Risiken.
- **Zusammenarbeit mit Behörden**: Meldung des Vorfalls an die zuständigen Behörden und Zusammenarbeit mit Strafverfolgungsbehörden zur Aufklärung des Vorfalls.
- **Überprüfung und Verbesserung der Sicherheitsmaßnahmen**: Analyse des Vorfalls, um Schwachstellen zu identifizieren und zukünftige Angriffe zu verhindern.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


| SI-Einheit (Dezimal)                     | IEC-Einheit (Binär)                   |
| ---------------------------------------- | ------------------------------------- |
| 1 kB = $10^3$ Byte = 1000 Byte           | 1 KiB = $2^{10}$ Byte = 1024 Byte     |
| 1 MB = $10^6$ Byte = 1 Million Byte      | 1 MiB = $2^{20}$ Byte = $1024^2$ Byte |
| 1 GB = $10^9$ Byte = 1 Milliarde Byte    | 1 GiB = $2^{30}$ Byte = $1024^3$ Byte |
| 1 TB = $10^{12}$ Byte = 1 Billion Byte   | 1 TiB = $2^{40}$ Byte = $1024^4$ Byte |
| 1 PB = $10^{15}$ Byte = 1 Billiarde Byte | 1 PiB = $2^{50}$ Byte = $1024^5$ Byte |

## Formel
$$
\dfrac{Zahl}{Fremdfaktor}\times Eigenfaktor
$$


## Quellen

> Kolkmann, T. (2017). Gibibyte, Mebibyte, Kibibyte – Was soll das sein? GIGA. Retrieved from https://www.giga.de/downloads/windows-10/specials/gibibyte-mebibyte-kibibyte-was-soll-das-sein
> Ka, L. (2020, May 07). Formel Mebibyte zu Megabyte, Gibibyte zu Terabyte, Kibibyte, Tebibyte. Youtube. Retrieved from https://www.youtube.com/watch?v=PGh3Kk3gqu8

Datenqualität bezieht sich auf die **Eignung von Daten für den vorgesehenen Zweck**. Hohe Datenqualität ist entscheidend für fundierte Entscheidungen, effiziente Prozesse und die Zufriedenheit der Kunden.

## Merkmale der Datenqualität
- Aktualität
	- **Beschreibung**: Die Daten sind aktuell und relevant. Veraltete Daten können die Entscheidungsfindung negativ beeinflussen.
	- **Messung**: Anteil der Daten, die innerhalb eines bestimmten Zeitrahmens aktualisiert wurden.
- Eindeutigkeit
- Einheitlichkeit
- Genauigkeit
- Konformität
- Konsistenz
- Korrektheit
	- **Beschreibung**: Die Daten sind genau und fehlerfrei. Ungenaue Daten können zu falschen Schlussfolgerungen führen.
	- **Messung**: Vergleich der Daten mit einer vertrauenswürdigen Quelle oder durch manuelle Überprüfung.
- Redundanzfreiheit
- Relevanz
- Verständlichkeit
- Vollständigkeit
	- **Beschreibung**: Alle erforderlichen Daten sind vorhanden. Fehlende Daten können die Analyse und Entscheidungsfindung beeinträchtigen.
	- **Messung**: Anteil der vollständigen Datensätze im Vergleich zur Gesamtzahl der Datensätze.
- Zuverlässigkeit
- Historisierung
	- **Beschreibung**: Änderungen an den Daten sind nachvollziehbar. Dies ist wichtig für die Rückverfolgbarkeit und Analyse von Trends.
	- **Messung**: Überprüfung, ob historische Daten gespeichert und zugänglich sind.
- Widerspruchsfreiheit
	- **Beschreibung**: Die Daten sind konsistent und frei von Konflikten. Inkonsistenzen können zu Verwirrung und Fehlentscheidungen führen.
	- **Messung**: Analyse von Datensätzen auf Inkonsistenzen.

### Messung der Datenqualität
- **Defect per Million Opportunities (DPMO)**: Eine Kennzahl zur Quantifizierung der Anzahl der Fehler pro Million Möglichkeiten. 
  - **Berechnung**: 
  $DPMO = \left( \frac{\text{Anzahl der Fehler}}{\text{Anzahl der Datensätze} \times \text{Anzahl der Merkmale pro Datensatz}} \right) \times 1.000.000$

## Prozess
 1. **Sicherung der originalen Datenquelle**: Durch eine Sicherungskopie der Papierliste wird gewährleistet, dass die originalen Daten unverändert und un- mittelbar digital abgespeichert werden. 
 2. **Definition und Anwendung der Anforderungen**: Die bereits beschriebenen Anforderungen an die Daten werden angewandt. Wären die Anforderungen zuvor noch nicht festgelegt, müsste dies noch zusätzlich erfolgen. 
 3. **Analyse der Daten**: Die Daten werden mithilfe der Anforderungen analysiert und bewertet. 4
 4. **Standardisierung der Daten**: Alle erhobenen Daten werden durch Standardisierungsmaßnahmen vereinheitlicht, beispielsweise wird das Datum einheitlich in das Format TT.MM.JJ gebracht. 
 5. **Bereinigung der Daten**: Unnötige Daten werden entfernt und ein (künstlicher) Primärschlüssel wird hinzugefügt.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Schutz **personenbezogener Daten** und die **Wahrung der Privatsphäre** von Individuen. Er umfasst **rechtliche, technische und organisatorische Maßnahmen**, die sicherstellen, dass persönliche Informationen verantwortungsvoll und im Einklang mit den geltenden Gesetzen verarbeitet werden.

## Wichtige Aspekte des Datenschutzes
- **Personenbezogene Daten**: Alle Informationen, die sich auf eine identifizierte oder identifizierbare natürliche Person beziehen (z. B. Name, Adresse, E-Mail).
- **Verarbeitung**: Jede Art der Verarbeitung personenbezogener Daten, einschließlich Erhebung, Speicherung, Nutzung und Übertragung.
- **Einwilligung**: Die Zustimmung der betroffenen Person zur Verarbeitung ihrer Daten ist oft erforderlich.

## Grundprinzipien des Datenschutzes
- **Rechtmäßigkeit, Verarbeitung nach Treu und Glauben, Transparenz**: Daten müssen rechtmäßig und transparent verarbeitet werden.
- **Zweckbindung**: Daten dürfen nur für festgelegte, legitime Zwecke erhoben und verarbeitet werden.
- **Datenminimierung**: Es sollten nur die Daten erhoben werden, die für den jeweiligen Zweck notwendig sind.
- **Richtigkeit**: Personenbezogene Daten müssen korrekt und auf dem neuesten Stand sein.
- **Speicherbegrenzung**: Daten dürfen nicht länger als nötig gespeichert werden.
- **Integrität und Vertraulichkeit**: Daten müssen durch geeignete technische und organisatorische Maßnahmen geschützt werden.

## Maßnahmen zur Gewährleistung des Datenschutzes
- **Datenschutzrichtlinien**: Entwicklung und Implementierung von Richtlinien, die den Umgang mit personenbezogenen Daten regeln.
- **Schulung der Mitarbeiter**: Sensibilisierung und Schulung der Mitarbeiter in Bezug auf Datenschutzbestimmungen und -praktiken.
- **Technische Maßnahmen**: Einsatz von Verschlüsselung, Zugriffskontrollen und anonymisierenden Verfahren, um personenbezogene Daten zu schützen.
- **Datenschutz-Folgenabschätzung**: Durchführung von Bewertungen, um die Risiken für die Rechte und Freiheiten der betroffenen Personen zu identifizieren und zu minimieren.

## Aktuelle Trends und Entwicklungen
- **Datenschutz-Grundverordnung (DSGVO)**: Die EU-Verordnung, die strenge Regeln für die Verarbeitung personenbezogener Daten festlegt und den Schutz der Privatsphäre stärkt.
- **Recht auf Vergessenwerden**: Betroffene Personen haben das Recht, die Löschung ihrer personenbezogenen Daten zu verlangen.
- **Internationale Datenübertragungen**: Regelungen zur Übertragung personenbezogener Daten außerhalb der EU, um den Datenschutz zu gewährleisten.

## Strategien zur Erkennung von Anforderungen
- **Analyse der Aufgabenstellung**: 
	- Achten Sie auf Schlüsselbegriffe wie „Zugriffsrechte“, „Sicherheit“, „Transparenz“ oder „Einwilligung“. Diese Begriffe weisen oft auf spezifische Anforderungen hin.
- **Identifikation von Stakeholdern**: 
	- Überlegen Sie, welche Personen oder Gruppen von der Datenverarbeitung betroffen sind (z. B. Mitarbeiter, Kunden) und welche Anforderungen sie an den Datenschutz stellen könnten.
- **Berücksichtigung von Gesetzen und Vorschriften**: 
	- Machen Sie sich mit relevanten Datenschutzgesetzen (z. B. DSGVO) vertraut. Diese Gesetze enthalten oft spezifische Anforderungen, die in der Aufgabenstellung berücksichtigt werden müssen.
- **Prüfung bestehender Richtlinien**: 
	- Überlegen Sie, ob es bereits bestehende Datenschutzrichtlinien im Unternehmen gibt, die als Grundlage für die neuen Anforderungen dienen können.
- **Risikoanalyse**: 
	- Führen Sie eine Risikoanalyse durch, um potenzielle Schwachstellen in der Datenverarbeitung zu identifizieren. Dies kann helfen, spezifische Anforderungen zu formulieren, die zur Risikominderung beitragen.


## Rechte der betroffenen Personen
- **Recht auf Auskunft (Artikel 15)**: Betroffene haben das Recht zu erfahren, ob und welche personenbezogenen Daten verarbeitet werden.
- **Recht auf Berichtigung (Artikel 16)**: Betroffene können die Berichtigung unrichtiger oder unvollständiger Daten verlangen.
- **Recht auf Löschung (Artikel 17)**: Betroffene können die Löschung ihrer Daten verlangen, wenn diese nicht mehr benötigt werden oder unrechtmäßig verarbeitet wurden.
- **Recht auf Einschränkung der Verarbeitung (Artikel 18)**: Betroffene können die Einschränkung der Verarbeitung ihrer Daten verlangen.
- **Recht auf Datenübertragbarkeit (Artikel 20)**: Betroffene haben das Recht, ihre Daten in einem strukturierten, gängigen und maschinenlesbaren Format zu erhalten.
- **Widerspruchsrecht (Artikel 21)**: Betroffene können Widerspruch gegen die Verarbeitung ihrer Daten einlegen.

## Regelwerke und Normen
- BSI IT-Grundschutz
	- typische Gefahren zusammen mit umfangreichen Maßnahmenvorschlägen
- DIN EN ISO 270001
	- prozessorientiert und nur knappe Beschreibung der Regelungen
- VdS 10000
	- Informationssicherheitsmanagementsystem für kleine und mittlere Unternehmen (KMU) der VdS Schadenverhütung GmbH

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Schutz von Daten vor **unbefugtem Zugriff**, **Verlust** oder **Zerstörung**. Sie umfasst Maßnahmen, die sicherstellen, dass Daten vertraulich, integer und verfügbar bleiben.
- Betroffen **alle Daten**

## Wichtige Aspekte der Datensicherheit
- **Vertraulichkeit**: Sicherstellen, dass nur autorisierte Personen Zugriff auf die Daten haben.
- **Integrität**: Gewährleisten, dass die Daten korrekt und unverändert sind.
- **Verfügbarkeit**: Sicherstellen, dass die Daten bei Bedarf zugänglich sind.

## Maßnahmen zur Gewährleistung der Datensicherheit
- **Zugriffskontrollen**: Implementierung von Benutzerrechten und -rollen, um den Zugriff auf sensible Daten zu steuern.
- **Verschlüsselung**: Daten sowohl im Ruhezustand als auch während der Übertragung verschlüsseln, um sie vor unbefugtem Zugriff zu schützen.
- **Sicherheitsrichtlinien**: Entwicklung und Durchsetzung von Richtlinien zur Datensicherheit, die das Verhalten der Mitarbeiter regeln.
- **Backup und Wiederherstellung**: Regelmäßige Sicherung von Daten und Implementierung von Wiederherstellungsplänen im Falle eines Datenverlusts.

## Risiken für die Datensicherheit
- **Cyberangriffe**: Phishing, Malware und Ransomware können zu Datenverlust oder -kompromittierung führen.
- **Menschliches Versagen**: Fehler bei der Handhabung von Daten oder unzureichende Schulung der Mitarbeiter können Sicherheitslücken schaffen.
- **Physische Bedrohungen**: Verlust oder Diebstahl von Geräten, auf denen sensible Daten gespeichert sind.

## Aktuelle Trends und Entwicklungen
- **Cloud-Sicherheit**: Mit der zunehmenden Nutzung von Cloud-Diensten wird die Sicherheit von in der Cloud gespeicherten Daten immer wichtiger.
- **Künstliche Intelligenz**: Einsatz von KI zur Erkennung und Abwehr von Bedrohungen in Echtzeit.
- **Datenschutzgesetze**: Einhaltung von Vorschriften wie der Datenschutz-Grundverordnung (DSGVO) zur Sicherstellung der Datensicherheit.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Datensorgfalt bezieht sich auf die **verantwortungsvolle und sorgfältige Handhabung von Daten** während ihres gesamten Lebenszyklus. Dies umfasst die **Erhebung, Speicherung, Verarbeitung, Nutzung und Löschung von Daten**. Das Ziel der Datensorgfalt ist es, die Integrität, Vertraulichkeit und Verfügbarkeit von Daten zu gewährleisten und gleichzeitig die Rechte der betroffenen Personen zu schützen.

## Wichtige Aspekte der Datensorgfalt

### Datenqualität
- **Beschreibung**: Sicherstellung, dass die gesammelten Daten genau, vollständig und aktuell sind. Hohe Datenqualität ist entscheidend für fundierte Entscheidungen und effektive Prozesse.
- **Maßnahmen**: Regelmäßige Überprüfungen und Validierungen der Daten, um Fehler und Inkonsistenzen zu identifizieren und zu beheben.

### Datenschutz
- **Beschreibung**: Schutz personenbezogener Daten vor unbefugtem Zugriff, Missbrauch oder Verlust. Die Einhaltung von Datenschutzgesetzen, wie der Datenschutz-Grundverordnung (DSGVO), ist ein wesentlicher Bestandteil der Datensorgfalt.
- **Maßnahmen**: Implementierung von Sicherheitsmaßnahmen wie Verschlüsselung, Zugriffskontrollen und Schulungen für Mitarbeiter.

### Datenminimierung
- **Beschreibung**: Erhebung und Verarbeitung nur der Daten, die für den jeweiligen Zweck notwendig sind. Dies reduziert das Risiko von Datenmissbrauch und erleichtert die Einhaltung von Datenschutzbestimmungen.
- **Maßnahmen**: Regelmäßige Überprüfung der Datenerhebungspraktiken und Anpassung an die Prinzipien der Datensparsamkeit.

### Dokumentation und Nachverfolgbarkeit
- **Beschreibung**: Sorgfältige Dokumentation aller Datenverarbeitungsprozesse, um Transparenz und Nachverfolgbarkeit zu gewährleisten. Dies ist wichtig für Audits und die Einhaltung von Vorschriften.
- **Maßnahmen**: Erstellung von Protokollen und Berichten über die Datenverarbeitung, einschließlich der Zwecke, der verwendeten Daten und der beteiligten Personen.

### Schulung und Sensibilisierung
- **Beschreibung**: Schulung der Mitarbeiter im Umgang mit Daten und den relevanten Datenschutzbestimmungen. Sensibilisierung für die Bedeutung von Datensorgfalt und den Schutz personenbezogener Daten.
- **Maßnahmen**: Regelmäßige Schulungen und Workshops, um das Bewusstsein für Datensorgfalt zu fördern und Best Practices zu vermitteln.

## Vorteile der Datensorgfalt
- **Schutz der Privatsphäre**: Durch sorgfältigen Umgang mit Daten wird das Risiko von Datenschutzverletzungen und Identitätsdiebstahl verringert.
- **Vertrauen der Kunden**: Ein verantwortungsvoller Umgang mit Daten stärkt das Vertrauen der Kunden und Nutzer in das Unternehmen.
- **Rechtliche Sicherheit**: Die Einhaltung von Datenschutzbestimmungen und die Umsetzung von Datensorgfalt reduzieren das Risiko von rechtlichen Konsequenzen und Strafen.

## Herausforderungen bei der Umsetzung der Datensorgfalt
- **Technologische Komplexität**: Die Implementierung von Sicherheitsmaßnahmen und die Verwaltung von Daten können komplex sein und erfordern technisches Know-how.
- **Widerstand gegen Veränderungen**: Mitarbeiter könnten an bestehenden Praktiken festhalten, die nicht den Prinzipien der Datensorgfalt entsprechen.
- **Ressourcenaufwand**: Die Umsetzung von Datensorgfalt erfordert Zeit und Ressourcen, die möglicherweise nicht immer verfügbar sind.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Datensparsamkeit ist ein Prinzip, das darauf abzielt, **nur die Daten zu erheben, zu speichern und zu verarbeiten, die für einen bestimmten Zweck unbedingt erforderlich sind.** Dieses Konzept ist besonders relevant im Kontext des Datenschutzes und der Datenverarbeitung, um die Privatsphäre von Individuen zu schützen und die Risiken im Umgang mit Daten zu minimieren.

### Wichtige Aspekte der Datensparsamkeit

### Minimierung der Datenerhebung
- **Beschreibung**: Unternehmen sollten nur die Daten sammeln, die für die Erfüllung eines bestimmten Zwecks notwendig sind. Überflüssige Daten sollten vermieden werden.
- **Vorteil**: Reduziert das Risiko von Datenmissbrauch und erleichtert die Einhaltung von Datenschutzbestimmungen.

### Zweckbindung
- **Beschreibung**: Daten dürfen nur für die Zwecke verwendet werden, für die sie ursprünglich erhoben wurden. Eine spätere Verwendung für andere Zwecke sollte klar definiert und rechtlich zulässig sein.
- **Vorteil**: Schützt die Rechte der betroffenen Personen und fördert das Vertrauen in den Umgang mit Daten.

### Datenlöschung
- **Beschreibung**: Daten sollten regelmäßig überprüft und gelöscht werden, wenn sie nicht mehr benötigt werden. Dies umfasst auch die Implementierung von Richtlinien zur Datenaufbewahrung.
- **Vorteil**: Minimiert das Risiko von Datenlecks und verringert die Menge an gespeicherten Daten, die potenziell missbraucht werden könnten.

### Transparenz
- **Beschreibung**: Unternehmen sollten transparent darüber informieren, welche Daten sie erheben, zu welchem Zweck und wie lange diese gespeichert werden.
- **Vorteil**: Erhöht das Vertrauen der Kunden und Nutzer in den Umgang mit ihren Daten.

## Vorteile der Datensparsamkeit
- **Schutz der Privatsphäre**: Durch die Minimierung der Datenspeicherung wird das Risiko von Datenschutzverletzungen und Identitätsdiebstahl verringert.
- **Einhaltung von Vorschriften**: Datensparsamkeit unterstützt die Einhaltung von Datenschutzgesetzen wie der Datenschutz-Grundverordnung (DSGVO), die strenge Anforderungen an die Datenerhebung und -verarbeitung stellt.
- **Kosteneffizienz**: Weniger gespeicherte Daten bedeuten geringere Kosten für Speicherung, Verwaltung und Sicherung von Daten.

## Herausforderungen bei der Umsetzung der Datensparsamkeit
- **Widerstand gegen Veränderungen**: Mitarbeiter und Unternehmen könnten an bestehenden Praktiken festhalten, die nicht datensparsam sind.
- **Technologische Einschränkungen**: Einige Systeme und Prozesse sind möglicherweise nicht darauf ausgelegt, datensparsam zu arbeiten, was Anpassungen erfordert.
- **Schulung und Sensibilisierung**: Es ist notwendig, Mitarbeiter über die Bedeutung der Datensparsamkeit und die entsprechenden Praktiken zu schulen.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Ein Datenbankmanagementsystem (DBMS) ist eine Softwarelösung, die das **Speichern, Abrufen und Verwalten von Daten** in Datenbanken ermöglicht. Es bildet die Schnittstelle zwischen der physischen Datenspeicherung und den Anwendungen bzw. Benutzern.

## Kernfunktionen
- Datenspeicherung und -organisation
- Datenabfrage und -manipulation 
- Transaktionsmanagement
- Zugriffskontrolle und Sicherheit
- Datenkonsistenz und -integrität
- Backup und Recovery

## Architektur und Komponenten
Die typische DBMS-Architektur besteht aus mehreren Schichten:
1. **Physische Ebene:** Verwaltung der Daten auf Speichermedien
2. **Logische Ebene:** Abstraktion der Datenstrukturen
3. **Konzeptuelle Ebene:** Gesamtsicht auf die Datenbank
4. **Externe Ebene:** Benutzersichten und Schnittstellen

## Datenmodelle und Abfragesprachen

DBMS basieren auf verschiedenen Datenmodellen:

1. **Relationales Modell:** Daten in Tabellen mit Beziehungen
   - Beispiel-DBMS: Oracle, MySQL, PostgreSQL
   - Abfragesprache: SQL
2. **Objektorientiertes Modell:** Daten als Objekte mit Methoden
   - Beispiel-DBMS: ObjectStore, Versant
   - Abfragesprache: OQL
3. **Dokumentenorientiertes Modell:** Daten in flexiblen Dokumentstrukturen
   - Beispiel-DBMS: MongoDB, CouchDB
   - Abfragesprache: MongoDB Query Language

## Transaktionsmanagement

Transaktionen gewährleisten die ACID-Eigenschaften:
- **A**tomicity: Ganz oder gar nicht
- **C**onsistency: Datenbank bleibt in konsistentem Zustand
- **I**solation: Nebenläufige Transaktionen beeinflussen sich nicht
- **D**urability: Dauerhafte Speicherung der Änderungen

### Concurrency Control Methoden
- Sperrverfahren (z.B. Two-Phase Locking)
- Zeitstempelverfahren
- Optimistische Verfahren

## Datensicherheit und -integrität

### Sicherheitsmechanismen
- Authentifizierung und Autorisierung
- Verschlüsselung
- Auditing

### Integritätsbedingungen
- Entitätsintegrität (Primärschlüssel)
- Referenzielle Integrität (Fremdschlüssel)
- Domänenintegrität (Wertebereichsprüfungen)

## Verteilte Datenbanksysteme

Verteilte DBMS verwalten Daten über mehrere physische Standorte:

- Fragmentierung: Horizontale vs. Vertikale Partitionierung
- Replikation: Synchrone vs. Asynchrone Replikation
- Verteilte Abfrageverarbeitung und -optimierung

## Moderne Entwicklungen
- **NewSQL:** Skalierbare relationale Systeme (z.B. Google Spanner)
- **Polyglot Persistence:** Kombination verschiedener Datenbanktypen
- **In-Memory Datenbanken:** Hauptspeicherbasierte Verarbeitung für Echtzeitanwendungen


- Prozess zur **Identifizierung und Behebung von Softwarefehlern** (Bugs).

### Arten von Bugs
- **Syntaxfehler**: Schreibfehler im Code.
- **Laufzeitfehler**: Fehler während der Ausführung (z.B. Division durch Null).
- **Logikfehler**: Code läuft, liefert aber falsche Ergebnisse.

### Debugging-Methoden
- **Print-Debugging**: Ausgaben zur Überprüfung von Variablen und Programmfluss.
- **Debugger-Tools**: Schrittweise Ausführung des Codes (z.B. in IDEs).
- **Unit-Tests**: Tests für einzelne Komponenten.

### Debugging-Strategien
- **Reproduzieren**: Fehler unter kontrollierten Bedingungen nachstellen.
- **Isolieren**: Code auf das Minimum reduzieren, das den Fehler verursacht.
- **Überprüfen von Annahmen**: Sicherstellen, dass Annahmen korrekt sind.

### Best Practices
- **Code-Reviews**: Feedback von anderen Entwicklern einholen.
- **Dokumentation**: Festhalten von Versuchen und Lösungen.
- **Versionierung**: Änderungen mit Versionskontrollsystemen (z.B. Git) nachverfolgen.

### Tools und Ressourcen
- **Debugger**: IDE-eigene oder externe Debugger (z.B. GDB).
- **Logging-Frameworks**: Protokollierung mit Bibliotheken (z.B. Log4j).
- **Online-Ressourcen**: Stack Overflow, GitHub, offizielle Dokumentationen.

### Tipps für effektives Debugging
- Ruhe bewahren und geduldig sein.
- Probleme in kleinere Teile aufteilen.
- Community um Hilfe bitten, wenn nötig.

## Quellen 

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Maßnahmen** und **Strategien** zur **Sicherstellung der Sicherheit von Endgeräten** (z.B. Laptops, Desktops, Mobilgeräte) innerhalb eines Unternehmensnetzwerks. Die Hauptziele sind:

- Sicherstellung, dass **alle Endgeräte den Sicherheitsrichtlinien entsprechen**.
- Schutz vor **unbefugtem Zugriff und bösartigen Aktivitäten**.
- Minimierung von Risiken und Schwachstellen, die durch Endgeräte eingeführt werden könnten.

## Wichtige Komponenten
1. **Gerätemanagement**:
   - **Inventarisierung**: Überblick über alle verbundenen Geräte und deren Sicherheitsstatus.
   - **Konfigurationsmanagement**: Sicherstellen, dass alle Geräte den gewünschten Konfigurationen und Sicherheitsstandards entsprechen.
2. **Endpoint Protection**:
   - **Antivirus-Software**: Schutz vor Malware und Viren.
   - **Endpoint Detection and Response (EDR)**: Erkennung und Reaktion auf Bedrohungen in Echtzeit.
3. **Netzwerksicherheit**:
   - **Firewalls**: Überwachung und Kontrolle des Datenverkehrs.
   - **Intrusion Detection Systems (IDS) / Intrusion Prevention Systems (IPS)**: Erkennung und Prävention von Angriffen.
4. **Zugangskontrollen**:
   - **Multi-Faktor-Authentifizierung (MFA)**: Sicherstellung der Identität des Benutzers.
   - **Gerätebasierte Authentifizierung**: Nur autorisierte Geräte dürfen auf das Netzwerk zugreifen.
5. **Sicherheitsrichtlinien und -updates**:
   - **Patch-Management**: Regelmäßiges Einspielen von Software- und Betriebssystem-Updates.
   - **Sicherheitsrichtlinien**: Erstellung und Durchsetzung von Policies für Gerätesicherheit (z.B. Verschlüsselung, Passwortregeln).

## Tools und Techniken

### Gerätemanagement
- **Mobile Device Management (MDM)**: Verwaltung von Mobilgeräten, z.B. mit Tools wie Microsoft Intune oder AirWatch.
- **Unified Endpoint Management (UEM)**: Integration aller Endgeräte-Management-Funktionen in einer zentralen Plattform.

### Endpoint Protection
- **Antivirus-Software**: Lösungen wie McAfee, Symantec oder Windows Defender.
- **Endpoint Detection and Response (EDR)**: Tools wie CrowdStrike oder Carbon Black.

### Netzwerksicherheit
- **Firewalls**: Hardware- oder Softwarelösungen zum Schutz des Netzwerks, z.B. Palo Alto Networks oder Cisco.
- **Intrusion Detection Systems (IDS) / Intrusion Prevention Systems (IPS)**: z.B. Snort oder Suricata.

### Sicherheitsüberprüfung
- **Vulnerability Scanning**: Regelmäßige Schwachstellenüberprüfung der Geräte mit Tools wie Nessus oder OpenVAS.
- **Compliance-Checks**: Überprüfen der Einhaltung von internen Richtlinien und externen Standards.

## Vor- und Nachteile

### Vorteile

- **Erhöhte Sicherheit**: Durch umfassende Überwachung und Schutzmaßnahmen.
- **Einhaltung von Standards**: Einfache Einhaltung von Compliance-Anforderungen und Unternehmensrichtlinien.
- **Zentralisierte Verwaltung**: Vereinfachte Administration durch zentrale Tools und Systeme.

### Nachteile

- **Komplexität**: Verwaltung der Vielzahl von Geräten und Sicherheitsmaßnahmen kann komplex und zeitaufwendig sein.
- **Kosten**: Hohe Anschaffungs- und Betriebskosten für professionelle Sicherheitslösungen.
- **Performance-Einbußen**: Sicherheitsmaßnahmen können die Systemleistung beeinträchtigen.

## Best Practices

- **Regelmäßige Updates**: Sicherstellen, dass alle Geräte regelmäßig aktualisiert und gepatcht werden.
- **Schulung der Benutzer**: Schulungen zur Sensibilisierung für Sicherheitsbedrohungen und bewährte Methoden.
- **Sicherheitsrichtlinien durchsetzen**: Implementierung und Durchsetzung klarer Sicherheitsrichtlinien für alle Endgeräte.
- **Kontinuierliche Überwachung**: Ständige Überwachung der Gerätesicherheit und sofortige Reaktion auf erkannte Bedrohungen.

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com

## Grundlagen von DHCP
- **Definition**: DHCP ist ein Netzwerkprotokoll, das **automatisch IP-Adressen** und **andere Netzwerkinformationen** an Geräte in einem Netzwerk zuweist.
- **Zweck**: Erleichtert die Verwaltung von IP-Adressen und reduziert manuelle Konfigurationen.

## Funktionsweise von DHCP
- **DHCP-Server**: Ein Server, der IP-Adressen und Konfigurationsinformationen bereitstellt.
- **DHCP-Client**: Ein Gerät, das eine IP-Adresse und Konfiguration vom DHCP-Server anfordert.

## DHCP-Prozess
1. **DHCP Discover**: Der Client sendet eine **Broadcast**-Nachricht, um einen DHCP-Server zu finden.
2. **DHCP Offer**: Der Server antwortet mit einem **Angebot**, das eine IP-Adresse und andere Konfigurationsdaten enthält.
3. **DHCP Request**: Der Client **wählt ein Angebot aus** und sendet eine Anfrage an den Server.
4. **DHCP Acknowledgment (ACK)**: Der Server **bestätigt die Zuweisung** der IP-Adresse und sendet die endgültigen Konfigurationsdaten.

## DHCP-Optionen
- **IP-Adresse**: Die zugewiesene IP-Adresse für den Client.
- **Subnetzmaske**: Bestimmt, welche Teile der IP-Adresse das Netzwerk und den Host identifizieren.
- **Gateway**: Die IP-Adresse des Routers, über den der Client das Internet erreichen kann.
- **DNS-Server**: Die IP-Adressen der DNS-Server, die der Client verwenden soll.

## Vorteile von DHCP
- **Automatisierung**: Reduziert den **Aufwand** für die manuelle IP-Adresszuweisung.
- **Zentralisierte Verwaltung**: Erleichtert die **Verwaltung** von IP-Adressen in großen Netzwerken.
- **Flexibilität**: Clients können sich einfach in das Netzwerk einfügen und erhalten automatisch die erforderlichen Einstellungen.

## DHCP-Reservierungen
- **Definition**: Eine feste IP-Adresse kann einem bestimmten DHCP-Client zugewiesen werden, basierend auf seiner MAC-Adresse.
- **Zweck**: Sicherstellung, dass bestimmte Geräte immer die gleiche IP-Adresse erhalten (z. B. Drucker, Server).

## DHCP-Sicherheit
- **DHCP Snooping**: Eine Sicherheitsfunktion, die nur autorisierte DHCP-Server im Netzwerk zulässt.
- **Rogue DHCP-Server**: Unautorisierte DHCP-Server, die falsche IP-Adressen zuweisen können, um Angriffe zu ermöglichen.

## Relevanz in Netzwerken
- **Netzwerkadministration**: DHCP ist ein wesentlicher Bestandteil der Netzwerkverwaltung, insbesondere in großen und dynamischen Umgebungen.
- **Integration mit anderen Protokollen**: DHCP kann mit anderen Protokollen wie DNS und Active Directory integriert werden.

## Fazit
DHCP ist ein unverzichtbares Protokoll für die effiziente Verwaltung von IP-Adressen in modernen Netzwerken. Es automatisiert die Zuweisung von Netzwerkinformationen und erleichtert die Netzwerkadministration erheblich. Ein grundlegendes Verständnis von DHCP ist für Netzwerkadministratoren und IT-Profis von großer Bedeutung.


## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Balkendiagramm
- horizontales [[#Säulendiagramm]]
- leicht zu erkennen, visualisiert Datensätze schnell
- **Vorteile**
	1. **leicht zu lesen und zu interpretieren**, was sie ideal für die Präsentation von Daten an ein breites Publikum macht.
	2. **klaren Vergleich zwischen verschiedenen Kategorien** oder Gruppen, da die Längen der Balken visuell die Unterschiede darstellen.
	3. sowohl für **qualitative als auch quantitative Daten** verwendet werden und sind in verschiedenen Formaten (horizontal oder vertikal) darstellbar.
- **Nachteile**
	1. **unübersichtlich werden und viel Platz** einnehmen, was die Lesbarkeit beeinträchtigen kann.
	1. Skala nicht richtig gewählt ist, können Balkendiagramme die Daten **verzerrt darstellen und falsche Eindrücke** vermitteln.
	2. zeigen **keine Trends über die Zeit** oder komplexe Beziehungen zwischen Variablen, was in manchen Fällen notwendig sein kann.
- **Anwendungsfälle**
	1. **Marktforschung**: Vergleich von Marktanteilen verschiedener Unternehmen oder Produkte in einem bestimmten Sektor.
	2. **Umfragen**: Darstellung der Ergebnisse von Umfragen, z.B. die Präferenzen von Konsumenten zu verschiedenen Produkten oder Dienstleistungen.
	3. **Finanzberichte**: Visualisierung von Einnahmen, Ausgaben oder anderen finanziellen Kennzahlen über verschiedene Zeiträume oder Abteilungen hinweg.
![[Pasted image 20240928120415.png]]

## Liniendiagramm
- kontinuierliche Daten/Daten mit unendlichen Werten darstellen
- **Vorteile**
	1. **Einfache Lesbarkeit**, was sie ideal für die Präsentation von Trends und Entwicklungen über Zeiträume hinweg macht.
	2. **Darstellung von Trends**, da sie Veränderungen in den Daten über einen bestimmten Zeitraum klar zeigen.
	3. **Vergleich von mehreren Datensätzen** möglich, indem mehrere Linien in einem Diagramm dargestellt werden, was einen direkten Vergleich erleichtert.
- **Nachteile**
	1. **Überladung mit Informationen**, wenn zu viele Linien dargestellt werden, was die Lesbarkeit und das Verständnis beeinträchtigen kann.
	2. **Schwierigkeiten bei der Interpretation** von Datenpunkten, die nahe beieinander liegen, da sie visuell schwer zu unterscheiden sein können.
	3. **Nicht ideal für kategoriale Daten**, da sie hauptsächlich für kontinuierliche Daten geeignet sind und bei kategorialen Daten weniger aussagekräftig sein können.
- **Anwendungsfälle**
	1. **Finanzanalysen**: Darstellung von Umsatz- und Gewinnentwicklungen über mehrere Jahre.
	2. **Wetterdaten**: Visualisierung von Temperatur- oder Niederschlagsänderungen über verschiedene Zeiträume.
	3. **Web-Analytics**: Analyse von Besucherzahlen oder Seitenaufrufen über Zeit, um Trends im Nutzerverhalten zu erkennen.
![[Pasted image 20240928120607.png]]
## Diagramm Fläche
- ähnelt [[#Liniendiagramm]]
- zeigt Veränderungen im Zeitverlauf dar, zusätzlichen **Volumen**
- **Vorteile**
	1. **Visualisierung von kumulierten Werten**, was hilft, die Gesamtentwicklung über Zeit oder Kategorien hinweg darzustellen.
	2. **Einfache Darstellung von Trends**, da die Fläche unter der Kurve Veränderungen im Zeitverlauf klar zeigt.
	3. **Vergleich mehrerer Datensätze** möglich, indem verschiedene Flächen übereinandergelegt werden, was den Vergleich zwischen verschiedenen Gruppen erleichtert.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Interpretation** von Werten, da die Fläche nicht immer die genauen Zahlen zeigt und visuelle Eindrücke täuschen können.
	2. **Überladung mit Informationen**, wenn zu viele Flächen dargestellt werden, was die Lesbarkeit und das Verständnis beeinträchtigen kann.
	3. **Nicht ideal für kleine Datenmengen**, da die Vorteile der Flächendarstellung bei wenigen Datenpunkten nicht zur Geltung kommen.
- **Anwendungsfälle**
	1. **Finanzberichte**: Darstellung von Einnahmen und Ausgaben über Zeit, um die finanzielle Entwicklung eines Unternehmens zu visualisieren.
	2. **Umweltanalysen**: Visualisierung von Veränderungen in CO2-Emissionen oder anderen Umweltfaktoren über Jahre hinweg.
	3. **Verkaufsanalysen**: Vergleich von Verkaufszahlen verschiedener Produkte über Zeit, um Trends und saisonale Schwankungen zu erkennen.

![[Pasted image 20240928121454.png]]
## Streudiagramm
- auch **Punktediagramm**
- zeigt **Beziehungen** zwischen zwei Elementen auf Grundlage zwei verschiedener Variablen dar 
- **Vorteile**
	1. **Visualisierung von Beziehungen** zwischen zwei Variablen, was hilft, Korrelationen oder Muster zu erkennen.
	2. **Identifikation von Ausreißern**, da einzelne Punkte, die weit von der Mehrheit entfernt sind, leicht erkennbar sind.
	3. **Flexibilität in der Darstellung**, da sowohl quantitative als auch qualitative Daten in einem Streudiagramm abgebildet werden können.
- **Nachteile**
	1. **Schwierigkeiten bei der Interpretation** von großen Datenmengen, da die Punkte überlappen und die Übersichtlichkeit leiden kann.
	2. **Keine klare Darstellung von Trends**, es sei denn, eine Trendlinie wird hinzugefügt, was zusätzliche Interpretation erfordert.
	3. **Begrenzte Aussagekraft**, wenn die Daten nicht ausreichend variieren oder wenn keine signifikante Beziehung zwischen den Variablen besteht.
- **Anwendungsfälle**
	1. **Wissenschaftliche Forschung**: Untersuchung der Beziehung zwischen zwei Variablen, wie z.B. Temperatur und Pflanzenwachstum.
	2. **Marktforschung**: Analyse von Kundenverhalten, z.B. Zusammenhang zwischen Einkommen und Ausgaben für bestimmte Produkte.
	3. **Qualitätskontrolle**: Überwachung von Produktionsprozessen, um die Beziehung zwischen verschiedenen Produktionsparametern zu analysieren.
![[Pasted image 20240928133101.png]]
## Kreisdiagramm
- stellt Zahlen in **Prozenten** dar
- **Vorteile**
	1. **Einfache Visualisierung von Anteilen**, was hilft, die Verteilung von Kategorien innerhalb eines Ganzen schnell zu erfassen.
	2. **Intuitive Darstellung**, die es ermöglicht, die relativen Größen der Teile zueinander leicht zu vergleichen.
	3. **Ansprechend und übersichtlich**, was sie ideal für Präsentationen und Berichte macht, um wichtige Informationen hervorzuheben.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Interpretation** von Werten, insbesondere wenn die Unterschiede zwischen den Segmenten gering sind.
	2. **Begrenzte Anzahl an Kategorien**, da zu viele Segmente das Diagramm unübersichtlich machen und die Lesbarkeit beeinträchtigen können.
	3. **Nicht geeignet für zeitliche Entwicklungen**, da sie keine Informationen über Veränderungen im Zeitverlauf liefern.
- **Anwendungsfälle**
	1. **Marktforschung**: Darstellung der Marktanteile verschiedener Unternehmen oder Produkte innerhalb eines Sektors.
	2. **Umfragen**: Visualisierung der Verteilung von Antworten auf eine Frage, z.B. die Präferenzen der Konsumenten.
	3. **Budgetverteilung**: Darstellung der Aufteilung eines Budgets auf verschiedene Ausgabenposten, um die Verteilung der Mittel zu verdeutlichen.
![[Pasted image 20240928133216.png]]
## Piktogramm
- Bilder und Symbole werden für Darstellung von Daten verwendet
- **Vorteile**
	1. **Visuelle Anschaulichkeit**, die es ermöglicht, Informationen schnell und intuitiv zu erfassen, da Bilder oft leichter verständlich sind als Text.
	2. **Ansprechende Gestaltung**, die das Interesse der Betrachter weckt und die Aufmerksamkeit auf wichtige Daten lenkt.
	3. **Einfache Darstellung von quantitativen Informationen**, indem Symbole verwendet werden, um Mengen oder Anteile darzustellen, was die Interpretation erleichtert.
- **Nachteile**
	1. **Begrenzte Detailtiefe**, da Piktogramme oft nur eine vereinfachte Darstellung von Daten bieten und keine genauen Werte anzeigen.
	2. **Missverständnisse durch unterschiedliche Interpretationen**, da Symbole je nach kulturellem Kontext unterschiedlich verstanden werden können.
	3. **Schwierigkeiten bei der Darstellung komplexer Daten**, da Piktogramme nicht immer geeignet sind, um komplexe Zusammenhänge oder Trends darzustellen.
- **Anwendungsfälle**
	1. **Umfragen und Statistiken**: Visualisierung von Umfrageergebnissen, z.B. die Verteilung von Meinungen oder Präferenzen in einer Bevölkerung.
	2. **Bildungsbereich**: Verwendung in Lehrmaterialien, um Konzepte oder Daten anschaulich zu erklären, z.B. in Infografiken.
	3. **Marketing und Werbung**: Einsatz in Werbematerialien, um Produkteigenschaften oder Vorteile schnell und ansprechend zu kommunizieren.

![[Pasted image 20240928133506.png]]
## Säulendiagramm
- eignet sich zur Darstellung **chronologischer Daten**
- **Vorteile**
	1. **Einfache Lesbarkeit**, was sie ideal für die Präsentation von Daten an ein breites Publikum macht.
	2. **Klare Vergleichbarkeit** zwischen verschiedenen Kategorien oder Gruppen, da die Höhen der Säulen visuell die Unterschiede darstellen.
	3. **Flexibilität in der Darstellung**, da sie sowohl für qualitative als auch quantitative Daten verwendet werden können und in verschiedenen Formaten (horizontal oder vertikal) darstellbar sind.
- **Nachteile**
	1. **Platzbedarf**, da bei vielen Kategorien das Diagramm unübersichtlich werden und viel Platz einnehmen kann.
	2. **Verzerrung durch Skalen**, wenn die Skala nicht richtig gewählt ist, können Säulendiagramme die Daten verzerrt darstellen und falsche Eindrücke vermitteln.
	3. **Begrenzte Detailtiefe**, da sie keine Trends über die Zeit oder komplexe Beziehungen zwischen Variablen zeigen können.
- **Anwendungsfälle**
	1. **Marktforschung**: Vergleich von Marktanteilen verschiedener Unternehmen oder Produkte in einem bestimmten Sektor.
	2. **Umfragen**: Darstellung der Ergebnisse von Umfragen, z.B. die Präferenzen von Konsumenten zu verschiedenen Produkten oder Dienstleistungen.
	3. **Finanzberichte**: Visualisierung von Einnahmen, Ausgaben oder anderen finanziellen Kennzahlen über verschiedene Zeiträume oder Abteilungen hinweg.

![[Pasted image 20240928133602.png]]

## Blasendiagramm
- wie [[#Streudiagramm]], bloß werden durch **Punktgröße** und **Farbe** noch zwei weitere Variablen dargestellt
- **Vorteile**
	1. **Visualisierung von mehreren Dimensionen**, da die Position der Blasen auf der X- und Y-Achse sowie die Größe der Blasen zusätzliche Informationen darstellen.
	2. **Identifikation von Mustern und Trends**, da die Verteilung der Blasen auf dem Diagramm Korrelationen zwischen Variablen aufzeigen kann.
	3. **Einfache Darstellung von Datenpunkten**, die eine große Menge an Informationen in einem kompakten Format präsentieren.
- **Nachteile**
	1. **Schwierigkeiten bei der Interpretation**, insbesondere wenn viele Blasen überlappen oder wenn die Größe der Blasen nicht intuitiv wahrgenommen wird.
	2. **Begrenzte Lesbarkeit**, wenn zu viele Datenpunkte dargestellt werden, was zu Verwirrung führen kann.
	3. **Nicht ideal für kleine Datenmengen**, da die Vorteile der Blasendarstellung bei wenigen Punkten nicht zur Geltung kommen.
- **Anwendungsfälle**
	1. **Marktforschung**: Analyse von Produkten oder Dienstleistungen, wobei Preis (X-Achse), Kundenzufriedenheit (Y-Achse) und Marktanteil (Größe der Blase) dargestellt werden.
	2. **Wirtschaftsanalyse**: Visualisierung von Unternehmensdaten, z.B. Umsatz (X-Achse), Gewinn (Y-Achse) und Mitarbeiterzahl (Größe der Blase).
	3. **Umweltstudien**: Darstellung von Daten zu Emissionen, wobei die X-Achse CO2-Ausstoß, die Y-Achse Luftqualität und die Blasengröße die Bevölkerung eines Gebiets repräsentiert.

![[Pasted image 20240928133737.png]]
## Pegelkarte
- auch **Gauge-Diagramm**, zeigt wo Datenwerte auf bestimmter Skala liegen
- **Vorteile**
	1. **Einfache Visualisierung von Leistungskennzahlen**, die es ermöglicht, den aktuellen Status auf einen Blick zu erfassen, z.B. Fortschritt oder Zielerreichung.
	2. **Intuitive Darstellung**, die es den Betrachtern erleichtert, den aktuellen Stand im Verhältnis zu einem definierten Ziel oder Bereich zu verstehen.
	3. **Schnelle Identifikation von Problemen**, da Abweichungen von den Zielwerten sofort sichtbar sind.
- **Nachteile**
	1. **Begrenzte Detailtiefe**, da sie oft nur einen einzelnen Wert darstellen und keine umfassenden Informationen über Trends oder historische Daten bieten.
	2. **Subjektive Interpretation**, da die Farbcodierung (z.B. rot, gelb, grün) unterschiedlich interpretiert werden kann und nicht immer objektiv ist.
	3. **Nicht geeignet für komplexe Datenanalysen**, da sie keine Beziehungen zwischen mehreren Variablen darstellen können.
- **Anwendungsfälle**
	1. **Geschäftsberichte**: Darstellung von KPIs (Key Performance Indicators), wie Umsatz, Gewinn oder Kundenzufriedenheit, um den aktuellen Stand zu visualisieren.
	2. **Projektmanagement**: Überwachung des Fortschritts von Projekten, z.B. den Abschlussgrad im Vergleich zu den geplanten Meilensteinen.
	3. **Gesundheitsüberwachung**: Visualisierung von Vitalzeichen oder anderen Gesundheitskennzahlen, um den aktuellen Gesundheitszustand schnell zu erfassen.
![[Pasted image 20240928133957.png]]
## Gestapeltes Venn
- **überschneidende Beziehungen** zwischen mehreren Datensätzen darstellen
- **Vorteile**
	1. **Visualisierung von Überschneidungen**, die es ermöglicht, die Beziehungen zwischen mehreren Gruppen oder Kategorien klar darzustellen.
	2. **Einfache Darstellung von Mehrfachzugehörigkeiten**, da die Bereiche, in denen sich die Kreise überschneiden, die gemeinsamen Elemente zwischen den Gruppen zeigen.
	3. **Intuitive Interpretation**, die es den Betrachtern erleichtert, die Verteilung und die Beziehungen zwischen den verschiedenen Gruppen zu verstehen.
- **Nachteile**
	1. **Komplexität bei vielen Gruppen**, da die Darstellung unübersichtlich werden kann, wenn zu viele Kreise oder Überschneidungen vorhanden sind.
	2. **Begrenzte Detailtiefe**, da sie oft keine quantitativen Informationen über die Größe der Gruppen oder die Anzahl der Elemente in den Überschneidungen bieten.
	3. **Schwierigkeiten bei der genauen Interpretation**, insbesondere wenn die Kreise sehr nah beieinander liegen oder sich stark überschneiden.
- **Anwendungsfälle**
	1. **Marktforschung**: Analyse von Zielgruppen, um zu verstehen, wie verschiedene Kundensegmente miteinander interagieren oder sich überschneiden.
	2. **Wissenschaftliche Studien**: Untersuchung von Gemeinsamkeiten und Unterschieden zwischen verschiedenen Arten oder Populationen in der Biologie oder Ökologie.
	3. **Datenanalyse**: Visualisierung von Daten, um die Beziehungen zwischen verschiedenen Variablen oder Kategorien zu verdeutlichen, z.B. in der Soziologie oder Psychologie.
![[Pasted image 20240928134335.png]]

## Mosaik-Plot
- **Visualisierung von Verhältnissen** zwischen mehreren kategorialen Variablen in einer kompakten und vergleichbaren Form.
- **Vorteile**
	1. **Visualisierung von komplexen Datenbeziehungen**, die es ermöglicht, die Verteilung und die Beziehungen zwischen mehreren Kategorien auf einen Blick zu erfassen.
	2. **Einfache Darstellung von Anteilen**, da die Größe der Mosaikfelder die relative Häufigkeit oder den Anteil der jeweiligen Kategorie darstellt.
	3. **Intuitive Interpretation**, die es den Betrachtern erleichtert, Muster und Trends in den Daten zu erkennen, insbesondere bei großen Datensätzen.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Quantifizierung**, da die genauen Werte oft nicht direkt aus der Darstellung abgelesen werden können.
	2. **Überladung mit Informationen**, wenn zu viele Kategorien oder Unterkategorien dargestellt werden, was die Lesbarkeit und das Verständnis beeinträchtigen kann.
	3. **Begrenzte Detailtiefe**, da sie keine zeitlichen Entwicklungen oder komplexen Beziehungen zwischen Variablen darstellen können.
- **Anwendungsfälle**
	1. **Marktforschung**: Analyse von Kundenpräferenzen, um die Verteilung von Kaufentscheidungen über verschiedene Produktkategorien darzustellen.
	2. **Sozialwissenschaftliche Studien**: Untersuchung von demografischen Daten, um die Verteilung von Merkmalen wie Geschlecht, Alter oder Einkommen in einer Population zu visualisieren.
	3. **Gesundheitsforschung**: Darstellung von Krankheitsverteilungen oder Risikofaktoren in verschiedenen Bevölkerungsgruppen, um Muster und Zusammenhänge zu erkennen.
![[Pasted image 20240928134619.png]]
## Gantt-Diagramm
- Veranschaulichung eines **Projektplans**, auf einer Achse Aufgaben, aber anderer Zeitachse 
- **Vorteile**
	1. **Einfache Visualisierung von Projektzeitplänen**, die es ermöglicht, den Fortschritt und die Dauer von Aufgaben auf einen Blick zu erfassen.
	2. **Klare Darstellung von Abhängigkeiten**, da die Beziehungen zwischen verschiedenen Aufgaben und deren zeitliche Abfolge deutlich gemacht werden.
	3. **Hilfreich für die Ressourcenplanung**, da es zeigt, welche Ressourcen zu welchem Zeitpunkt benötigt werden und wie sie auf verschiedene Aufgaben verteilt sind.
- **Nachteile**
	1. **Komplexität bei großen Projekten**, da Gantt-Diagramme unübersichtlich werden können, wenn viele Aufgaben und Abhängigkeiten dargestellt werden.
	2. **Begrenzte Detailtiefe**, da sie oft keine Informationen über die Qualität oder den Status der Aufgaben bieten, sondern sich nur auf die Zeitachse konzentrieren.
	3. **Schwierigkeiten bei der Anpassung**, da Änderungen im Zeitplan oft eine Neugestaltung des gesamten Diagramms erfordern können.
- **Anwendungsfälle**
	1. **Projektmanagement**: Planung und Überwachung von Projekten in verschiedenen Branchen, um den Fortschritt und die Einhaltung von Fristen zu verfolgen.
	2. **Bauprojekte**: Darstellung der verschiedenen Phasen und Aufgaben im Bauprozess, um sicherzustellen, dass alle Schritte rechtzeitig abgeschlossen werden.
	3. **Softwareentwicklung**: Visualisierung von Entwicklungszyklen, um die Planung
![[Pasted image 20240928134751.png]]

## Radarkarte
- auch bekannt als **Spinnen-** oder **Netzdiagramm**
- mehrere verschiedene quantitative Achsen, zeigen mehrere Variablen an
- **Vorteile**
	1. **Visualisierung mehrdimensionaler Daten**, die es ermöglicht, mehrere Variablen gleichzeitig darzustellen und deren Beziehungen zueinander zu erkennen.
	2. **Einfache Identifikation von Stärken und Schwächen**, da die Form und Größe des Diagramms aufzeigt, in welchen Bereichen eine Leistung über oder unter dem Durchschnitt liegt.
	3. **Intuitive Darstellung**, die es den Betrachtern erleichtert, komplexe Informationen auf einen Blick zu erfassen und zu vergleichen.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Quantifizierung**, da die Werte oft schwer abzulesen sind und die Interpretation subjektiv sein kann.
	2. **Begrenzte Anzahl an Variablen**, da zu viele Achsen das Diagramm unübersichtlich machen und die Lesbarkeit beeinträchtigen können.
	3. **Nicht ideal für zeitliche Entwicklungen**, da Radarkarten keine Informationen über Veränderungen im Zeitverlauf liefern.
- **Anwendungsfälle**
	1. **Leistungsbewertung**: Vergleich von Produkten oder Dienstleistungen anhand mehrerer Kriterien, z.B. in der Marktforschung oder Produktentwicklung.
	2. **Mitarbeiterbewertung**: Visualisierung der Kompetenzen und Fähigkeiten von Mitarbeitern in verschiedenen Bereichen, um Stärken und Entwicklungsfelder zu identifizieren.
	3. **Sportanalysen**: Vergleich der Leistungen von Athleten oder Teams in verschiedenen Disziplinen oder Statistiken, um deren Gesamtleistung zu bewerten.
![[Pasted image 20240928134930.png]]
## Wasserfall-Diagramm
- Ausgangswert durch eine **Reihe von Zwischenwerten** erhöht und verringert wird
- - **Vorteile**
	1. **Einfache Visualisierung von Veränderungen**, die es ermöglicht, den Einfluss einzelner Faktoren auf einen Gesamtwert über einen bestimmten Zeitraum oder Prozess darzustellen.
	2. **Klare Darstellung von positiven und negativen Werten**, da die unterschiedlichen Farben (z.B. grün für Gewinne und rot für Verluste) sofort ins Auge fallen und die Entwicklung nachvollziehbar machen.
	3. **Hilfreich für die Analyse von Finanzdaten**, da sie die Entwicklung von Einnahmen, Ausgaben und Gewinnen in einem übersichtlichen Format zeigen.
- **Nachteile**
	1. **Begrenzte Detailtiefe**, da sie oft keine genauen Werte anzeigen, sondern nur die Veränderungen zwischen den einzelnen Schritten darstellen.
	2. **Schwierigkeiten bei der Interpretation**, wenn zu viele Datenpunkte oder Kategorien dargestellt werden, was die Übersichtlichkeit beeinträchtigen kann.
	3. **Nicht ideal für zeitliche Entwicklungen**, da sie sich eher auf die Veränderung von Werten als auf deren Verlauf über die Zeit konzentrieren.
- **Anwendungsfälle**
	1. **Finanzberichte**: Darstellung von Umsatz- und Gewinnentwicklungen, um die Auswirkungen von Kosten und Einnahmen auf den Gesamtgewinn zu visualisieren.
	2. **Projektmanagement**: Analyse von Budgetveränderungen im Verlauf eines Projekts, um die Auswirkungen von Ausgaben und Einsparungen zu verdeutlichen.
	3. **Verkaufsanalysen**: Visualisierung von Verkaufszahlen, um die Auswirkungen von Marketingmaßnahmen oder saisonalen Schwankungen auf den Gesamtumsatz zu zeigen.
![[Pasted image 20240928135119.png]]
## Wärmekarte
- Muster, Varianz und Cluster werden sichtbar
- - **Vorteile**
	1. **Einfache Visualisierung von Datenintensität**, die es ermöglicht, Muster und Trends in großen Datensätzen schnell zu erkennen, indem Farben verwendet werden, um Werte darzustellen.
	2. **Intuitive Darstellung**, die es den Betrachtern erleichtert, Bereiche mit hoher oder niedriger Aktivität auf einen Blick zu identifizieren.
	3. **Flexibilität in der Anwendung**, da Wärmekarten in verschiedenen Bereichen eingesetzt werden können, z.B. in der Webanalyse, Marktforschung oder Gesundheitsforschung.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Quantifizierung**, da die genauen Werte oft nicht direkt aus der Darstellung abgelesen werden können und die Interpretation subjektiv sein kann.
	2. **Überladung mit Informationen**, wenn zu viele Datenpunkte oder Kategorien dargestellt werden, was die Lesbarkeit und das Verständnis beeinträchtigen kann.
	3. **Begrenzte Detailtiefe**, da sie oft keine Informationen über die Ursachen von Mustern oder Trends liefern, sondern lediglich die Intensität darstellen.
- **Anwendungsfälle**
	1. **Web-Analytics**: Analyse von Nutzerverhalten auf Webseiten, um zu sehen, welche Bereiche am häufigsten besucht oder angeklickt werden.
	2. **Marktforschung**: Visualisierung von Kundenpräferenzen oder Kaufverhalten in verschiedenen Regionen oder demografischen Gruppen.
	3. **Gesundheitsforschung**: Darstellung von Krankheitsverteilungen oder Risikofaktoren in verschiedenen Bevölkerungsgruppen, um Muster und Zusammenhänge zu erkennen.

![[Pasted image 20240928135234.png]]
## Trichterdiagramm
- Fluss von Nutzern durch einen **Konversionsprozess**
- **Vorteile**
	1. **Einfache Visualisierung von Prozessen**, die es ermöglicht, den Fortschritt durch verschiedene Phasen eines Prozesses, wie z.B. Verkaufs- oder Marketingtrichter, klar darzustellen.
	2. **Identifikation von Engpässen**, da es sofort sichtbar macht, wo in einem Prozess die meisten Verluste oder Abbrüche auftreten.
	3. **Intuitive Darstellung**, die es den Betrachtern erleichtert, die Abnahme der Anzahl von Elementen (z.B. Leads, Kunden) von einer Phase zur nächsten zu verstehen.
- **Nachteile**
	1. **Begrenzte Detailtiefe**, da sie oft keine genauen Werte anzeigen, sondern nur die relative Größe der einzelnen Phasen darstellen.
	2. **Schwierigkeiten bei der Interpretation**, wenn die Phasen nicht klar definiert sind oder wenn es viele Zwischenstufen gibt, was die Übersichtlichkeit beeinträchtigen kann.
	3. **Nicht ideal für komplexe Prozesse**, da sie sich eher auf die Darstellung von linearen Abläufen konzentrieren und weniger für nicht-lineare Prozesse geeignet sind.
- **Anwendungsfälle**
	1. **Vertrieb und Marketing**: Analyse des Verkaufsprozesses, um zu sehen, wie viele Leads in zahlende Kunden umgewandelt werden.
	2. **Kundenakquise**: Visualisierung der Schritte, die ein potenzieller Kunde durchläuft, von der ersten Kontaktaufnahme bis zum Kauf.
	3. **Projektmanagement**: Darstellung von Phasen in einem Projekt, um den Fortschritt und die Anzahl der abgeschlossenen Aufgaben in jeder Phase zu verfolgen.
![[Pasted image 20240928135506.png]]
## Pareto-Diagramm
- enthält sowohl Balken als auch Liniendiagramm
- Balken stellen Einzelwerte dar, Linie gibt kumulierte Summe an
- **Vorteile**
	1. **Einfache Identifikation von Hauptursachen**, da es die wichtigsten Faktoren oder Probleme hervorhebt, die den größten Einfluss auf ein Ergebnis haben, basierend auf dem Pareto-Prinzip (80/20-Regel).
	2. **Kombination von Balken- und Liniendiagramm**, die es ermöglicht, sowohl die absoluten Werte als auch den kumulierten Prozentsatz der Gesamtwirkung darzustellen.
	3. **Hilfreich für Priorisierungen**, da es Entscheidungsträgern hilft, sich auf die kritischsten Bereiche zu konzentrieren, die verbessert werden müssen.
- **Nachteile**
	1. **Begrenzte Detailtiefe**, da es oft nur die wichtigsten Kategorien darstellt und weniger relevante Faktoren ignoriert werden können.
	2. **Schwierigkeiten bei der Interpretation**, wenn die Daten nicht klar kategorisiert sind oder wenn es viele kleine Kategorien gibt, die das Diagramm überladen.
	3. **Nicht ideal für alle Datentypen**, da es sich am besten für qualitative Daten eignet und weniger für quantitative Analysen.
- **Anwendungsfälle**
	1. **Qualitätsmanagement**: Analyse von Fehlerursachen in einem Produktionsprozess, um die häufigsten Probleme zu identifizieren und zu beheben.
	2. **Kundenfeedback**: Auswertung von Kundenbeschwerden oder -anfragen, um die häufigsten Anliegen zu erkennen und priorisieren zu können.
	3. **Kostenanalyse**: Identifikation der Hauptkostenfaktoren in einem Unternehmen, um gezielte Einsparungsmaßnahmen zu entwickeln.
![[Pasted image 20240928135650.png]]
## Gestapeltes Balkendiagramm
- **verschiedene Kategorien** von Daten in einem einzelnen Balken übereinander gestapelt
- Darstellung von zusammengesetzten Daten, um die **Verteilung und den Vergleich von Teilmengen** innerhalb einer Gesamtmenge
- **Vorteile**
	1. **Visualisierung von Teil-Ganzes-Beziehungen**, da es ermöglicht, sowohl die Gesamtwerte als auch die Anteile der einzelnen Kategorien auf einen Blick zu erfassen.
	2. **Vergleich von Kategorien**, da mehrere Gruppen in einem Diagramm dargestellt werden können, was den direkten Vergleich zwischen verschiedenen Datensätzen erleichtert.
	3. **Einfache Identifikation von Trends**, da Veränderungen in den einzelnen Kategorien über verschiedene Zeiträume oder Bedingungen hinweg leicht erkennbar sind.
- **Nachteile**
	1. **Schwierigkeiten bei der genauen Ablesung**, da die einzelnen Segmente in großen oder komplexen Diagrammen schwer zu unterscheiden sein können.
	2. **Begrenzte Anzahl an Kategorien**, da zu viele gestapelte Segmente das Diagramm überladen und die Lesbarkeit beeinträchtigen können.
	3. **Verlust von Detailinformationen**, da die genauen Werte der einzelnen Kategorien oft nicht direkt ablesbar sind und zusätzliche Daten benötigt werden, um die genauen Zahlen zu verstehen.
- **Anwendungsfälle**
	1. **Verkaufsanalyse**: Darstellung der Verkaufszahlen verschiedener Produkte innerhalb einer Kategorie über mehrere Zeiträume, um Trends und Veränderungen zu erkennen.
	2. **Budgetverteilung**: Visualisierung der Ausgaben in verschiedenen Abteilungen eines Unternehmens, um die Verteilung der finanziellen Mittel zu analysieren.
	3. **Marktforschung**: Vergleich der Marktanteile verschiedener Unternehmen in einer Branche, um die Wettbewerbslandschaft zu verstehen.
![[Pasted image 20240928135735.png]]

## Flussdiagramm
- Darstellung eines Prozesses oder Workflows, die aus verschiedenen Symbolen und Pfeilen besteht, die die Schritte und deren **Reihenfolge** darstellen
- komplexe Prozesse zu visualisieren, zu analysieren und zu optimieren, indem es die einzelnen Schritte und Entscheidungen klar darstellt
- **Vorteile**
	1. **Einfache Visualisierung von Prozessen**, die es ermöglicht, komplexe Abläufe klar und verständlich darzustellen.
	2. **Identifikation von Engpässen und Ineffizienzen**, da der gesamte Prozess auf einen Blick betrachtet werden kann, was die Optimierung erleichtert.
	3. **Förderung der Kommunikation**, da Flussdiagramme als gemeinsames Verständnis für Teammitglieder dienen und Missverständnisse reduzieren.
- **Nachteile**
	1. **Überladung von Informationen**, wenn zu viele Schritte oder Entscheidungen dargestellt werden, was die Lesbarkeit und Verständlichkeit beeinträchtigen kann.
	2. **Begrenzte Flexibilität**, da Änderungen im Prozess oft eine vollständige Überarbeitung des Diagramms erfordern können.
	3. **Subjektive Interpretation**, da unterschiedliche Personen den gleichen Prozess unterschiedlich darstellen können, was zu Inkonsistenzen führen kann.
- **Anwendungsfälle**
	1. **Softwareentwicklung**: Visualisierung von Algorithmen oder Programmabläufen, um die Logik und Struktur des Codes zu verdeutlichen.
	2. **Prozessoptimierung**: Analyse von Geschäftsprozessen, um Verbesserungspotenziale zu identifizieren und die Effizienz zu steigern.
	3. **Schulung und Einarbeitung**: Verwendung in Schulungsunterlagen, um neuen Mitarbeitern die Abläufe und Verfahren im Unternehmen verständlich zu machen.
![[Pasted image 20240928140026.png]]
## Boxplot
- Grafische Darstellung der **Verteilung von Datenpunkten** durch fünf Kennzahlen: **Minimum, erstes Quartil, Median, drittes Quartil und Maximum**.
- Hilfreich zur **Identifikation von Ausreißern** und zur Visualisierung der Verteilung und **Streuung** von Daten in verschiedenen Gruppen.
- **Vorteile**
	1. **Klarheit der Datenverteilung**, da Box-Plots eine kompakte Übersicht über zentrale Tendenzen und Streuungen bieten.
	2. **Identifikation von Ausreißern**, da extreme Werte außerhalb der Box und Whisker deutlich sichtbar sind.
	3. **Vergleich zwischen Gruppen**, da mehrere Box-Plots nebeneinander dargestellt werden können, um Unterschiede in der Verteilung zu analysieren.
- **Nachteile**
	1. **Verlust von Detailinformationen**, da individuelle Datenpunkte nicht angezeigt werden, was die Interpretation erschweren kann.
	2. **Schwierigkeiten bei der Interpretation**, wenn die Datenverteilung stark asymmetrisch ist oder mehrere Gruppen verglichen werden.
	3. **Begrenzte Aussagekraft bei kleinen Stichproben**, da die Box-Plot-Darstellung bei wenigen Datenpunkten weniger aussagekräftig ist.
- **Anwendungsfälle**
	1. **Statistische Analyse**: Vergleich von Testergebnissen oder Messwerten in verschiedenen Gruppen, um Unterschiede in der Leistung zu erkennen.
	2. **Qualitätskontrolle**: Überwachung von Produktionsdaten, um die Konsistenz und Stabilität von Prozessen zu bewerten.
	3. **Forschung**: Visualisierung von Umfragedaten oder experimentellen Ergebnissen, um die Verteilung und Variabilität der Antworten zu analysieren.

![[Pasted image 20240928140154.png]]

## Quellen

> https://piktochart.com/de/blog/diagramm-arten/

- sagt aus **wie dicht** betrachteten Werte **um einen beliebigen Punkt** verteilt sind
- bei [[Zufallsvariable|diskreten Zufallsvariablen]]: Wahrscheinlichkeitsfunktion
	- jedem Ergebnis kann eine Wahrscheinlichkeit zugeordnet werden
	1. Die Wahrscheinlichkeit für ein mögliches Ergebnis **nie kleiner 0**
	2. Summe aller Wahrscheinlichkeiten **immer 1**
- bei [[Zufallsvariable|stetigen Zufallsvariablen]]: Wahrscheinlichkeitsdichte/Dichtefunktion
	- keine Einzelnen Punkte
	- Bildet über unendlich viele Werte ein integral
	1. $f(x) \geq 0$ für alle $x \in R$
	2. $\int^{\infty}_{-\infty} f(x)dx = 1$
	3. $P(X = x) = 0$ für alle $x \in R$

## Notwendigkeit einer digitalen Signatur (Zertifikate)
- **Authentifizierung**: Bestätigung der Identität von Benutzern und Systemen.
- **Integrität**: Sicherstellung, dass Daten während der Übertragung nicht verändert wurden.
- **Vertraulichkeit**: Verschlüsselung von Daten, um unbefugten Zugriff zu verhindern.
- **Vertrauenswürdigkeit**: Vertrauensbasis für Online-Transaktionen und Kommunikation.
- **Rechtliche Anerkennung**: Digitale Signaturen haben rechtliche Gültigkeit in vielen Ländern.

## Praktische Umsetzung
- **Zertifizierungsstelle (CA)**:
  - Auswahl einer vertrauenswürdigen CA zur Ausstellung von digitalen Zertifikaten.
  - CA überprüft Identität des Antragstellers.

- **Zertifikatstypen**:
  - **SSL/TLS-Zertifikate**: Für sichere Webseiten ([[HTTPS]]).
  - **Code Signing-Zertifikate**: Für die Signierung von Software und Anwendungen.
  - **S/MIME-Zertifikate**: Für die sichere E-Mail-Kommunikation.

- **Zertifikat beantragen**:
  - Erstellung eines Schlüsselpaares (privater und öffentlicher Schlüssel).
  - Einreichung einer Zertifikatsanfrage (CSR) bei der CA.

- **Zertifikat installieren**:
  - Installation des erhaltenen Zertifikats auf dem Server oder in der Anwendung.
  - Konfiguration der Software zur Nutzung des Zertifikats.

- **Zertifikatsverwaltung**:
  - Regelmäßige Überprüfung und Erneuerung von Zertifikaten.
  - Widerruf von Zertifikaten bei Verlust des privaten Schlüssels oder bei Kompromittierung.

## Quellen

> OpenAI. (2024). _ChatGPT AI language model_. Abgerufen am 18. September 2024, von [https://www.openai.com/chatgpt](https://www.openai.com/chatgpt)

- **Definition**: Disaster-Recovery (DR) umfasst **Strategien und Technologien zur Vermeidung oder Minimierung von Datenverlusten und Betriebsunterbrechungen** infolge von **Katastrophenereignissen** (z. B. Geräteausfälle, Cyberattacken, Naturkatastrophen).

## 1. Disaster-Recovery-Planung
- *Entwicklung einer Strategie*, *Planung*, *Einsatz geeigneter Technologien* und *kontinuierliche Tests* sind entscheidend.
- Sicherungs- und Wiederherstellungsprozesse allein bilden keinen vollständigen DR-Plan.

## 2. Wichtige Konzepte
- **Failover**: Auslagerung von Workloads auf Backup-Systeme.
- **Failback**: Rückkehr zum ursprünglichen Primärsystem.

## 3. Business-Continuity-Planung
- Sicherstellung, dass **wesentliche Abläufe im Notfall aufrechterhalten** oder schnell wiederhergestellt werden.

## 4. Business-Impact-Analyse
- **Analyse** der **Auswirkungen** auf das Unternehmen zur **Identifikation kritischer Bereiche und Funktionen**.
- Erstellung von **Katastrophenszenarien** zur Vorhersage von Verlusten.

## 5. Risikoanalyse
- Bewertung der **Wahrscheinlichkeit** und **potenzieller Folgen** von Risiken.
- Identifikation finanzieller Verluste, Imageschäden und Produktivitätsverluste.

## 6. Priorisierung von Anwendungen
- Klassifizierung nach Wichtigkeit:
  - **Geschäftskritisch**: Unentbehrliche Anwendungen.
  - **Wichtig**: Anwendungen mit tolerierbaren Ausfallzeiten.
  - **Nicht wesentlich**: Vorübergehend ersetzbare Anwendungen.

## 7. Dokumentation von Abhängigkeiten
- Bestandsaufnahme von Hardware und Software sowie kritischen Abhängigkeiten zwischen Anwendungen.

## 8. Wiederherstellungsziele
- **RTO (Recovery Time Objective)**: Maximale Zeitspanne für die Wiederherstellung.
- **RPO (Recovery Point Objective)**: Maximales Alter der wiederherzustellenden Daten.
- **RCO (Recovery Consistency Objective)**: Tolerierbare Anzahl inkonsistenter Einträge in Geschäftsdaten.

## 9. Einhaltung gesetzlicher Vorschriften
- Sicherstellung, dass alle DR-Lösungen **Datenschutz- und Sicherheitsanforderungen** erfüllen.

## 10. Auswahl von Technologien
- Backups als Grundlage für den DR-Plan.
- Berücksichtigung von cloudbasierten Backup-Lösungen oder DRaaS-Anbietern.

## 11. Auswahl von Recovery-Standorten
- **Geografische Trennung** der Backup-Daten zur Risikominderung.

## 12. Kontinuierliche Tests und Überprüfung
- Regelmäßige Tests des DR-Plans zur Sicherstellung der Verlässlichkeit.
- Aktualisierung des Plans bei Änderungen der Hardware- und Software-Assets.

## 13. Disaster-Recovery as a Service (DRaaS)
- Cloudbasierte Lösungen zur Kostensenkung und Effizienzsteigerung.
- Anbieter dokumentieren RTOs und RPOs in Service-Level-Vereinbarungen (SLAs).

Das **Domain Name System (DNS)** ist ein zentrales Element des Internets, das die Umwandlung von **Domainnamen** in **IP-Adressen** ermöglicht. Es fungiert als eine Art **Telefonbuch** für das Internet, indem es Benutzern erlaubt, Webseiten über leicht merkbare Namen anstelle von numerischen IP-Adressen zu erreichen. 

### Hauptmerkmale:
- **Hierarchische Struktur**: DNS ist in eine hierarchische Struktur unterteilt, die aus **Root-DNS-Servern**, **Top-Level-Domains (TLDs)** und **Subdomains** besteht.
- **Verteilte Datenbank**: DNS-Daten sind über viele Server verteilt, was die **Zuverlässigkeit** und **Verfügbarkeit** erhöht.

### Anwendungsgebiete:
- **Webseitenzugriff**: Umwandlung von Domainnamen in IP-Adressen.
- **E-Mail-Routing**: Verwendung von **MX-Einträgen** zur Bestimmung von E-Mail-Servern.
- **Lastverteilung**: Nutzung von **CNAME**-Einträgen zur Verteilung des Datenverkehrs.

## Struktur des DNS

1. **DNS-Server-Typen**:
   - **Authoritative DNS-Server**: Beherbergen die tatsächlichen DNS-Daten für eine Domain.
   - **Recursive DNS-Server**: Leiten Anfragen an die entsprechenden autoritativen Server weiter.

2. **DNS-Einträge**:
   - **A-Eintrag**: Verknüpft einen Domainnamen mit einer IPv4-Adresse.
   - **AAAA-Eintrag**: Verknüpft einen Domainnamen mit einer IPv6-Adresse.
   - **CNAME-Eintrag**: Alias für einen anderen Domainnamen.
   - **MX-Eintrag**: Bestimmt den Mailserver für eine Domain.

### Beispiel für DNS-Einträge:
```plaintext
example.com.    IN  A       192.0.2.1
www.example.com. IN  CNAME   example.com.
example.com.    IN  MX      10 mail.example.com.
```

## Vorteile und Herausforderungen

### Vorteile:
- **Benutzerfreundlichkeit**: Ermöglicht die Verwendung von **einprägsamen Domainnamen**.
- **Skalierbarkeit**: Unterstützt eine große Anzahl von Domains und Subdomains.
- **Redundanz**: Durch die verteilte Struktur wird die **Verfügbarkeit** erhöht.

### Herausforderungen:
- **Sicherheitsrisiken**: Anfällig für **DNS-Spoofing** und **DDoS-Angriffe**.
- **Komplexität**: Die Verwaltung von DNS kann für große Organisationen herausfordernd sein.
- **Caching-Probleme**: Änderungen an DNS-Einträgen können durch **Caching** verzögert werden.

## Best Practices

- **Regelmäßige Überprüfung**: Führen Sie regelmäßige **Audits** Ihrer DNS-Einträge durch, um sicherzustellen, dass sie aktuell sind.
- **Sicherheitsmaßnahmen**: Implementieren Sie **DNSSEC** (Domain Name System Security Extensions) zur Erhöhung der Sicherheit.
- **Monitoring**: Nutzen Sie **Monitoring-Tools**, um die Verfügbarkeit und Leistung Ihrer DNS-Server zu überwachen.
- **Backup**: Erstellen Sie regelmäßige **Backups** Ihrer DNS-Konfigurationen.

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **e**rweiterte **E**reignisgesteuerte **P**rozess**k**etten
- zur Modellierung von **[[Geschäftsprozess|Geschäftsprozessen]]** geeignet

	## Regeln
1. Ein eEPK **beginnt und endet mit einem Ereignis.**
2. **Ereignisse und Funktionen wechseln** sich im Ablauf immer ab.
3. Sowohl Ereignis aus auch Funktion haben jeweils nur **einen Kontrollflußeingang** und **einen Kontrollflußausgang.**
4. Ein **Konnektor** kann **mehrere Kontrollflußeingänge** und **mehrere Kontrollflußausgänge** haben.
5. **Mehrere Teilabläufe** werden durch die **gleiche Art Konnektor** **zusammengeführt**, mit **der sie aufgeteilt** wurden.

## Elemente
![[Pasted image 20240918104010.png]]
- **Ereignis**, Start oder Ende eines Prozesses. Auslöser und Ergebnis von Funktionen
![[Pasted image 20240918104044.png]]
- **Funktion**, Elementarer Arbeitsschritt. Transformiert Input zu Output. Wird durch *Ereignis ausgelöst und hat Ereignis als Folge*
![[Pasted image 20240918104129.png]]
- **Oder-Konnektor** / **Operator**, teilt/verbindet Abfolge. Teilfolgen können *alternativ* oder auch *alle* durchlaufen werden
![[Pasted image 20240918104221.png]]
- **XOR-Konnektor** / **Operator**, teilt/verbindet Abfolge. Teilfolgen können nur *alternativ* durchlaufen werden
![[Pasted image 20240918104252.png]]
- **Und-Konnektor** / **Operator**, teilt/verbindet Abfolge. *Alle* Teilfolgen werden durchlaufen 
![[Pasted image 20240918105726.png]]
- **Kontrollfluss**, Verbindet Ereignisse und Funktionen sowie Konnektoren
![[Pasted image 20240918105748.png]]
- **Prozesswegweiser**, verweist auf kompletten *Teilprozess*, der separat modelliert ist
![[Pasted image 20240918105820.png]]
- **Organisationseinheit** / **Person**, Beteiligten an Funktion
![[Pasted image 20240918105857.png]]
- **Daten**, beschreibt welche Daten von einer Funktion *benötigt* oder *erzeugt* werden
![[Pasted image 20240918105931.png]]
- **Programm** / **Modul**, beschreibt mit welchem Modul/Programm die Funktion Daten transformiert
![[Pasted image 20240918110321.png]]
- **Anwendungssystem**, beschreibt mit welchem Anwendungssystem (mehreren Modulen, Programme, ...) die Funktion Daten transformiert

## Beispiele

![[Pasted image 20240918110920.png]]![[Pasted image 20240918110927.png]]

- **spezialisierte Computer**, die in andere Geräte oder **Systeme integriert** sind, um **spezifische Funktionen** auszuführen. Sie sind oft für die Steuerung, Überwachung oder Verarbeitung von Daten in Echtzeit konzipiert.
- **Ziel**: Bereitstellung von Funktionalitäten in Geräten, die nicht primär als Computer wahrgenommen werden, und Optimierung der Leistung, Effizienz und Benutzerfreundlichkeit.

### Merkmale von Embedded Systems
- **Spezialisiert**: Entwickelt für spezifische Anwendungen oder Aufgaben, im Gegensatz zu allgemeinen Computern.
- **Echtzeitbetrieb**: Reagiert in Echtzeit auf Eingaben und Ereignisse, was für viele Anwendungen (z.B. Automobiltechnik, Medizintechnik) entscheidend ist.
- **Ressourcenschonend**: Oft mit begrenzten Ressourcen (Speicher, Rechenleistung, Energie) ausgestattet, um die Effizienz zu maximieren.
- **Zuverlässigkeit**: Hohe Anforderungen an Stabilität und Fehlertoleranz, da sie häufig in sicherheitskritischen Anwendungen eingesetzt werden.

### Anwendungsbereiche von Embedded Systems
- **Automobilindustrie**: Steuerungssysteme für Motoren, Bremsen, Airbags und Infotainment-Systeme.
- **Medizintechnik**: Geräte wie Herzschrittmacher, Überwachungsgeräte und bildgebende Systeme.
- **Haushaltsgeräte**: Intelligente Kühlschränke, Waschmaschinen und Mikrowellen mit integrierter Steuerung.
- **Industrieautomation**: Steuerung von Maschinen, Robotern und Fertigungsprozessen.
- **Telekommunikation**: Router, Modems und andere Netzwerkgeräte.

### Komponenten von Embedded Systems
- **Hardware**: Mikrocontroller oder Mikroprozessor, Speicher (RAM, Flash), Sensoren, Aktuatoren und Schnittstellen (z.B. USB, Ethernet).
- **Software**: Betriebssysteme (z.B. RTOS - Real-Time Operating System) und Anwendungssoftware, die spezifische Funktionen implementieren.
- **Firmware**: Spezielle Software, die in die Hardware integriert ist und grundlegende Funktionen steuert.

### Entwicklungsprozess von Embedded Systems
1. **Anforderungsanalyse**: Festlegung der funktionalen und nicht-funktionalen Anforderungen.
2. **Systemdesign**: Entwurf der Hardware- und Softwarearchitektur.
3. **Implementierung**: Programmierung der Software und Integration der Hardware.
4. **Test und Validierung**: Überprüfung der Funktionalität und Zuverlässigkeit des Systems.
5. **Deployment**: Implementierung des Systems in der Zielumgebung.
6. **Wartung und Updates**: Regelmäßige Aktualisierungen und Fehlerbehebungen nach der Inbetriebnahme.

### Herausforderungen bei Embedded Systems
- **Komplexität**: Integration von Hardware und Software kann komplex sein und erfordert fundierte Kenntnisse in beiden Bereichen.
- **Echtzeitanforderungen**: Sicherstellung, dass das System in der vorgegebenen Zeit auf Ereignisse reagiert.
- **Sicherheitsaspekte**: Schutz vor Cyberangriffen und Gewährleistung der Datensicherheit, insbesondere in sicherheitskritischen Anwendungen.
- **Ressourcenmanagement**: Effiziente Nutzung von Speicher, Rechenleistung und Energie.
### Wichtige Begriffe
- **Mikrocontroller**: Ein integrierter Schaltkreis, der einen Prozessor, Speicher und Peripheriegeräte in einem einzigen Chip vereint.
- **RTOS (Real-Time Operating System)**: Ein Betriebssystem, das für die Echtzeitverarbeitung von Aufgaben optimiert ist.
- **Firmware**: Software, die in die Hardware eines Geräts integriert ist und grundlegende Funktionen steuert.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- in **Konzeptionsphase** für *Planung* oder **Implementierungsphase** zur *Dokumentation*


## Elemente
![[Pasted image 20240916120044.png]]
- **Entität**, Objekt aus realer Welt, über welches man Informationen speichern möchte
![[Pasted image 20240916120112.png]]
- **Beziehung**, verbindet Entitäten
![[Pasted image 20240916120057.png]]
- **Attribut**, Eigenschaften aus denen Entität zusammengesetzt ist 

## Beziehungen
- **1:1**, Referenz steht auf einer beliebigen Seite
- **1:n**, n-Seite referenziert 1-Seite
- **n:m**, künstliche Tabelle



## Entropie
- Maß für die **Unsicherheit** oder **Unordnung** in einem Datensatz. Je höher die Entropie, desto unordentlicher oder gemischter sind die Klassen im Datensatz.
- Zahlenwert zwischen **0** und **1**. 
	- Entropie 0: Es kann eine **absolut eindeutige Klassifikation** für den Knoten vorgenommen werden. 
	- Entropie 1: Es ist gar **keine Tendenz** zu einer Klassifikation möglich.
### Formel
#### Allgemein
$S$ = Datensatz
$C$ = Alle Klassen im Satz $S$
$p(c)$ = Anzahl der Datenpunkte die zur Klasse $c$ gehören, im Verhältnis zur Gesamtzahl der Datenpunkte in Satz $S$
$$
Entropie(S) = - \sum_{c \in C} p(c) log_2 p(c)
$$
#### IHK
$$
\sum P \cdot log_2 \dfrac{1}{P}
$$
- $P$ Wahrscheinlichkeit von einer Klasse im Bezug auf alle Datenpunkte
##### Beispiel
- 91 durchgeführte Werbemaßnahmen 
- 40 fehlgeschlagene Werbemaßnahmen
- 51 erfolgreich durchgeführte Werbemaßnahmen

$\sum P \cdot log_2 \dfrac{1}{P} = \dfrac{51}{91} \cdot log_2 \dfrac{1}{\dfrac{91}{51}} + \dfrac{40}{91} \cdot log_2 \dfrac{1}{\dfrac{40}{51}} = \dfrac{51}{91} \cdot log_2 \dfrac{91}{51} + \dfrac{40}{91} \cdot log_2 \dfrac{91}{40} \approx 0,9894$

> [!NOTE]- Erklärung
> - Die Entropie wird berechnet, indem man für jede Klasse $c$ die Wahrscheinlichkeit $p(c)$ betrachtet, dass ein zufällig ausgewählter Datenpunkt aus dem Datensatz $S$ zu dieser Klasse gehört. 
>- Der Ausdruck $p(c) \log_2 p(c)$ quantifiziert die Unsicherheit oder den Informationsgehalt, der mit der Klasse $c$ verbunden ist. 
 > - Wenn $p(c)$ hoch ist (d.h. viele Datenpunkte gehören zu dieser Klasse), ist der Informationsgehalt niedrig, weil wir relativ sicher sind, dass ein zufällig ausgewählter Punkt zu dieser Klasse gehört. 
  >- Umgekehrt, wenn $p(c)$ niedrig ist (d.h. wenige Datenpunkte gehören zu dieser Klasse), ist der Informationsgehalt hoch, weil es weniger wahrscheinlich ist, dass ein zufällig ausgewählter Punkt zu dieser Klasse gehört.
>- Das Minuszeichen vor der Summe sorgt dafür, dass die Entropie immer einen positiven Wert hat, da der Logarithmus von Werten zwischen 0 und 1 negativ ist. 
>- Die Entropie ist also ein Maß für die durchschnittliche Unsicherheit oder Unordnung im Datensatz: 
  >- Wenn alle Stichproben in Datensatz $S$ zu einer Klasse gehören, dann ist $Entropie(S) = 0$, was bedeutet, dass es keine Unsicherheit gibt, da alle Datenpunkte gleich sind.
  >- Wenn die Hälfte der Proben einer Klasse und die andere Hälfte einer anderen Klasse zugeordnet werden, dann ist $Entropie(S) = 1$ (maximaler Wert), was maximale Unsicherheit anzeigt, da die Klassen gleichmäßig verteilt sind.

- wenn alle Stichproben in Datensatz $S$ zu einer Klasse gehören dann $Entropie(S) = 0$
- wenn die Hälfte der Proben einer Klasse und die andere Hälfte einer anderen Klasse zugeordnet werden, dann $Entropie(S) = 1$ (maximal Wert)

- Attribut mit *geringster Entropie* sollte gewählt werden

### Berechnung


## Informationsgewinn
- Unterschied der *Entropie* **vor** und **nach** einer **Teilung** eines bestimmten Attributs
- Attribut mit **höchstem** Informationsgewinn erzeugt beste Aufteilung

### Formel
$$
G(D,A) = Entropie(S) - \sum_{v \in V(A)} \dfrac{|D_v|}{|D|}\times{Entropie(S_v)}
$$

> [!NOTE]- Erklärung
>- Der Informationsgewinn $G(D,A)$ misst, wie viel Unsicherheit (Entropie) durch die Teilung des Datensatzes $D$ anhand des Attributs $A$ reduziert wird.
>- $Entropie(S)$ ist die Entropie des ursprünglichen Datensatzes $S$, bevor eine Teilung erfolgt. Es gibt an, wie unrein oder gemischt die Klassen im Datensatz sind.
>- Der Ausdruck $\sum_{v \in V(A)} \dfrac{D_v}{D} \times Entropie(S_v)$ repräsentiert die gewichtete Summe der Entropien der Teilmengen, die durch die Teilung des Datensatzes nach den Werten $v$ des Attributs $A$ entstehen.
  >- Hierbei ist $V(A)$ die Menge der möglichen Werte des Attributs $A$.
  > - $D_v$ ist die Anzahl der Datenpunkte, die dem Wert $v$ des Attributs $A$ zugeordnet sind, und $D$ ist die Gesamtanzahl der Datenpunkte im Datensatz $D$.
  > - Der Term $\dfrac{D_v}{D}$ gibt den Anteil der Datenpunkte an, die dem Wert $v$ zugeordnet sind, und gewichtet somit die Entropie $Entropie(S_v)$ der Teilmenge $S_v$, die den Wert $v$ hat.
> - Der Informationsgewinn $G(D,A)$ ist also die Differenz zwischen der Entropie des ursprünglichen Datensatzes und der gewichteten Summe der Entropien der Teilmengen. 
 > - Ein hoher Wert von $G(D,A)$ bedeutet, dass die Teilung des Attributs $A$ zu einer signifikanten Reduktion der Unsicherheit führt, was darauf hinweist, dass $A$ ein gutes Attribut für die Klassifikation ist.
  >- Ein niedriger oder negativer Wert würde darauf hindeuten, dass die Teilung nicht viel zur Klärung der Klassen beiträgt.

$G(D,A)$ = Informationsgewinn für das Attribut $A$ in Bezug auf den Datensatz $D$.
$V(A)$ = Möglichen Werte des Attributs $A$
$|D_v|$ = Anzahl der Datenpunkte, die dem Wert $v$ des Attributs $A$ zugeordnet sind
$|D|$ = Gesamtanzahl der Datenpunkte im Datensatz $D$
$Entropie(S_v)$ = Entropie des Teilsets $S_v$


- Der Informationsgewinn $G(D,A)$ ist also die **Entropie des ursprünglichen Datensatzes** minus die **gewichtete Summe der Entropien der Teilmengen, die durch die Teilung entstehen**. Ein höherer Wert von $G(D,A)$ bedeutet, dass das Attribut $A$ eine **bessere Trennung** der Klassen ermöglicht.


## Quellen

> Was ist ein Entscheidungsbaum | IBM. (2024, September 17). Retrieved from https://www.ibm.com/de-de/topics/decision-trees
> Tutorials, T. M. (2017, February 16). Machine Learning #39 - Entscheidungsbäume #3 - Entropie und Informationsgewinn. Youtube. Retrieved from https://www.youtube.com/watch?v=lg1pb0YaAjI

- **Nichtparametrische** **überwachte** Lernmethode
- Verwendet für **Klassifikation** und **Regression**
- Modell trifft Vorhersagen durch einfache **Entscheidungsfragen**, die aus den Merkmalen des Datensatzes gelernt werden.

## Funktionsweise
- Der Entscheidungsbaum wird erstellt, indem der Datensatz **rekursiv nach Klassen aufgesplittet** wird (vom Allgemeinen zum Speziellen) -> *rekursive Partitionierung*. Der Prozess endet, wenn eine weitere Partitionierung keinen zusätzlichen Vorhersagewert mehr bietet.

## Arten von Entscheidungsbäumen
1. **Klassifikationsbaum**
   - Gibt normalerweise Ja- oder Nein-Ausgaben / binäre Ausgaben zurück.
2. **Regressionsbaum**
   - Gibt fortlaufende Werte, also numerische Ausgaben zurück.
3. **CART** (Classification and Regression Trees)
   - Sammelbegriff für Klassifikations- und Regressionsbäume.

## Terminologie
- **Wurzelknoten** (*Root Node*): Höchster Knoten, der die gesamte Entscheidung oder "Nachricht" repräsentiert.
- **Entscheidungsknoten** (*Decision/Internal Node*): Knoten, der nach einer Entscheidung steht.
- **Blattknoten** (*Leaf/Terminal Node*): Letzter Knotenpunkt im Baum.
- **Aufspaltung** (*Splitting*): Ein Knotenpunkt verzweigt sich in mehrere Knoten.
- **Beschnitt** (*Pruning*): Mehrere Zweige werden zu einem Baum zusammengefasst, um Überanpassung zu vermeiden.

## Vorteile
- Einfach zu verstehen und zu interpretieren.
- Geringer Vorbereitungsaufwand für Daten erforderlich.
- Entscheidungslogik ist transparent; es handelt sich um ein "White Box"-Modell.

## Nachteile
- Überanpassung (Overfitting) bei zu speziellen Daten und zu komplexen Entscheidungsbäumen.
- Instabilität, da kleine Änderungen im Datensatz das Modell erheblich beeinflussen können.
- Bei unausgewogenen Datensätzen kann das Modell voreingenommen sein.

## Warum ist Entropie wichtig?
- **Auswahl des besten Attributs:** Durch die Berechnung der Entropie für verschiedene Attribute kann dasjenige ausgewählt werden, das die größte Reduktion der Unsicherheit verursacht.
- **Erstellung des Baums:** Der Algorithmus wählt rekursiv die Attribute mit dem höchsten Informationsgewinn aus, um den Baum zu konstruieren.

## Quellen

> 1.10. Decision Trees. (2024, September 11). Abgerufen von https://scikit-learn.org/stable/modules/tree.html  
> Decision Trees in Machine Learning: Two Types (+ Examples). (2024, September 12). Abgerufen von https://www.coursera.org/articles/decision-tree-machine-learning  
> Contributors to Wikimedia projects. (2024, Juli 16). Decision tree learning - Wikipedia. Abgerufen von https://en.wikipedia.org/w/index.php?title=Decision_tree_learning&oldid=1234846759


## Prognose
- **Prognose** eines Ergebnisses eines **Zufallsexperiments**: 
  - Der *erwartete Ausgang* eines Zufallsexperiments, der Wert, den die Zufallsvariable am ehesten annimmt.
  - Mathematisch dargestellt als: $x = E(X)$

## Diskrete Zufallsvariable
- Der Erwartungswert $E(X)$ einer [[Zufallsvariable|diskreten Zufallsvariable]] wird berechnet durch:
  $$E(X) = \sum x_i \times f(x_i)$$
- Hierbei addieren wir die Produkte der möglichen Werte $x_i$ und deren relativen Wahrscheinlichkeiten $p_i$.

### Beispiel
| Ereignis | Gewinn     | Gewinn - Verlust | Wahrscheinlichkeit |
|----------|------------|------------------|--------------------|
| 1.       | € 10.000  | € 9.999          | 1%                 |
| 2.       | € 500     | € 499            | 9%                 |
| 3.       | € 0       | -€ 1             | 90%                |

Berechnung des Erwartungswerts:
$$E(X) = 9.999 \times 0,01 + 499 \times 0,09 + (-1) \times 0,9 = 144$$

## Stetige Zufallsvariable
- Der Erwartungswert $E(X)$ einer [[Zufallsvariable|stetigen Zufallsvariable]] wird berechnet durch:
  $$E(X) = \int_{-\infty}^{\infty} x \times f(x)$$
- Hierbei ist $f(x)$ die [[Dichtefunktion]] der Zufallsvariablen.

## Zusammenfassung
- Der Erwartungswert ist ein zentrales Konzept in der Wahrscheinlichkeitstheorie, das den durchschnittlichen Ausgang eines Zufallsexperiments beschreibt.
- Bei diskreten Zufallsvariablen erfolgt die Berechnung durch Summation, während bei stetigen Zufallsvariablen eine Integration notwendig ist.


- weit verbreitete Technologie für **lokale Netzwerke (LAN)**, die die Übertragung von Daten zwischen Geräten in einem Netzwerk ermöglicht. Es ist im **IEEE 802.3 Standard** definiert und bildet die Grundlage für die meisten modernen Netzwerke.

- Zugriffsverfahren **CSMA/CD** (Carrier Sense Multiple Access with Collision Detection). Bei diesem Verfahren **hören die Geräte** im Netzwerk, bevor sie Daten senden, um sicherzustellen, dass das Medium frei ist. Wenn zwei Geräte gleichzeitig senden, kommt es zu einer **Kollision**. In diesem Fall erkennen die Geräte die Kollision und warten eine **zufällige Zeit**, bevor sie erneut versuchen, ihre Daten zu senden. Dieses Verfahren hilft, die **Effizienz des Netzwerks zu maximieren und Kollisionen zu minimieren.**

- **Datenübertragung**: Daten werden in **Frames** übertragen, die eine bestimmte Struktur haben. Ein Ethernet-Frame besteht aus:
  - **Header**: Enthält Informationen wie die **Quell- und Ziel-MAC-Adressen** sowie den Typ des Protokolls.
  - **Payload**: Der eigentliche **Dateninhalt**, der übertragen wird (z.B. IP-Pakete).
  - **Trailer**: Enthält **Prüfziffern** (z.B. CRC), um sicherzustellen, dass die Daten korrekt übertragen wurden.

## Einordnung
  - **[[OSI-Modell]]**: Ethernet gehört zur **Data Link Layer (Schicht 2)** des OSI-Modells. Hier werden die physikalischen Adressen (MAC-Adressen) verwendet, um Geräte im Netzwerk zu identifizieren und den Zugriff auf das Übertragungsmedium zu steuern.
  - **[[TCP-IP-Modell|TCP/IP-Modell]]**: Im TCP/IP-Modell wird Ethernet in die **Link Layer** / **Netzzugangsschicht** integriert, die die physische Verbindung und die Datenübertragung zwischen Geräten in einem Netzwerk behandelt. Ethernet ist somit eine der grundlegenden Technologien, die die Kommunikation in TCP/IP-Netzwerken ermöglicht.

## Vorteile
- **Hohe Geschwindigkeit:** Unterstützt Geschwindigkeiten von 10 Mbps bis zu 100 Gbps und mehr.
- **Zuverlässigkeit**: Robuste Technologie mit geringer Fehleranfälligkeit.
- **Skalierbarkeit**: Einfaches Hinzufügen neuer Geräte ohne große Änderungen am Netzwerk.
- **Kosteneffizienz**: Weit verbreitete und kostengünstige Hardware.
## Nachteile
- **Reichweite**: Begrenzte Reichweite (typisch 100 Meter für Twisted-Pair-Kabel).
- **Kollisionen**: Bei älteren Varianten können Kollisionen auftreten, was die Leistung beeinträchtigen kann.
- **Sicherheitsrisiken**: Offene Netzwerke können anfällig für unbefugten Zugriff sein.

# Anwendungen
- Lokale Netzwerke (LAN): Verbindung von Computern, Druckern und anderen Geräten in Büros und Heimen.
- Rechenzentren: Hohe Bandbreite und Zuverlässigkeit für Serververbindungen.
- Industrie: Verwendung in industriellen Automatisierungssystemen (z.B. EtherCAT, Profinet).

## Quellen
> IEEE. (n.d.). IEEE 802.3 Ethernet Working Group. Retrieved from https://www.ieee802.org/3/
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


- **E**xtract, **T**ransform, **L**oad
- Prozess von **Vereinigung** von Daten aus **heterogenen Quellen**

## Extraktion
- Extraktion einer Selektion von Daten aus Quellen
- Daten liegen in **verschiedenen** Datenformaten, -strukturen, etc. vor
- Arten
	- **periodisch**, Quelle wird in regelmäßigen Abständen abgefragt
	- **ereignisgesteuert**, Quelle wird bei bestimmten Ereignissen abgefragt
	- **anfragegesteuert**, Quelle stellt Daten erst auf Anfrage bereit

## Transformation
- **Syntaktische Transformation**
	- **Verbesserung**/**Umsetzung**/**Korrektur** der Daten basierend auf **formalen** Aspekten
	- Bspw. **Standardisierung** von Datumstypen
- **Semantische Transformation**
	- **Inhaltliche Aspekte** werden überprüft
	- Bspw. Eliminierung von Duplikaten, Schlüsselanpassungen, Umrechnungen von Maßeinheiten, Aggregation, Anreicherungen, ...
## Load
- effizientes Einladen von Daten
- Datenbank **nur kurz** oder **gar nicht** blockiert
- **Integrität** soll gewährleistet werden
- Anfertigung von **Versionshistorie**
## Quellen

> Autoren der Wikimedia-Projekte. (2003, December 02). ETL-Prozess – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=ETL-Prozess&oldid=243460066

Die euklidische Distanz ist ein **Maß für den Abstand** zwischen zwei Punkten in einem **n-dimensionalen Raum**
## Allgemeine Formel
- Für zwei Punkte $P_1(x_1, y_1)$ und $P_2(x_2, y_2)$ im **zweidimensionalen Raum**: $d(P_1, P_2) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$
- Für n-dimensionale Räume: 
  $d(P_1, P_2) = \sqrt{\sum_{i=1}^n (p_{2i} - p_{1i})^2}$
  Wobei $p_{1i}$ und $p_{2i}$ die i-ten Koordinaten der Punkte $P_1$ und $P_2$ sind.
## Algorithmus
1. Berechne die Differenz jeder Koordinate der beiden Punkte.
2. Quadriere jede dieser Differenzen.
3. Summiere alle quadrierten Differenzen.
4. Ziehe die Quadratwurzel aus dieser Summe.
## Beispiel
$P_1(1,2)$
$P_2(4,-2)$
$\vec{P_1P_2} = \left(\begin{array}{c} 4 \\ -2 \end{array}\right) - \left(\begin{array}{c} 1 \\ 2\end{array}\right) = \left(\begin{array}{c} 3 \\ -4 \end{array}\right)$
$d(P_1, P_2) = \sqrt{3^2 + (-4)^2} = \sqrt{25} = 5$

- Klasse an *stochastischen*[^1], *metaheuristischen*[^2] **Optimierungsverfahren**, deren Funktionsweise an der Evolution angelehnt ist
- **naturanaloges** Optimierungsverfahren

## Anwendungsgebiete
- Entwicklung von Sensornetzen
- Aktienmarktanalyse
- RNA-Strukturvorhersage
- Designoptimierungen
- ROboterbahnplanung

## Grundbegriffe
- **Individuum**, Hypothese, die Aufgestellt wird
- **Population**, Menge an Individuen
- **Generation**, Hierarchische Teilmenge an Populationen (... <- Kind <- Eltern <- Großeltern)
- **Nachfolger**, ein Kind ist Nachfolger von Eltern und Großeltern, ...
- **Fitnessfunktion**, Güte-Funktion, Maß wie gut Hypothese/*Individuum* ist für Daten

## Grundalgorithmus
- besteht aus drei *Unteralgorithmen*
### Darstellungsform 1
```python # Pseudocode
while !optimal: # So lange nicht alles Optimal ist
	# Eltern mit größter Fitness
	parents <- select_parents(population) 
	
	# Kinder werden anhand von Eltern generiert
	children <- generate_children(parents)
	
	# Children werden in Population gesteckt, Population wird selektiert
	population <- select_population(fitness, population, children)
	# Möglich mit sowohl nur children als auch population + children
	# Bei population + children bias Richtung einer Lösung -> im lokalen Maximum hängen bleiben
	# Bei nur children experimenteller, bessere Lösungen könnten gefunden werden
```
### Darstellungsform 2
`Initialisierung`: 
$t = 0$; *Intialisierung des Generationszählers*
$P_t$ = Zufällige Startpopulation
$f(p) \forall p  \in P_t$ *Berechnung der initialen Bewertung*
*Berechne für alle $p$ in $P_t$ die Fitness $f(p)$*

**while** Abbruchkriterien sind nicht erfüllt **do**
`Partnerwahl`: Wähle entsprechend $f(p)$ eine Teilmenge von $P_t$ und speichere sie in $M_t$
`Nachkommen`: Rekombiniere und mutiere Individuen $p \in M_t$ und speichere sie in $M'_t$;
`Bewertung`: Berechne die Fitness $f(p') \forall p' \in M'_t$ *Berechne die Fitness aller Nachkommen $p'$ aus der neuen Teilmenge $M'_t$*
`Nachfolgegeneration:` Erzeuge $P_{t+1}$ durch fitnessbasierte Auswahl aus $P_t$ und $M'_t$;
$t := t + 1$; *Erhöhe den Generationszähler*
**end while**
`Ergebnis`: Liefere bestes Individuum $p \in P_t$ als Ergebnis ab;

- Abbruchkriterien sind häufig Anzahl durchlaufener Generationen, vergangene Zeit oder erreichte Lösungsqualität

## Genetische Operatoren
### Mutationen
- Suchoperator, Suchraum wird erkundet
- Methode um Kinder zu generieren mit *einem* Elternteil
```python # Pseudocode
def mutate(parent):
	# Zu Verständniszwecken Ausgabe von parent
	print(parent) 
	# -> 0b11000001001001010010

	# Normalverteilt um 0, zufall hat gleiche Bitlänge wie parent
	# Mögliche Ergebnisse von z sind -1, 0 und 1 
	zufall[] = new BitArray(parent.length)
	zufall <- rand()

	for index in z:
		child[index] = parent[index] + zufall[index] # Bitwise Operations 
	
	return child
```

### Rekombination
- Suchoperator, Suchraum wird erkundet
- Methode um Kinder zu generieren mit *zwei* Elternteilen
```python # Pseudocode
# Uniformer Rekombinationsalgorithmus
def uniform_rekomb(parent1, parent2):
	# Zu Verständniszwecken Ausgabe von parent1, parent2
	print(parent1, parent2) 
	# -> 0b11000001001001010010 0b11001111001100011010

	# Zufalls Bitarray von Elternteilen
	# Da parent1 und parent2 gleiche Länge egal ob parent1.length oder ...
	zufall[] = new BitArray(parent1.length)
	# Array ist Gleichverteilt, 50% 1 50% 0
	zufall <- rand()

	child = 0b
	for index in zufall:
		# Wenn zufall am index ist 0, dann von parent1
		if zufall[index] == 0:
			child += parent1[index]
		# Wenn zufall am index ist 1, dann von parent2
		elif zufall[index] == 1:
			child += parent2[index]

	return child
	
# Crossover Rekombinationsalgorithmus
def crossover_rekomb(parent1, parent2):
	# Single Point bei nur z1, Two Point bei z1 und z2
	z1, z2 <- rand()

	# Bspw. z1 ist 3, z2 ist 7
	z1 = 3
	z2 = 7

	# Ersten z1 Bits von p1, Zweiten z2 Bits von p2, letzten von p1
	child1 = parent1[1:3] + parent2[3:7] + parent1[7:MAX]
	# child1 = parent1[1:z1] + parent2[z1:z2] + parent1[z2:MAX]
	
	# Ersten z1 Bits von p2, Zweiten z2 Bits von p1, letzten von p2
	child2 = parent2[1:3] + parent1[3:7] + parent2[7:MAX]
	# child2 = parent2[1:z1] + parent1[z1:z2] + parent2[z2:MAX]

	return child1, child2
```

### Selektion

#### Inselmodell *(häufig bevorzugt)*
```python # Pseudocode
def island_selection(population):
	# Population wird in x Gruppen aufgeteilt (mind. 2)
	islands <- split_population(population)

	while true:
		for island in islands:
			# aus jeder Gruppe werden die fittesten X parents ausgewählt
			fittest <- select_fittest(island)
			
			# die parents generieren dann children
			children = generate_children(fittest) # Rekomb, Mutation, ...
			
			# children kommen nicht in Gesamtpopulation sondern in ihre Gruppe zurück
			island += children

			# im jedem Durchgang werden zufällig wenige Individuen zwischen Inseln ausgetauscht
			zufall_individuum = select_random(island)
			push_to_other_island(zufall_individuum)
```

#### Einfache Menge
- eine große Menge, Population als ganzes

#### Nachbarschaft
- Aus der **Nachbarschaft** werden die **fittesten** Individuen ausgewählt.
- Beispiel:
	- Individuen:
		- a: `000`
		- b: `100`
		- c: `001`
	- **Nachbarschaftsbeziehungen**:
		- `a` ist benachbart mit `b` und `c` (Unterschied: **1 Bit**)
		- `b` und `c` sind nicht benachbart (Unterschied: **2 Bits**)
	- **Fitnesslevel**: `b` < `a` < `c`
- **Ergebnis** der Selektion: `[c, a, c]`
	- Aus der Nachbarschaft von `a` ist `c` am **fittesten**.
	- Aus der Nachbarschaft von `b` ist `a` am **fittesten**.
	- Aus der Nachbarschaft von `c` ist `c` am **fittesten**.
- Bei zu vielen Individuen kann **gefiltert** werden:
	- Wenn ein Element nur einmal ausgewählt wurde, wird es entfernt.
	- Wenn es zweimal ausgewählt wurde, bleibt es, je nach gewünschter **Ergebnisgröße**.
- Aus der Nachbarschaft wird immer der **fitteste** Individuum ausgewählt.

#### Fitness Based Selection
$$
P(x) = \dfrac{|children|}{|population|} \times \dfrac{fitness(x)}{\sum_{y \in population}fitness(y)}
$$
$|children|$ = Anzahl an produzierten Kindern
$|population|$ = Anzahl/Größe der neuen Population
$fitness(x)$ = Berechnung der Fitness vom Individuum; Wie gut ist Hypothese `x` auf meinen Trainingsdaten? (Richtige Klassifizierung, ...)
$\sum_{y \in population}fitness(y)$ = Fitness der Population

-> Wie wahrscheinlich ist es dass Individuum `x` wiederverwendet wird?

#### Ranking Based Selection

$$
P(x) = \dfrac{g(r(x))}{\sum_{y \in population}g(r(y))}
$$
$r(x)$ = Ranking, wie gut Individuum ist. Bestes Individuum ist $r(x) = 1$, zweitbestes Individuum ist $r(x) = 2$, usw. anhand von Fitnessfunktion
$g(x)$ = Monotonfallende Funktion, bspw. $g(b)=a^{-b}=5^{-1}$, wobei $b$ der Rang von $r(x)$ ist. $^{-1}$ hat höhere Wahrscheinlichkeit (0,2) als $^{-2}$ (0,04) usw.
$\sum_{y \in population}g(r(y))$ = Gesamtheit der gewichteten Wahrscheinlichkeiten für alle Individuen in der Population, basierend auf ihren Rängen

#### Tournament Selection
- Wähle **zufällig zwei Individuen** aus der Population aus und **vergleiche** sie anhand einer Fitnessfunktion.
- Wenn das Fitnessmaß von Individuum `x` größer ist als das von Individuum `y`, erhält `x` einen Punkt.
- Wiederhole diesen Prozess, indem du erneut zufällig zwei Individuen auswählst, bis alle Individuen miteinander verglichen wurden.
- Am Ende des Vergleichs wird ein Ranking erstellt, wobei eine **höhere Punktzahl einen besseren Rang** bedeutet.
- Die besten `k` Individuen werden in die neue Population übernommen.

$$
$$

[^1:] Mathematik der Daten und des Zufalls, Wahrscheinlichkeitsrechnung, ...
[^2:] mit begrenztem Wissen und wenig Zeit dennoch zu wahrscheinlichen Aussagen/praktikablen Lösungen kommen; "Es dient dazu, eine oder mehrere Heuristiken (auf Erfahrung und begrenztem Wissen beruhender Suchalgorithmus) zu finden, zu generieren, zu tunen oder auszuwählen, die eine hinreichend gute Lösung für ein Optimierungsproblem oder ein Problem des maschinellen Lernens bieten kann, insbesondere bei unvollständigen oder unvollkommenen Informationen oder begrenzter Rechenleistung."
## Quellen

> Seite „Evolutionärer Algorithmus“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 16. September 2024, 14:20 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Evolution%C3%A4rer_Algorithmus&oldid=248648647](https://de.wikipedia.org/w/index.php?title=Evolution%C3%A4rer_Algorithmus&oldid=248648647) (Abgerufen: 17. September 2024, 05:27 UTC)
> Tutorials, T. M. (2017, April 07). Machine Learning #57 - Evolutionäre Algorithmen #1 - Der Grundalgorithmus. Youtube. Retrieved from https://www.youtube.com/watch?v=sxT71gpsA2k
> Seite „Stochastik“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 16. September 2024, 15:07 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Stochastik&oldid=248650728](https://de.wikipedia.org/w/index.php?title=Stochastik&oldid=248650728) (Abgerufen: 17. September 2024, 05:28 UTC)
> Seite „Heuristik“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 16. August 2024, 15:08 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Heuristik&oldid=247773366](https://de.wikipedia.org/w/index.php?title=Heuristik&oldid=247773366) (Abgerufen: 17. September 2024, 05:29 UTC)
> Tutorials, T. M. (2017, April 07). Machine Learning #58 - Evolutionäre Algorithmen #2 - Mutationen. Youtube. Retrieved from https://www.youtube.com/watch?v=Bp4Xh-alVT4
> Tutorials, T. M. (2017, April 12). Machine Learning #59 - Evolutionäre Algorithmen #3 - Rekombinationen. Youtube. Retrieved from https://www.youtube.com/watch?v=as3lijLxVAo
> Tutorials, T. M. (2017, April 12). Machine Learning #60 - Evolutionäre Algorithmen #4 - Selektion. Youtube. Retrieved from https://www.youtube.com/watch?v=uf--mf-7njg
> Tutorials, T. M. (2017, April 17). Machine Learning #61 - Evolutionäre Algorithmen #5 - Fitness Based Selection. Youtube. Retrieved from https://www.youtube.com/watch?v=k58CWZjorUE
> Tutorials, T. M. (2017, April 17). Machine Learning #62 - Evolutionäre Algorithmen #6 - Ranking Based und Tournament Selection. Youtube. Retrieved from https://www.youtube.com/watch?v=9Mk5Vq3zhxs


- **Definition**: Fibre Channel (FC) ist ein Hochgeschwindigkeitsnetzwerkprotokoll, das hauptsächlich für die Verbindung von Speichersystemen und Servern verwendet wird.
- **Hauptmerkmale**:
  - Hohe Übertragungsraten (bis zu 128 Gbit/s)
  - Geringe Latenzzeiten
  - Unterstützt sowohl Block- als auch Datei-basierte Speicherprotokolle
- **Architektur**:
  - **Topologien**: Punkt-zu-Punkt, Fabric, und Arbitrated Loop
  - **Komponenten**: Host Bus Adapter (HBA), Switches, und Speichersysteme
- **Protokollschichten**:
  - **FC-0**: Physikalische Schicht (Kabel, Stecker)
  - **FC-1**: Codierung und Decodierung
  - **FC-2**: Übertragung von Daten (Framing)
  - **FC-3**: Mehrfachzugriff (z.B. Load Balancing)
  - **FC-4**: Protokoll-Integration (z.B. SCSI, IP)
- **Sicherheitsmerkmale**:
  - Zonenbildung zur Segmentierung des Netzwerks
  - Authentifizierung und Zugriffskontrolle
- **Anwendungsgebiete**:
  - SAN (Storage Area Network)
  - Datenzentren
  - Hochverfügbarkeitslösungen
- **Vorteile**:
  - Hohe Bandbreite und Zuverlässigkeit
  - Unterstützung für lange Distanzen (bis zu 10 km und mehr)
  - Geringe Störungen durch elektromagnetische Interferenzen
- **Nachteile**:
  - Höhere Kosten im Vergleich zu Ethernet-basierten Lösungen
  - Komplexität in der Einrichtung und Verwaltung

## Quellen

> DuckDuckGo. (2024, 18. September). _Konversation über das Fibre Channel Protokoll_. [https://duck.ai/](https://duck.ai/)

- Diagramm zeigt **Prozess/Arbeitsablauf** 
- Dient zur **Dokumentation**, **Planung** und **Optimierung** von Arbeitsprozessen

## Elemente
![[Pasted image 20240916131318.png]]
- **Terminator**, Start/Ende des Flussdiagramms
![[Pasted image 20240916131339.png]]
- **Verbindungspfeil**, Bindeglied zwischen Symbolen, bestimmt *Fließrichtung*
![[Pasted image 20240916131410.png]]
- **Prozess/Tätigkeit**
![[Pasted image 20240916131441.png]]
- **Dokument- u. Datensymbol**, benötigte (*Pfeil zeigt auf Dokument*) oder entstehende (*Pfeil führt vom Dokument weg*) Dokumente
![[Pasted image 20240916131551.png]]
- **Datenbank**
![[Pasted image 20240916131607.png]]
- **Entscheidung**, mind. zwei *Auswahloptionen*
![[Pasted image 20240916131631.png]]
- **Anmerkungen**

## Vorteile
- **Schnelle** und **einfache** Darstellung von linearen Prozessen
- Überblick über **Gesamtprozess**
- Erleichtert **Identifizierung** von Problemen und Verbesserungspotenzialen

## Nachteile
- **Parallele** Prozesse lassen sich schwer abbilden
- Problematische Darstellung von **detaillierten, kleinschrittigen** und **langen** Prozessen
- **komplexe** Materialeinflüsse und Produktionsschritte sind **schwer** einzubauen

## Quellen
> Flussdiagramm. (2023, December 21). Retrieved from https://studyflix.de/wirtschaft/flussdiagramm-7586

- **F**ailure **M**ode and **E**ffects **A**nalysis
- **System- und Risikoanalyse**
- mögliche **Fehlerquellen** in Produkten, Prozessen oder Systemen frühzeitig erkennen

## Ablauf
1. **Struktur- bzw. Funktionsanalyse**
	1. System oder Prozess beschreiben
	2. Modellierung des Prozesses, identifizieren von Teilprozessen
2. **Fehleranalyse**
	1. mögliche Fehler analysieren, welche **Folgen** und **Ursachen** haben sie?
	2. Hilfsstellung: 
		1. Welche Fehler *könnten passieren*?
		2. Welcher Fehler sind bereis in der *Vergangenheit* aufgetaucht?
		3. Wie kann der Fehler *enstehen*?
		4. Was sind die *Folgen* des Fehlers?
3. **Maßnahmenanalyse und Bewertung**
	1. Fehler und Folgen auf Skala **1 bis 10** bewerten, Risiko in **drei Kategorien** (*Auftrittswahrscheinlichkeit, Fehlerbedeutung, Entdeckungswahrscheinlichkeit*) [^1]
	2. Berechnung der **Risikoprioritätszahl** (RPZ)
		1. $RPZ=A \times B \times E$
	3. Einordnung der **RPZ** anhand von Skala [^2] 
4. **Optimierung**
	1. formulierten **Maßnahmen** auf Prozess **anwenden**
	2. anschließend **erneute Analyse durchführen**
	3. Fehlerquelle und erarbeiteten Maßnahmen **dokumentieren**

## Teilnehmer
- **Projektleiter / Initiator**, wer ist für Durchführung verantwortlich? *Unterstützung* von Verantwortlichen
- **Verantwortliche** für Durchführung von FMEA, *Beschaffung* aller *Informationen* und *Unterlagen*
- **FMEA-Moderator**, *Unterstützungsfunktion*, Zusammenstellung vom Team, Erstellung Terminplan
- **Teammitglieder**, helfen bei *Vorbereitung* und *Durchführung* von FMEA

## Arten
- **System-FMEA**, gesamtes System wird untersucht (z.B. *Zusammenarbeit* zwischen Bereichen)
- **Design-FMEA**, bei Neuentwicklung oder Konstruktion eines Produktes (z.B. Entwicklung eines neuen Elektromotors)
- **Prozess-FMEA**, Risiken von verschiedenen Prozessen im Vornherein zu finden (z.B. Neueinführung Software)

## Vorteile
- steigende **Kundenzufriedenheit**
- verstärktes **Qualitätsbewusstsein** der Beschäftigten
- **Dokumentation als Hilfestellung** für Fehler in ähnlichen Prozessen
## Nachteile
- **Zeit- und Personalaufwendig**
- Kostenintensiv
- **subjektive** Bewertung

## Nutzen für Unternehmen
### 1. Früherkennung von Fehlern
Die FMEA ermöglicht es, potenzielle Fehlerquellen bereits in der Planungs- und Entwicklungsphase zu identifizieren. Durch die frühzeitige Erkennung können Unternehmen proaktive Maßnahmen ergreifen, um Fehler zu vermeiden, bevor sie auftreten.

### 2. Risikominimierung
Durch die Bewertung der Schwere, Auftretenswahrscheinlichkeit und Entdeckungswahrscheinlichkeit von Fehlern können Unternehmen Risiken priorisieren und gezielt Maßnahmen zur Risikominderung einleiten. Dies trägt dazu bei, die Wahrscheinlichkeit von kostspieligen Fehlern und deren Auswirkungen zu verringern.

### 3. Verbesserung der Produkt- und Prozessqualität
Die FMEA fördert eine systematische Analyse von Produkten und Prozessen, was zu einer kontinuierlichen Verbesserung der Qualität führt. Durch die Identifikation und Beseitigung von Schwachstellen können Unternehmen die Zuverlässigkeit und Leistung ihrer Produkte steigern.

### 4. Kosteneinsparungen
Indem potenzielle Fehler frühzeitig erkannt und behoben werden, können Unternehmen teure Nacharbeiten, Rückrufaktionen oder Garantieansprüche vermeiden. Dies führt zu erheblichen Kosteneinsparungen und verbessert die Rentabilität.

### 5. Erhöhung der Kundenzufriedenheit
Ein höheres Maß an Qualität und Zuverlässigkeit führt zu einer höheren Kundenzufriedenheit. Kunden sind eher bereit, Produkte von Unternehmen zu kaufen, die nachweislich hohe Qualitätsstandards einhalten und proaktiv an der Vermeidung von Fehlern arbeiten.

### 6. Förderung der Teamarbeit und Kommunikation
Die Durchführung einer FMEA erfordert die Zusammenarbeit von verschiedenen Abteilungen und Fachbereichen. Dies fördert den Austausch von Wissen und Erfahrungen, verbessert die Kommunikation innerhalb des Unternehmens und stärkt das Teamgefühl.

### 7. Dokumentation und Nachverfolgbarkeit
Die FMEA bietet eine strukturierte Dokumentation der identifizierten Risiken und der ergriffenen Maßnahmen. Diese Dokumentation kann für zukünftige Projekte, Schulungen und Audits genutzt werden, um die kontinuierliche Verbesserung zu unterstützen.

### 8. Compliance und Normen
In vielen Branchen ist die Durchführung einer FMEA eine Voraussetzung für die Einhaltung von Normen und Vorschriften (z.B. ISO 9001, IATF 16949). Die FMEA hilft Unternehmen, diese Anforderungen zu erfüllen und ihre Marktposition zu stärken.


[^1:] Beispiels Bewertungsskala

| Bewertungsskala | Auftrittswahrscheinlichkeit (A) | Fehlerbedeutung (B)                              | Entdeckungswahrscheinlichkeit (E)                        |
| --------------- | ------------------------------- | ------------------------------------------------ | -------------------------------------------------------- |
| 1               | quasi auszuschließen            | keine, kein Kunde merkt etwas                    | zwangsläufig, in weiteren Prozessabschnitten             |
| 2               | unwahrscheinlich                | unbedeutend, Kunde wird gering gestört           | hoch                                                     |
| 3               | gering                          | Störungen, Probleme bei einigen Kunden           | nur bei gezielter Prüfung                                |
| 4 - 6           | gelegentlich                    | eingeschränkte Dienstleistung, verärgerte Kunden | keine beim Verkauf, Kunde entdeckt wahrscheinlich Fehler |
| 7 - 8           | häufig                          | Verletzung von Vorschriften, Schadensersatz      | sachverständiger Kunde entdeckt sicher den Fehler        |
| 9 - 10          | ständig                         | Verletzung von Vorschriften, Schadensersatz      | nicht sofort, Entdeckung erst nach mehreren Jahren       |

[^2:] RPZ Skala

| RPZ                        | Fehlerrisiko | Handlungsbedarf | Maßnahmen                                   |
| -------------------------- | ------------ | --------------- | ------------------------------------------- |
| 100 $\leq$ RPZ $\leq$ 1000 | hoch         | dringend        | **müssen** formuliert und umgesetzt werden  |
| 50 $\leq$ RPZ $\leq$ 100   | mittel       | vorhanden       | **sollten** formuliert und umgesetzt werden |
| 2 $\leq$ RPZ $\leq$ 50     | akzeptabel   | nicht zwingend  | **können** formuliert und umgesetzt werden  |
| RPZ $=$ 1                  | keines       | keiner          | **keine**                                   |

## Quellen

> FMEA. (2022, May 05). Retrieved from https://studyflix.de/jobs/karriere-tipps/fmea-4801

- **Cloud-Technologie**, Endgeräte vorverarbeiten Daten in **Fog Nodes** *(dezentrale Minirechenzentren)*, Fog-Nodes laden Daten in die **Cloud**

![[Pasted image 20240911072047.png]]
3. **Cloud-Layer**, *zentraler* **Daten-Endpunkt**
2. **Fog-Layer**, *dezentrale*, **leistungsstarke Server**, nehmen Daten entgegen, *vorverarbeiten* sie und laden sie bei Bedarf in die **Cloud**
1. **Edge-Layer**, intelligente Geräte (**Edge-Devices**) verarbeiten Daten *direkt* oder übermitteln an *Fog Nodes*

## Vorteile

- **weniger Netzwerk-Traffic** zur Cloud
- **Geringe Latenz**: dezentrale Server können näher am Endgerät sein
- **Datensicherheit**, *Fogging* erfolgt Vorverarbeitung **lokal**, wodurch Daten anonymisiert werden können

## Nachteile
- **steigender Wartungsbedarf** durch Verteilung von Verarbeitungs- und Speicherelementen
- **höhere Hardware-Kosten**, durch lokale Datenverarbeitung
- **zusätzliche Anforderungen** an **Netzwerksicherheit**, Daten können an Fog-Nodes abgegriffen 

## Quellen

> Redaktion, I. (2024). Fog-Computing. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/server/knowhow/fog-computing-definition-und-erklaerung/#content-was-ist-fog-computing-eine-definition

[[Entropie und Informationsgewinn]]
[[Neural Network]]
[[Varianz]]
[[Erwartungswerte]]
[[Datenarten]]
[[Datenschutz]]
[[Datenmengen]]
[[Datenanalyse]]
[[Datenqualität]]
[[Datensorgfalt]]
[[Präventive IT-Sicherheitsmaßnahmen]]
[[IT-Grundschutzmodell]]
[[Datensicherheit]]
[[CRISP-DM]]
[[KI vs ML vs DL]]
[[Vertriebsmodelle]]
[[Maschinelles Lernen]]
[[Clustering]]
[[Klassifikation]]
[[BPMN vs EPK vs UML]]

## Funktionale Anforderungen
- Beschreiben konkrete Funktionen und Aufgaben des Systems
- Definieren, WAS das System tun soll
- Haben direkten Bezug zur Zweckbestimmung des Produkts
- Spezifisch für das jeweilige Produkt
**Beispiele:**
- Berechnung des Body-Mass-Index auf eine Nachkommastelle
- Warnung vor Arzneimittel-Wechselwirkungen
- Produkte in den Warenkorb legen können

## Nicht-funktionale Anforderungen (NFAs)
- Beschreiben Qualitätsmerkmale und Betriebseigenschaften  
- Definieren, WIE das System seine Funktionen ausführen soll
- Meist produktunspezifisch

**Hauptkategorien:**
- Leistung (z.B. Antwortzeiten, Durchsatz)
- Zuverlässigkeit (z.B. Verfügbarkeit, Fehlertoleranz)  
- Benutzerfreundlichkeit (z.B. Bedienbarkeit, Ergonomie)
- Sicherheit (z.B. Authentifizierung, Datenschutz)

**Weitere Beispiele:**
- System muss innerhalb von 10 ms Ergebnis berechnen
- 15.000 Transaktionen pro Sekunde verarbeiten können
- 4 Wochen Dauerbetrieb ohne Neustart
- 95% Verfügbarkeit

## Wichtige Punkte
- NFAs sind genauso wichtig wie funktionale Anforderungen
- Beeinflussen maßgeblich Benutzerzufriedenheit und Produktqualität
- Klare Trennung nicht immer möglich (z.B. Fehlertoleranz)
- Sollten gemeinsam mit funktionalen Anforderungen dokumentiert werden
- Bei der Projektplanung nicht vernachlässigen

## Best Practices für NFAs
- Klar und prägnant formulieren
- Messbare Kriterien definieren  
- Realistisch und erreichbar gestalten
- Priorisieren und flexibel halten
- Regelmäßig überprüfen und anpassen
- Stakeholder-Feedback einholen


- zur Berechnung **durchschnittlicher prozentualer Veränderungen** 

## Formel
$$
\bar{x} = \sqrt[n]{\prod^{n}_{i=1}x_i} = \sqrt[n]{x_1 \times x_2 \times ... \times x_n}
$$

## Beispiel

| Oktober | November | Dezember | Januar | Februar |
| ------- | -------- | -------- | ------ | ------- |
| 1000€   | 950€     | 1030€    | 1050€  | 1200€   |
**Kontostand**


| Oktober | November | Dezember | Januar | Februar |
| ------- | -------- | -------- | ------ | ------- |
| -5%     | 8,42%    | 1,94%    | 14,29% | ???     |
**Monatliche Wachstumsraten**


$\bar{x}_{geom}=\sqrt[4]{0,95 \times 1,0842 \times 1,0194 \times 1,1429} \approx 1,047 = 4,7\%$

## Quellen

> Geometrisches Mittel. (2018, December 11). Retrieved from https://studyflix.de/statistik/geometrisches-mittel-1038

- **Kategorien von Geräten**, die auf Basis ihrer **Funktionalität, Leistung, Größe und Einsatzgebiet** eingeteilt werden. Diese Klassifizierung hilft, die unterschiedlichen Eigenschaften und Einsatzmöglichkeiten von Geräten zu verstehen.
- **Ziel**: Erleichterung der Auswahl, Entwicklung und Integration von Geräten in verschiedenen Anwendungen und Systemen.

## Wichtige Geräteklassen

### Embedded Systems
- **Beschreibung**: Spezialisierte Computer, die in andere Geräte integriert sind, um spezifische Funktionen auszuführen.
- **Beispiele**: Mikrocontroller in Haushaltsgeräten, Steuerungssysteme in Automobilen.

### Mobile Geräte
- **Beschreibung**: Tragbare Geräte, die für die mobile Nutzung konzipiert sind und oft über drahtlose Kommunikationsmöglichkeiten verfügen.
- **Beispiele**: Smartphones, Tablets, tragbare Fitness-Tracker.

### Desktop-Computer
- **Beschreibung**: Stationäre Computer, die für den Einsatz an einem festen Standort konzipiert sind und in der Regel über leistungsstarke Hardware verfügen.
- **Beispiele**: PCs, Workstations, All-in-One-Computer.

### Server
- **Beschreibung**: Leistungsstarke Computer, die Dienste, Daten und Anwendungen für andere Computer im Netzwerk bereitstellen.
- **Beispiele**: Webserver, Datenbankserver, Cloud-Server.

### IoT-Geräte (Internet of Things)
- **Beschreibung**: Vernetzte Geräte, die Daten sammeln und austauschen, um intelligente Anwendungen zu ermöglichen.
- **Beispiele**: Smart Home-Geräte, Sensoren in der Industrie, vernetzte Gesundheitsgeräte.

### Wearables
- **Beschreibung**: Tragbare Technologien, die in der Regel zur Überwachung von Gesundheitsdaten oder zur Verbesserung der Benutzererfahrung entwickelt wurden.
- **Beispiele**: Smartwatches, Fitness-Tracker, VR-Brillen.

## Anwendungsbereiche von Geräteklassen
- **Industrie**: Automatisierung, Überwachung und Steuerung von Produktionsprozessen.
- **Gesundheitswesen**: Überwachung von Patienten, Diagnosetechnologien und medizinische Geräte.
- **Unterhaltung**: Gaming, Multimedia und interaktive Anwendungen.
- **Smart Homes**: Vernetzte Geräte zur Verbesserung des Wohnkomforts und der Sicherheit.

## Herausforderungen bei Geräteklassen
- **Interoperabilität**: Sicherstellung, dass Geräte verschiedener Klassen nahtlos zusammenarbeiten können.
- **Sicherheit**: Schutz vor Cyberangriffen und unbefugtem Zugriff, insbesondere bei vernetzten Geräten.
- **Energieeffizienz**: Optimierung des Energieverbrauchs, insbesondere bei tragbaren und IoT-Geräten.

### Wichtige Begriffe
- **Embedded Systems**: Integrierte Computersysteme, die spezifische Aufgaben in Geräten ausführen.
- **IoT (Internet of Things)**: Vernetzung von Geräten, die Daten sammeln und austauschen.
- **Interoperabilität**: Fähigkeit von Geräten, miteinander zu kommunizieren und zusammenzuarbeiten.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Ablauf** von betrieblichen **Funktionen**, der zu einem vom Unternehmen gewünschten **Ergebnis** führt -> **Umsatz** in irgend einer Form
- wird durch **definiertes Ereignis** ausgelöst
- transformiert **Input** durch Einsatz materieller und immaterieller Güter zu **Output**

```mermaid
flowchart LR

	Input-- transformation mit Gütern ---Output
```

## Bewertung von Risiken bei Änderungen an Geschäftsprozessen

1. **Wahrscheinlichkeit des Eintretens**
   - Einschätzung, wie wahrscheinlich ein Risiko eintritt.
   - Methoden zur Ermittlung:
     - Historische Datenanalyse
     - Expertenmeinungen
     - Risikoanalysen
2. **Auswirkungen auf das Unternehmen**
   - Bewertung der Konsequenzen eines eintretenden Risikos.
   - Mögliche Auswirkungen:
     - Finanzielle Verluste
     - Reputationsschäden
     - Rechtliche Konsequenzen
     - Störungen im operativen Geschäft
3. **Risikominderung und Kontrollmechanismen**
   - Analyse der bestehenden Maßnahmen zur Risikominderung.
   - Wichtige Aspekte:
     - Vorhandene Kontrollen und Strategien
     - Effektivität der Risikominderungsmaßnahmen
     - Anpassungsbedarf der bestehenden Prozesse

## Quellen

> Brell, C. (2021). Geschäftsprozess modellieren mit eEPK Geschäftsprozess. Bienen, Natur und Internet of Things. Retrieved from https://cbrell.de/blog/geschaeftsprozess-modellieren-mit-eepk

## Einführung in das UWG
- Das Gesetz gegen unlauteren Wettbewerb (UWG) **schützt Unternehmen und Verbraucher vor unlauteren Geschäftspraktiken**.
- Ziel: **Fairer Wettbewerb** und Schutz der Marktteilnehmer.

## Relevante Aspekte für die Fachinformatik
- **Irreführende Werbung**: Softwareprodukte dürfen nicht mit *falschen oder übertriebenen Eigenschaften* beworben werden.
- **Vergleichende Werbung**: Erlaubt, solange sie *objektiv und nicht irreführend* ist. Falsche Vergleiche können rechtliche Konsequenzen haben.
- **Schleichwerbung**: Verboten, insbesondere in digitalen Medien. I*nhalte müssen als Werbung gekennzeichnet sein.*

## Verbotene Handlungen
- **Aggressive Geschäftspraktiken**: Z.B. unerwünschte Werbung (*Spam*) oder *Belästigung von Kunden*.
- **Nachahmung**: *Unzulässig*, wenn Produkte oder Dienstleistungen so gestaltet sind, dass sie den Eindruck erwecken, sie seien von einem anderen Anbieter.

## Rechtsfolgen
- **Abmahnungen**: Wettbewerber können bei Verstößen Abmahnungen aussprechen.
- **Schadensersatz**: Bei nachweislichem Schaden durch unlautere Praktiken kann Schadensersatz gefordert werden.
- **Unterlassungsklagen**: Betroffene können rechtliche Schritte einleiten, um unlautere Praktiken zu stoppen.

## Praktische Anwendung in der Fachinformatik
- **Softwareentwicklung**: Achten auf *korrekte Produktdarstellungen* und Vermeidung von irreführenden Informationen.
- **Marketingstrategien**: Entwicklung von *fairen und transparenten Werbemaßnahmen*.
- **Datenschutz**: Berücksichtigung von *Datenschutzbestimmungen* in der Werbung und Kundenansprache.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Grundlagen von Groupware
- **Definition**: Groupware ist Software, die die Zusammenarbeit und Kommunikation innerhalb von Teams und Organisationen unterstützt.
- **Zweck**: Fördert die gemeinsame Nutzung von Informationen und die Koordination von Aufgaben.

## Wichtige Funktionen
- **E-Mail**: Ermöglicht die Kommunikation zwischen Teammitgliedern.
- **Kalender**: Gemeinsame Planung von Terminen und Veranstaltungen.
- **Dokumentenmanagement**: Speicherung, Bearbeitung und gemeinsame Nutzung von Dokumenten.
- **Aufgabenverwaltung**: Zuweisung und Nachverfolgung von Aufgaben innerhalb des Teams.

## Beispiele für Groupware
- **Microsoft 365**: Inklusive Outlook, Teams und SharePoint.
- **Google Workspace**: Beinhaltet Gmail, Google Drive und Google Docs.
- **Nextcloud**: Open-Source-Lösung für Dateispeicherung und Zusammenarbeit.

## Vorteile von Groupware
- **Effizienz**: Verbessert die Produktivität durch bessere Kommunikation und Zusammenarbeit.
- **Transparenz**: Erleichtert den Zugriff auf Informationen und den Status von Projekten.
- **Flexibilität**: Unterstützt remote und hybride Arbeitsmodelle.

## Sicherheit
- **Zugriffssteuerung**: Bestimmt, wer auf welche Informationen zugreifen kann.
- **Datenverschlüsselung**: Schützt sensible Informationen während der Übertragung und Speicherung.

## Fazit
Groupware ist ein wichtiges Werkzeug für die Zusammenarbeit in modernen Arbeitsumgebungen. Ein grundlegendes Verständnis der Funktionen und Sicherheitsaspekte ist entscheidend, um die Effizienz und Sicherheit der Teamarbeit zu gewährleisten.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Systeme oder Komponenten** **mehrfach** vorhanden sind, um die **Ausfallsicherheit** und **Verfügbarkeit** von IT-Systemen zu erhöhen. Ziel ist es, den **kontinuierlichen Betrieb** bei einem Hardware-Ausfall zu gewährleisten.

## Arten von Redundanzen

### Failover
- **Definition**: Failover ist ein Mechanismus, bei dem bei einem Ausfall eines Systems oder einer Komponente automatisch auf ein redundantes (Backup-)System umgeschaltet wird.
- **Typen von Failover**:
  - **Cold Failover**: Backup-System wird erst nach einem Ausfall hochgefahren.
  - **Warm Failover**: Backup-System läuft bereits, muss aber noch initialisiert werden.
  - **Hot Failover**: Backup-System läuft in Echtzeit und übernimmt sofort den Betrieb, ohne merkbare Verzögerung.

### Switchover
- **Definition**: Switchover bezeichnet einen geplanten Wechsel von einem aktiven System zu einem redundanten System, ohne dass ein Fehler vorliegt. Es wird manuell initiiert und dient oft dazu, Wartungsarbeiten durchzuführen oder Lasten besser zu verteilen.
- **Unterschied zu Failover**: Failover erfolgt automatisch und ungeplant bei einem Fehler, während Switchover manuell und geplant durchgeführt wird.
- **Beispiel**: Vor einer geplanten Wartung wird ein aktiver Server auf ein Backup-System umgeschaltet, um den primären Server ohne Unterbrechung des Dienstes warten zu können.

### N+1 Redundanz
- Eine zusätzliche Komponente steht für eine Anzahl N aktiver Komponenten bereit.
- **Beispiel**: 3 Server sind aktiv, und 1 Server ist als Backup konfiguriert.

### N+2, N+M Redundanz
- Erweiterte Konzepte von N+1, bei denen mehr als eine redundante Komponente vorhanden ist.

### [[RAID]]

### Cluster-Redundanz
- **Active-Passive Cluster**: Ein System ist aktiv, das andere im Standby (ähnlich wie Failover).
- **Active-Active Cluster**: Mehrere Systeme sind gleichzeitig aktiv und teilen die Last. Fällt eines aus, übernehmen die verbleibenden Systeme.

## Netzwerk-Redundanzen

### Link Aggregation (LACP)
- **Definition**: Mehrere Netzwerkverbindungen werden zu einer einzigen logischen Verbindung zusammengefasst. Falls ein Kabel oder ein Port ausfällt, bleibt die Verbindung über die anderen aktiv.
- **Vorteile**: Erhöht sowohl die Bandbreite als auch die Ausfallsicherheit.

### Spanning Tree Protocol (STP)
- **Definition**: Ein Netzwerkprotokoll, das Schleifen in redundanten Netzwerken verhindert, indem es automatisch Redundanzpfade deaktiviert und bei Ausfall eines Pfades wieder aktiviert.
- **Vorteil**: Verhindert Netzwerkloops und sorgt für Ausfallsicherheit durch automatische Neuberechnung von Pfaden.

### Hot Standby Router Protocol (HSRP) / Virtual Router Redundancy Protocol (VRRP)
- **Definition**: Protokolle, die Redundanz zwischen mehreren Routern herstellen. Fällt der aktive Router aus, übernimmt ein Backup-Router automatisch die Weiterleitung des Netzverkehrs.
- **Vorteil**: Sicherstellung, dass der Netzwerkzugriff immer über einen funktionsfähigen Router gewährleistet ist.

### Multipathing
- **Definition**: Mehrere Pfade zwischen einem Endgerät und einem Netzwerk oder einer Speicherressource werden genutzt. Wenn ein Pfad ausfällt, übernimmt ein anderer Pfad den Verkehr.
- **Beispiel**: In SANs (Storage Area Networks) oft verwendet, um den Zugriff auf Speichergeräte zu sichern.

### Dual-Homed
- **Definition**: Ein Gerät ist über zwei unabhängige Netzwerke verbunden, sodass bei einem Netzwerkausfall die Verbindung über das zweite Netzwerk bestehen bleibt.
- **Vorteil**: Vollständige Redundanz auf Netzwerkebene für kritische Systeme.

## Vorteile von Hardware- und Netzwerk-Redundanzen
- **Erhöhte Verfügbarkeit**: Systeme bleiben bei Hardware- oder Netzwerkausfällen weiterhin verfügbar.
- **Ausfallsicherheit**: Minimierung von Single Points of Failure (SPOF).
- **Minimierung von Downtime**: Redundanzsysteme und -netzwerke sorgen für weniger Ausfallzeiten und einen kontinuierlichen Betrieb.
- **Datenintegrität**: Bei RAID- und Multipathing-Systemen wird die Datenintegrität trotz Ausfällen gewahrt.

## Best Practices für Redundanzen
- **Regelmäßige Tests**: Redundanzsysteme und -netzwerke sollten regelmäßig getestet werden, um ihre Funktionsfähigkeit sicherzustellen.
- **Monitoring**: Monitoring-Systeme sollten implementiert werden, um Fehler frühzeitig zu erkennen.
- **Geografische Redundanz**: Für höchste Ausfallsicherheit sollten Backup-Systeme und Netzwerke an verschiedenen Standorten betrieben werden (Disaster Recovery).

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed1d06-5424-800b-bc26-8455a49771b1

## Zugangskontrolle
- **Zutrittskontrollsysteme**: Verwendung von Kartenlesern, biometrischen Scannern (z. B. Fingerabdruck, Gesichtserkennung) oder PIN-Codes, um den Zugang zu sensiblen Bereichen wie Gebäuden, Serverräumen oder Schränken zu steuern.
- **Schlüsselmanagement**: Physische Schlüssel oder elektronische Schlüssel, die nur autorisierten Personen zur Verfügung stehen.
- **Besuchermanagement**: Registrierung und Überwachung von Besuchern, um sicherzustellen, dass nur autorisierte Personen Zugang zu bestimmten Bereichen haben.

## Videoüberwachung
- **Überwachungskameras**: Installation von CCTV-Kameras zur Überwachung von Eingängen, Fluren und sensiblen Bereichen, um unbefugten Zugang zu erkennen und aufzuzeichnen.
- **Bewegungserkennung**: Kameras mit Bewegungssensoren, die Alarm auslösen, wenn unbefugte Bewegungen erkannt werden.

## Physische Barrieren
- **Zäune und Mauern**: Errichtung von Zäunen oder Mauern um das Gelände, um unbefugten Zugang zu verhindern.
- **Sicherheits-Türen**: Verwendung von verstärkten Türen, die schwer zu brechen sind, um den Zugang zu kritischen Bereichen zu schützen.

## Alarmanlagen
- **Einbruchmeldeanlagen**: Systeme, die bei unbefugtem Zutritt Alarm auslösen und die Sicherheitskräfte benachrichtigen.
- **Brandmeldeanlagen**: Systeme zur Erkennung von Rauch oder Feuer, die im Notfall Alarm auslösen.

## Sicherheitsbewusstsein und Schulung
- **Mitarbeiterschulungen**: Regelmäßige Schulungen für Mitarbeiter über Sicherheitsrichtlinien, um das Bewusstsein für physische Sicherheitsrisiken zu schärfen.
- **Sicherheitsrichtlinien**: Dokumentation und Kommunikation von klaren Richtlinien zur physischen Sicherheit.

## Physische Sicherheit von Hardware
- **Server-Racks und -Schränke**: Verwendung von abschließbaren Server-Racks oder -Schränken, um Server und andere kritische Hardware zu schützen.
- **Kabelmanagement**: Sicherstellung, dass Kabel und Verbindungen ordentlich und sicher verlegt sind, um Manipulationen zu verhindern.

## Notfallpläne
- **Evakuierungspläne**: Entwicklung und Kommunikation von Notfallplänen für verschiedene Szenarien (z. B. Feuer, Einbruch), um die Sicherheit der Mitarbeiter zu gewährleisten.
- **Sicherheitsübungen**: Regelmäßige Übungen zur Überprüfung der Notfallpläne und zur Schulung der Mitarbeiter im Umgang mit Sicherheitsvorfällen.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- systematische **Prüfungen von Hardwarekomponenten**, um deren Funktionalität, **Qualität und Zuverlässigkeit sicherzustellen**. Sie sind entscheidend für die Qualitätssicherung in der Produktion und im Vertrieb.

## Arten von Hardwaretests
- **Wareneingangskontrolle**
  - **Zweck:** Überprüfung der gelieferten Hardware auf Vollständigkeit und Mängel.
  - **Durchführung:**
    - Sichtprüfung auf äußerliche Schäden.
    - Vergleich mit Bestellunterlagen (Menge, Typ, Spezifikationen).
    - Funktionstests (z.B. Einschalten, Grundfunktionen).
  - **Dokumentation:** Protokollierung der Ergebnisse und eventueller Mängel.
- **Mangelhafte Lieferung**
  - **Identifikation:** Erkennung von defekten oder nicht konformen Produkten.
  - **Maßnahmen:**
    - Rückmeldung an den Lieferanten.
    - Dokumentation der Mängel (Fotos, Berichte).
    - Entscheidung über Rücksendung oder Nachbesserung.
  - **Prüfkriterien:** Funktionalität, Kompatibilität, Qualität.
- **Warenausgangskontrolle**
  - **Zweck:** Sicherstellung, dass nur einwandfreie Produkte das Lager verlassen.
  - **Durchführung:**
    - Endkontrolle der Produkte vor dem Versand.
    - Überprüfung der Verpackung und der Versanddokumente.
    - Durchführung von Funktionstests, falls erforderlich.
  - **Dokumentation:** Versandprotokolle, Prüfberichte.

## Wichtige Prüfmethoden
- **Visuelle Inspektion:** Überprüfung auf sichtbare Mängel oder Beschädigungen.
- **Funktionstests:** Testen der Hardware unter realistischen Bedingungen.
- **Leistungstests:** Messen der Leistungsfähigkeit (z.B. Geschwindigkeit, Kapazität).
- **Kompatibilitätstests:** Sicherstellen, dass die Hardware mit anderen Komponenten funktioniert.

## Dokumentation und Nachverfolgbarkeit
- Alle Tests sollten dokumentiert werden, um eine lückenlose Nachverfolgbarkeit zu gewährleisten.
- Verwendung von Prüfprotokollen und Berichten zur Analyse und Verbesserung der Prozesse.

## Bedeutung von Hardwaretests
- **Qualitätssicherung:** Minimierung von Fehlern und Mängeln.
- **Kundenzufriedenheit:** Sicherstellung, dass die gelieferten Produkte den Erwartungen entsprechen.
- **Kostenreduktion:** Vermeidung von Rücksendungen und Nacharbeiten.


## [[Hashing]]
- **Definition**: Ein Verfahren, das Daten beliebiger Größe in einen festen Hashwert (Fingerprint) umwandelt.
- **Einsatzbereich**: Datenintegrität, Passwortspeicherung, [[Digitale Signatur|digitale Signaturen]].

### Auswahl des Hashing-Verfahrens
- **MD5**
	- **Länge**: 128 Bit
	- **Sicherheit**: Veraltet, anfällig für Kollisionen (zwei unterschiedliche Eingaben erzeugen denselben Hashwert).
	- **Einsatz**: Früher weit verbreitet, heute nicht mehr empfohlen für sicherheitskritische Anwendungen.
- **SHA-1**
	- **Länge**: 160 Bit
	- **Sicherheit**: Anfällig für Kollisionen, nicht mehr als sicher angesehen.
	- **Einsatz**: Ehemals Standard für digitale Signaturen, sollte durch sicherere Alternativen ersetzt werden.
- **SHA-256**
	- **Länge**: 256 Bit
	- **Sicherheit**: Aktuell als sicher angesehen, Teil der SHA-2-Familie.
	- **Einsatz**: Weit verbreitet in sicherheitskritischen Anwendungen, z.B. Blockchain, digitale Zertifikate.
- **SHA-3**
	- **Länge**: Variabel (224, 256, 384, 512 Bit)
	- **Sicherheit**: Neueste Hash-Funktion, die als sicher gilt.
	- **Einsatz**: Zukünftige Anwendungen, wo höchste Sicherheit erforderlich ist.

## Verschlüsselungsverfahren
- **Definition**: Verfahren zur Umwandlung von Klartext in Geheimtext, um die Vertraulichkeit der Daten zu gewährleisten.

### Auswahl des Verschlüsselungsverfahrens
- **AES (Advanced Encryption Standard)**
	- **Schlüssellängen**: 128, 192, 256 Bit
	- **Sicherheit**: Sehr sicher, weit verbreitet und standardisiert.
	- **Einsatz**: Ideal für die Verschlüsselung von Daten in verschiedenen Anwendungen, z.B. Dateisysteme, VPNs.
- **RSA (Rivest-Shamir-Adleman)**
	- **Schlüssellängen**: 1024, 2048, 4096 Bit
	- **Sicherheit**: Sicher, aber langsamer als symmetrische Verfahren.
	- **Einsatz**: Häufig für den Schlüsselaustausch und digitale Signaturen verwendet.
- **ChaCha20**
	- **Schlüssellängen**: 256 Bit
	- **Sicherheit**: Hohe Sicherheit und Geschwindigkeit, besonders auf mobilen Geräten.
	- **Einsatz**: Alternativ zu AES in bestimmten Anwendungen, z.B. in TLS.

## Zusammenfassung der Auswahl
- **Hashing**: SHA-256 oder SHA-3 für sicherheitskritische Anwendungen; MD5 und SHA-1 vermeiden.
- **Verschlüsselung**: AES für symmetrische Verschlüsselung; RSA für asymmetrische Verschlüsselung; ChaCha20 als moderne Alternative.

## Quellen
> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

# Hashing

- **Kryptografische Methode** zur Umwandlung von Datensätzen und Zeichen beliebiger Länge in **kompakte, feste Hashwerte**.
- Eine **Hashfunktion** ist ein kryptografischer Algorithmus, der Daten vollständig zerlegt und in eine Zeichenfolge fester Länge umwandelt.
- Der **Hashwert** ist das Ergebnis der Hashfunktion und hat immer die gleiche Länge, die vom verwendeten Algorithmus abhängt.

## Charakteristische Eigenschaften
- **Determinismus**: Gleiche Eingaben führen immer zu identischen Hashwerten, unabhängig von der Länge der Eingabe.
- **Nicht rücklesbar**: Hashwerte können nicht in die ursprünglichen Daten zurückverwandelt werden.
- **Kollisionssicherheit**: Es ist extrem unwahrscheinlich, dass verschiedene Eingaben denselben Hashwert erzeugen. Tritt dies doch auf, spricht man von einer *Kollision*.
- **Kontinuität**: Kleine Änderungen in den Eingabedaten führen zu signifikant unterschiedlichen Hashwerten. Je nach Anwendungsfall können die Unterschiede stark oder minimal sein.

## Anwendungsbereiche
- **Suche nach Duplikaten**: Identifikation identischer Daten.
- **Prüfsummen und digitale Signaturen**: Gewährleistung der Integrität von Daten.
- **Suche nach ähnlichen Daten**: Vergleich von Datensätzen auf Ähnlichkeit.
- **Authentifizierungssysteme**: Sicherstellung der Identität von Benutzern.
- **Caching**: Effiziente Speicherung von Daten zur schnelleren Wiederverwendung.
- **"Verschlüsselung" wichtiger Daten**: Schutz sensibler Informationen durch Hashing.

## Digitale Signaturen und Prüfsummen
- **Digitale Fingerabdrücke**: Ein einzigartiger Hashwert, der eine Datei oder Nachricht repräsentiert.
- Bestätigung der Integrität bei der Kommunikation zwischen Sender und Empfänger.
- **Zero-Knowledge Passwortspeicherung**: Speicherung von Hashwerten anstelle von Klartextpasswörtern, um die Sicherheit zu erhöhen.

## Vorteile
- Sensible Daten können sicher und kompakt gespeichert und verwaltet werden.
- Hashwerte sind nicht rücklesbar, was die Sicherheit erhöht.
- Gestohlene Hashwerte sind für Angreifende ohne weiteres nicht nützlich, da sie nicht die ursprünglichen Daten offenbaren.

## Quellen

> Redaktion, I. (2022). Was ist Hashing? So funktioniert das Hashverfahren. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/websites/web-entwicklung/hashing

- **Hauptprozesse**, Teil der Wertschöpfungskette. Womit wird das Geld verdient? Zweck des Unternehmens
	- z.B. Produktion
- **Teilprozesse**, was sind unterstützende Prozesse? 
	- z.B. Instandhaltung, 

- **Unternehmenszweck**, wofür es das Unternehmen gibt. Wofür das Unternehmen gegründet wurde

![[Pasted image 20240924092010.png]]

- HTTP **Secure**, Erweiterung von HTTP
- alle Daten zwischen **Browser und Zielserver** werden **verschlüsselt**
- Browser und Server **handeln** **pro Aufruf Schlüssel** aus, Daten werden damit verschlüsselt um während des Transports gesichert zu sein
- **HTTPS-Zertifikat**, Webseite ist wirklich die Seite, die sie vorgibt zu sein


## Quellen
> MainHoster. (2019, February 22). #40 Einfach Erklärt: "Https / SSL Zertifikate". Youtube. Retrieved from https://www.youtube.com/watch?v=bzTjRW3fJlc

- **I**terative **D**ichotomiser **3**, Algorithmus zur **Entscheidungsfindung**
- wird bei [[Entscheidungsbaum|Entscheidungsbäumen]] eingesetzt mit **großen Datenmengen** und **vielen verschiedene Attributen** von Bedeutung

- Basisstruktur ist **iterativ**
- **[[Entropie und Informationsgewinn|Entropien]]** berechnet, Attribut mit höchstem [[Entropie und Informationsgewinn|Informationsgewinn]] bzw. kleinster [[Entropie und Informationsgewinn]] wird gewählt. Wenn jedem Blattknoten eine Klassifikation zugeordnet ist, ist Verfahren terminiert 
## Algorithmus

$T = Daten$

- ***Wenn*** alle Elemente aus $T$ zu einer Klasse gehören
	- ***Dann***
		- *// Erzeuge ein Blatt //*
			- ***Konstruiere*** ein Blatt mit **Klasse** als **Bezeichner**
	- ***Sonst***
		- *// Erzeuge rekursiv einen Teilbaum //*
			- ***Wähle*** Merkmal $x_i$ mit höchstem **[[Entropie und Informationsgewinn|information gain]]**
				- ***Für alle*** vorkommende Werte von Merkmal $x_i$
					- ***Konstruiere*** alle Teilbäume rekursiv mit den entsprechenden Teilmengen als Daten
				- ***Ende*** für Alle
				- ***Konstruiere*** einen Baumknoten mit Bezeichner $x_i$ und hänge alle erzeugten Teilbäume an
	- ***Ende*** Sonst
- ***Ende***

## Beispiel

| play | outlook | temp | humid | wind | day     | moon |
| ---- | ------- | ---- | ----- | ---- | ------- | ---- |
| no   | sunny   | hot  | high  | weak | tuesday | full |
| ...  | ...     | ...  | ...   | ...  | ...     | ...  |
- Input Datensatz, `play` wird die vorhergesagte Variable sein

![[Pasted image 20240912134913.png]]


## Quellen

> Autoren der Wikimedia-Projekte. (2004, February 28). Iterative Dichotomiser 3 – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Iterative_Dichotomiser_3&oldid=209630820
> Example: How to train the ID3 classifier to perform classification (SPMF - Java). (2024, September 12). Retrieved from https://www.philippe-fournier-viger.com/spmf/ID3.php

- Framework bestehend aus **Strategien und Technologien**, die Unternehmen helfen, **digitale Identitäten zu verwalten** und den **Zugang zu Ressourcen sicherzustellen**. Die Hauptziele sind:
- Sicherstellung, dass die **richtigen Personen** Zugriff auf die **richtigen Ressourcen** zur **richtigen Zeit** aus den richtigen Gründen haben.
- **Minimierung** von **Sicherheitsrisiken** durch **zentrale Verwaltung** und **Überwachung** von **Zugriffsrechten**.

## Wichtige Komponenten

1. **Identitätsverwaltung**:
   - **Benutzerkonten**: Erstellung, Verwaltung, Aktivierung/Deaktivierung von Benutzerkonten.
   - **Authentifizierung**: Methoden wie Passwörter, biometrische Daten, MFA (Multi-Faktor-Authentifizierung).
2. **Zugriffssteuerung**:
   - **Rollenbasierte Zugriffskontrolle (RBAC)**: Zuweisung von Zugriffsrechten basierend auf definierten Rollen.
   - **Attributbasierte Zugriffskontrolle (ABAC)**: Entscheidungen basierend auf benutzerdefinierten Attributen (z.B. Abteilung, Standort).
3. **Verzeichnisse & Identitätsdatenbanken**:
   - Zentralisierte Speicherung und Verwaltung von Identitätsinformationen (z.B. Active Directory).
4. **Zugriffsüberwachung und -prüfung**:
   - **Audit-Logs**: Aufzeichnung von Zugriffsversuchen und -aktivitäten.
   - **Compliance-Berichte**: Sicherstellung der Einhaltung gesetzlicher Vorgaben und Unternehmensrichtlinien.

## Tools und Techniken

### Authentifizierungstools

- **Single Sign-On (SSO)**: Einmaliges Anmelden für Zugriff auf mehrere Applikationen.
- **Multi-Faktor-Authentifizierung (MFA)**: Kombination verschiedener Authentifizierungsmethoden (z.B. Passwort + SMS-Code).

### Zugriffsmanagement

- **Active Directory (AD)**: Verwaltung von Benutzern und Gruppenzugriffsrechten in Windows-Umgebungen.
- **Identity Governance & Administration (IGA)**: Tools wie SailPoint oder One Identity zur Verwaltung und Überprüfung von Zugriffsrechten.
- **LDAP (Lightweight Directory Access Protocol)**: Protokoll zur Abfrage und Modifikation von Verzeichnisdiensten, oft verwendet zur Authentifizierung und Autorisierung.

### Sicherheitsüberprüfung

- **Penetrationstests (Pentests)**: Simulierte Angriffe zur Überprüfung der Sicherheit.
- **Vulnerability Scanner**: Tools wie Nessus oder OpenVAS zur Identifizierung von Schwachstellen.

## Best Practices

- **Principle of Least Privilege (PoLP)**: Gewähren von minimal erforderlichen Zugriffsrechten.
- **Regelmäßige Überprüfung**: Regelmäßige Audits und Überprüfung der Zugriffsrechte.
- **Benutzerschulung**: Schulung der Benutzer zu sicherheitsrelevanten Themen und bewährten Methoden.

## Vor- und Nachteile

### Vorteile

- **Erhöhte Sicherheit**: Durch zentrale Verwaltung, MFA und regelmäßige Überprüfungen.
- **Effizienzsteigerung**: Einfacher Zugang für Benutzer über SSO und automatisierte Prozesse.
- **Compliance**: Einhaltung von gesetzlichen und regulatorischen Anforderungen.

### Nachteile

- **Komplexität**: Implementierung und Verwaltung können komplex und kostenintensiv sein.
- **Einzelpunktversagen**: Zentralisiertes IAM-System kann zum „Single Point of Failure“ werden.
- **Benutzerfreundlichkeit**: Möglicherweise reduzierte Benutzerfreundlichkeit durch zusätzliche Sicherheitsmaßnahmen wie MFA.

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com

- Prozess zur **Identifizierung**, **Analyse** und **Behebung** von **Vorfällen** (Incidents), die den normalen Betrieb eines IT-Services stören oder unterbrechen. Ziel ist es, die Auswirkungen von Vorfällen auf den Geschäftsbetrieb zu minimieren und die Servicequalität aufrechtzuerhalten.

## Ziele des Incident Managements
- **Schnelle Wiederherstellung**: Minimierung der Ausfallzeiten und schnelle Wiederherstellung des normalen Betriebs.
- **Kundenzufriedenheit**: Sicherstellung, dass Benutzer und Kunden über den Status ihrer Anfragen informiert sind und ihre Probleme zeitnah gelöst werden.
- **Dokumentation**: Erfassung und Dokumentation von Vorfällen zur Analyse und Verbesserung der Prozesse.
- **Prävention**: Identifizierung von wiederkehrenden Problemen zur Vermeidung zukünftiger Vorfälle.

## Komponenten eines Ticketsystems
- **Ticket-Erstellung**: Benutzer können Vorfälle über verschiedene Kanäle (z. B. E-Mail, Webportal, Telefon) melden, wodurch ein Ticket im System erstellt wird.
- **Ticket-Kategorisierung**: Klassifizierung der Tickets nach Typ, Dringlichkeit und Schweregrad, um die Priorität der Bearbeitung festzulegen.
- **Ticket-Zuweisung**: Zuweisung von Tickets an die zuständigen Supportmitarbeiter oder -teams basierend auf den Kategorien und Verfügbarkeiten.
- **Ticket-Tracking**: Verfolgung des Status von Tickets (z. B. offen, in Bearbeitung, gelöst) und Bereitstellung von Updates für die Benutzer.
- **Kommunikation**: Möglichkeit für Supportmitarbeiter, mit den Benutzern zu kommunizieren, um zusätzliche Informationen zu sammeln oder den Fortschritt zu erläutern.
- **Lösungsdokumentation**: Erfassung der Lösungen und Maßnahmen, die zur Behebung des Vorfalls ergriffen wurden, um zukünftige Referenzen zu ermöglichen.

## Prozess des Incident Managements
1. **Incident Identifikation**: Erkennung und Meldung eines Vorfalls durch Benutzer oder Monitoring-Systeme.
2. **Ticket-Erstellung**: Erstellung eines Tickets im System mit allen relevanten Informationen (z. B. Beschreibung, Dringlichkeit, betroffene Systeme).
3. **Kategorisierung und Priorisierung**: Klassifizierung des Tickets und Festlegung der Priorität basierend auf der Schwere des Vorfalls und den Auswirkungen auf den Geschäftsbetrieb.
4. **Zuweisung**: Zuweisung des Tickets an das zuständige Support-Team oder den Mitarbeiter.
5. **Untersuchung und Diagnose**: Analyse des Vorfalls, um die Ursache zu identifizieren und mögliche Lösungen zu finden.
6. **Lösung und Wiederherstellung**: Implementierung der Lösung und Wiederherstellung des normalen Betriebs.
7. **Ticket-Schließung**: Dokumentation der Lösung im Ticket und Schließung des Tickets. Informieren des Benutzers über die Behebung des Vorfalls.
8. **Nachverfolgung und Analyse**: Überprüfung der Vorfälle zur Identifizierung von Trends, wiederkehrenden Problemen und Möglichkeiten zur Prozessverbesserung.

## Vorteile eines Ticketsystems
- **Zentralisierte Verwaltung**: Alle Vorfälle werden an einem Ort erfasst und verwaltet, was die Nachverfolgung und Analyse erleichtert.
- **Effizienzsteigerung**: Automatisierung von Prozessen wie Ticket-Erstellung, Zuweisung und Statusverfolgung verbessert die Effizienz des Support-Teams.
- **Transparenz**: Benutzer können den Status ihrer Tickets einsehen und erhalten regelmäßige Updates, was die Kundenzufriedenheit erhöht.
- **Wissensdatenbank**: Dokumentation von Lösungen und häufigen Problemen ermöglicht die Erstellung einer Wissensdatenbank zur Unterstützung zukünftiger Vorfälle.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- auch **Smart Manufacturing** genannt
- Integration neuer Technologien wie [[IoT]], [[Cloud-Computing]], [[Big Data]] und [[Maschinelles Lernen]]

### Technologien und Konzepte
- **Cyber-physische Systeme**: Vernetzung von physischen und digitalen Prozessen
  - **Beispiele**: Digitale Zwillinge, Sensoren
  - **Vorteile**: Echtzeitüberwachung, verbesserte Effizienz
  - **Nachteile**: Hohe Implementierungskosten, Sicherheitsrisiken

- **Automatisierung**: Einsatz von Robotern und automatisierten Systemen zur Effizienzsteigerung
  - **Beispiele**: Industrieroboter, autonome Fahrzeuge
  - **Vorteile**: Erhöhung der Produktionsgeschwindigkeit, Reduzierung menschlicher Fehler
  - **Nachteile**: Arbeitsplatzverlust, hohe Anfangsinvestitionen

- **Datenanalyse**: Nutzung von Daten zur Optimierung von Produktionsprozessen und Entscheidungsfindung
  - **Beispiele**: Predictive Analytics, Business Intelligence-Tools
  - **Vorteile**: Bessere Entscheidungsfindung, Identifikation von Verbesserungspotenzialen
  - **Nachteile**: Datenüberflutung, Datenschutzbedenken

- **Flexibilität**: Anpassungsfähigkeit der Produktionssysteme an sich ändernde Anforderungen
  - **Beispiele**: Modulare Produktionssysteme, 3D-Druck
  - **Vorteile**: Schnelle Reaktion auf Marktveränderungen, individuelle Kundenwünsche
  - **Nachteile**: Komplexität der Systeme, höhere Schulungsanforderungen

- **Vernetzung**: Kommunikation zwischen Maschinen, Geräten und Menschen in Echtzeit
  - **Beispiele**: Industrie 4.0-Protokolle (z.B. MQTT, OPC UA)
  - **Vorteile**: Effiziente Zusammenarbeit, verbesserte Transparenz
  - **Nachteile**: Abhängigkeit von stabilen Netzwerken, Cybersecurity-Risiken

- **Kundenzentrierung**: Individualisierte Produkte und Dienstleistungen durch direkte Kundeninteraktion
  - **Beispiele**: Mass Customization, Kundenportale
  - **Vorteile**: Höhere Kundenzufriedenheit, Wettbewerbsvorteil
  - **Nachteile**: Höhere Produktionskosten, komplexe Logistik

- **Nachhaltigkeit**: Ressourcenschonende Produktion und Reduzierung von Abfällen
  - **Beispiele**: Kreislaufwirtschaft, energieeffiziente Maschinen
  - **Vorteile**: Reduzierung der Umweltbelastung, Kosteneinsparungen durch Effizienz
  - **Nachteile**: Anfangsinvestitionen in nachhaltige Technologien, mögliche Produktionsverzögerungen

![[Pasted image 20240919135944.png]]

## Quellen

> Ibm. (2023, December 19). Was ist Industrie 4.0 und wie funktioniert sie? | IBM. Retrieved from https://www.ibm.com/de-de/topics/industry-4-0


## 1. Grundformel für Information
- **Formel**: $I(x) = -\log_2(P(x))$
- **Begriffe**:
	- $I(x)$: Information des Ereignisses $x$
	- $P(x)$: Wahrscheinlichkeit des Ereignisses $x$

## 2. Wichtige Eigenschaften
- **Einheit**: Bits
- **Unwahrscheinlichkeit**: Je unwahrscheinlicher ein Ereignis, desto höher die Information.
- **Sichere Ereignisse**: $P(x) = 1 \Rightarrow I(x) = 0$ (keine neue Information).

## 3. Interpretation der Bits
- **1 Bit**: Information einer Ja/Nein-Entscheidung.
- **2 Bits**: Information einer Entscheidung mit 4 gleichwahrscheinlichen Möglichkeiten.
- **n Bits**: Information einer Entscheidung mit $2^n$ gleichwahrscheinlichen Möglichkeiten.

## 4. Beispiele
- $P(x) = 0,5 \Rightarrow I(x) = 1 \text{ Bit}$
- $P(x) = 0,25 \Rightarrow I(x) = 2 \text{ Bits}$
- $P(x) = 0,125 \Rightarrow I(x) = 3 \text{ Bits}$

## 5. Anwendungen
- Entscheidungsbäume
- Datenkompression
- Kryptographie
- Maschinelles Lernen

## 6. Merksätze
- Mehr Überraschung = Mehr Information.
- Perfekte Vorhersage = Keine Information.
- Information ist additiv für unabhängige Ereignisse.


## Begriffsdefinitionen
- **Integration**: Zusammenführen von verschiedenen Systemen oder Modulen, um eine einheitliche Funktionalität zu gewährleisten.
- **Modularisierung**: Aufteilung eines Systems in kleinere, unabhängige Module, die spezifische Aufgaben erfüllen.

## Ziele der Modularisierung
- **Wiederverwendbarkeit**: Module können in verschiedenen Projekten eingesetzt werden.
- **Wartbarkeit**: Einfachere Anpassungen und Fehlerbehebungen durch isolierte Module.
- **Teamarbeit**: Mehrere Entwickler können parallel an verschiedenen Modulen arbeiten.

## Methoden der Modularisierung
- **Funktionale Modularisierung**: Module basieren auf spezifischen Funktionen oder Aufgaben.
- **Datenbasierte Modularisierung**: Module sind um Datenstrukturen herum organisiert.
- **Schichtenarchitektur**: Trennung von Präsentation, Logik und Datenzugriff in verschiedene Schichten.

## Integrationstechniken
- **API (Application Programming Interface)**: Schnittstellen zur Kommunikation zwischen Modulen.
- **Middleware**: Software, die als Vermittler zwischen verschiedenen Anwendungen oder Modulen fungiert.
- **Service-Oriented Architecture (SOA)**: Architekturansatz, der Dienste als zentrale Bausteine verwendet.

## Herausforderungen
- **Komplexität**: Zunehmende Komplexität bei der Integration vieler Module.
- **Kompatibilität**: Sicherstellen, dass verschiedene Module miteinander kommunizieren können.
- **Testbarkeit**: Module müssen unabhängig getestet werden können.

## Vorteile der Integration
- **Effizienz**: Durch die Zusammenführung verschiedener Systeme können Ressourcen besser genutzt werden.
- **Konsistenz**: Einheitliche Daten und Prozesse sorgen für eine höhere Datenintegrität und weniger Fehler.
- **Erweiterbarkeit**: Neue Module oder Systeme können einfacher integriert werden, was die Anpassungsfähigkeit erhöht.
- **Zentralisierte Verwaltung**: Erleichtert die Überwachung und Verwaltung von Systemen.

## Nachteile der Integration
- **Komplexität**: Die Integration vieler Systeme kann zu einer erhöhten Komplexität führen, die schwer zu managen ist.
- **Abhängigkeiten**: Module können voneinander abhängig werden, was die Wartung erschwert.
- **Kosten**: Hohe Kosten für die Integration, insbesondere bei bestehenden Systemen.
- **Risiko von Ausfällen**: Ein Fehler in einem integrierten System kann Auswirkungen auf andere Systeme haben.

## Vorteile der Modularisierung
- **Wiederverwendbarkeit**: Module können in verschiedenen Projekten oder Anwendungen wiederverwendet werden.
- **Wartbarkeit**: Fehler können leichter lokalisiert und behoben werden, da Module isoliert sind.
- **Teamarbeit**: Mehrere Entwickler können gleichzeitig an verschiedenen Modulen arbeiten, was die Produktivität erhöht.
- **Flexibilität**: Module können unabhängig aktualisiert oder ersetzt werden, ohne das gesamte System zu beeinflussen.

## Nachteile der Modularisierung
- **Initialer Aufwand**: Die Aufteilung in Module erfordert anfangs mehr Planung und Designaufwand.
- **Kommunikationsaufwand**: Module müssen gut definiert und dokumentiert sein, um effektiv zu kommunizieren, was zusätzlichen Aufwand bedeutet.
- **Performance**: In einigen Fällen kann die Modularisierung zu Performance-Einbußen führen, insbesondere wenn viele Schnittstellen verwendet werden.
- **Komplexität der Schnittstellen**: Die Verwaltung und Pflege der Schnittstellen zwischen Modulen kann komplex und fehleranfällig sein.
## Best Practices
- **Klare Schnittstellen definieren**: Um die Interoperabilität zu gewährleisten.
- **Dokumentation**: Jedes Modul sollte gut dokumentiert sein.
- **Regelmäßige Refaktorisierung**: Um die Modularität und Wartbarkeit zu verbessern.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Netzwerk von **physischen Objekten**, die mit **Sensoren**, **Software** und anderen Technologien ausgestattet sind, um **Daten zu sammeln** und mit anderen **Geräten und Systemen** über das Internet zu **kommunizieren**.

## Architektur von IoT-Systemen  
- **Geräte:** Physische Geräte wie Sensoren, Aktoren, Maschinen, die Daten erfassen oder Aktionen ausführen.
- **Netzwerk:** Kommunikationsinfrastruktur, die den Datenaustausch zwischen Geräten und Servern ermöglicht (z.B. WLAN, 4G/5G, Bluetooth).
- **Cloud:** Speichert und verarbeitet die Daten, führt Analysen durch und bietet Schnittstellen für Benutzer.
- **Benutzer:** Verwenden Anwendungen, um die gesammelten Daten zu visualisieren, zu analysieren und Steuerungen durchzuführen.

## Komponenten eines IoT-Systems  
- **Sensoren:** Erfassen physische Umgebungsparameter (z.B. Temperatur, Bewegung, Licht).
- **Aktoren:** Führen Aktionen basierend auf den erhaltenen Daten durch (z.B. Motorsteuerung, Heizung regeln).
- **Gateways:** Dienen als Vermittler zwischen IoT-Geräten und der Cloud, aggregieren Daten und leiten sie weiter.
- **Protokolle:** Ermöglichen die Kommunikation zwischen Geräten (z.B. MQTT, HTTP, CoAP).
  
## Anwendungsbereiche von IoT  
- **Smart Home:** Vernetzte Geräte wie Thermostate, Beleuchtung, Sicherheitskameras, die automatisch gesteuert werden können.
- **Industrie 4.0:** Vernetzung von Maschinen und Produktionsprozessen, um die Effizienz zu steigern (z.B. Predictive Maintenance).
- **Smart Cities:** Einsatz von Sensoren und vernetzten Geräten, um Verkehrssteuerung, Müllentsorgung und Energieversorgung effizienter zu gestalten.
- **Gesundheitswesen:** Vernetzte Geräte zur Überwachung von Patienten, z.B. Wearables zur Messung von Vitaldaten.
- **Landwirtschaft:** Sensoren zur Überwachung von Bodenqualität, Wetterbedingungen und automatisierten Bewässerungssystemen.

## IoT-Protokolle  
- **MQTT (Message Queuing Telemetry Transport):** Leichtgewichtiges Protokoll, ideal für Geräte mit begrenzten Ressourcen und Netzwerken mit hoher Latenz.
- **CoAP (Constrained Application Protocol):** Ähnlich wie HTTP, aber für Geräte mit begrenzten Ressourcen optimiert.
- **HTTP/HTTPS:** Standardprotokoll für Webanwendungen, auch für IoT-Geräte verwendet, wenn keine Echtzeitkommunikation erforderlich ist.

## Herausforderungen und Risiken von IoT  
- **Sicherheit:** IoT-Geräte sind oft anfällig für Cyberangriffe, insbesondere durch mangelnde Verschlüsselung oder unsichere Standardpasswörter.
- **Skalierbarkeit:** Das exponentielle Wachstum von IoT-Geräten erfordert leistungsfähige Infrastrukturen, um Daten effizient zu verarbeiten und zu speichern.
- **Interoperabilität:** Unterschiedliche Hersteller und Systeme verwenden oft inkompatible Protokolle und Standards, was die Integration erschwert.
- **Datenschutz:** Der Umgang mit großen Mengen an personenbezogenen Daten erfordert strenge Datenschutzvorkehrungen (z.B. Einhaltung der DSGVO).

## Schritte zur Entwicklung eines IoT-Systems  
1. **Anforderungsanalyse:** Identifizierung der zu erfassenden Daten und Aktionen.
2. **Geräteauswahl:** Auswahl passender Sensoren, Aktoren und Kommunikationsprotokolle.
3. **Netzwerkinfrastruktur:** Planung der Kommunikationsarchitektur (z.B. WLAN, 5G).
4. **Datenverarbeitung:** Entscheidung über lokale (Edge Computing) oder Cloud-basierte Verarbeitung.
5. **Sicherheitskonzepte:** Implementierung von Verschlüsselung, Authentifizierung und Zugriffskontrollen.
6. **Benutzeroberfläche:** Entwicklung von Anwendungen zur Visualisierung und Steuerung der IoT-Geräte.

## Edge Computing vs. Cloud Computing in IoT  
- **[[Fog-Computing|Edge Computing]]:** Daten werden nahe der Quelle (d.h. am Gerät oder Gateway) verarbeitet, um Latenzzeiten zu reduzieren und Bandbreite zu sparen.
- **[[Cloud-Computing|Cloud Computing]]:** Daten werden an zentrale Server gesendet, um dort verarbeitet, analysiert und gespeichert zu werden. Vorteilhaft bei großen Datenmengen oder rechenintensiven Aufgaben.

## Relevante Begriffe  
- **Smart Devices:** Intelligente Geräte, die über Sensoren verfügen und mit dem Internet verbunden sind.
- **Wearables:** Tragbare IoT-Geräte, die oft zur Gesundheitsüberwachung eingesetzt werden (z.B. Fitness-Tracker).
- **Digital Twin:** Virtuelles Modell eines physischen Objekts, das dessen Zustand in Echtzeit überwacht.
- **IoT-Plattformen:** Softwarelösungen zur Verwaltung und Analyse von IoT-Daten (z.B. AWS IoT, Microsoft Azure IoT Hub).

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed3ccd-34d4-800b-a198-dee9a0d61710

- **I**nternet **P**rotocol
- [[OSI-Modell|Ebene 3, Vermittlungsschicht/Network Layer]]

## Adressierung
### IPv4
- **32-Bit** lang
- `00000000.00000000.00000000.00000000`
- vier **durch Punkte** **getrennte** Dezimalzahlen
- begrenzter Adressraum (4,3 Milliarden)
- besteht aus **Netzwerk-** und **Hostsegment**

### IPv6
- **128-Bit** lang
- **acht** durch **Doppelpunkte** getrennte Gruppen von **vier hexadezimalen Ziffern**
- nahezu **unbegrenzte Anzahl an Adressen** (340 Sextillionen)
- effizienteres **Datenrouting** und **Paketverarbeitungsfunktionen**
- besteht aus **Netzwerk-**, **Subnetz-** und **Interface-Identifikator**
	- **Netzwerk**-Identifikator: identifiziert **Netzwerk**
	- **Subnetz**-Identifikator: identifiziert **spezifisches Subnetz**
	- **Interface**-Identifikator: identifiziert **spezifisches Gerät**

### Subnetzmaske
- teilt IP-Netzwerk in Subnetze auf
- **CIDR**: Classles Inter-Domain Routing
- **CIDR-Notation**: Anzahl von *1er Bits* in Subnetzmaske
- **mehr Flexibilität** als klassenbasiertes Routing
- **VLSM**: Variable Length Subnet Mask
	- Methode zur Subnetz-Aufteilung
	- Verwendung verschiedener Subnetzmasken innerhalb desselben Netzwerkes
### Adressraum
- durch **Internet Assigned Numbers Authority** *(IANA)* festgelegt
- **privater** Adressraum: wird **nicht** geroutet, nur in einem Netzwerksegment erreichbar
	- 10.0.0.0 - 10.255.255.255 *(/8)*
	- 172.16.0.0 - 172.31.255.255 *(/12)*
	- 192.168.0.0 - 192.168.255.255 *(/16)*
- **öffentlicher** Adressraum: im gesamten Internet eindeutig, wird geroutet

### Adresstypen
- **Multicast**: an eine *Gruppe* von Hosts
- **Anycast**: *nächstgelegenes Gerät* einer *Gruppe*
- **Unicast**: an ein *einzelnes Gerät* adressiert
- **Broadcast**: an *alle Geräte* im Netzwerk
- **Loopback**: *selbstidentifkation* des Gerätes
### Klassen
1. **A**: 0.X.X.X - 127.X.X.X
2. **B**: 128.X.X.X - 191.X.X.X
4. **C**: 192.X.X.X - 223.X.X.X
5. **D**: 224.X.X.X - 239.X.X.X
6. **E**: 240.X.X.X - 255.X.X.X

## Quellen

> Torben Haack (2024), AP1 Vorbereitung, IP-Adressen.md

- Gruppe von **Protokollen** zur **Sicherung von Verbindungen** zwischen Geräten
- häufig für [[VPN-Modelle|VPNs]] benutzt
- **Verschlüsselung** von [[TCP-IP-Modell|IP-Paketen]], **Authentifizierung** der Quelle

## Funktionsweise
1. **Schlüsselaustausch**, [[Verschlüsselungsart#Asymmetrische Verschlüsselung|Schlüsselpaar]] wird ausgetauscht
2. **Paket-Header** und **-Trailer**, Daten bekommen extra Header bezüglich *Authentifizierung* und *Verschlüsselung* als auch Trailer -> Overhead
3. **Authentifizierung**, für jedes Paket Authentifizierung, quasi wie *Echtheitsstempel* auf Sammlerstück -> Pakete garantiert von vertrauenswürdiger Quelle
4. **Verschlüsselung**, Daten und Header von Paketen werden verschlüsselt
5. **Übertragung**, Pakete werden als [[TCP-UDP|UDP]] verschickt, dadurch kommen Pakete einfacher durch Firewalls
6. **Entschlüsselung**, Daten werden entschlüsselt

## Protokolle
- **Authentication Header** *(AH)*, Sicherstellung dass Daten von vertrauenswürdiger Quelle kommen und nicht manipuliert wurden
- **Einkapselndes Sicherheitsprotokoll** *(ESP)*, verschlüsselt IP-Header und Daten für jedes Paket. Im Transportmodus nur Daten verschlüsselt. ESP fügt zu jedem Paket Header und Trailer hinzu
- **Security Association** *(SA)*, Reihe von Protokollen für Aushandlung der Verschlüsselungsschlüsseln und -algorithmen

## Vorteile
- **Netzwerksicherheit**: IPsec bietet eine starke Sicherheit auf Netzwerkebene, indem es Datenpakete verschlüsselt und Authentifizierungsmethoden verwendet, um sicherzustellen, dass die Daten nur von autorisierten Benutzern gelesen werden können.
- **Unterstützung für IP-basierte Anwendungen**: Da IPsec alle IP-basierten Anwendungen unterstützt, kann es nahtlos in bestehende Netzwerke integriert werden, ohne dass spezielle Anpassungen erforderlich sind.
- **Bewährte Technologie**: IPsec ist eine etablierte Technologie, die seit vielen Jahren verwendet wird und sich als zuverlässig erwiesen hat

## Nachteile
- **Komplexität**: Die Implementierung und Konfiguration von IPsec kann komplex sein, was zu höheren Kosten und längeren Implementierungszeiten führen kann.
- **Leistungsprobleme**: In einigen Fällen kann die Verschlüsselung von Daten zu einer Verringerung der Netzwerkgeschwindigkeit führen, insbesondere bei älteren Hardwarelösungen
- **Kompatibilität**: IPsec kann in bestimmten Netzwerkkonfigurationen oder mit bestimmten Firewalls Probleme bei der Kompatibilität aufweisen, was die Nutzung erschweren kann.

## Quellen

> Funktionsweise von IPsec VPNs. (2024, September 20). Retrieved from https://www.cloudflare.com/de-de/learning/network-layer/what-is-ipsec
> IPsec VPN und SSL VPN: Die wichtigsten Unterschiede auf einen Blick - Leipziger Zeitung. (2024, April 21). Retrieved from https://www.l-iz.de/vpn/ipsec-vpn-vs-ssl-vpn
> Was ist ein IPSec und wie genau funktioniert dieses? (2019, July 25). Retrieved from https://www.cactusvpn.com/de/der-leitfaden-fur-anfanger-zu-vpn/was-ist-ipsec


- **I**nternet **S**mall **C**omputer **S**ystem **I**nterface
- Zugriff auf zentral verfügbare Speicherressourcen
- Verbund von SCSI mit [[TCP-IP-Modell]]
- Zugriff auf [[Speicherlösungen|blockbasierte Speicherlösungen]] ohne teure [[Fibre Channel]] Infrastruktur
- setzt auf [[Client-Server|Client-Server-Modell]]

## Aktoren
- **iSCSI Node Names**, weltweit einmaliger Name für Target oder Node, meistens **IQN** *(iSCSI Qualified Name)*
- **iSCSI Initiator Nodes**, Clients
	- im Betriebssystem installierte Treiber
	- verschickten SCSI-Befehle eingepackt in [[TCP-IP-Modell|TCP/IP Paketen]]
- **iSCSI Target Nodes**, Server die Speicherplatz bereitstellen
	- wandeln iSCSI-Befehle in SCSI-Befehle um -> kann zu hoher Rechenlast führen
	- stellen ein oder mehrere LUs (*Logical Units*[^1]) bereit

## Funktionswiese
1. iSCSI-Iniator baut **Session** mit iSCSI-Target auf (normal operational session oder discovery session)
2. iSCSI-Iniator **verpackt** Befehle in PDUs[^2] und verschickt sie anschließend
3. iSCSI-Target **entpackt** Befehle und beantwortet Dienstanfrage

## Vor- und Nachteile
- **Vorteile**
	- Nutzung vorhandener Infrastruktur und Hardware
	- Administratoren mit [[Ethernet]]/[[TCP-IP-Modell|TCP-IP]] bereits vertraut
	- Flexibilität, durch [[TCP-IP-Modell|TCP/IP-Protokoll]] Routing über Netzwerksegmente hinweg
	- -> kostengünstiger Aufbau, einfache Wartung, hohe Flexibilität und Skalierbarkeit
- **Nachteile**
	- höhere Latenzzeit als über [[Fibre Channel]]
	- Performance Einbuße durch [[TCP-IP-Modell|TCP/IP]] Overhead
	- [[Netzwerkkonzepte|LAN]]-Performance beeinträchtigt Speicherzugriff


[^1:] dezidierte Festplatten-Adressierung
[^2:] Protocol Data Units

## Quellen

> Billo, T. (2021). Was ist iSCSI? Storage-Insider. Retrieved from https://www.storage-insider.de/was-ist-iscsi-a-679345

- auch **Fischgrätendiagramm**
- findet heraus welche **Ursachen** zum **Problem beitragen**
- man untersucht **7 Bereiche** (*die 7 M's*)

## Bereiche

### 1. Menschen
- Ausbildungsstand und Qualifikationen
- Teamzusammensetzung und -dynamik
- Kommunikationsfähigkeiten
- Stressresistenz und Belastbarkeit
- Kreativität und Problemlösungsfähigkeiten
- Gesundheitszustand und Work-Life-Balance
- Kulturelle Diversität im Team
### 2. Maschinen
- Alter und Zustand der Produktionsanlagen
- Wartungsintervalle und -qualität
- Technologiestand der eingesetzten Software
- Ergonomie der Arbeitsplätze
- Verfügbarkeit von Ersatzteilen
- Automatisierungsgrad der Prozesse
- IT-Infrastruktur und Netzwerkstabilität
### 3. Material
- Qualität der Rohstoffe
- Lagerungsbedingungen
- Lieferantenbeziehungen und -zuverlässigkeit
- Materialeigenschaften und Verarbeitbarkeit
- Verfügbarkeit und Lieferzeiten
- Kostenentwicklung der Materialien
- Nachhaltigkeit und Umweltverträglichkeit
### 4. Methoden
- Standardisierung von Prozessen
- Lean-Management-Ansätze
- Qualitätsmanagementsysteme
- Projektmanagement-Methodiken
- Informationsfluss und Dokumentation
- Entscheidungsfindungsprozesse
- Innovationsmanagement und Ideenfindung
### 5. Mitwelt / Milieu
- Gesetzliche Rahmenbedingungen und Regulierungen
- Wettbewerbssituation in der Branche
- Technologische Trends und Innovationen
- Gesellschaftliche Wertvorstellungen und Erwartungen
- Wirtschaftliche Faktoren wie Inflation oder Wechselkurse
- Politische Stabilität und internationale Beziehungen
- Klimawandel und Umweltschutzauflagen
### 6. Messung
- Genauigkeit und Kalibrierung von Messinstrumenten
- Statistische Methoden zur Datenanalyse
- Frequenz und Zeitpunkt der Datenerhebung
- Repräsentativität der Stichproben
- Validität und Reliabilität der Messmethoden
- Dateninterpretation und Berichterstattung
- Automatisierte vs. manuelle Datenerfassung
### 7. Management
- Strategische Ausrichtung und Zielsetzung
- Ressourcenallokation und Budgetierung
- Personalentwicklung und Talentmanagement
- Risikomanagement und Compliance
- Change-Management-Fähigkeiten
- Kommunikationsstrategie und Transparenz
- Ethische Grundsätze und Unternehmenskultur

## Auswertung
- welche **Ursache** hat **größten Einfluss** zum Problem

![[Pasted image 20240913095535.png]]

![[Pasted image 20240913095645.png]]


## Ziele des Ishikawa-Diagramms
1. **Ursachenidentifikation**: Systematische Analyse der Ursachen eines Problems, um die Wurzel des Problems zu finden.
2. **Verbesserung der Problemlösungsfähigkeiten**: Förderung eines strukturierten Ansatzes zur Problemlösung innerhalb des Teams oder Unternehmens.
3. **Teamarbeit und Kommunikation**: Verbesserung der Zusammenarbeit und Kommunikation zwischen verschiedenen Abteilungen, indem alle relevanten Perspektiven einbezogen werden.
4. **Prävention von Problemen**: Identifikation potenzieller Probleme im Voraus, um präventive Maßnahmen zu ergreifen und zukünftige Fehler zu vermeiden.
5. **Dokumentation und Nachverfolgbarkeit**: Bereitstellung einer klaren Dokumentation der Ursachenanalyse, die für zukünftige Referenzen und Schulungen genutzt werden kann.


## Quellen

> ZumFachwirt. (2017, February 06). Ishikawa Diagramm Erklärung & Beispiel (Unternehmensführung Fachwirt IHK) -Fischgrätendiagramm. Youtube. Retrieved from https://www.youtube.com/watch?v=3_LM2uK8AU0
> Ishikawa-Diagramm: Ursachenanalyse und Problemlösung. (2023, January 20). Retrieved from https://blog.hubspot.de/sales/ishikawa-diagramm

- **systematischen Erfassung** und **Bewertung** des **aktuellen Zustands** eines **Unternehmens** oder eines **spezifischen Prozesses**, um **Schwachstellen und Optimierungspotenziale** zu identifizieren.
- Bestandteile je nach Schwerpunkt
	- **Aufgaben** des Untersuchungsbereichs **hinterfragen** und **bewerten**
	- bestehende Prozesse analysieren
	- Bearbeitungszeiten und Mengen aufbereiten
	- organisatorische Strukturen hinterfragen

## Methoden zur Datensammlung
- **Interviews** mit Mitarbeitern und Führungskräften
- **Umfragen** zur Erfassung von Meinungen und Erfahrungen (z.B. Fragebogen)
- **Beobachtung** von Arbeitsabläufen
- **Dokumentenanalyse** bestehender Unterlagen und Berichte
- **Prozessuale Analyse**, dokumentation aller Tätigkeitsschritten

### Stakeholder
- **Mitarbeiter** verschiedener Ebenen
- **Führungskräfte**
- **Externe Berater** oder Experten
- Relevante **Abteilungen** (z.B. HR, IT, Produktion, ...)
### Analysemethoden
- **Aufgabenkritik** (Fokus auf Aufgaben)
	- [[ABC-Analyse]]
	- [[SWOT-Analyse]]
	- [[Portfolioanalyse]]
- **Prozessoptimierung** (Fokus auf Prozessen)
	- [[FMEA]]
	- [[Ishikawa-Diagramm]]
- **Personalbedarfsermittlung** (Fokus Aufgaben mit Bearbeitungszeiten und Mengen)
	- [[SWOT-Analyse]]

## Checkliste möglicher Schwachstellen
- **Aufgaben**
	- überflüssige Aufgaben
	- zu einfache/komplexe Aufgaben
	- unklare Aufgabenstellungen
	- Ort und Zeit der Aufgabenerfüllung ungeeignet
	- fehlende Aufgabenpriorisierung
- **Beschäftigten**
	- unzureichend qualifizierte oder überqualifizierte Beschäftigte
	- zu wenig/viel Personal
	- mangelnde Führungskompetenzen
	- einseitige Abhängigkeiten
- **Sachmittel und Arbeitsumfeld**
	- ungeeigneter Standort/lange Wege
	- nicht kompatibel/normengerecht
	- hohe Störanfälligkeit
	- hohe Entwicklungs- und Wartungskosten
- **Informationen**
	- falscher Informationszeitpunkt
	- zu viele Informationen
	- unvollständige Informationen
	- schlecht oder uneinheitlich aufbereitete Informationen
- **Prozesse**
	- zu viele Rückkopllungen
	- zu viele/wenige Verzweigungen
	- fehlender [[Kontinuierlicher Verbesserungsprozess]]
	- fehlende Qualitätssicherung
- **Funktionen (Stellen, Kompetenzen)**
	- zu zentrale/dezentrale Strukturen
	- fehlende Aufstiegsmöglichkeiten/Anreize
	- umständliche Kommunikationswege
	- zu starke Spezialisierung
	- überflüssige Stabsstellen

## Quellen

> Bundesministerium des Innern und für Heimat. (2024, September 19). Retrieved from https://www.orghandbuch.de/Webs/OHB/DE/Organisationshandbuch/2_Vorgehensmodell/23_Hauptuntersuchung/232_IstAnalyse/istanalyse-node.html
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Ganzheitlicher Ansatz zur Informationssicherheit
- Berücksichtigt technische, infrastrukturelle, organisatorische und personelle Aspekte
- Bietet verschiedene Vorgehensweisen: Basis-, Standard- und Kern-Absicherung

## Komponenten
1. **BSI-Standards**: Beschreiben die Methodik (z.B. BSI-Standard 200-2)
2. **IT-Grundschutz-Kompendium**: Enthält Bausteine mit Sicherheitsanforderungen und Maßnahmen
3. **Umsetzungshinweise**: Praktische Hilfestellungen zur Implementierung

## Prozess des ITSM
1. **Initiierung des Sicherheitsprozesses**
   - Management-Entscheidung und Verantwortung der Leitungsebene
   - Ernennung eines Informationssicherheitsbeauftragten (ISB)
   - Definition des Geltungsbereichs (Informationsverbund)
   - Erstellung einer Leitlinie zur Informationssicherheit
2. **Organisation des Sicherheitsprozesses**
   - Aufbau einer Organisation zur Informationssicherheit
   - Konzeption und Planung des Sicherheitsprozesses
3. **Durchführung des Sicherheitsprozesses**
   - Modellierung nach IT-Grundschutz
   - IT-Grundschutz-Check
   - Umsetzung der Sicherheitskonzeption

## Vorgehensweisen
- **Basis-Absicherung**: Schneller Einstieg, grundlegende Erst-Absicherung
- **Standard-Absicherung**: Umfassende Sicherheit für normale Schutzbedarfe
- **Kern-Absicherung**: Fokus auf kritische Geschäftsprozesse und Ressourcen

## Vorteile
- Systematischer Ansatz zur Identifikation und Behandlung von Sicherheitsrisiken
- Praxiserprobte Methodik, in Verwaltung und Wirtschaft bewährt
- Skalierbar für Institutionen unterschiedlicher Größe und Komplexität

## [[Kontinuierlicher Verbesserungsprozess]]
- Regelmäßige Überprüfung und Aktualisierung des Sicherheitskonzepts
- Anpassung an veränderte Anforderungen und neue Bedrohungen
- Möglichkeit zur Steigerung des Sicherheitsniveaus über die Zeit


- Geschäftsphilosophie, **stetige Veränderung** und **Verbesserung** -> [[Kontinuierlicher Verbesserungsprozess|KVP]]
- hilft bei **Effizienzsteigerung**

## Zentrale Prinzipien
1. **Standardisierung**, bei langfristiger Verbesserung dauerhafte Einbindung ([[SDCA]])
2. **Kritikorientierung**, Kritik erwünscht, ([[PDCA]])
3. **Qualitätsorientierung**, Qualitätsstandards werden regelmäßig kontrolliert
4. **Kundenorientierung**, Bedürfnisse & Wünsche sollen erfüllt werden
5. **Prozessorientierung**, verbesserter Prozess führt zu verbessertes Ergebnis
*=> Produkte, Qualität und Prozesse verbessern*

- Mitarbeiter sollen nicht nur ihre Arbeit machen sondern drüber nachdenken, wie sie ihre Arbeit verbessern können

## Vorteile
- **Steigerung der Effizienz**: Durch kontinuierliche Verbesserungen können Prozesse optimiert und Ressourcen besser genutzt werden.
- **Mitarbeiterengagement**: Die Einbeziehung der Mitarbeiter in den Verbesserungsprozess fördert deren Motivation und Zufriedenheit.
- **Flexibilität**: Unternehmen können sich schneller an Veränderungen im Markt oder in der Technologie anpassen.
- **Qualitätssteigerung**: Regelmäßige Überprüfungen und Anpassungen führen zu einer höheren Produkt- und Dienstleistungsqualität.
- **Kundenbindung**: Durch die Fokussierung auf Kundenbedürfnisse können Unternehmen ihre Kunden besser bedienen und langfristige Beziehungen aufbauen.

## Nachteile
- **Zeitaufwand**: Die Implementierung von kontinuierlichen Verbesserungsprozessen kann zeitintensiv sein und kurzfristig Ressourcen binden.
- **Widerstand gegen Veränderungen**: Mitarbeiter könnten sich gegen ständige Veränderungen sträuben, was die Umsetzung erschweren kann.
- **Überfrachtung mit Prozessen**: Zu viele Verbesserungsinitiativen können zu Verwirrung und Ineffizienz führen, wenn sie nicht gut koordiniert sind.
- **Mangelnde kurzfristige Ergebnisse**: Die Vorteile von Kaizen sind oft langfristig, was in schnelllebigen Märkten als Nachteil empfunden werden kann.
- **Abhängigkeit von Mitarbeiterengagement**: Der Erfolg von Kaizen hängt stark von der aktiven Teilnahme und dem Engagement der Mitarbeiter ab.

## Quellen

> Kaizen. (2022, June 03). Retrieved from https://studyflix.de/jobs/karriere-tipps/kaizen-4933

- Skalenniveau mit **höchstem** Informationsgehalt
- **Reihenfolgen** und **quantifizierbare Abstände** können interpretiert werden (Temperatur, Gewicht, ...)

## Quellen

> Kardinalskala. (2019, June 28). Retrieved from https://studyflix.de/statistik/kardinalskala-1363


| **Aspekt**              | **Künstliche Intelligenz (KI)**                                              | **Maschinelles Lernen (ML)**                                                  | **Deep Learning (DL)**                                                             |
| ----------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| **Definition**          | KI ist der Überbegriff für Systeme, die menschenähnliche Intelligenz zeigen. | ML ist ein Teilbereich der KI, der Algorithmen nutzt, um aus Daten zu lernen. | DL ist ein Teilbereich des ML, der neuronale Netze mit vielen Schichten verwendet. |
| **Ziel**                | Entwicklung von Systemen, die Aufgaben intelligent ausführen können.         | Verbesserung der Leistung von Algorithmen durch Erfahrung.                    | Automatisierung der Merkmalsextraktion und -klassifikation.                        |
| **Techniken**           | Regelbasierte Systeme, Expertensysteme, ML, DL.                              | Überwachtes, unüberwachtes und bestärkendes Lernen.                           | Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs).            |
| **Datenabhängigkeit**   | Kann auch ohne große Datenmengen arbeiten (z.B. regelbasierte Systeme).      | Benötigt große Datenmengen, um Muster zu erkennen.                            | Benötigt sehr große Datenmengen für effektives Training.                           |
| **Anwendungsbeispiele** | Sprachassistenten, Robotik, Spiele.                                          | Empfehlungsalgorithmen, Betrugserkennung.                                     | Bild- und Spracherkennung, autonome Fahrzeuge.                                     |
| **Komplexität**         | Kann einfach oder komplex sein, je nach Anwendung.                           | Mittlere Komplexität, abhängig von den Algorithmen.                           | Hohe Komplexität, erfordert oft spezialisierte Hardware (z.B. GPUs).               |
| **Interpretierbarkeit** | Oft schwer zu interpretieren, besonders bei komplexen Systemen.              | Teilweise interpretierbar, je nach Algorithmus.                               | Oft als "Black Box" betrachtet, schwer zu interpretieren.                          |

### Fazit
- **KI** ist der umfassende Begriff, der alle Technologien umfasst, die darauf abzielen, menschenähnliche Intelligenz zu simulieren.
- **ML** ist ein spezifischer Ansatz innerhalb der KI, der sich auf das Lernen aus Daten konzentriert.
- **DL** ist eine spezialisierte Form des ML, die auf tiefen neuronalen Netzen basiert und besonders leistungsfähig bei der Verarbeitung unstrukturierter Daten ist.


- KI bezeichnet die **Simulation menschlicher Intelligenz** durch Maschinen, besonders Computersysteme. Sie umfasst **Algorithmen und Modelle**, die in der Lage sind, **Daten zu analysieren, Muster zu erkennen und Entscheidungen zu treffen**.

## Teilgebiete der KI  
- **[[Maschinelles Lernen|Maschinelles Lernen (ML)]]:** KI-Teilbereich, in dem Systeme aus Daten lernen, ohne explizit programmiert zu werden. Wichtige ML-Methoden:
  - **[[Überwachtes und nicht-überwachtes Lernen|Überwachtes Lernen]]:** Modell wird mit beschrifteten Daten trainiert (z.B. Klassifikation, Regression).
  - **[[Überwachtes und nicht-überwachtes Lernen|Unüberwachtes Lernen]]:** Modell erkennt Muster in unbeschrifteten Daten (z.B. Clustering, Dimensionalitätsreduktion).
  - **Bestärkendes Lernen:** Modell lernt durch Belohnung und Bestrafung.
  
- **Deep Learning (DL):** Subfeld des maschinellen Lernens, das neuronale Netze mit vielen Schichten verwendet, um komplexe Muster zu erkennen (z.B. Bilderkennung, Sprachverarbeitung).

- **Neuroevolution:** Optimiert neuronale Netze durch evolutionäre Algorithmen.

## [[Neural Network|Künstliche neuronale Netze (KNN)  ]]
- **Perzeptron:** Einfachste Form eines Neurons, das Input-Gewichte mit einer Aktivierungsfunktion kombiniert.
- **Mehrschichtige Neuronale Netze (MLP):** Bestehen aus Input-, Hidden- und Output-Schichten, verwenden Aktivierungsfunktionen (z.B. ReLU, Sigmoid).
- **Backpropagation:** Optimierungsalgorithmus, der Fehler rückwärts durch das Netzwerk propagiert, um Gewichte zu aktualisieren.

## [[Support Vector Machine|Support Vector Machines (SVM)  ]]
- Klassifikationsmodell, das eine **Hyperplane** erstellt, um Daten in verschiedene Klassen zu trennen.
- **Ziel:** Maximiere den Abstand (Margin) zwischen der Hyperplane und den nächsten Datenpunkten (Support Vectors).

## Anwendungsgebiete der KI  
- **Sprachverarbeitung (NLP):** z.B. Chatbots, Übersetzungsdienste.
- **Bild- und Spracherkennung:** z.B. Gesichtserkennung, Spracherkennung.
- **Empfehlungssysteme:** z.B. Produktvorschläge (Amazon, Netflix).
- **Autonome Systeme:** z.B. selbstfahrende Autos, Drohnen.

## Schritte zur Entwicklung eines KI-Modells  
1. **Daten sammeln:** Datenquellen identifizieren und Daten vorbereiten.
2. **Datenvorverarbeitung:** Bereinigung, Normalisierung, ggf. Reduktion.
3. **Feature-Engineering:** Auswahl relevanter Merkmale.
4. **Modelltraining:** Training eines Modells mit geeigneten Algorithmen.
5. **Evaluation:** Testen des Modells anhand eines separaten Datensatzes.
6. **Deployment:** Einsatz des Modells im produktiven Umfeld.

## Ethik und Herausforderungen der KI  
- **Bias (Verzerrung):** KI-Modelle können Vorurteile lernen, wenn die Trainingsdaten nicht repräsentativ sind.
- **Transparenz:** Black-Box-Modelle wie Deep Learning erschweren die Nachvollziehbarkeit von Entscheidungen.
- **Datenschutz:** Umgang mit personenbezogenen Daten erfordert strikte Einhaltung von Datenschutzrichtlinien (z.B. DSGVO).

## Relevante Begriffe  
- **Overfitting:** Modell passt zu stark an Trainingsdaten an, verallgemeinert schlecht auf neue Daten.
- **Underfitting:** Modell erfasst die zugrunde liegenden Muster nicht ausreichend.
- **Kreuzvalidierung:** Technik, um die Generalisierungsfähigkeit eines Modells zu testen.
- **Hyperparameteroptimierung:** Feintuning von Parametern (z.B. Lernrate, Batchgröße).

## Quellen
> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed3ccd-34d4-800b-a198-dee9a0d61710

- gehört zum [[Überwachtes und nicht-überwachtes Lernen|überwachten Lernen]]
- gesucht wird eine **Funktion**, die eine möglichst genaue **Trennlinie** zwischen den Datenpunkten beschreibt
- Ziel: Zuordnung von Datenpunkten zu **vordefinierten Kategorien** oder Klassen

## Zweck
- **Organisation:** Die Daten werden übersichtlich und suchbar.
- **Analyse:** Durch die Klassifizierung lassen sich Muster und Zusammenhänge erkennen.
- **Entscheidungsfindung:** Die Ergebnisse der Klassifikation können genutzt werden, um zukünftige Entscheidungen zu treffen, z.B. welche Werbemaßnahmen besonders effektiv sind.

## Arten der Klassifikation
1. **Binäre Klassifikation**: Zwei mögliche Klassen
2. **Multi-Class-Klassifikation**: Mehr als zwei mögliche Klassen
3. **Multi-Label-Klassifikation**: Ein Datenpunkt kann mehreren Klassen zugeordnet werden

## Wichtige Algorithmen
- [[Regression#**Logistische** Regression|Logistische Regression]]: Möglichkeit einer *dichotomen/binären Klassifikation*
- [[Entscheidungsbaum|Entscheidungsbäume]]
- [[Random Forest]]
- [[Support Vector Machine|Support Vector Machines (SVM)]]
- [[K-Nearest Neighbor|K-Nearest Neighbors (KNN)]]
- [[Neural Network|Neuronale Netze]]

## Vorgehen
1. Datensammlung und -aufbereitung
2. Auswahl relevanter Features
3. Aufteilung in Trainings- und Testdaten
4. Modellauswahl und -training
5. Evaluation und Optimierung
6. Anwendung auf neue, ungesehene Daten

## Evaluationsmetriken
### Fachbuch
- **Accuracy**: Anteil korrekt klassifizierter Instanzen
- **Precision**: Anteil der korrekt als positiv klassifizierten Instanzen an allen als positiv klassifizierten ($Precision=\dfrac{True Positives}{False Positives + True Positives}​$)
- **Recall**: Anteil der korrekt als positiv klassifizierten Instanzen an allen tatsächlich positiven ($Recall = \dfrac{True Positives}{True Positives + False Negatives}$)
- **F1-Score**: Harmonisches Mittel (ausgewogenes Verhältnis) aus Precision und Recall
- **ROC-Kurve** und **AUC**: Visualisierung und Quantifizierung der Modellperformance
- **Confusion Matrix**, tabellarische Darstellung der tatsächlichen und vorhergesagten Klassifikationen eines Modells

### IHK
- Genauigkeit (= $\dfrac{\text{Korrekte} \space \text{Vorhersagen}}{\text{Gesamtzahl} \space \text{der} \space \text{Daten}}$)
- Kompaktheit
- Effizienz (gemessen an Trainingszeit und Vorhersagedauer)
- Skalierbarkeit für größere Datenmengen
- Robustheit
- ...

## Herausforderungen
- **Overfitting**: Modell lernt Trainingsdaten zu genau und generalisiert schlecht
- **Underfitting**: Modell ist zu einfach und erfasst wichtige Muster nicht
- **Imbalancierte Daten**: Ungleiche Verteilung der Klassen im Datensatz
- Fehlende oder verrauschte Daten

## Anwendungsgebiete
- Spam-Erkennung in E-Mails
- Medizinische Diagnose
- Bilderkennung
- Spracherkennung
- Kreditwürdigkeitsprüfung

## Vor- und Nachteile
- **Vorteile**:
	- Ermöglicht automatisierte Entscheidungsfindung
	- Kann mit großen Datenmengen umgehen
	- Vielseitig einsetzbar in verschiedenen Domänen
- **Nachteile**:
	- Benötigt oft große Mengen gelabelter Daten
	- Kann bei komplexen Problemen rechenintensiv sein
	- Ergebnisse können durch Bias in den Trainingsdaten beeinflusst werden




- Der K-Nearest Neighbors (KNN) Algorithmus ist einer der **beliebtesten** und **einfachsten** Klassifikatoren im Bereich des maschinellen Lernens.
- Es handelt sich um einen **überwachten** Lernklassifikator, der die **Klassifikation** eines **einzelnen Datenpunktes** auf Basis der *(einfachen)* **Mehrheitswahl** vornimmt.

## Funktionsweise
- KNN ist ein **Lazy Learning Modell** *(träges Lernen)*[^1], das nur **einen** Trainingsdatensatz speichert, anstatt eine Trainingsphase zu durchlaufen.
- Es handelt sich um ein inst**anz-/speicherbasiertes Lernverfahren**, was zu einer starken Belastung des Arbeitsspeichers führt.
- Mit **zunehmendem Datensatz** wird der Algorithmus **zunehmend ineffizient**, was die Gesamtleistung des Modells beeinträchtigt.
- Trotz dieser Nachteile wird KNN häufig angewendet, da es **einfach zu implementieren** ist und eine **hohe Genauigkeit** bietet.

### Klassifikationsprozess
- Der Algorithmus findet die **k nächsten Nachbarn** *(Datenpunkte)* und kalkuliert das **Label** (Klassifikation) oder den vorhergesagten Wert (Regression) basierend auf der **$p=2$-Mehrheit** der Zuordnung der nahen Datenpunkte.

## Anwendungsbeispiele
- Einfache Empfehlungssysteme
- Mustererkennung
- Data Mining
- Finanzmarktprognosen
- Erkennung von Eindringlingen

## Abstandsmetriken
Die **nächsten** Datenpunkte werden durch verschiedene Abstandsalgorithmen bestimmt:

1. **Euklidischer Abstand** $(p=2)$
   - Häufigste verwendete Abstandsmetrik für reellwertige Vektoren.
   - Berechnung: 
     $$d(x,y)=\sqrt{\sum^{n}_{i=1}(y_i-x_i)^2}$$

2. **Manhattan-Abstand** $(p=1)$
   - Auch als Taxi-Distanz oder Stadtblock-Distanz bekannt.
   - Berechnung: 
     $$d(x,y)=(\sum^{m}_{i=1}|x_i-y_i|)$$

3. **Minkowski-Abstand**
   - Verallgemeinerte Form des euklidischen und Manhattan-Abstands.
   - Berechnung: 
     $$d(x,y)=(\sum^{n}_{i=1}|x_i-y_i|)^{1/p}$$

4. **Hamming-Abstand**
   - Typischerweise bei booleschen oder String-Vektoren verwendet.
   - Überlappungsmetrik zur Identifizierung von Punkten, an denen Vektoren nicht übereinstimmen.
   - Berechnung: 
     $$D_H=(\sum^{k}_{i=1}|x_i-y_i|)$$
   - Eigenschaften:
     - $x=y \Rightarrow D=0$
     - $x \neq y \Rightarrow D \neq 1$
   - Beispiel:
     - Hamming-Abstand 2, nur zwei Werte unterscheiden sich.

## Variabilität und Verzerrung
- Kleine k-Werte führen zu **hoher Varianz** und geringer Verzerrung.
- Große k-Werte führen zu **geringer Varianz** und hoher Verzerrung.

## Vorteile
- Einfache **Anwendung**.
- Einfache **Anpassung**, da alle Trainingsdaten im Arbeitsspeicher gehalten werden.
- Wenige **Hyperparameter**, lediglich k und die Abstandsmetrik.

## Nachteile
- Schlechte **Skalierung**, da KNN ein träger Algorithmus ist.
- Bei zu vielen Dimensionen steigen die Klassifizierungsfehler.
- Überanpassung durch zu niedrige k-Werte, Unteranpassung durch zu hohe k-Werte.

## Best Practices
- Verwenden Sie einen ungeraden **k-Wert**, um **Unentschieden** zu vermeiden.

[^1]: Trainingsdaten werden in den Algorithmus geladen; erst bei Vorhersagen werden die Trainingsdaten ausgewertet.

## Quellen

> Technology, I. (2024, September 02). What is the K-Nearest Neighbor (KNN) Algorithm? Youtube. Retrieved from https://www.youtube.com/watch?v=b6uHw7QW_n4  
> Was ist der „k-nearest neighbors algorithm"? | IBM. (2024, September 11). Retrieved from https://www.ibm.com/de-de/topics/knn  
> https://sebastianraschka.com/pdf/lecture-notes/stat479fs18/02_knn_notes.pdf  


- Methode zur **Entwicklung** und **Umsetzung** von **ständiger Verbesserung** in **kleinen Schritten**
- zieht Mitarbeiter ein die **direkt Leistung erbringen**

- Grundmodell: [[PDCA]]

## Quellen

> Ideenmanagement, H.-D. S. (2024, January 23). KVP Kontinuierlicher Verbesserungsprozess in 9 Minuten einfach erklärt. Youtube. Retrieved from https://www.youtube.com/watch?v=Yn2NBFLW0Co

- misst die **Stärke** einer **statistischen Beziehung** zwischen zwei Variablen
- **positive** Korrelation
	- je *mehr* Variable A... desto *mehr* Variable B
- **negative** Korrelation
	- je *mehr* Variable A... desto *weniger* Variable B
- **Korrelationskoeffizient** drückt die Stärke des statischen Zusammenhangs aus, liegt zwischen *-1* und *+1*
	- $x \geq 1$ positiver Zusammenhang
	- $x = 0$ kein Zusammenhang
	- $x \leq 0$ negativer Zusammenhang
- **Formel**: $r_{xy} = \dfrac{s_{xy}}{s_x \times s_y}$

In jedem Projekt ist eine **präzise Kostenplanung** entscheidend für den Erfolg. Die Kostenarten helfen dabei, die **verschiedenen Ausgaben zu kategorisieren und zu analysieren**. Zu den wichtigsten Kostenarten gehören Softwarekosten, Hardwarekosten, Personalkosten, Kommunikationskosten und Qualifizierungskosten.

## Kostenarten im Detail

### Softwarekosten
- **Definition**: Kosten, die für den Erwerb, die Entwicklung und die Wartung von Software anfallen.
- **Beispiele**:
  - Lizenzgebühren für Softwareprodukte (z.B. Betriebssysteme, Anwendungssoftware)
  - Kosten für die Entwicklung individueller Softwarelösungen
  - Wartungs- und Supportkosten
  - Kosten für Software-Updates und -Upgrades

### Hardwarekosten
- **Definition**: Ausgaben für physische Geräte und Infrastruktur, die für das Projekt benötigt werden.
- **Beispiele**:
  - Anschaffungskosten für Computer, Server und Netzwerkausrüstung
  - Kosten für Peripheriegeräte (Drucker, Scanner, etc.)
  - Installations- und Einrichtungskosten
  - Wartungs- und Reparaturkosten für Hardware

### Personalkosten
- **Definition**: Kosten, die für die Beschäftigung von Mitarbeitern im Rahmen des Projekts anfallen.
- **Beispiele**:
  - Gehälter und Löhne der Projektmitarbeiter
  - Sozialabgaben und Versicherungen
  - Kosten für externe Berater oder Dienstleister
  - Schulungs- und Weiterbildungskosten für Mitarbeiter

### Kommunikationskosten
- **Definition**: Ausgaben, die für die interne und externe Kommunikation im Projekt erforderlich sind.
- **Beispiele**:
  - Telefon- und Internetkosten
  - Kosten für Videokonferenzen und Webinare
  - Reisekosten für Meetings und Konferenzen
  - Kosten für Kommunikationsmittel (z.B. E-Mail-Tools, Projektmanagement-Software)

### Qualifizierungskosten
- **Definition**: Kosten, die für die Weiterbildung und Qualifizierung der Mitarbeiter im Projekt anfallen.
- **Beispiele**:
  - Kosten für Schulungen und Workshops
  - Teilnahmegebühren für Konferenzen und Seminare
  - Kosten für Zertifizierungen und Prüfungen
  - Materialien und Ressourcen für die Weiterbildung



Die **Kosten-Nutzen-Analyse** (KNA) ist ein **Verfahren zur Bewertung der Wirtschaftlichkeit von Projekten**. Sie untersucht, ob sich eine Investition lohnt, indem sie die Kosten den erwarteten Nutzen gegenüberstellt.

## Ziel
Das Ziel der KNA ist es, die Rentabilität von Maßnahmen zu prüfen und verschiedene Projekte miteinander zu vergleichen, um Ressourcen optimal zu verteilen.

## Schritte der Kosten-Nutzen-Analyse

### 1. Problemdefinition
- Klare Formulierung des Projekts oder der Maßnahme.

### 2. Identifikation von Kosten und Nutzen
- **Kosten**: Alle finanziellen Aufwendungen (z.B. Investitionen, Betriebskosten).
- **Nutzen**: Monetär bewertbare Vorteile sowie nicht-monetäre Faktoren wie Kundenzufriedenheit und Qualitätssteigerung.

### 3. Quantifizierung
- Schätzung der Kosten und Nutzen in monetären Einheiten.
- Berücksichtigung sowohl direkter als auch indirekter Effekte.

### 4. Diskontierung
- Zukünftige Kosten und Nutzen auf den heutigen Wert umrechnen, um den Barwert zu ermitteln.

### 5. Vergleich
- Gegenüberstellung von Gesamtkosten und Gesamtnutzen.
- Berechnung des Kosten-Nutzen-Verhältnisses (K/N).

## Entscheidungsfindung
- **K/N > 1**: Nutzen übersteigt die Kosten – wirtschaftlich sinnvoll.
- **K/N < 1**: Kosten übersteigen den Nutzen – nicht empfehlenswert.
- **K/N = 1**: Kosten und Nutzen sind gleich – Neutralität.

## Anwendungsbereiche
Die KNA kann in verschiedenen Bereichen angewendet werden, z.B.:
- Neuinstallation oder Ersatz von EDV-Systemen
- Umorganisation betrieblicher Strukturen
- Marketingmaßnahmen und Budgetplanung
- Einführung neuer Vergütungssysteme
- Aus- und Weiterbildungsmaßnahmen für Mitarbeiter

## Nicht-monetäre Nutzenfaktoren
Berücksichtige auch nicht-monetäre Faktoren wie:
- Verbesserung der Kundenzufriedenheit
- Steigerung der Motivation der Mitarbeiter
- Optimierung der Lieferbereitschaft

## Beispiel zur Anwendung
### Weiterbildung von Mitarbeitern
1. **Aufwand (Kosten)**:
   - Lehrgangsgebühren: 10.000 €
   - Hotelkosten: 1.250 €
   - Reisekosten: 500 €
   - Ausfallzeiten: 1.750 €
   - **Gesamtaufwand**: 13.500 €

2. **Nutzen (Ergebnis)**:
   - Verbesserung der Arbeitsabläufe: 9.000 €
   - Abbau von Überstunden: 2.250 €
   - Reduzierung der Fehlerquote: 1.250 €
   - **Gesamtnutzen**: 12.500 €

3. **Ergebnis**: Gesamtaufwand (13.500 €) > Gesamtnutzen (12.500 €) – die Weiterbildung lohnt sich nicht in diesem Jahr.

## Checkliste für die KNA
Vor Durchführung einer KNA sollten folgende Punkte beachtet werden:
- Bestimmung eines konkreten Ziels.
- Festlegung der Gewichtung des Nutzens.
- Benennung einer neutralen Person für die Durchführung.
- Festlegung von Entscheidungsträgern.
- Auswahl relevanter Merkmale für die Analyse.
- Sicherstellung der Verfügbarkeit von Daten zur Schätzung des Nutzens.
  
## Fazit
Die KNA ist ein essentielles Werkzeug zur Bewertung von Projekten und hilft dabei, fundierte Entscheidungen zu treffen, um wirtschaftliche Effizienz zu gewährleisten.

Citations:
[1] https://studyflix.de/wirtschaft/kosten-nutzen-analyse-4893

KPI (Key Performance Indicators) sind **messbare Werte**, die verwendet werden, um den **Erfolg eines Unternehmens oder eines bestimmten Prozesses** zu bewerten. Im Kontext der Qualitätslenkung dienen KPIs dazu, die Qualität von Produkten und Dienstleistungen zu überwachen und sicherzustellen, dass sie den festgelegten Standards und Anforderungen entsprechen.

## Wichtige Aspekte von KPIs in der Qualitätslenkung
- **Messbarkeit**: KPIs müssen quantifizierbar sein, um eine objektive Bewertung der Qualität zu ermöglichen.
- **Relevanz**: Die gewählten KPIs sollten direkt mit den Zielen der Qualitätslenkung und den spezifischen Anforderungen des Unternehmens verknüpft sein.
- **Aktualität**: KPIs sollten regelmäßig aktualisiert werden, um aktuelle Informationen über die Qualität zu liefern und rechtzeitige Entscheidungen zu ermöglichen.

## Beispiele für KPIs in der Qualitätslenkung
- **Fehlerquote**: Der Prozentsatz der fehlerhaften Produkte oder Dienstleistungen im Verhältnis zur Gesamtproduktion. Eine niedrige Fehlerquote deutet auf eine hohe Qualität hin.
- **Kundenzufriedenheit**: Messungen, die auf Umfragen oder Feedback basieren, um zu bewerten, wie zufrieden Kunden mit den Produkten oder Dienstleistungen sind.
- **Reklamationsrate**: Der Anteil der Kundenreklamationen im Verhältnis zur Gesamtzahl der verkauften Produkte oder Dienstleistungen. Eine hohe Reklamationsrate kann auf Qualitätsprobleme hinweisen.
- **Durchlaufzeit**: Die Zeit, die benötigt wird, um einen Prozess von Anfang bis Ende abzuschließen. Eine kürzere Durchlaufzeit kann auf eine effizientere und qualitativ hochwertigere Produktion hinweisen.
- **Einhaltung von Standards**: Der Prozentsatz der Produkte oder Dienstleistungen, die den festgelegten Qualitätsstandards entsprechen. Dies kann durch Audits oder Inspektionen gemessen werden.

## Vorteile der Verwendung von KPIs in der Qualitätslenkung
- **Frühzeitige Problemerkennung**: Durch die Überwachung von KPIs können potenzielle Qualitätsprobleme frühzeitig erkannt und behoben werden.
- **Datenbasierte Entscheidungen**: KPIs liefern objektive Daten, die als Grundlage für Entscheidungen zur Verbesserung der Qualität dienen.
- **Zielverfolgung**: KPIs helfen dabei, Fortschritte in Bezug auf Qualitätsziele zu verfolgen und sicherzustellen, dass die Qualitätsstrategie effektiv umgesetzt wird.

## Herausforderungen und Risiken
- **Falsche KPIs**: Die Auswahl ungeeigneter KPIs kann zu einer verzerrten Sicht auf die Qualität führen und falsche Entscheidungen nach sich ziehen.
- **Datenqualität**: Die Genauigkeit und Zuverlässigkeit der gesammelten Daten sind entscheidend für die Wirksamkeit von KPIs. Schlechte Daten können zu falschen Schlussfolgerungen führen.
- **Überfokussierung auf KPIs**: Eine zu starke Konzentration auf KPIs kann dazu führen, dass andere wichtige Aspekte der Qualität vernachlässigt werden.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Lagemaße sind **statistische Kennzahlen**, die das **Zentrum von Verteilungen** beschreiben. Sie helfen dabei, große Datenmengen zu einem **repräsentativen Wert** zusammenzufassen und **erleichtern die Interpretation** der Daten.

## Wichtige Lagemaße
- **[[Arithmetisches Mittel]]**: 
  - Das [[Arithmetisches Mittel|arithmetische Mittel]] ist der Durchschnittswert einer Datenreihe und wird berechnet, indem die Summe aller Werte durch die Anzahl der Werte geteilt wird.
- **[[Median]]**: 
  - Der [[Median]] ist der Wert, der die Daten in zwei gleich große Hälften teilt. Bei einer ungeraden Anzahl von Werten ist es der mittlere Wert, bei einer geraden Anzahl der Durchschnitt der beiden mittleren Werte.
- **[[Modalwert]] (Modus)**: 
  - Der [[Modalwert]] ist der Wert, der in einer Datenreihe am häufigsten vorkommt. Es kann mehrere [[Modalwert|Modalwerte]] geben, wenn mehrere Werte gleich häufig sind.

## Bedeutung der Lagemaße
Lagemaße sind wichtig, um:
- **Einfache Vergleiche** zwischen verschiedenen Datensätzen zu ermöglichen.
- Ein **besseres Verständnis** der Verteilung von Daten zu erhalten.
- **Ausreißer und deren Einfluss** auf die Datenanalyse zu identifizieren.

## Anwendung
Lagemaße finden Anwendung in verschiedenen Bereichen, wie z.B.:
- Wirtschaft (z.B. Durchschnittseinkommen)
- Sozialwissenschaften (z.B. Medianalter)
- Naturwissenschaften (z.B. häufigste Messwerte)

## Quellen

> Lagemaße: Definition & Berechnung | StudySmarter. (2024, September 16). Retrieved from https://www.studysmarter.de/schule/mathe/stochastik/lagemasse
> DuckDuckGo. (2024). *Chat mit KI-Modell zu Lagemaßen in der Statistik*. Abgerufen am 16. September 2024, von https://duck.ai

- **Verschlankung** aller innerbetrieblichen **Unternehmensprozesse**
- optimales Ergebnis erzielen, ohne Ressourcen zu verschwenden
- Realisierung **nachhaltiger Erfolge**

## Ziele
- **Ressourcenverschwendung** vermeiden
- **Fehlleistungen** ausschließen
- Effiziente Nutzung des **Kapitals**
- **Überproduktion** ausschließen
- bessere Kommunikation durch **flache Hierarchie**
![[Pasted image 20240920062029.png]]

## Leitlinien
- **Kundenorientierte** Produktion
	- betrieblichen Herstellungsprozess an die **Bedürfnisse** des **Konsumenten** orientieren (Zeit, Ort, Qualität)
- **Prozessidentifikation**
	- Durchleuchtung der gesamten Prozesse (Beschaffung Materialien bis zur Lieferung des Produkts) -> wo Kosteneinsparungen möglich? Wo zeitliche Optimierungen möglich?
- **Flussprinzip** beachten
	- Produktionsprozess im Fluss halten
	- **Engpässe** und **Überproduktion** vermeiden
	- flexible, auftragsbezogene Produktion erreichen
- **Pullprinzip** einführen
	- Produktionsleistung erst erbringen, **wenn Kunde** sie **anfordert**
- **Stillstand** vermeiden
	- Prozesse **ständig auf neusten Stand** halten
	- neue Technologien? neue Maschinen?

Hier ist eine kurze Übersicht über die Vor- und Nachteile von Lean Management:

## Vorteile

1. **Ressourcenschonung**: Lean Management zielt darauf ab, Verschwendung zu minimieren, was zu einer effizienteren Nutzung von Ressourcen führt.
2. **Kostenreduktion**: Durch die Eliminierung von Überproduktion und Fehlleistungen können Unternehmen ihre Kosten erheblich senken.
3. **Verbesserte Qualität**: Fokussierung auf die Bedürfnisse der Kunden führt zu einer höheren Produktqualität und Kundenzufriedenheit.
4. **Flexibilität**: Die Einführung des Pull-Prinzips ermöglicht eine anpassungsfähige Produktion, die auf die tatsächliche Nachfrage reagiert.
5. **Bessere Kommunikation**: Flache Hierarchien fördern die Kommunikation und Zusammenarbeit innerhalb des Unternehmens.
6. **Nachhaltige Erfolge**: Durch kontinuierliche Verbesserung und Prozessoptimierung werden langfristige Erfolge gesichert.

## Nachteile

1. **Implementierungsaufwand**: Die Einführung von Lean Management erfordert Zeit, Schulung und möglicherweise eine grundlegende Umstrukturierung der Prozesse.
2. **Widerstand der Mitarbeiter**: Veränderungen können auf Widerstand stoßen, insbesondere wenn Mitarbeiter an bestehenden Prozessen festhalten möchten.
3. **Risiko der Überoptimierung**: Zu starke Fokussierung auf Effizienz kann zu einer Vernachlässigung anderer wichtiger Aspekte wie Innovation oder Mitarbeiterzufriedenheit führen.
4. **Abhängigkeit von Lieferanten**: Das Pull-Prinzip kann die Abhängigkeit von Lieferanten erhöhen, was bei Lieferengpässen problematisch sein kann.
5. **Mangelnde Flexibilität bei plötzlichen Änderungen**: In dynamischen Märkten kann es schwierig sein, sich schnell an Veränderungen anzupassen, wenn die Prozesse zu stark standardisiert sind.

## Quellen 

> ▷ Lean Management » Definition, Erklärung & Beispiele + Übungsfragen. (2022, May 10). Retrieved from https://www.bwl-lexikon.de/wiki/lean-management



- **kontinuierlichen, selbstgesteuerten Prozess des Lernens**, der über die formale Schul- und Hochschulausbildung hinausgeht. Es umfasst alle Lernaktivitäten, die Individuen in ihrem Leben durchführen, um Wissen, Fähigkeiten und Kompetenzen zu erwerben oder zu erweitern.
- **Ziel**: **Anpassung an sich verändernde Anforderungen** in Beruf und Gesellschaft, persönliche Entwicklung und Förderung der Selbstständigkeit.

### Bedeutung des lebenslangen Lernens
- **Berufliche Entwicklung**: In einer sich schnell verändernden Arbeitswelt ist kontinuierliches Lernen entscheidend, um mit neuen Technologien und Methoden Schritt zu halten.
- **Persönliche Entfaltung**: Lebenslanges Lernen fördert die persönliche Entwicklung, Kreativität und Selbstbewusstsein.
- **Gesellschaftliche Teilhabe**: Bildung und Wissen sind Schlüssel zur aktiven Teilnahme an gesellschaftlichen und politischen Prozessen.

### Formen des lebenslangen Lernens
- **Formales Lernen**: Strukturierte Lernprozesse in Bildungseinrichtungen (z.B. Schulen, Universitäten, Weiterbildungseinrichtungen).
- **Informelles Lernen**: Ungeplantes und unstrukturiertes Lernen im Alltag (z.B. durch Hobbys, Reisen, soziale Interaktionen).
- **Non-formales Lernen**: Geplante Lernaktivitäten außerhalb des formalen Bildungssystems (z.B. Workshops, Seminare, Online-Kurse).

### Methoden und Ansätze
- **E-Learning**: Nutzung digitaler Medien und Online-Plattformen für das Lernen (z.B. MOOCs, Webinare).
- **Peer-Learning**: Lernen in Gruppen oder durch den Austausch mit Gleichgesinnten.
- **Mentoring und Coaching**: Unterstützung durch erfahrene Personen, die Wissen und Erfahrungen weitergeben.
- **Selbstgesteuertes Lernen**: Individuelle Planung und Durchführung von Lernprozessen, basierend auf persönlichen Interessen und Zielen.

### Herausforderungen des lebenslangen Lernens
- **Motivation**: Die eigene Motivation aufrechtzuerhalten, um kontinuierlich zu lernen.
- **Zugang zu Ressourcen**: Verfügbarkeit von Lernmaterialien und -möglichkeiten, insbesondere in ländlichen oder benachteiligten Regionen.
- **Zeitmanagement**: Die Balance zwischen beruflichen, familiären und persönlichen Verpflichtungen zu finden, um Zeit für das Lernen zu schaffen.

### Wichtige Begriffe
- **E-Learning**: Elektronisches Lernen über digitale Plattformen.
- **MOOC (Massive Open Online Course)**: Online-Kurse, die für eine große Anzahl von Teilnehmern zugänglich sind.
- **Selbstgesteuertes Lernen**: Individuelles Lernen, das von den Lernenden selbst organisiert wird.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Messinstrument in der empirischen Sozialforschung
- Dient zur Messung von Einstellungen und Meinungen
## Kernmerkmale
- Meist 5-7 Antwortmöglichkeiten
- Symmetrisch um einen neutralen Mittelpunkt
- Reicht von starker Ablehnung bis zu starker Zustimmung

## Vorteile
- Einfach zu verstehen und anzuwenden
- Ermöglicht differenzierte Antworten
- Gut für statistische Auswertungen geeignet

## Nachteile
- Mögliche Tendenz zur Mitte
- Subjektive Interpretation der Abstände zwischen den Stufen
- Anfälligkeit für Antwortverzerrungen

## Anwendungsbereiche
- Umfragen und Fragebögen
- Marktforschung
- Psychologische Untersuchungen
- Kundenzufriedenheitsmessungen

## Beispiel
![[Pasted image 20240928182249.png]]


#### Funktion: 
$f(x) = mx-b$
$y = 2x - 3$

#### Parameter:

1. **Steigung (m = 2)**
   - **Bedeutung**: Die Steigung gibt an, wie stark sich der Wert von \( y \) verändert, wenn \( x \) um 1 Einheit erhöht wird.
   - **Interpretation**: 
     - Eine Steigung von 2 bedeutet, dass \( y \) um 2 Einheiten steigt, wenn \( x \) um 1 Einheit steigt.
     - Positive Steigung: Die Gerade steigt von links nach rechts.

2. **y-Achsenabschnitt (b = -3)**
   - **Bedeutung**: Der y-Achsenabschnitt ist der Punkt, an dem die Gerade die y-Achse schneidet.
   - **Interpretation**: 
     - Bei \( x = 0 \) ist \( y = -3 \).
     - Dies bedeutet, dass die Gerade die y-Achse bei -3 kreuzt.

#### Zusammenfassung:
- **Steigung (m)**: Gibt die Richtung und Steilheit der Geraden an.
- **y-Achsenabschnitt (b)**: Gibt den Punkt an, an dem die Gerade die y-Achse schneidet.




- **Verteilung** von **Rechenlasten** auf zwei oder mehr Computer
- **reduziert Belastung** jedes einzelnen Servers, macht Server **effizienter** -> höhere **Performance** und geringere **Latenz**

## Funktionsweise
- **Hard-** oder **Softwarebasiert**
- Anfragen werden bestimmten Servern zugewiesen
- Zuweisung geschieht auf Grundlage von Algorithmen

### statische Algorithmen
- Lastenverteilung ohne aktuellen Zustand des Systems zu berücksichtigen
- lässt sich **schnell einrichten**, kann aber zu **Ineffizienzen** führen
- **Round-Robin-DNS**, DNS-Server rotiert A-Adressen der angefragten Domain
	- **Vorteile**, einfache Implementierung
	- **Nachteile**, DNS- & clientseitiges Caching -> ein Server wird überlastet

### dynamische Algorithmen
- **berücksichtigt** aktuelle Verfügbarkeit, Arbeitslast und Zustand der einzelnen Server
- **Vorteile**
	- können Traffic von schlecht performenden Servern auf weniger ausgelastete Server verlagern -> **gleichmäßig** und **effizienter** Traffic
- **Nachteile**
	- schwieriger zu konfigurieren
- **Beispiele**, Least Connection, Weighted Least Connection, ressourcenbasiertes und geolokalisiertes Load Balancing

## Beispiel
![[Pasted image 20240918101849.png]]
![[Pasted image 20240918101855.png]]

## Quellen

> Was ist Lastverteilung? | So funktionieren Load Balancer. (2024, September 18). Retrieved from https://www.cloudflare.com/de-de/learning/performance/what-is-load-balancing

- **M**edia-**A**ccess-**C**ontrol-Adresse
- **physische Adresse** von Netzwerkkarten 
- [[OSI-Modell|Ebene 2, Sicherrungsschicht, Data Link Layer]]

- **48-Bit** lang
- besteht aus **hexadezimalen Ziffern**
- **Sechs Segmente** die entweder durch `-` oder `:` getrennt werden

- `50-9A-4C-29-E3-11` oder `50:9A:4C:29:E3:11`
- ersten drei Segmente: durch **Institute of Electrical and Electronic Engineers** *(IEEE)* fest vergebende Herstellerkennung
- zweiten drei Segmente: individuell vergeben

## Quellen

> Mierke, M. (2020). Was ist eine MAC-Adresse? Tipps-Tricks. Retrieved from https://www.heise.de/tipps-tricks/Was-ist-eine-MAC-Adresse-4949263.html

Eine Machbarkeitsstudie ist ein wesentliches Instrument im [[Projektmanagement]], das die **Durchführbarkeit, Rentabilität und Wirtschaftlichkeit** eines Projekts bewertet. Sie untersucht verschiedene Faktoren, um die Erfolgsaussichten zu ermitteln.

## Ziele
- Bestimmung der Bedingungen für den Projekterfolg
- Einschätzung möglicher Risiken und Einschränkungen
- Identifizierung benötigter Ressourcen
- Berechnung des Budgets und des potenziellen [[Return on Investment]] (ROI)
- Information der Stakeholder über Projektbedingungen und -phasen

## Aspekte

### Wirtschaftliche Aspekte
- Durchführung einer [[Kosten-Nutzen-Analyse]]
- Berücksichtigung von Infrastrukturressourcen
- Bewertung des [[Return on Investment]] (ROI)
- Analyse des zeitlichen Rahmens und des investierten Kapitals
- Berechnung des Umsatzpotenzials
- Ermittlung geeigneter Fördermöglichkeiten
- Kalkulation der benötigten Infrastruktur

### Technische Aspekte
- Definition relevanter Systemanforderungen (Hardware, Kompatibilität, Skalierbarkeit)
- Berücksichtigung der bestehenden IT-Infrastruktur
- Beachtung der IT-Sicherheit (Datenschutz, unbefugter Zugriff)
- Analyse von Wartung, Support und Schulungsbedarf
- Betrachtung des Datenbankmanagements

### Rechtliche Aspekte
- Berücksichtigung geltender Datenschutzgesetze und -richtlinien
- Prüfung von Urheberrechten und Zugriffsberechtigungen
- Sicherstellung der Compliance

## Durchführung 
1. Vorläufige Analyse zur Identifikation offensichtlicher Hindernisse
2. Festlegung des Projektumfangs und der Bewertungskriterien
3. Marktforschung zur Überprüfung der Konkurrenz und Marktrealisierbarkeit
4. Finanzielle Bewertung (Kosten, erwartete Vorteile, Amortisierung)
5. Identifikation potenzieller Probleme und alternativer Lösungen
6. Bewertung der Ergebnisse
7. Entscheidungsfindung und Empfehlung weiterer Schritte

## Vorteile
- Ganzheitliche Bewertung der Projektmachbarkeit
- Identifikation alternativer Lösungswege
- Aufdeckung von Risiken und Hindernissen
- Fundierte Entscheidungsgrundlage für oder gegen ein Projekt
- Verhinderung von Fehlinvestitionen
- Aufzeigen der Marktsituation
- Informationssammlung für die spätere Projektdurchführung

## Nachteile
- Zeitaufwendig
- Kostenintensiv[

## Grundlagen von Mailservern
- **Definition**: Mailserver sind Systeme, die E-Mails senden, empfangen und speichern.
- **Zweck**: Ermöglichen die Kommunikation über das Internet.

## Wichtige Protokolle
- **SMTP**: Protokoll zum Senden von E-Mails.
- **POP3**: Protokoll zum Abrufen von E-Mails vom Server.
- **IMAP**: Protokoll für den Zugriff auf E-Mails auf dem Server, ohne sie herunterzuladen.

## Komponenten eines Mailservers
- **Mail Transfer Agent (MTA)**: Sendet und empfängt E-Mails (z. B. Postfix).
- **Mail Delivery Agent (MDA)**: Zustellt E-Mails an Benutzerpostfächer.
- **Mail User Agent (MUA)**: E-Mail-Client, den Benutzer verwenden (z. B. Outlook).

## Sicherheit
- **TLS/SSL**: Verschlüsselung für sichere E-Mail-Verbindungen.
- **SPF/DKIM/DMARC**: Mechanismen zur Authentifizierung und zum Schutz vor Spoofing.

## Fazit
Mailserver sind essenziell für die E-Mail-Kommunikation. Ein grundlegendes Verständnis der Protokolle und Sicherheitsmaßnahmen ist wichtig, um die Funktionalität und Sicherheit der E-Mail-Dienste zu gewährleisten.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Teilbereich der **Künstlichen Intelligenz** (KI), der es Computern ermöglicht, **aus Daten zu lernen** und **Muster zu erkennen**, ohne explizit programmiert zu werden. Es basiert auf Algorithmen, die aus Erfahrungen lernen und Vorhersagen oder Entscheidungen treffen können.

## Schritte
1. **Daten sammeln**
2. **Daten aufbereiten**
3. **Daten in Lerndaten und Testdaten unterteilen**
4. **Modell auswählen (z. B. Trenngerade)**
5. **Modell trainieren (optimale Gerade finden)**
6. **Bewertungskriterium für die Güte des Modells bestimmen**
7. **Modell evaluieren**

## Arten des maschinellen Lernens
- **[[Überwachtes und nicht-überwachtes Lernen|Überwachtes Lernen]]**: Algorithmen werden mit gekennzeichneten Daten trainiert, d.h. die Eingabedaten sind mit den entsprechenden Ausgaben verknüpft. Beispiele sind Klassifikations- und Regressionsaufgaben.
- **[[Überwachtes und nicht-überwachtes Lernen|Unüberwachtes Lernen]]**: Algorithmen arbeiten mit unbeschrifteten Daten und versuchen, Muster oder Strukturen zu erkennen. Beispiele sind Clusteranalysen und Dimensionsreduktion.
- **Bestärkendes Lernen**: Ein Agent lernt, Entscheidungen zu treffen, indem er Belohnungen oder Bestrafungen für seine Aktionen erhält. Es wird häufig in Spielen und Robotik eingesetzt.

## Algorithmen des maschinellen Lernens
- **[[Regression|Lineare Regression]]**: Ein einfaches Modell zur Vorhersage einer kontinuierlichen Zielvariable basierend auf einer oder mehreren Eingangsvariablen.
- **[[Entscheidungsbaum|Entscheidungsbäume]]**: Ein baumartiges Modell, das Entscheidungen basierend auf den Eingabedaten trifft und leicht interpretierbar ist.
- **[[Neural Network|Künstliche Neuronale Netze]]**: Inspiriert vom menschlichen Gehirn, bestehen sie aus Schichten von Neuronen und sind besonders effektiv für komplexe Aufgaben wie Bild- und Sprachverarbeitung.
- **[[Support Vector Machine|Support Vector Machines (SVM)]]**: Ein Klassifikationsalgorithmus, der versucht, die beste Trennlinie zwischen verschiedenen Klassen zu finden.

## Anwendungen des maschinellen Lernens
- **Bild- und Spracherkennung**: Verwendung in Anwendungen wie Gesichtserkennung, Spracherkennung und automatischen Übersetzungen.
- **Empfehlungssysteme**: Personalisierte Empfehlungen in E-Commerce und Streaming-Diensten basierend auf Benutzerverhalten.
- **Finanzanalyse**: Vorhersage von Markttrends, Betrugserkennung und Risikomanagement.
- **Medizin**: Diagnoseunterstützung, Analyse von medizinischen Bildern und personalisierte Behandlungspläne.

## Vorteile des maschinellen Lernens
- **Automatisierung**: Erlaubt die Automatisierung von Prozessen und Entscheidungsfindungen, was Effizienz und Produktivität steigert.
- **Datenanalyse**: Fähigkeit, große Datenmengen zu analysieren und wertvolle Erkenntnisse zu gewinnen.
- **Anpassungsfähigkeit**: Modelle können sich an neue Daten anpassen und ihre Leistung im Laufe der Zeit verbessern.

## Herausforderungen
- **Datenqualität**: Die Leistung von ML-Modellen hängt stark von der Qualität und Quantität der verwendeten Daten ab.
- **Überanpassung**: Modelle können zu komplex werden und sich zu stark an die Trainingsdaten anpassen, was ihre Generalisierungsfähigkeit beeinträchtigt.
- **Erklärbarkeit**: Viele ML-Modelle, insbesondere neuronale Netze, sind schwer zu interpretieren, was die Nachvollziehbarkeit von Entscheidungen erschwert.
- **Ethik und Bias**: Risiken von Vorurteilen in den Daten, die zu unfairen oder diskriminierenden Ergebnissen führen können.

## Quelle

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- auch **Zentralwert** genannt, 50% sind kleiner, 50% sind größer
- Werte werden **nach Größe sortiert**

## Anwendungsbereiche
- bei [[Ordinalskala|ordinal skalierten Variablen]]
- bei [[Kardinalskala|intervall- und verhältnisskalierten]] Daten
- nicht für [[Nominalskala|nominal skalierte Variablen]]

## Formel
1. Werte werden *(aufsteigend)* geordnet
2. bei ungerader Anzahl ist **mittlere Zahl** der Median
3. bei gerader Anzahl wird Median als **arithmetisches Mittel** beider Zahlen (*Unter- und Obermedian*) definiert

$n$=Anzahl der Messwerte
$x_n$=$x$ am Index $n$
- gerade: $\widetilde{x}=\dfrac{1}{2}(x_{\dfrac{n}{2}}+x_{\dfrac{n}{2}+1})$
- ungerade: $\widetilde{x}=x_{\dfrac{n+1}{2}}$

## Vorteile
- **Robustheit** gegenüber Ausreißern 
- benötigt kein **Intervallskalenniveau**, wie der [[Arithmetisches Mittel|Mittelwert]]

## Quellen 

> Seite „Median“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 15. August 2024, 16:20 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Median&oldid=247735977](https://de.wikipedia.org/w/index.php?title=Median&oldid=247735977) (Abgerufen: 13. September 2024, 10:01 UTC)
> Median. (2020, September 14). Retrieved from https://studyflix.de/statistik/median-2215


- regelt die **Zusammenarbeit zwischen Arbeitgeber und Arbeitnehmern** im Betrieb. Ein zentrales Element des BetrVG ist die **Mitbestimmung der Arbeitnehmer** durch den Betriebsrat. Der Betriebsrat hat in verschiedenen Bereichen des Betriebs Entscheidungs- und Mitwirkungsrechte.

## Mitbestimmungsrechte des Betriebsrats
- **Drei** Kategorien
	- **Informationsrecht**
	- **Mitwirkungsrecht (Beratungsrecht)**
	- **Mitbestimmungsrecht (Zustimmungsrecht)**


## Rechte des Betriebsrats im Einzelnen

### Informationsrechte
- Der Arbeitgeber **muss** den **Betriebsrat** über bestimmte Angelegenheiten **informieren**, damit dieser seine Aufgaben ordnungsgemäß erfüllen kann.
- **Beispiele**:
  - **Personalplanung** (§ 92 BetrVG): Der Betriebsrat muss über geplante Einstellungen, Versetzungen und Entlassungen informiert werden.
  - **Wirtschaftliche Angelegenheiten** (§ 106 BetrVG): Informationen zu wirtschaftlichen Planungen, z. B. über Betriebserweiterungen oder -einschränkungen.

### Mitwirkungsrechte (Beratungsrechte)
- Der Betriebsrat hat das Recht, in bestimmten Angelegenheiten angehört und **beraten** zu werden, **aber keine Entscheidungsbefugnis**. Der Arbeitgeber muss den Betriebsrat konsultieren, bevor er eine Entscheidung trifft.
- **Beispiele**:
  - **Personelle Einzelmaßnahmen** (§ 99 BetrVG): Der Betriebsrat muss bei Einstellungen, Eingruppierungen, Umgruppierungen und Versetzungen angehört werden. Der Betriebsrat kann unter bestimmten Voraussetzungen widersprechen, hat aber kein Vetorecht.
  - **Betriebliche Bildungsmaßnahmen** (§ 96 BetrVG): Der Arbeitgeber muss den Betriebsrat über betriebliche Aus- und Weiterbildungsmaßnahmen informieren und sich mit ihm beraten.

### Mitbestimmungsrechte (Zustimmungsrechte)
- Der Betriebsrat hat in bestimmten Angelegenheiten das Recht, Entscheidungen des Arbeitgebers **mitzubestimmen**. **Ohne** die **Zustimmung** des Betriebsrats kann der Arbeitgeber in diesen Fällen **keine Maßnahme** durchführen.
- **Beispiele**:
  - **Arbeitszeitregelungen** (§ 87 BetrVG): Mitbestimmung bei der Festlegung der Arbeitszeit, Überstunden, Pausenregelungen und Schichtplänen.
  - **Lohn- und Gehaltsstrukturen** (§ 87 BetrVG): Der Betriebsrat hat Mitbestimmungsrechte bei der Einführung von leistungsbezogenen Entgelten und Prämien.
  - **Urlaubsregelungen** (§ 87 BetrVG): Festlegung des Urlaubsplans und Regelungen zu Urlaubszeiten.
  - **Betriebsordnung** (§ 87 BetrVG): Mitbestimmung bei der Einführung von betrieblichen Verhaltensrichtlinien und der Kleiderordnung.

### Wirtschaftliche Mitbestimmung
- **Wirtschaftsausschuss** (§ 106 ff. BetrVG): In größeren Unternehmen (ab 100 Arbeitnehmern) gibt es einen Wirtschaftsausschuss, der den Betriebsrat über wirtschaftliche Angelegenheiten informiert und beratend zur Seite steht.
- **Betriebsänderungen** (§ 111 BetrVG): Bei wesentlichen Änderungen des Betriebs (z. B. Rationalisierungsmaßnahmen, Stilllegungen oder Massenentlassungen) hat der Betriebsrat ein Mitbestimmungsrecht. In solchen Fällen muss ein Sozialplan ausgehandelt werden, um die Folgen für die Arbeitnehmer abzumildern.


## Besondere Mitbestimmungsrechte

### Soziale Angelegenheiten (§ 87 BetrVG)
In sozialen Angelegenheiten, die den täglichen Betrieb und das Zusammenleben der Belegschaft betreffen, hat der Betriebsrat volle Mitbestimmung. Diese Rechte gelten insbesondere für:
- **Arbeitszeiten**: Beginn und Ende der Arbeitszeit, Überstundenregelungen.
- **Urlaubsgrundsätze**: Regelungen zur Verteilung von Urlaub.
- **Technische Überwachung**: Mitbestimmung bei der Einführung technischer Überwachungseinrichtungen (z. B. Kameras oder Zeiterfassungssysteme).
- **Lohnformen**: Regelungen zur Akkord- oder Prämienvergütung.

###  Personelle Angelegenheiten
Der Betriebsrat hat umfassende Mitwirkungsrechte bei personellen Maßnahmen, wie:
- **Kündigungen** (§ 102 BetrVG): Vor jeder Kündigung muss der Betriebsrat angehört werden. Er kann Widerspruch einlegen, aber die endgültige Entscheidung liegt beim Arbeitgeber.
- **Einstellung und Versetzung** (§ 99 BetrVG): Bei personellen Maßnahmen wie Neueinstellungen, Eingruppierungen oder Versetzungen hat der Betriebsrat ein Mitwirkungsrecht.

### Gesundheitsschutz (§ 89 BetrVG)
Der Betriebsrat hat ein Mitwirkungsrecht in Fragen des betrieblichen Arbeitsschutzes und der Unfallverhütung. Er muss beteiligt werden, wenn es um die Einführung von Maßnahmen geht, die die Sicherheit und Gesundheit der Arbeitnehmer betreffen.


## Vor- und Nachteile der Mitbestimmung

### Vorteile
- **Schutz der Arbeitnehmerrechte**: Durch die Mitbestimmungsrechte des Betriebsrats werden die Interessen der Arbeitnehmer umfassend vertreten.
- **Förderung der Betriebskultur**: Eine gute Zusammenarbeit zwischen Betriebsrat und Arbeitgeber kann das Betriebsklima verbessern und zu einer höheren Mitarbeiterzufriedenheit führen.
- **Bessere Entscheidungen**: Die Einbindung des Betriebsrats sorgt für vielfältigere Perspektiven, was oft zu besseren und nachhaltigeren Entscheidungen führt.

### Nachteile
- **Verlangsamung von Entscheidungen**: Die Mitbestimmung kann Entscheidungsprozesse verlangsamen, da der Betriebsrat in viele Angelegenheiten eingebunden werden muss.
- **Potenzielle Konflikte**: Bei Meinungsverschiedenheiten zwischen Betriebsrat und Arbeitgeber können Konflikte entstehen, die das Betriebsklima belasten.
- **Erhöhte Komplexität**: In größeren Betrieben kann die Vielzahl an Mitbestimmungsrechten und Gremien die Struktur komplexer und schwerfälliger machen.

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed1d06-5424-800b-bc26-8455a49771b1

- auch **Vorführmodell** oder **Demonstrationsmodell** genannt
- Attrappe um **Design und (Teil-)Funktionen** eines geplanten oder bereits eingeführten Produkts zu **demonstrieren**

- wird in **frühen Entwicklungsphasen** eingesetzt um **Anforderungen** an **Benutzeroberfläche** in Zusammenarbeit mit Auftraggeber und Anwender besser ermitteln zu können 
- reines **Grundgerüst** der Bedienelemente 


## Quellen

> Seite „Vorführmodell“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 28. August 2024, 16:38 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Vorf%C3%BChrmodell&oldid=248122901](https://de.wikipedia.org/w/index.php?title=Vorf%C3%BChrmodell&oldid=248122901) (Abgerufen: 17. September 2024, 08:31 UTC)

- gibt **Wert** an der **am häufigsten** vorkommt
- $x_{mod}$
- gibt es mehrere Werte die gleichermaßen Vorkommen spricht man von einer **multimodaler Verteilung**

## Beispiel
$$
18,22,25,22,20,27,21,19,19,19,22,20,25,42,30
$$
$$
x_{1,mod}= 19
\space\space\space\space
x_{2,mod}=22
$$
## Quellen

> Dalwigk, F. (2020, July 17). Arithmetisches Mittel, Median, Modalwert. Youtube. Retrieved from https://www.youtube.com/watch?v=DhXz9vM6Z8c&t=125s

## MTBF
- **M**ean **T**ime **B**etween **F**ailures
- durchschnittliche Zeit zwischen Ausfällen
- **Definition**
	- **Verfügbarkeit** = $p=\dfrac{MTBF}{MTBF+MTTR}$
	- **Unverfügbarkeit** = $q = 1 - p=\dfrac{MTTR}{MTBF+MTTR}$
	- **Ausfallrate** = $\lambda = \dfrac{1}{MTBF}$

## MTTR
- **M**ean **T**ime **T**o **R**epair
- durchschnittliche Zeit bis zur Wiederherstellung des Systems


## Quellen

> Griesbauer, D. (2019, March 06). Zuverlässigkeit, MTBF, MTTR, Verfügbarkeit, Ausfallrate, Ausfallwahrscheinlichkeit | Prof. Gries. Youtube. Retrieved from https://www.youtube.com/watch?v=H6tdbnBg1hk

- **Untersuchung und Bewertung von Netzwerkverbindungen**, um die Leistung, Sicherheit und Zuverlässigkeit eines Netzwerks zu gewährleisten. Sie ist ein wichtiger Bestandteil der Qualitätslenkung in der Softwareentwicklung.

## Ziele
- **Leistungsüberwachung**: Sicherstellen, dass das Netzwerk effizient arbeitet und die Bandbreite optimal genutzt wird.
- **Fehlerdiagnose**: Identifikation von Problemen wie hohe Latenzzeiten oder Paketverluste.
- **Sicherheitsüberprüfung**: Erkennung von unautorisierten Zugriffen oder Anomalien im Netzwerkverkehr.

## Wichtige Kennzahlen
- **Bandbreite**: Die maximale Datenmenge, die über das Netzwerk übertragen werden kann. Sie wird in Bit pro Sekunde (bps) gemessen.
- **Reaktionszeiten (Latenz)**: Die Zeit, die benötigt wird, um eine Anfrage zu senden und die Antwort zu erhalten. Hohe Latenz kann die Benutzererfahrung negativ beeinflussen.
- **Paketverlust**: Der Prozentsatz der Datenpakete, die während der Übertragung verloren gehen. Ein hoher Paketverlust kann auf Netzwerkprobleme hinweisen.

## Methoden der Netzwerkanalyse
- **Traffic Monitoring**: Überwachung des Datenverkehrs im Netzwerk, um Engpässe und ungewöhnliche Aktivitäten zu identifizieren.
- **Protokollanalyse**: Untersuchung der Netzwerkprotokolle (z.B. TCP/IP), um die Kommunikation zwischen Geräten zu verstehen und zu optimieren.
- **Netzwerk-Topologie-Analyse**: Visualisierung und Analyse der Netzwerkstruktur, um Schwachstellen und Optimierungspotenziale zu erkennen.

## Werkzeuge zur Netzwerkanalyse
- **Wireshark**: Ein weit verbreitetes Tool zur Analyse von Netzwerkprotokollen und -verkehr.
- **NetFlow Analyzer**: Überwacht den Netzwerkverkehr und bietet Einblicke in Bandbreitennutzung und -engpässe.
- **Ping und Traceroute**: Einfache Tools zur Überprüfung der Erreichbarkeit von Netzwerkgeräten und zur Analyse der Netzwerkpfade.

## Best Practices
- Regelmäßige Überwachung des Netzwerks, um Probleme frühzeitig zu erkennen.
- Dokumentation der Netzwerkarchitektur und -konfiguration zur besseren Fehlerdiagnose.
- Implementierung von Sicherheitsmaßnahmen, um unautorisierten Zugriff zu verhindern.



## Netzwerktypen

### PAN 
- **P**ersonal **A**rea **N**etwork 
- Geräte in **unmittelbarer Nähe**. 
- **Kabelgebunden** (FireWire, USB) oder **Kabellos** (Bluetooth, ZigBee, Infrarot, NFC). 
- **Typische Teilnehmer:** Laptops, Smartphones, Tablets. 
- **Datenübertragungsrate:** Gering, abhängig von der Technologie (z. B. Bluetooth 1–3 Mbit/s, ZigBee bis zu 250 kbit/s). 
- **Ausdehnung:** Wenige Meter (ca. 1–10 m). 
- **Sicherheitsaspekte:** Verschlüsselung häufig über einfache Verfahren wie Preshared Key (Bluetooth) oder spezielle Standards wie AES bei ZigBee.
### LAN
- **L**ocal **A**rea **N**etwork
- Ethernet-basierte Übertragung über **Kupfer**- und **Glasfaserkabel**. 
- **Datenübertragungsrate:** Hohe Übertragungsraten (10 Mbit/s bis 2,5 Gbit/s, in Rechenzentren auch 100 Gbit/s). 
- **Ausdehnung:** Typischerweise auf ein Gebäude oder einen Campus beschränkt, nicht mehr als $1km^2$. 
- **Sicherheitsaspekte:** Zugriffsbeschränkungen über VLANs, Firewalls, und Verschlüsselungstechnologien wie WPA3 für WLAN.
#### WLAN
- **Wireless** LAN - **Datenübertragungsrate:** Variiert je nach Standard (Wi-Fi 5 bis zu 1,3 Gbit/s, Wi-Fi 6 bis zu 9,6 Gbit/s). 
- **Sicherheitsaspekte:** 
	- **Verschlüsselung:** WPA2, WPA3 (aktueller Standard), basierend auf **Preshared Key (PSK)** oder **RADIUS**-Authentifizierung. 
	- **Preshared Key (PSK):** Gemeinsamer Schlüssel für alle Teilnehmer, einfach einzurichten, aber weniger sicher bei großen Netzwerken. 
	- **RADIUS:** Zentralisiertes Authentifizierungsprotokoll für größere Netzwerke, bietet höhere Sicherheit durch individuelle Authentifizierung. 
	- **Absicherung:** Über Firewalls, VPN für Remote-Zugriffe und Netzwerksicherheitsprotokolle wie IPsec.

#### VLAN
- **Virtual** LAN: Logische Trennung innerhalb eines physischen Netzwerks, z. B. zur Isolierung von Abteilungen in einem Unternehmen. 
- **Sicherheitsaspekte:** Ermöglicht die logische Segmentierung, um den Netzwerkverkehr zu kontrollieren und die Angriffsfläche zu verringern.

### MAN
- **M**etropolitan **A**rea **N**etwork
- Verbindung zwischen Standorten in einer Stadt oder Region, z. B. zwischen **Niederlassungen eines Unternehmens** oder **Fakultäten einer Universität**. 
- **Datenübertragungsrate:** Hohe Geschwindigkeit über Glasfaser (bis zu 100 Gbit/s). - **Ausdehnung:** Bis zu 100 km.
- **Sicherheitsaspekte:** Nutzung von VPNs oder speziellen Sicherheitslösungen zur sicheren Übertragung zwischen den Standorten.
### WAN
- **W**ide **A**rea **N**etwork - Bereitgestellt durch **WAN-Provider** (z. B. Telekommunikationsunternehmen). 
- **Technologien:** MPLS, Frame Relay, VPN, DSL, Glasfaser, Satelliten.
- **Datenübertragungsrate:** Variiert stark, z. B. DSL 1–100 Mbit/s, Glasfaser 100 Mbit/s bis 100 Gbit/s. 
- **Ausdehnung:** Über Länder und Kontinente hinweg.
- **Sicherheitsaspekte:** Datenverschlüsselung über VPN oder IPsec, oft in Kombination mit Firewalls.

### GAN
- **G**lobal **A**rea **N**etwork 
- Zusammenschluss vieler WANs, um das Internet oder globale Firmennetze zu bilden. 
- **Verbindungsmethoden:** Unterseekabel (Glasfaser) und Satelliten. - **Datenübertragungsrate:** Abhängig von der Infrastruktur (Glasfaser > 100 Gbit/s, Satelliten bis zu 1 Gbit/s). 
- **Ausdehnung:** Weltweit. 
- **Sicherheitsaspekte:** Verschlüsselungstechnologien wie IPsec, TLS und Sicherheitsprotokolle zur Absicherung globaler Verbindungen.

## Sicherheitskonzepte und -risiken

### Verschlüsselungstechnologien
- **WPA2/WPA3 (Wi-Fi Protected Access):** Verschlüsselungsprotokolle für drahtlose Netzwerke.
  - **WPA2:** Nutzt AES (Advanced Encryption Standard) zur Sicherung von WLAN-Verbindungen.
  - **WPA3:** Verbesserte Sicherheit gegenüber WPA2, mit Features wie **SAE** (Simultaneous Authentication of Equals) zur Vermeidung von Brute-Force-Angriffen.
- **Preshared Key (PSK):** Einfaches Verfahren zur Verschlüsselung, bei dem ein gemeinsamer Schlüssel verwendet wird, geeignet für kleine Netzwerke.
- **RADIUS (Remote Authentication Dial-In User Service):** Authentifizierungsprotokoll für größere Netzwerke, bietet zentrale Authentifizierung und individuelle Nutzeranmeldungen.
- **IPsec (Internet Protocol Security):** Verschlüsselt den Datenverkehr auf Netzwerkebene, wird häufig bei VPNs verwendet.
- **TLS (Transport Layer Security):** Verschlüsselung für den Schutz von Daten während der Übertragung, besonders bei Webverbindungen (https).

### Sicherheitsrisiken
- **Man-in-the-Middle-Angriffe (MitM):** Ein Angreifer schaltet sich zwischen die Kommunikation zweier Parteien, um Daten abzufangen oder zu manipulieren.
- **Unverschlüsselte Netzwerke:** Ohne ausreichende Verschlüsselung können Angreifer leicht auf vertrauliche Daten zugreifen.
- **Schwachstellen in drahtlosen Netzwerken:** Schwache oder unsichere Passwörter und veraltete Verschlüsselungsstandards wie WEP oder unsichere WPA-Implementierungen erhöhen das Risiko von Angriffen.
- **Rogue Access Points:** Falsche, bösartige WLAN-Zugangspunkte, die eingerichtet werden, um unbefugten Zugriff auf ein Netzwerk zu erlangen.

### Sicherheitsmaßnahmen
- **Firewalls:** Blockieren unautorisierten Netzwerkverkehr, schützen vor externen Angriffen.
- **VPN (Virtual Private Network):** Verschlüsselt die Internetverbindung und verbirgt den Standort des Benutzers, besonders nützlich für Remote-Zugriffe.
- **Netzsegmentierung (z. B. durch VLANs):** Trennung von Netzwerkbereichen zur Kontrolle des Datenverkehrs und Minimierung von Sicherheitsrisiken.
- **Zugriffskontrollen:** Berechtigungen basierend auf Nutzerrollen (z. B. über RADIUS), um sicherzustellen, dass nur autorisierte Benutzer auf das Netzwerk zugreifen können.
- **Regelmäßige Updates und Patches:** Schließen von Sicherheitslücken in Betriebssystemen und Netzwerkgeräten.
- **Starke Passwortrichtlinien:** Verwendung komplexer und einzigartiger Passwörter, regelmäßige Passwortwechsel.
- **Intrusion Detection Systems (IDS) und Intrusion Prevention Systems (IPS):** Überwachen Netzwerke auf verdächtige Aktivitäten und reagieren darauf.

## Netzwerktopologien

### Bustopologie
![[Pasted image 20240918080536.png]]
- **Merkmale:** Alle Geräte sind über ein gemeinsames Kabel (Bus) verbunden. 
- **Vorteile:** Einfach und kostengünstig zu implementieren.
- **Nachteile:** Bei Kabelbruch fällt das gesamte Netzwerk aus, begrenzte Bandbreite durch geteilte Verbindung.
- **Ausdehnung:** Begrenzt, typischerweise in kleineren Netzwerken.
  
### Sterntopologie
![[Pasted image 20240918080546.png]]
- **Merkmale:** Alle Geräte sind mit einem zentralen Knoten (Hub/Switch) verbunden.
- **Vorteile:** Hohe Ausfallsicherheit, da bei Ausfall eines Geräts das Netzwerk weiter funktioniert.
- **Nachteile:** Fällt der zentrale Knoten aus, ist das gesamte Netzwerk betroffen.
- **Ausdehnung:** Abhängig von der Anzahl der Verbindungen zum zentralen Knoten.

### Ringtopologie
![[Pasted image 20240918080600.png]]
- **Merkmale:** Geräte sind in einem Ring angeordnet, jedes Gerät ist mit zwei Nachbarn verbunden.
- **Vorteile:** Datenpakete zirkulieren in eine Richtung, daher geringe Kollisionen.
- **Nachteile:** Fällt ein Gerät oder ein Kabel aus, kann das Netzwerk unterbrochen werden.
- **Ausdehnung:** Geeignet für Netzwerke mit mäßiger Größe.

### Vermaschte Topologie (Mesh)
![[Pasted image 20240918080619.png]]
- **Merkmale:** Jedes Gerät ist mit mehreren anderen Geräten verbunden, oft in **vollständig** oder **teilweise vermaschter** Form.
- **Vorteile:** Sehr hohe Ausfallsicherheit, da mehrere Verbindungen existieren.
- **Nachteile:** Hoher Verkabelungsaufwand und kostenintensive Implementierung.
- **Ausdehnung:** Sehr große Netzwerke, typischerweise WANs.

### Baumtopologie
![[Pasted image 20240918080653.png]]
- **Merkmale:** Kombination aus Stern- und Bustopologie, Geräte sind hierarchisch angeordnet.
- **Vorteile:** Erweiterbar und relativ flexibel.
- **Nachteile:** Fällt eine zentrale Verbindung aus, können große Teile des Netzwerks ausfallen.
- **Ausdehnung:** Gut skalierbar für größere Netzwerke.

## Quellen

> Dalwigk, F. (2021, October 20). PAN vs. LAN vs. MAN vs. WAN vs. GAN vs. VPN ... Netzwerktypen einfach erklärt | Netzwerktechnik. Youtube. Retrieved from https://www.youtube.com/watch?v=JbGSAhl7ptI
> ChatGPT. (2024, September 18). Netzwerktypen und Sicherheitskonzepte. OpenAI. https://chat.openai.com

- **schematische Darstellung der Netzwerkarchitektur**, die die verschiedenen Komponenten eines Netzwerks und deren Verbindungen zeigt. Er dient als Leitfaden für die Planung, Implementierung und Verwaltung von Netzwerken.

## Wichtige Elemente eines Netzwerkplans
- **Netzwerkgeräte**:
	- **Router**: Leitet Daten zwischen verschiedenen Netzwerken.
	- **Switches**: Verbindet Geräte innerhalb eines Netzwerks und leitet Datenpakete weiter.
	- **Firewalls**: Schützen das Netzwerk vor unbefugtem Zugriff.
	- **Server**: Stellen Dienste und Ressourcen für Clients bereit.
	- **Clients**: Endgeräte, die auf die Dienste der Server zugreifen.
- **Verbindungen**:
	- **Kabeltypen**: Ethernet (Kupfer), Glasfaser (für hohe Bandbreiten).
	- **Drahtlose Verbindungen**: WLAN, Bluetooth.
- **IP-Adressierung**:
	- Zuweisung von IP-Adressen zu Geräten im Netzwerk.
	- Unterscheidung zwischen statischen und dynamischen IP-Adressen.
- **Sicherheitsmaßnahmen**:
	- Implementierung von Firewalls, VPNs und Zugangskontrollen.

![[Pasted image 20240928155529.png]]![[Pasted image 20240928155551.png]]

## Point-to-Point 
![[Pasted image 20240928160244.png]]
- einfache, direkte physikalische Verbindung
- beide Geräte können diese Verbindung für gegenseitige Kommunikation nutzen
- **Vorteile**
	- Hohe Übertragungsgeschwindigkeit
	- Einfache Implementierung und Wartung
	- Geringe Latenzzeit
- **Nachteile**
	- Begrenzte Reichweite
	- Hohe Kosten bei vielen Verbindungen
	- Ausfall eines Geräts unterbricht die Kommunikation

## Point-to-Multipoint
![[Pasted image 20240928160346.png]]
- mehrere Hosts durch zentrales System gespeist
- alle Hosts haben eine Leitung zum zentralen System
- **Vorteile**
	- Effiziente Nutzung der Ressourcen
	- Einfache Erweiterung durch Hinzufügen neuer Hosts
	- Zentrale Verwaltung und Kontrolle
- **Nachteile**
	- Zentrales System kann zum Flaschenhals werden
	- Ausfall des zentralen Systems führt zu Kommunikationsausfall
	- Höhere Komplexität in der Verkabelung

## Line / Chain / Linien-Topologie
![[Pasted image 20240928160430.png]]
- Leitung von Host zu Host werden verlegt
- **Vorteile**
	- Einfache Installation und Erweiterung
	- Geringe Kosten für Verkabelung
	- Gut für kleine Netzwerke
- **Nachteile**
	- Ausfall eines Hosts kann das gesamte Netzwerk beeinträchtigen
	- Begrenzte Anzahl von Hosts, die angeschlossen werden können
	- Schwierigkeiten bei der Fehlersuche

## Bus-Topologie
![[Pasted image 20240928160551.png]]
- Alle Geräte sind über ein gemeinsames Kabel verbunden
- **Vorteile**
	- Geringe Kosten für Verkabelung
	- Einfache Installation
	- Gut für kleine Netzwerke
- **Nachteile**
	- Ausfall des Hauptkabels führt zum Ausfall des gesamten Netzwerks
	- Begrenzte Anzahl von Geräten, die angeschlossen werden können
	- Schwierigkeiten bei der Fehlersuche

## Ring-Topologie
![[Pasted image 20240928160604.png]]
- Jedes Gerät ist mit zwei anderen Geräten verbunden, wodurch ein geschlossener Ring entsteht
- **Vorteile**
	- Datenübertragung in eine Richtung reduziert Kollisionen
	- Einfache Datenübertragung und -verwaltung
	- Vorhersehbare Leistung
- **Nachteile**
	- Ausfall eines Geräts kann das gesamte Netzwerk beeinträchtigen
	- Schwierige Fehlersuche
	- Höhere Kosten für Verkabelung

## Stern-Topologie
![[Pasted image 20240928160614.png]]
- Alle Geräte sind über ein zentrales Gerät (Switch oder Hub) verbunden
- **Vorteile**
	- Einfache Fehlersuche und Wartung
	- Ausfall eines Geräts beeinträchtigt nicht das gesamte Netzwerk
	- Hohe Leistung und Skalierbarkeit
- **Nachteile**
	- Abhängigkeit vom zentralen Gerät
	- Höhere Kosten für zentrale Geräte und Verkabelung
	- Komplexität bei der Verkabelung

## Baum-Topologie
![[Pasted image 20240928160623.png]]
- Kombination aus Stern- und Bus-Topologie, hierarchische Struktur
- **Vorteile**
	- Flexibel und erweiterbar
	- Gute Organisation der Netzwerkstruktur
	- Einfache Fehlersuche in Teilbereichen
- **Nachteile**
	- Komplexität in der Implementierung
	- Ausfall des Hauptkabels kann große Teile des Netzwerks beeinträchtigen
	- Höhere Kosten für Verkabelung und zentrale Geräte

## Mesh / Maschen-Topologie
![[Pasted image 20240928160638.png]]
- Jedes Gerät ist mit mehreren anderen Geräten verbunden
- **Vorteile**
	- Hohe Redundanz und Ausfallsicherheit
	- Daten können mehrere Wege nehmen, was die Leistung verbessert
	- Gute Skalierbarkeit
- **Nachteile**
	- Hohe Kosten für Verkabelung und Hardware
	- Komplexe Implementierung und Wartung
	- Schwierigkeiten bei der Fehlersuche


Neuronale Netze sind Modelle des **maschinellen Lernens**, die dem menschlichen Gehirn nachempfunden sind. Sie bestehen aus verschiedenen Schichten, die Informationen verarbeiten und Ergebnisse liefern.

## Aufbau eines Neuronalen Netzes
Ein neuronales Netz besteht aus drei Hauptschichten:

- **Eingabeschicht**: Nimmt Informationen auf.
- **Verborgene Schichten**: Verarbeiten und gewichten die Informationen. Es können mehrere verborgene Schichten vorhanden sein.
- **Ausgabeschicht**: Gibt das verarbeitete Ergebnis aus.

### Struktur
- **Knoten (Neuronen)**: Die Verarbeitungseinheiten des Netzes.
- **Kanten (Verbindungen)**: Die Verbindungen zwischen den Neuronen, die Gewichtungen tragen.

![[Pasted image 20240919130334.png]]
## Funktionsweise
1. **Informationserfassung**: Daten werden in der Eingabeschicht aufgenommen.
2. **Datenverarbeitung**: Informationen werden durch die verborgenen Schichten geleitet und gewichtet.
3. **Ergebnisausgabe**: Die Ausgabeschicht liefert das finale Ergebnis.
![[image.psd(1).png]]
## Wichtige Konzepte
- **Gewichtungen**: Bestimmen die Stärke der Verbindungen zwischen Neuronen.
- **Aktivierungsfunktion**: Entscheidet, ob und wie stark ein Neuron aktiviert wird.
- **Schwellenwert**: Der Mindestwert, ab dem ein Neuron aktiviert wird.

### Aktivierungsfunktionen
- **Sigmoid**: Werte zwischen 0 und 1, geeignet für binäre Klassifikation.
- **ReLU (Rectified Linear Unit)**: Gibt positive Werte zurück, sonst 0. Ideal für tiefe Netzwerke.
- **Tanh**: Werte zwischen -1 und 1, oft besser als Sigmoid in versteckten Schichten.

## Regularisierungstechniken
Um Überanpassung (Overfitting) zu vermeiden, werden folgende Techniken eingesetzt:

- **L1-Regularisierung (Lasso)**: Bestraft die Summe der absoluten Werte der Gewichtungen. Führt dazu, dass einige Gewichtungen auf null gesetzt werden, was die Merkmalsauswahl erleichtert.
  
- **L2-Regularisierung (Ridge)**: Bestraft die Summe der quadrierten Werte der Gewichtungen. Reduziert Gewichtungen gleichmäßig und stabilisiert das Modell.

- **Dropout**: Deaktiviert zufällig Neuronen während des Trainings, um robuste Merkmale zu lernen und die Abhängigkeit zwischen Neuronen zu verringern.

## Lernprozess
Der Lernprozess eines neuronalen Netzes umfasst folgende Schritte:

1. **Initialisierung**: Zufällige Zuweisung von Gewichtungen.
2. **Training**: Anpassung der Gewichtungen basierend auf Trainingsdaten.
3. **Fehlerrückführung (Backpropagation)**: Optimierung der Gewichtungen zur Minimierung des Fehlers.

### Optimierungsalgorithmen
- **Stochastic Gradient Descent (SGD)**: Eine einfache und weit verbreitete Methode.
- **Adam**: Kombiniert die Vorteile von AdaGrad und RMSprop, oft schneller und effektiver.
- **RMSprop**: Passt die Lernrate für jede Gewichtung an, um schneller zu konvergieren.

### Lernratenanpassung
Die Lernrate beeinflusst die Geschwindigkeit und Effektivität des Trainings:

- **Zu hohe Lernrate**: Kann zu instabilem Training führen.
- **Zu niedrige Lernrate**: Kann das Training verlängern und das Modell in lokalen Minima festhalten.

#### Adaptive Lernraten
- **AdaGrad**: Passt die Lernrate basierend auf der Häufigkeit der Aktualisierungen an.
- **RMSprop**: Verbessert AdaGrad, indem es die Lernrate basierend auf dem gleitenden Durchschnitt der quadratischen Gradienten anpasst.
- **Adam**: Nutzt sowohl den gleitenden Durchschnitt der Gradienten als auch der quadrierten Gradienten zur Anpassung der Lernrate.

## Beispielberechnung
- **Eingabe**: $x₁ = 1, x₂ = 0,6$
- **Gewichte**: $W₁ = 0,4, W₂ = -0,5$
- **Berechnung**: 
  $x = x₁ \times W₁ + x₂ \times W₂ = 1 \times 0,4 + 0,6 \times (-0,5) = 0,1$
- Das Ergebnis wird durch die Aktivierungsfunktion geleitet.

## Architekturen
- **Convolutional Neural Networks (CNNs)**: Besonders geeignet für Bildverarbeitung.
- **Recurrent Neural Networks (RNNs)**: Ideal für zeitliche Daten und Sequenzen.
- **Generative Adversarial Networks (GANs)**: Für die Generierung neuer Daten.

## Anwendungsgebiete
- **Mustererkennung** in großen Datensätzen.
- **Vorhersagemodelle** für Geschäftsprozesse.
- **Anomalieerkennung** in IT-Systemen.
- **Bildverarbeitung** und Objekterkennung.

## Vor- und Nachteile

### Vorteile
- Verarbeitung **komplexer, nichtlinearer Zusammenhänge.**
- **Gute Performanz** bei großen Datenmengen.

### Nachteile
- Benötigt **große Trainingsdatensätze.**
- "**Black Box**" - Entscheidungsprozess schwer nachvollziehbar.
- Ethische Bedenken: **Bias in den Daten** kann zu unfairen Entscheidungen führen.


> Neuronale Netze. (2022, January 26). Retrieved from https://studyflix.de/informatik/neuronale-netze-4297
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Definition**: NFS ist ein **Speicherprotokoll**, das einen effizienten Dateizugriff über ein Netzwerk ermöglicht. Es wurde 1984 von Sun Microsystems für Unix-basierte Systeme entwickelt und ist besonders bei Linux-Benutzern beliebt.

- **Funktionsweise**:
  - **Client**: Ein NFS-fähiger Client fordert eine Datei oder ein Verzeichnis vom NFS-Server an, indem er *Remote Procedure Calls (RPC)* verwendet.
  - **Server**: Der NFS-Server führt folgende Prüfungen durch:
    - Überprüfung, ob die angeforderte Datei oder das Verzeichnis **verfügbar** ist.
    - Überprüfung, ob der Client die erforderlichen **Zugriffsberechtigungen** hat.
  - **Mounting**: Nach erfolgreicher Prüfung **mountet der Server die Datei** oder das Verzeichnis **remote auf dem Client** und ermöglicht den **Zugriff über eine virtuelle Verbindung**. Für den Client sieht der Zugriff auf die Remote-Serverdatei ähnlich aus wie der Zugriff auf eine lokale Datei.

- **Caching**: NFS-Clients speichern **Dateien im Cache**, um die Zugriffsgeschwindigkeit zu verbessern.

- **Dateisperren**: NFS bietet Mechanismen zur **Sperrung von Dateien**, wenn **mehrere Computer gleichzeitig** versuchen, in dieselbe Datei zu schreiben, um Dateninkonsistenzen zu vermeiden.

- **Synchronisierte Dateiattributaktualisierungen**: NFS stellt sicher, dass **Änderungen an Dateiattributen** (z.B. Zeitstempel, Berechtigungen) **synchronisiert** werden, um die Konsistenz der Daten zu gewährleisten.

## Vorteile von NFS
- **Transparente Nutzung**: Benutzer können auf **Remote-Dateien zugreifen**, als wären sie lokal gespeichert.
- **Plattformunabhängigkeit**: NFS unterstützt **verschiedene Betriebssysteme**, was die **Interoperabilität zwischen unterschiedlichen Systemen** erleichtert.
- **Skalierbarkeit**: NFS kann **leicht in großen Netzwerken mit vielen Clients und Servern implementiert** werden.

## Quellen 
> NFS und SMB – Unterschied zwischen Speicherprotokollen für den Dateizugriff – AWS. (2024, September 17). Retrieved from https://aws.amazon.com/de/compare/the-difference-between-nfs-smb


- Daten haben **keine logische Reihenfolge** (Geschlecht, Haarfarbe, Farbe von Kleidung)
- lediglich **Ausprägung** kann unterschieden werden

## Quellen

> Nominalskala. (2019, June 27). Retrieved from https://studyflix.de/statistik/nominalskala-1359

- Strategie zur **Beseitigung und Vermeidung von Redundanz** in relationalen Datenbanken 

> *"Normalisierung bezeichnet man **die Überführung** einer Datenbanktabelle in eine **Normalform höheren Grades**. Die Überführung in eine Normalform **geringeren** Grades wird **Denormalisierung** genannt."*
> - https://www.ionos.de/digitalguide/hosting/hosting-technik/normalisierung-von-datenbanken/anomali

## Normalformen

1. **1. Normalform (1NF)**, alle Daten liegen *atomar* vor, Tabellenspalten beinhalten *gleichartige Werte*
2. **2. Normalform (2NF)**, jedes *Nichtschlüsselattribut* muss vom *Primärschlüssel voll funktional abhängig* sein
3. **3. Normalform (3NF)**,  *kein Nichtschlüsselattribut* darf von einem *Schlüsselkandidaten transitiv* abhängig sein

## Vorteile
- **weniger Redundanz**
- **Verhinderung** von **Anomalien**
- **spezialisiertere Abfragen** möglich
## Nachteile
- Integration von **Fremdschlüsseln**
- viele **Joins erforderlich**
- bei größeren Datensätzen mit vielen Abhängigkeiten, **viele Tabellen**

## Beispiel
- Ausgangslage
![[Pasted image 20240911123548.png]]
- **1NF**, *mehrwertige Daten* aufspalten, Spalten auf *Gleichartigkeit* prüfen
![[Pasted image 20240911123609.png]]
![[Pasted image 20240911124014.png]]
- **2NF**, Spalten die nicht *voll funktional abhängig* sind, werden ausgelagert (`Anz.` ist nur von `P.-Nr.` abhängig aber nicht `R.-Nr.`, daher wird `P.-Nr.` und abhängige Spalten ausgelagert.)
![[Pasted image 20240911125052.png]]
![[Pasted image 20240911125102.png]]
- **3NF**, Spalten die von einem *Nichtschlüsselattribut abhängig* sind, werden ausgelagert (`Artikel` ist von `Art.-Nr.` abhängig, `Art.-Nr.` ist jedoch kein Primärschlüssel)
![[Pasted image 20240911125857.png]]
![[Pasted image 20240911130048.png]]
![[Pasted image 20240911130054.png]]

## Quellen

> Redaktion, I. (2018). Weniger Redundanz dank Datenbank-Normalisierung. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/hosting/hosting-technik/normalisierung-von-datenbanken

# NoSQL-Datenbanken

NoSQL steht für "**N**ot **O**nly **SQL**" und bezeichnet Datenbanksysteme, die **nicht dem relationalen Modell folgen**. Sie wurden entwickelt, um Einschränkungen relationaler Datenbanken zu überwinden, insbesondere in Bezug auf **Skalierbarkeit** und **Flexibilität** bei großen Datenmengen.

## Charakteristika
- **Schemafrei**: Flexible Datenstrukturen ohne festes Schema
- **Horizontal skalierbar**: Einfache Verteilung auf mehrere Server
- **Hohe Performanz**: Optimiert für schnelle Lese- und Schreibzugriffe
- **Eventual Consistency**: Verzicht auf sofortige Konsistenz zugunsten von Verfügbarkeit

## NoSQL-Datenbanktypen

### 1. Dokumentenorientierte Datenbanken
- Speichern Daten in flexiblen, JSON-ähnlichen Dokumenten
- **Beispiele**: MongoDB, CouchDB
- **Anwendung**: Content Management, Echtzeitanalysen

### 2. Spaltenorientierte Datenbanken
- Speichern Daten in Spalten statt in Zeilen
- **Beispiele**: Cassandra, HBase
- **Anwendung**: Große Datenmengen, Analysen

### 3. Key-Value Stores
- Einfache Schlüssel-Wert-Paare
- **Beispiele**: Redis, Amazon DynamoDB
- **Anwendung**: Caching, Sitzungsverwaltung

### 4. Graphdatenbanken
- Speichern Daten in Knoten und Kanten
- **Beispiele**: Neo4j, Amazon Neptune
- **Anwendung**: Soziale Netzwerke, Empfehlungssysteme

## CAP-Theorem
Das CAP-Theorem besagt, dass ein verteiltes System nur zwei der drei folgenden Eigenschaften gleichzeitig garantieren kann:

- **Consistency**: Alle Knoten sehen die gleichen Daten zur gleichen Zeit
- **Availability**: Jede Anfrage erhält eine Antwort
- **Partition Tolerance**: Das System funktioniert trotz Netzwerkausfällen

NoSQL-Datenbanken priorisieren oft **Verfügbarkeit und Partitionstoleranz** über strikte Konsistenz.

## Vergleich zu relationalen Datenbanken

| Aspekt | NoSQL | Relational |
|--------|-------|------------|
| Schema | Flexibel | Starr |
| Skalierung | Horizontal | Vertikal |
| Konsistenz | Eventual | ACID |
| Abfragesprache | Datenbankspezifisch | SQL |

## Vor- und Nachteile von NoSQL-Datenbanken

### Vorteile
- **Flexibilität**: Schemafreie Datenstrukturen ermöglichen eine einfache Anpassung an sich ändernde Datenanforderungen.
- **Skalierbarkeit**: Horizontale Skalierung ermöglicht die Verarbeitung großer Datenmengen durch die Verteilung auf mehrere Server.
- **Hohe Verfügbarkeit**: Systeme sind oft so konzipiert, dass sie auch bei Ausfällen weiterhin funktionieren.

### Nachteile
- **Komplexität der Datenkonsistenz**: Eventual Consistency kann zu Inkonsistenzen führen, was in bestimmten Anwendungen problematisch sein kann.
- **Eingeschränkte Abfragemöglichkeiten**: Abfragen sind oft weniger mächtig als in relationalen Datenbanken und erfordern spezifische Kenntnisse der jeweiligen NoSQL-Datenbank.
- **Fehlende Standardisierung**: Viele NoSQL-Datenbanken haben unterschiedliche Abfragesprachen und APIs, was die Interoperabilität erschwert.

## Anwendungsfälle
- Big Data-Verarbeitung
- Echtzeitanwendungen
- Internet of Things (IoT)
- Content Delivery Networks (CDN)

## Herausforderungen
- Fehlende Standardisierung
- Komplexe Datenkonsistenz
- Eingeschränkte Abfragemöglichkeiten im Vergleich zu SQL

## Praxisrelevante Konzepte

### Map/Reduce
Ein Programmiermodell zur **parallelen Verarbeitung großer Datenmengen**:
1. **Map**: Daten aufteilen und verarbeiten
2. **Reduce**: Ergebnisse zusammenführen

### Sharding
**Horizontale Partitionierung** von Daten **über mehrere Server** zur Verbesserung der Skalierbarkeit.

### Replikation
Daten werden auf **mehreren Knoten** gespeichert, um **Ausfallsicherheit** und **Leseperformanz** zu erhöhen.



| Kriterium                     | SQL                                                                                                           | NoSQL                                                                                                |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| **Datenspeicherung**          | Speicherung in relationalen Tabellen                                                                          | Datenspeicherung immer und überall möglich als Key-Value Paare in einer Datei                        |
| **Datenstruktur**             | Komplexe relationale Datenstruktur                                                                            | Hierarchische Speicherung in JSON-Basierten Dokumentation o. Ä.                                      |
| **Redundanz**                 | Geringe Redundanz durch Normalisierung                                                                        | Ggf. hohe Redundanz                                                                                  |
| **Schema**                    | Statisch<br><br>Schema muss festgelegt werden, bevor Daten hinzugefügt werden können                          | Dynamisch<br><br>Daten können ohne zuvor definiertes Schema hinzugefügt werden                       |
| **Skalierbarkeit**            | Vertikale Skalierung (scale up):<br><br>Aufrüstung der bestehenden Server, wenn sich die Datenbank vergrößert | Horizontale Skalierung (scale out):<br><br>Verteilung der Datenbank über mehrere "hosts" -> Sharding |
| **Transaktionseigenschaften** | *ACI*<br><br>*A*tomic, *C*onsistency, *I*solation, *D*urability                                               | *BASE*<br><br>*B*asically *A*vailable, *S*oft State, *E*ventually Consistent                         |

## Vorteile relationaler Datenbanken
- Standardisierte Abfragesprache durch SQL
- ACID-Eigenschaften, Atomicity, Consistency, Isolation, Durability -> verlässliche und konsistente Informationen in Datenbanken
- Weit verbreitete Datenbank: Hierdurch ist meist ein breites Wissen über Funktionsweise vorhanden

## Vorteile NoSQL-Datenbanken
- Verschiedene Datenbankmodelle können gleichzeitig genutzt werden
- Flexible Schemata sind möglich, Daten können unterschiedliche Strukturen (halb/unstrukturiert) aufweisen
- Erleichterte Verarbeitung von umfangreichen, nicht verbundenen, unbestimmten oder schnell veränderlichen Daten
- Erhöhte Leistung bei hohen Datenaufkommen im Vergleich zu relationalen Datenbanken

- **Scoring-Modell**, mehrere **Handlungsalternativen** können gemäß verschiedenen **Zielkriterien beurteilt** und **verglichen** werden
- Entscheidungsfindung **transparent** und **objektiv** durch Einbindung von **qualitativen und quantitativen Faktoren** -> psychologische, soziale, technische Aspekte berücksichtigen

## Schritte
1. Alternativen bzw. **Entscheidungsvarianten** festlegen
2. **Bewertungskriterien** definieren
3. **Gewichtung** der Bewertungskriterien festlegen
4. **Bewertungsmaßstab** festlegen, z.B. eins bis fünf
5. **Bewertungen** der Entscheidungsvarianten
6. **Auswertung** und **Auswahl** ($Wichtung \times Punktzahl$)

## Vorteile

1. **Transparenz**: Die Nutzwertanalyse ermöglicht eine klare und nachvollziehbare Entscheidungsfindung, da alle Kriterien und Bewertungen offen gelegt werden.
2. **Objektivität**: Durch die Einbeziehung quantitativer und qualitativer Faktoren wird die Entscheidungsfindung weniger subjektiv und emotional.
3. **Flexibilität**: Die Methode kann an verschiedene Entscheidungssituationen und -kriterien angepasst werden.
4. **Berücksichtigung mehrerer Kriterien**: Die Nutzwertanalyse ermöglicht die gleichzeitige Bewertung mehrerer Handlungsalternativen anhand unterschiedlicher Zielkriterien.
5. **Einbindung von Stakeholdern**: Durch die transparente Vorgehensweise können verschiedene Interessengruppen in den Entscheidungsprozess einbezogen werden.

## Nachteile

1. **Subjektivität bei der Gewichtung**: Die Festlegung der Gewichtung der Bewertungskriterien kann subjektiv sein und zu Verzerrungen führen.
2. **Komplexität**: Bei einer großen Anzahl von Alternativen und Kriterien kann die Analyse komplex und zeitaufwendig werden.
3. **Schwierigkeiten bei der Bewertung**: Die Bewertung qualitativer Faktoren kann herausfordernd sein, da sie oft schwer quantifizierbar sind.
4. **Überbewertung von quantitativen Faktoren**: Es besteht die Gefahr, dass quantitative Aspekte überbewertet werden, während qualitative Faktoren vernachlässigt werden.
5. **Abhängigkeit von der Datenqualität**: Die Ergebnisse der Nutzwertanalyse sind stark von der Qualität und Verfügbarkeit der Daten abhängig.

## Beispiele
![[Pasted image 20240920103919.png]]

## Quellen

> Gemacht, P. l. (2020, November 25). Die Nutzwertanalyse einfach erklärt | Einfaches Beispiel | Kostenlose Vorlage. Youtube. Retrieved from https://www.youtube.com/watch?v=z5vHgIIEars

- Open Data sind Daten, die von allen **ohne Einschränkungen** genutzt, weiterverbreitet und weiterverwendet werden dürfen.
- Einschränkungen sind nur zur Sicherung von Ursprung und Offenheit erlaubt (z.B. Nennung des Urhebers).

**Wichtige Aspekte:**
- **Freie Lizenzen:** Um Nachnutzbarkeit zu gewährleisten, werden Freie Lizenzen verwendet.
- **Keine personenbezogenen Daten:** Offene Daten dürfen keine personenbezogenen oder datenschutzrechtlich geschützten Informationen enthalten.

**Beispiele für Open Data:**
- Lehrmaterialien
- Geodaten
- Statistiken
- Verkehrsinformationen
- Wissenschaftliche Publikationen

**Rechtlicher Rahmen:**
- In Deutschland und der Schweiz gibt es spezifische Regelungen für Open Data.

**Forderungen der Open-Data-Bewegung:**
- Förderung der Transparenz und Nachnutzbarkeit von Daten durch öffentliche Stellen.

**Argumente:**
- **Für Open Data:** Erhöhung der **Transparenz**, Förderung von **Innovation** und **Forschung**.
- **Gegen Open Data:** Bedenken hinsichtlich Datenschutz und Missbrauch von Daten.

**Projekte und Initiativen:**
- Open-Data-Hackathons und verschiedene Plattformen, die Open Data bereitstellen.

**Zusammenhang:**
- Open Data ist Teil der Wissensallmende und steht in Verbindung mit Themen wie Open Source, Open Access und Open Science.

## Quellen

> Seite „Open Data“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 4. September 2024, 14:27 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Open_Data&oldid=248313580](https://de.wikipedia.org/w/index.php?title=Open_Data&oldid=248313580) (Abgerufen: 16. September 2024, 10:14 UTC)

- Bildung von **Rangfolge** möglich
- lediglich **größer gleich** und **kleiner gleich** Vergleiche möglich
- **Abstände** haben **lassen sich nicht interpretieren** 
	- *1. 25 Punkte, 2. 18 Punkte; bloß weil 7 Punkte Vorsprung nicht gleich 7 mal besser bei Fußball*
	- *sehr lecker, sehr sehr lecker, lecker*

## Quellen

> Ordinalskala. (2019, June 13). Retrieved from https://studyflix.de/statistik/ordinalskala-1327

- **O**pen **S**ystems **I**nterconnection
- Referenzmodell für Netzwerkprotokolle als Schichtenarchitektur
- ermöglicht **standardisierte Kommunikation** zwischen verschiedenen Computersystemen

## Schichten

- jede Schicht hat eigenes **Abstraktionsniveau** und eine festgelegte **Funktion**
- Schichten ermöglichen auch **gezieltere Problembehebungen**

| Englisch               | Deutsch                    | Erklärung                                                                                              | Protokolle                                        |
| ---------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------ | ------------------------------------------------- |
| **A**pplication Layer  | **A**nwendungsschicht      | Dienste, Anwendungen und Netzwerkmanagement                                                            | HTTP, FTP, SSH                                    |
| **P**resentation Layer | **D**arstellungsschicht    | Umsetzung von systemabhängigen Darstellungen (ASCII, ...) in unabhängige Formen                        | X.226 (Connection-Oriented Presentation Protocl)  |
| **S**ession Layer      | **S**itzungsschicht        | Prozesskommunikation zwischen zwei Systemen, Behebung von Fehlern wie Zusammenbrüche der Sitzung, etc. | X.225, ISO 9548 (Connectionless Session Protocol) |
| **T**ransport Layer    | **T**ransportschicht       | End-to-End-Kommunikation. Beinhalten Header-Informationen und Fehlerkontrolle. *Pakete*                | TCP, UDP                                          |
| **N**etwork Layer      | **V**ermittlungsschicht    | Datentransfer zwischen Netzwerksegmenten. *Fragmente*                                                  | IP, ICMP                                          |
| **D**ata Link Layer    | **S**icherrungsschicht     | zuverlässige, funktionierende Kommunikation im selben Netzwerk. *Frames*                               | ARP, STP [^1]                                     |
| **P**hysical Layer     | **B**itübertragungsschicht | elektrische, mechanische, funktionale Schnittstelle                                                    | Ethernet, IEEE 802.11                             |

### Merksätze

1. **P**lease **D**o **N**ot **T**hrow **S**alami **P**izza **A**way ⏫
2. **A**lle **D**eutsche **S**tudenten **T**rinken **V**erschiedene **S**orten **B**ier ⏬

[^1]: Spanning Tree Protokoll

## Quellen

> OSI Modell. (2022, October 07). Retrieved from https://studyflix.de/informatik/osi-modell-5524
> 
> Autoren der Wikimedia-Projekte. (2002, July 13). OSI-Modell – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=OSI-Modell&oldid=247949880

## Grundlagen des Patentrechts
- **Definition**: Patentrecht schützt **technische Erfindungen** und gewährt dem **Erfinder** das exklusive Recht, seine Erfindung für einen bestimmten Zeitraum zu nutzen.
- **Rechtsgrundlage**: In Deutschland durch das **Patentgesetz (PatG)** geregelt.

## Voraussetzungen für die Patentierbarkeit
- **Neuheit**: Die Erfindung darf nicht zum **Stand der Technik** gehören.
- **Erfinderische Tätigkeit**: Die Erfindung muss sich für einen **Fachmann** nicht in naheliegender Weise aus dem Stand der Technik ergeben.
- **Gewerbliche Anwendbarkeit**: Die Erfindung muss in der **Industrie** oder im **Handel** einsetzbar sein.

## Patentarten
- **Erfindungspatente**: Schutz für technische Erfindungen.
- **Gebrauchsmuster**: Einfacherer und schnellerer Schutz für kleinere Erfindungen (nicht so umfassend wie Patente).
- **Softwarepatente**: Software kann patentierbar sein, wenn sie eine **technische Lösung** für ein technisches Problem bietet.

## Antragsverfahren
- **Patentanmeldung**: Einreichung beim **Deutschen Patent- und Markenamt (DPMA)**.
- **Prüfung**: Nach der Anmeldung erfolgt eine Prüfung auf **Neuheit** und **erfinderische Tätigkeit**.
- **Erteilung**: Bei positiver Prüfung wird das Patent erteilt.

## Rechte des Patentinhabers
- **Nutzungsrecht**: Exklusives Recht zur Nutzung, Herstellung und Vermarktung der Erfindung.
- **Lizenzvergabe**: Möglichkeit, **Lizenzen** an Dritte zu vergeben.
- **Rechtsdurchsetzung**: Möglichkeit, gegen **Verletzungen** des Patents vorzugehen.

## Dauer des Patents
- **Schutzdauer**: In der Regel **20 Jahre** ab Anmeldetag, bei Gebrauchsmustern **10 Jahre**.

## Wichtige Begriffe
- **Stand der Technik**: Alles, was vor dem Anmeldetag veröffentlicht wurde.
- **Patentverletzung**: Unerlaubte Nutzung einer patentierten Erfindung.
- **Lizenz**: Vertragliche Erlaubnis zur Nutzung einer patentierten Erfindung.

## Relevanz für Fachinformatiker
- **Entwicklung von Software**: Verständnis, wann Software patentierbar ist.
- **Innovationen schützen**: Strategien zur Sicherung von **geistigem Eigentum**.
- **Rechtliche Rahmenbedingungen**: Wissen über Rechte und Pflichten im Umgang mit Patenten.

## Fazit
Das Patentrecht ist für Fachinformatiker von großer Bedeutung, insbesondere bei der Entwicklung innovativer Softwarelösungen und Technologien. Ein fundiertes Wissen über die Patentierbarkeit und die Rechte des Patentinhabers ist essenziell, um **geistiges Eigentum** effektiv zu schützen.


## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Vorgehensweise im **kontinuierlichen Verbesserungsprozess**
- Weiterentwicklung von Produkten / Dienstleistungen, Fehler-Ursache-Analyse


## Schritte

1. **Plan** *(Planen)*: ***Ziele*** formulieren, welches ***Problem***? Welche ***Ressourcen***? Welche ***Lösung***? Wann ***Erfolg***?
2. **Do** *(Umsetzen)*: Umsetzung des ***Plans***
3. **Check** *(Überprüfen)*: ***Soll-Ist-Vergleich***, wurde ***Plan*** umgesetzt?
4. **Act** *(Handeln)*: Auf ***Ergebnis*** reagieren, Situation ***Verbessern***

## PDSA

3. **Study** *(Study)*: ***kein*** reiner ***Soll-Ist-Vergleich***, aus umgesetzten Lernen

## Vorteile
- wenig Anleitung auf Grund des **einfachen Aufbaus**
- **ständige Verbesserung** durch kreisförmige Konzeption
- iterativer Ansatz lässt **Kontrollen und Analysen** zu

## Nachteile
- **Unklare Definition** der Schritte kann zur falschen Ausführung führen
- Verbesserungen müssen **langfristig** bedacht sein
- Eher ein **reaktiver** als ein proaktiver Ansatz

## Quellen
> Was ist ein PDCA-Zyklus? Plan-Do-Check-Act einfach erklärt. (2024, September 10). Retrieved from https://der-prozessmanager.de/aktuell/wissensdatenbank/pdca-zyklus

- dezentrales Netzwerk
- alle Netzwerkgeräte kommunizieren **gleichberechtigt**
- **jeder** Netzwerkteilnehmer kann **Funktionen**, **Ressourcen** oder **Dienste** anbieten
- Peers können rollenbasiert eingeteilt werden
- **Anwendungsgebiete**
	- File Sharing (Torrents)
	- (Video-)Telefonie
	- Anonyme Netzwerke (Whisteblowing, ...)
- **Vorteile**
	- gute **Skalierbarkeit**
	- hohe **Ausfallsicherheit**
	- durch dezentrale Struktur **resistent**
	- **Aufgaben** können **flexibel** verteilt werden
	- Herkunft von Daten **schwer nachzuverfolgen**
	- prinzipiell **sicherer** als **[[Client-Server]]-Netzwerke**
- **Nachteile**
	- **sehr aufwendig** zu organisieren und zu verwalten
	- **Datenverfügbarkeit** abhängig von **Peers**
	- **Netzwerk** kann stark **belastet** werden in bestimmten Anwendungsfällen

## Quellen

> Schanze, R. (2021). Was ist Peer-to-Peer? – einfach erklärt. GIGA. Retrieved from https://www.giga.de/tipp/was-ist-peer-to-peer-einfach-erklaert

- **simulierter Angriff** auf ein IT-System, um Schwachstellen zu identifizieren, die von Angreifern ausgenutzt werden könnten.
- **Ziel**: Bewertung der Sicherheit eines Systems, Identifikation von Schwachstellen und Überprüfung der Wirksamkeit von Sicherheitsmaßnahmen.

## Arten von Penetration Tests
- **Black Box Testing**: Tester hat keine Informationen über das System. Simuliert einen externen Angreifer.
- **White Box Testing**: Tester hat vollständige Informationen über das System (z.B. Quellcode, Architektur). Simuliert einen internen Angreifer.
- **Gray Box Testing**: Tester hat teilweise Informationen über das System. Kombiniert Ansätze von Black und White Box Testing.

## Phasen eines Penetration Tests
1. **Planung und Vorbereitung**:
   - Zieldefinition: Was soll getestet werden? (z.B. Webanwendung, Netzwerk)
   - Genehmigungen einholen: Sicherstellen, dass der Test legal und autorisiert ist.
   - Umfang festlegen: Welche Systeme, Anwendungen und Daten sind in den Test einbezogen?
2. **Informationsbeschaffung**:
   - Sammlung von Informationen über das Zielsystem (z.B. IP-Adressen, Domain-Namen, offene Ports).
   - Tools: Nmap, Recon-ng, Maltego.
3. **Schwachstellenscanning**:
   - Identifikation von Schwachstellen durch automatisierte Scans.
   - Tools: Nessus, OpenVAS, Qualys.
4. **Exploitation**:
   - Ausnutzung identifizierter Schwachstellen, um Zugriff auf das System zu erlangen.
   - Tools: Metasploit, Burp Suite.
5. **Post-Exploitation**:
   - Analyse der erlangten Zugriffsrechte und Daten.
   - Ermittlung, wie tief ein Angreifer in das System eindringen könnte.
6. **Reporting**:
   - Dokumentation der Ergebnisse, identifizierten Schwachstellen und empfohlenen Maßnahmen.
   - Erstellung eines Abschlussberichts für die Stakeholder.
## Tools für Penetration Testing
- **Metasploit**: Framework zur Entwicklung und Ausführung von Exploits.
- **Burp Suite**: Tool zur Sicherheitsüberprüfung von Webanwendungen.
- **Nmap**: Netzwerk-Scanner zur Identifikation von offenen Ports und Diensten.
- **OWASP ZAP**: Open-Source-Tool zur Sicherheitsüberprüfung von Webanwendungen.

## Best Practices für Penetration Testing
- **Regelmäßige Tests**: Durchführung von Penetration Tests in regelmäßigen Abständen oder nach größeren Änderungen am System.
- **Ethische Richtlinien**: Einhaltung von ethischen Standards und gesetzlichen Vorgaben.
- **Schulung der Tester**: Sicherstellen, dass Tester über aktuelle Kenntnisse und Fähigkeiten verfügen.
- **Nachverfolgung der Ergebnisse**: Implementierung von Maßnahmen zur Behebung identifizierter Schwachstellen und Überprüfung der Wirksamkeit.
## Wichtige Begriffe
- **Exploit**: Ein Code oder ein Programm, das eine Schwachstelle ausnutzt.
- **Payload**: Der Teil eines Exploits, der die gewünschte Aktion ausführt (z.B. Zugriff auf ein System).
- **Risikobewertung**: Einschätzung der Schwere und Wahrscheinlichkeit von Sicherheitsrisiken.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **betrügerische Methode**, bei der Angreifer versuchen, sensible Informationen wie Benutzernamen, Passwörter, Kreditkartendaten oder andere persönliche Informationen von Opfern zu stehlen, indem sie sich **als vertrauenswürdige Quelle ausgeben**.

## Arten von Phishing
- **E-Mail-Phishing**: Die häufigste Form, bei der gefälschte E-Mails versendet werden, die wie legitime Nachrichten aussehen.
- **Spear-Phishing**: Zielgerichtete Angriffe auf spezifische Personen oder Organisationen, oft mit personalisierten Informationen.
- **Whaling**: Eine Form des Spear-Phishings, die sich auf hochrangige Führungskräfte (z.B. CEOs) konzentriert.
- **Smishing**: Phishing über SMS-Nachrichten, die Links oder Aufforderungen zur Preisgabe von Informationen enthalten.
- **Vishing**: Voice Phishing, bei dem Angreifer telefonisch versuchen, Informationen zu erlangen.

## Methoden
- **Falsche Webseiten**: Angreifer erstellen gefälschte Webseiten, die echten Seiten ähneln, um Benutzer zur Eingabe ihrer Daten zu verleiten.
- **Links und Anhänge**: E-Mails enthalten oft Links zu schädlichen Webseiten oder Anhänge, die Malware enthalten.
- **Dringlichkeit und Angst**: Phishing-Nachrichten erzeugen oft ein Gefühl der Dringlichkeit oder Angst, um Benutzer zu schnellen Entscheidungen zu drängen.

## Vorbeugung
- **Aufklärung**: Sensibilisierung der Benutzer für die Gefahren von Phishing und wie man verdächtige Nachrichten erkennt.
- **Überprüfung von Absendern**: E-Mails und Nachrichten sollten immer auf die Echtheit des Absenders überprüft werden.
- **Sichere Passwörter**: Verwendung starker, einzigartiger Passwörter und Aktivierung der Zwei-Faktor-Authentifizierung (2FA).
- **Antivirus-Software**: Einsatz von aktueller Sicherheitssoftware, die vor Phishing-Angriffen schützt.
- **Regelmäßige Updates**: Halten von Betriebssystemen und Anwendungen auf dem neuesten Stand, um Sicherheitslücken zu schließen.

## Auswirkungen
- **Finanzielle Verluste**: Verlust von Geld durch gestohlene Kontoinformationen oder betrügerische Transaktionen.
- **Identitätsdiebstahl**: Missbrauch persönlicher Daten zur Durchführung illegaler Aktivitäten.
- **Rufschädigung**: Unternehmen können durch erfolgreiche Phishing-Angriffe in ihrer Reputation geschädigt werden.
- **Rechtliche Konsequenzen**: Unternehmen können rechtlichen Konsequenzen ausgesetzt sein, wenn sie nicht ausreichend Schutzmaßnahmen ergreifen.

## Quellen
> Federal Trade Commission (FTC). (n.d.). How to Recognize and Avoid Phishing Scams. Retrieved from https://www.consumer.ftc.gov/articles/how-recognize-and-avoid-phishing-scams
> Anti-Phishing Working Group (APWG). (n.d.). Phishing Activity Trends Report. Retrieved from https://apwg.org/


- spielerisches Vorgehen bei Projektplanung
- SCRUM Poker
- Karten mit aufsteigenden Zahlen (0,1,2,3,5,8,13,20), Sonderkarten (Kaffepause, Ernsthafes Problem)

1. Moderator erläutert Vorgehen und Thema
2. Moderator nennt zu schätzende Aufgabe und steht für Rückfragen
3. Teilnehmer nehmen Schätzung vor und legen Karten mit passenden Zahlen verdeckt auf den Tisch
4. Alle Teilnehmer drehen Karten um
5. Höchsten und niedrigsten Schätzungen begründen Ihre Meinung
6. Weitere Schätzrunde
7. Schätz-Zyklen werden so lange durchgeführt bis alle gleich sind

- in Scrum sind Zahlen für Story Points, kann aber für andere Story Points benutzt werden

**Vorteile**
- spielerischer Ansatz
- strukturierter Ablauf
- unabhängige Expertenmeinungen
- gemeinsame Schätzungen
- Wissensverbreitung im Team


## Quellen

> https://www.youtube.com/watch?v=APDKb7Wo3gw

- **Prüfverfahren** zur **Sicherstellung der Datenqualität**, indem die **Glaubwürdigkeit** und **logische Konsistenz** von Daten überprüft wird.

## Zweck
- Erkennung von unplausiblen oder fehlerhaften Datensätzen
- Verbesserung der Datenqualität
- Vermeidung von Fehlentscheidungen aufgrund falscher Daten

## Arten von Plausibilitätskontrollen
1. **Wertebereichsprüfungen:**
	- Überprüfung, ob Werte innerhalb definierter Grenzen liegen
	- Beispiel: Alter einer Person zwischen 0 und 120 Jahren
2. **Formatprüfungen:**
	- Sicherstellung der korrekten Datenstruktur
	- Beispiel: Postleitzahlen müssen fünfstellig sein[2]
3. **Logische Prüfungen:**
	- Überprüfung der Konsistenz zwischen verschiedenen Datenelementen
	- Beispiel: Geburtsdatum muss vor dem aktuellen Datum liegen
4. **Relationskontrollen:**
	- Prüfung von Beziehungen zwischen verschiedenen Datenfeldern
	- Beispiel: Nettogewicht muss kleiner sein als Bruttogewicht[3]
5. **Vollständigkeitsprüfungen:**
	- Sicherstellung, dass alle erforderlichen Felder ausgefüllt sind
	- Beispiel: Pflichtfelder in einem Formular

## Implementierung
- Automatisierte Prüfungen bei der Dateneingabe
- Regelmäßige Überprüfungen des Datenbestands
- Einsatz spezieller Software-Tools zur Datenqualitätssicherung

## Vorteile
- Frühzeitige Erkennung von Datenfehlern
- Verbesserung der Entscheidungsgrundlage
- Kostenersparnis durch Vermeidung von Folgefehlern

## Herausforderungen
- Definition geeigneter Prüfregeln
- Balancierung zwischen Strenge der Kontrollen und Flexibilität
- Umgang mit Ausnahmen und Sonderfällen

## Best Practices
- Regelmäßige Aktualisierung der Prüfregeln
- Schulung der Mitarbeiter zur korrekten Dateneingabe
- Dokumentation der Plausibilitätskontrollen und ihrer Ergebnisse

- auch **semantisches Differential** genannt, Methode der **Umfragetechnik**
- Verwendet eine [[Likert-Skala]], typischerweise fünfstufig
- Basiert auf Gegensatzpaaren (z.B. "heiß" - "kalt")
- Häufig in Marktforschung, Kundenumfragen und Online-Fragebögen eingesetzt

## Erstellung eines Polaritätsprofils
1. Wähle eindeutige Antonyme als Gegensatzpaare
2. Berücksichtige die Zielgruppe bei der Auswahl der Adjektive
3. Stelle sicher, dass die Begriffspaare zur Fragestellung passen

## Arten der Skalen
- Verbal: z.B. von "weich" bis "hart"
- Numerisch: z.B. von -5 bis +5
- Symbolisch: z.B. von * bis *****
- Bipolar: z.B. von "sehr gut" bis "gar nicht gut"
- Unipolar: z.B. von "sehr verständlich" bis "sehr unverständlich"    

## Vorteile
- Ermöglicht tiefgründige Analyse von Motivationen und Einstellungen
- Bietet differenzierte Antwortmöglichkeiten
- Einfach auszuwerten

## Nachteile
- Begrenzte Aussagekraft bei komplexen Themen
- Mögliche Missverständnisse bei der Interpretation der Gegensatzpaare
- Sollte mit anderen Methoden kombiniert werden für umfassendere Ergebnisse
## Anwendungsbereiche
- Psychologische Umfragen
- Persönlichkeitstests
- Marktforschung
- Kundenzufriedenheitsanalysen
- Mitarbeiterbefragungen

- wichtiges Instrument aus **strategischen Managements**
- **Produkte und Dienstleistungen strategisch bewerten** und **Vorgehen plan**

## Boston Matrix
![[Pasted image 20240919090348.png]]
- Koordinatensystem, bestehend aus **vier Feldern** (X: Marktanteil, Y: Marktwachstum)
	1. **Poor Dogs**, kein Umsatz und wenig Wachstumspotenzial, Produktion einstellen; Desinvestitionsstrategie
	2. **Cash Cows**, etablierte und erfolgreiche Produkte ohne Investitionen, Weiterproduktion bis Verlust des Marktanteils; Geld wird für andere Investitionen *abgeschöpft*
	3. **Question Marks**, wenig Umsatz aber hohes Wachstum (Entscheidung ob Investiert oder geschlossen werden soll)
	4. **Stars**, Produkte mit höchsten Einnahmen, weitere Investitionen müssen getätigt werden
- jedes Produkt kann einer Kategorie zugeordnet werden und bietet **Überblick**

## Schritte
1. alle Daten sammlen
	- eigenes und Angebot der Konkurrenz aufschreiben
	- Umsatz
	- Marktanteil
	- Marktwachstum
2. Grafik erstellen
	- Produkte und Dienstleistungen in passendes Feld eintragen
3. Erkenntnisse ableiten
	- gutes Übersicht über Angebot
	- Stärken und Schwächen werden deutlich
	- z.B. mittels [[SWOT-Analyse]]

## Vorteile
- **Handlungsstrategie** für jedes Feld
- **einfache Darstellung** komplexer Sachverhalte
- gute **Übersicht** über eigene Marktsituation und Konkurrenz

## Nachteile
- Vernachlässigung **komplexer Faktoren**
- nur für Produkte mit **typischem Lebenszyklus**
- Handlungsstrategien **nicht für alle Produkte anwendbar**

## Quellen

> Portfolioanalyse. (2023, January 12). Retrieved from https://studyflix.de/wirtschaft/portfolioanalyse-5950

## Grundlagen von PowerShell
- **Definition**: PowerShell ist eine **objektorientierte Skriptsprache und Shell**, die von Microsoft entwickelt wurde, um **Systemadministration** und **Automatisierung** zu erleichtern.
- **Zweck**: Ermöglicht die **Verwaltung von Windows-Systemen und -Anwendungen** durch Befehle und Skripte.

## Wichtige Befehle
- **`Get-Command`**: Listet alle verfügbaren Cmdlets, Funktionen und Aliase auf.
- **`Get-Help`**: Zeigt die Hilfe zu Cmdlets und Funktionen an.
- **`Get-Process`**: Listet alle laufenden Prozesse auf.
- **`Set-Location`**: Wechselt das Verzeichnis (entspricht `cd`).
- **`Copy-Item`**: Kopiert Dateien oder Verzeichnisse.
- **`Move-Item`**: Verschiebt oder benennt Dateien oder Verzeichnisse um.
- **`Remove-Item`**: Löscht Dateien oder Verzeichnisse.
- **`Write-Output`**: Gibt Text oder Variablen aus.

## Variablen
- **Definition**: Variablen speichern Daten, die in Skripten verwendet werden können.
- **Deklaration**: `$variableName = value` (z. B. `$name = "Welt"`).
- **Zugriff**: Mit `$variableName` (z. B. `Write-Output "Hallo, $name"`).

## Kontrollstrukturen
- **Bedingte Anweisungen**: 
  - `if ($condition) { ... }`
  - `switch`-Anweisung für mehrere Bedingungen.
  
- **Schleifen**:
  - `for`-Schleife: `for ($i = 1; $i -le 5; $i++) { ... }`
  - `while`-Schleife: `while ($condition) { ... }`

## Funktionen
- **Definition**: Funktionen gruppieren Befehle zur Wiederverwendung.
- **Syntax**: 
  ```powershell
  function FunctionName {
      # Befehle
  }
  ```

## Skripterstellung
- **Dateiendung**: PowerShell-Skripte haben die Endung `.ps1`.
- **Ausführen**: Skripte können mit `.\script.ps1` ausgeführt werden.
- **Ausführungsrichtlinie**: Möglicherweise muss die Ausführungsrichtlinie geändert werden (`Set-ExecutionPolicy`), um Skripte auszuführen.

## Nützliche Tipps
- **Tab-Vervollständigung**: Automatisches Vervollständigen von Cmdlets und Dateinamen durch Drücken der Tab-Taste.
- **Verlauf**: Mit den Pfeiltasten durch den Befehlsverlauf navigieren.
- **Hilfe**: `Get-Help <Cmdlet>` für die Handbuchseite eines Cmdlets.

## Fazit
PowerShell ist ein leistungsfähiges Werkzeug zur Automatisierung und Verwaltung von Windows-Systemen. Ein grundlegendes Verständnis der Cmdlets, Variablen und Kontrollstrukturen ist entscheidend für die effektive Nutzung von PowerShell in der Systemadministration und Programmierung.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Netzwerksegmentierung
- Trennung des Netzwerks in logische Subbereiche
- Reduziert Angriffsfläche und erschwert laterale Bewegung von Angreifern
- Umsetzung durch VLANs, Firewalls zwischen Segmenten
- Kritische Systeme in eigenen Segmenten isolieren

## Firewall-Konfiguration
- Eingehenden und ausgehenden Datenverkehr filtern
- Whitelisting-Ansatz: Nur explizit erlaubte Verbindungen zulassen
- Regelmäßige Überprüfung und Anpassung der Regeln
- Einsatz von Next-Generation Firewalls mit erweiterten Funktionen

## Intrusion Detection/Prevention Systeme (IDS/IPS)
- Überwachung des Netzwerkverkehrs auf verdächtige Aktivitäten
- IDS: Erkennung und Meldung von Auffälligkeiten
- IPS: Automatische Abwehr erkannter Angriffe
- Regelmäßige Aktualisierung der Signaturen

## Systemhärtung

### Deaktivierung unnötiger Dienste und Ports
- Nur benötigte Dienste und Anwendungen aktivieren
- Offene Ports auf ein Minimum reduzieren
- Regelmäßige Überprüfung mit Port-Scannern

### Sichere Konfiguration von Betriebssystemen
- Aktivierung von Sicherheitsfeatures (z.B. DEP, ASLR)
- Restriktive Benutzerrechte und Zugriffskontrollen
- Regelmäßige Installation von Sicherheitsupdates

### Application Whitelisting
- Nur zugelassene Anwendungen dürfen ausgeführt werden
- Verhinderung der Ausführung von Schadsoftware
- Implementierung über Gruppenrichtlinien oder spezielle Software

## Zugriffskontrolle

### Starke Authentifizierung
- Komplexe Passwortrichtlinien durchsetzen
- Implementierung von Zwei-Faktor-Authentifizierung (2FA)
- Einsatz von Single Sign-On (SSO) Lösungen

### Privileged Access Management (PAM)
- Verwaltung und Überwachung privilegierter Konten
- Just-in-Time-Zugriff auf administrative Rechte
- Protokollierung aller Aktivitäten mit erhöhten Rechten

### Rollenbasierte Zugriffskontrolle (RBAC)
- Zuweisung von Berechtigungen basierend auf Rollen
- Regelmäßige Überprüfung und Anpassung der Zugriffsrechte
- Implementierung des Prinzips der geringsten Privilegien

## Datensicherheit

### Datenverschlüsselung
- Verschlüsselung sensibler Daten im Ruhezustand und bei der Übertragung
- Einsatz starker Verschlüsselungsalgorithmen (z.B. AES-256)
- Sichere Verwaltung von Schlüsseln und Zertifikaten

### Regelmäßige Backups
- Implementierung der 3-2-1 Backup-Strategie
- Verschlüsselung von Backups
- Regelmäßige Tests der Wiederherstellungsprozesse

### Data Loss Prevention (DLP)
- Identifikation und Schutz sensibler Daten
- Verhinderung unbeabsichtigter oder böswilliger Datenlecks
- Überwachung von Datenübertragungen und -zugriffen

## Schulung und Sensibilisierung

### Mitarbeiterschulungen
- Regelmäßige Schulungen zu IT-Sicherheitsthemen
- Sensibilisierung für Social Engineering und Phishing-Angriffe
- Durchführung von Phishing-Simulationen

### Sicherheitsrichtlinien
- Erstellung und Kommunikation klarer IT-Sicherheitsrichtlinien
- Regelmäßige Aktualisierung der Richtlinien
- Durchsetzung der Richtlinien durch technische Maßnahmen

## Schwachstellenmanagement

### Regelmäßige Sicherheitsaudits
- Durchführung von Penetrationstests und Vulnerability Scans
- Identifikation und Priorisierung von Schwachstellen
- Erstellung und Umsetzung von Maßnahmenplänen

### Patch-Management
- Zeitnahe Installation von Sicherheitsupdates
- Automatisierung des Patch-Prozesses wo möglich
- Testen von Patches vor dem Einspielen in Produktivumgebungen

## Netzwerküberwachung

### Security Information and Event Management (SIEM)
- Zentralisierte Sammlung und Analyse von Sicherheitsereignissen
- Erkennung von Anomalien und potenziellen Bedrohungen
- Automatisierte Alarmierung bei Sicherheitsvorfällen

### Netzwerk-Monitoring
- Kontinuierliche Überwachung des Netzwerkverkehrs
- Erkennung ungewöhnlicher Muster oder Aktivitäten
- Einsatz von Netzwerk-Analyzern und Protokollierungstools


## Definition
- **Predictive Maintenance (PdM)**: **Vorhersage von Wartungsbedarf** basierend auf Datenanalysen.
- Ziel: **Minimierung von Ausfallzeiten** und **Wartungskosten**.

## Wichtige Konzepte
- **Datenanalyse**: Nutzung von Sensordaten zur Identifikation von Mustern.
- **Maschinelles Lernen**: Algorithmen zur Vorhersage von Ausfällen.
- **IoT (Internet of Things)**: Vernetzung von Maschinen zur Datensammlung.
- **Zustandsüberwachung**: Echtzeit-Überwachung von Maschinenzuständen.

## Vorteile
- **Kosteneffizienz**: Reduzierung ungeplanter Ausfälle.
- **Lebensdauerverlängerung**: Optimierung der Wartungsintervalle.
- **Ressourcenschonung**: Effizienter Einsatz von Materialien und Personal.

## Herausforderungen
- **Datenqualität**: Notwendigkeit von präzisen und vollständigen Daten.
- **Integration**: Einbindung in bestehende Systeme und Prozesse.
- **Fachwissen**: Bedarf an Experten für Datenanalyse und Maschinenkenntnisse.

## Anwendungsbeispiele
- **Fertigung**: Vorhersage von Maschinenverschleiß.
- **Transport**: Wartung von Fahrzeugflotten basierend auf Nutzungsdaten.
- **Energie**: Überwachung von Turbinen und Generatoren.

## Technologien
- **[[Big Data]]**: Verarbeitung großer Datenmengen.
- **[[Cloud-Computing]]**: Speicherung und Analyse von Daten in der Cloud.
- **[[Fog-Computing|Edge Computing]]**: Datenverarbeitung nahe der Quelle zur Echtzeitanalyse.

## Quellen

> DuckDuckGo. (2024). *ChatGPT: An AI language model*. Retrieved September 18, 2024, from https://www.duckduckgo.com/chatgpt

- **P**rojects **IN** **C**ontrolled **E**nvironments
- **prozessorientierte** und **skalierbare** **Projektmanagementmethode**
- basiert auf **7 Prinzipien**, **7 Themen**, **7 Prozesse** 
- **Best-Practice** Leitfaden für Projekte

## 7 Prinzipien

1. **Fortlaufende geschäftliche Rechtfertigung**
	- Projekt braucht **berechtigten Grund**
	- **dokumentierten** und **genehmigten** erwarteten **Nutzen**
2. **Lernen aus Erfahrung**
	- Erfahrungen aus **anderen Projekten / Quellen** gezielt **aufgenommen**
	- Erfahrung aus **laufendem Projekt festgehalten**
3. **Rollen, Verantwortlichkeiten und Beziehungen definieren**
	- definierte **Rollen / Verantwortlichkeiten**
	- Interessen vom **Unternehmen**, den **Benutzern** und **Lieferanten** werden vertreten
4. **Steuern über Managementphasen**
	- **Planung**, **Überwachung** und **Steuerung** nach Phasen gegliedert
5. **Steuern nach dem Ausnahmeprinzip**
	- je Produktziel werden **Toleranzen definiert**
	- Handlungsrahmen für delegierte Befugnisse
6. **Produktorientierung**
	- auf **Definition** und **Lieferung** von Produkten ausgerichtet
	- Schwerpunkt auf **Qualitätsanforderungen**
	- auch *Ergebnisorientierung*
7. **Anpassen an das Projekt**
	- **Flexibel** an Unternehmen / Projekt angepasst
	- Auf Anforderungen von Umgebung, Umfangs, Komplexität, Wichtigkeit, Leistungsfähigkeit und Risiko eingehen

## 7 Themen
1. Business Case **(Warum?)**
	1. jedes Produkt benötigt Business Case (*wirtschaftliche **Rechtfertigung***)
	2. Basis für Überprüfung des Projektnutzens nach Projektabschluss
2. Projekt-Organisation **(Wer?)**
	1. beschreibt Rollen und Verantwortlichkeiten
	2. Aufgaben und Kompetenzen klar geregelt
3. Qualität **(Was?)**
	1. erläutert wie die ersten Ideen **immer weiter ausgearbeitet** werden
	2. welche **Qualitätskriterien** erfüllt werden müssen
	3. wie stellt Projektmanagement sicher dass **Anforderungen erfüllt werden**
4. Pläne **(Wie? Wie viel? Wann?)**
	1. **einzelnen Schritte** zur Entwicklung der Pläne und **anzuwendenden PRINCE2 Techniken**
	2. **Grundlage** für **Kommunikation und Steuerung** 
5. Risiko **(Was, wenn?)**
	1. wie geht Projekt mit **Unsicherheiten** um?
6. Änderungen **(Was sind die Auswirkungen?)**
	1. wie werden Issues[^1] bewertet und behandelt
7. Fortschritt **(Wo stehen wir jetzt? Wohin gehen wir? Sollen wir weitermachen?)**
	1. fortlaufende **Kontrolle** der **Realisierbarkeit** der Pläne
	2. Entscheidungsprozess für Abnahme von Plänen, Beobachtung erzielter Ergebnisse und Eskalationsprozess für nicht erreichen

## 7 Prozesse
1. **Vorbereitung eines Projektes**
	1. Auftraggeber und Projektmanager ernennen
	2. Vorhandene Erfahrungen erfassen
	3. Projektmanagement-Team entwerfen und ernennen
	4. Business-Case-Entwurf erstellen
	5. Projektlösungsansatz auswählen und Projektbeschreibung zusammenstellen
	6. Initiierungsphase planen
2. **Lenkung eines Projektes**
	1. Initiierung freigeben
	2. Projekt freigeben
	3. Phasen- oder Ausnahmeplan freigeben
	4. Ad-hoc-Anweisung geben
	5. projektabschluss freigeben
3. **Initiierung eines Projektes**
	1. Anpassungsanforderungen festlegen
	2. Risikomanagement-Ansatz erstellen
	3. Projektplan erstellen
	4. ...
4. **Steuerung der Phasen**
	1. Arbeitspaket freigeben
	2. Status eines Arbeitspakets prüfen
	3. Abgeschlossene Arbeitspakete entgegennehmen
5. **Management der Produktlieferung**
	1. Arbeitspaket annehmen
	2. Arbeitspaket ausführen
	3. Arbeitspaket abliefern
6. **Management der Phasenübergänge**
	1. Nächste Managementphase planen
	2. Projektplan aktualisieren
	3. Business Case aktualisieren
7. **Abschluss eines Projektes**
	1. Produkte übergeben
	2. Projekt überwarten
	3. Projektabschluss empfehlen

## Stärken
- **Nutzenorientiert**
- **standardisierte Projekte**
- **aktives Stakeholdermanagement**

## Schwächen
- hohe Flexibilität und starke Verankerung im Unternehmen erfordert **hohe zusätzliche Investitionskosten**
- **branchenabhängige Spezialistenaspekte** werden **nicht berücksichtigt**
- **Komplex** gegenüber SCRUM o. Ä.

[^1:] allgemeine Probleme, Änderungsanträge, Produkt welches Spezifikationen nicht erfüllt
## Quellen

> Itpro. (2021, June 11). PRINCE2 - Seven Principles, Themes, and Processes Explained. Youtube. Retrieved from https://www.youtube.com/watch?v=d9Tecl1WZBk
>
>domendos. (2023). PRINCE2 - 7 Grundprinzipien, 7 Themen, 7 Prozesse | dieprojektmanager. dieprojektmanager. Retrieved from https://dieprojektmanager.com/prince2-7-grundprinzipien-themen-prozesse/#Die_7_Prozesse_von_PRINCE2
>
>Autoren der Wikimedia-Projekte. (2006, April 15). PRINCE2 – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=PRINCE2&oldid=248325742

- **Ablaufdiagramm** für **Computerprogramme**, grafische Darstellung zur Umsetzung eines **Algorithmuses**

## Elemente
![[Pasted image 20240911140817.png]]
- **Anfangs-/Endpunkt**
![[Pasted image 20240911140840.png]]
- **Kontrollfluss**
![[Pasted image 20240911140857.png]]
- **Operation**, Tätigkeit
![[Pasted image 20240911140914.png]]
- **Unterprogramm**, abfolge von nicht genauer definierten Anweisungen
![[Pasted image 20240911140949.png]]
- **Verzweigung**, Entscheidungen
![[Pasted image 20240911141008.png]]
- **Ein- und Ausgabe**

## Beispiel

![[Pasted image 20240911141021.png]]

## Quellen

> Autoren der Wikimedia-Projekte. (2004, March 22). Programmablaufplan – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Programmablaufplan&oldid=245655720

## Performance und Speicherverbrauch
- **Definition**: Die Effizienz, mit der eine Programmiersprache Aufgaben ausführt und Ressourcen nutzt.
- **Aspekte**:
	- **Kompilierte Sprachen** (z.B. C, C++): Bieten in der Regel höhere Performance und geringeren Speicherverbrauch, da der Code direkt in Maschinensprache übersetzt wird.
	- **Interpretierte Sprachen** (z.B. Python, Ruby): Können langsamer sein, da der Code zur Laufzeit interpretiert wird, was zu höherem Speicherverbrauch führen kann.
	- **Bytecode-Sprachen** (z.B. Java): Bieten eine Balance zwischen Performance und Portabilität, da sie in eine Zwischensprache kompiliert werden, die von einer virtuellen Maschine ausgeführt wird.

## Portabilität
- **Definition**: Die Fähigkeit, Software auf verschiedenen Plattformen ohne oder mit minimalen Änderungen auszuführen.
- **Aspekte**:
	- **Java**: Hohe Portabilität durch die Java Virtual Machine (JVM), die es ermöglicht, auf verschiedenen Systemen zu laufen.
	- **Skriptsprachen** (z.B. JavaScript): Oft plattformunabhängig, da sie in Webbrowsern ausgeführt werden.
	- **Kompilierte Sprachen**: Können plattformabhängig sein, es sei denn, sie sind speziell für mehrere Plattformen konzipiert (z.B. C# mit .NET Core).

## Frameworks/Bibliotheken
- **Definition**: Vorhandene Tools und Ressourcen, die die Entwicklung erleichtern und beschleunigen.
- **Aspekte**:
	- **Web-Entwicklung**: Sprachen wie JavaScript (mit Frameworks wie React oder Angular) sind ideal für die Frontend-Entwicklung.
	- **Datenanalyse**: Python bietet umfangreiche Bibliotheken (z.B. Pandas, NumPy), die die Datenverarbeitung erleichtern.
	- **Mobile Entwicklung**: Sprachen wie Swift (für iOS) und Kotlin (für Android) haben spezifische Frameworks, die die Entwicklung vereinfachen.

## Einsatz von integrierten Entwicklungsumgebungen (IDEs)
- **Definition**: Softwareanwendungen, die Entwicklern helfen, Code zu schreiben, zu testen und zu debuggen.
- **Aspekte**:
	- **IDEs für kompilierte Sprachen**: Visual Studio für C# oder Eclipse für Java bieten umfangreiche Funktionen zur Codevervollständigung und Fehlerbehebung.
	- **IDEs für Skriptsprachen**: PyCharm für Python oder WebStorm für JavaScript bieten spezifische Tools zur Unterstützung der jeweiligen Sprache.
	- **Benutzerfreundlichkeit**: Die Wahl einer Sprache kann auch von der Verfügbarkeit einer benutzerfreundlichen IDE abhängen.

## Aufwand
- **Definition**: Der Ressourcen- und Zeitaufwand, der für die Entwicklung und Wartung der Software erforderlich ist.
- **Aspekte**:
	- **Skriptsprachen**: Oft weniger Aufwand bei der Entwicklung, da sie schneller zu schreiben und zu testen sind (z.B. Python).
	- **Kompilierte Sprachen**: Höherer Aufwand in der Entwicklungsphase, da der Code kompiliert werden muss, aber oft effizienter in der Ausführung.
	- **Wartungsaufwand**: Abhängig von der Komplexität der Sprache und der verwendeten Frameworks/Bibliotheken.

## Know-how/Fachkenntnis
- **Definition**: Das vorhandene Wissen und die Erfahrung der Entwickler mit bestimmten Programmiersprachen.
- **Aspekte**:
	- **Verfügbarkeit von Entwicklern**: Die Wahl einer Sprache kann durch die Verfügbarkeit von Fachkräften beeinflusst werden (z.B. viele Entwickler für JavaScript).
	  - **Lernkurve**: Einige Sprachen (z.B. Haskell) haben eine steilere Lernkurve, während andere (z.B. Python) als einsteigerfreundlicher gelten.
	- **Community und Support**: Eine starke Community kann den Lernprozess erleichtern und Unterstützung bieten (z.B. große Community für JavaScript und Python).

## Definition eines Projekts
- Ein Projekt ist ein zeitlich begrenztes Vorhaben mit einem einzigartigen Ergebnis.
- Merkmale: Einmaligkeit, zeitliche Begrenzung, Zielorientierung, Ressourcenbeschränkung.

## Projektphasen
- **Initiierung**: Definition des Projekts, Zielsetzung, Machbarkeitsstudie.
- **Planung**: Detaillierte Planung von Aufgaben, Ressourcen, Zeitrahmen und Budget.
- **Durchführung**: Umsetzung der geplanten Aktivitäten, Koordination des Teams.
- **Überwachung und Kontrolle**: Fortschritt überwachen, Anpassungen vornehmen, Risiken managen.
- **Abschluss**: Projektbewertung, Dokumentation der Ergebnisse, Abschlussbericht.

## Sachebene vs. Beziehungsebene
### Sachebene
- **Definition**: Inhaltliche Aspekte der Kommunikation.
- **Beispiele**:
	- Projektstatus und Fortschritt
	- Budgetübersicht und Ressourcenzuweisung
	- Zeitplan und Meilensteine
	- Aufgabenverteilung und Verantwortlichkeiten
	- Risikoanalyse und -management

### Beziehungsebene
- **Definition**: Zwischenmenschliche Aspekte der Kommunikation.
- **Beispiele**:
	- Teamdynamik und Zusammenarbeit
	- Konflikte und deren Lösung
	- Feedbackkultur und Wertschätzung
	- Vertrauen und Respekt im Team
	- Motivation und Engagement der Teammitglieder

## Befugnisse des Projektleiters
- **Entscheidungsbefugnis**: Treffen von Entscheidungen, die den Projektverlauf betreffen.
- **Ressourcenzuweisung**: Verwaltung und Zuweisung von Ressourcen (Personal, Budget, Materialien).
- **Kommunikationsbefugnis**: Steuerung der Kommunikation innerhalb des Teams und an Stakeholder.
- **Konfliktmanagement**: Erkennen und Lösen von Konflikten.
- **Berichterstattung**: Erstellung und Kommunikation von Statusberichten.
- **Zugriff auf Informationen**: Zugang zu relevanten Informationen für Planung und Durchführung.

## Projektmanagement
- **Projektleiter**: Verantwortlich für Planung, Durchführung und Abschluss des Projekts.
- **Projektteam**: Gruppe von Personen, die an der Umsetzung des Projekts arbeiten.
- **Stakeholder**: Personen oder Gruppen mit Interesse am Projekt (z. B. Kunden, Sponsoren).

## Werkzeuge und Methoden
- **Gantt-Diagramm**: Visualisierung des Projektzeitplans.
- **Projektstrukturplan (PSP)**: Hierarchische Gliederung der Projektaufgaben.
- **Risikoanalyse**: Identifikation und Bewertung von Risiken.
- **Agile Methoden**: Flexibles Projektmanagement (z. B. Scrum, Kanban).

## Ressourcenmanagement
- **Personal**: Zuweisung von Teammitgliedern und deren Aufgaben.
- **Budget**: Finanzielle Mittel, die für das Projekt benötigt werden.
- **Materialien**: Notwendige Ressourcen und Werkzeuge für die Durchführung.

## Kommunikation im Projekt
- **Regelmäßige Meetings**: Austausch von Informationen, Statusupdates.
- **Dokumentation**: Protokolle, Berichte, Pläne zur Nachverfolgbarkeit.
- **Feedback**: Kontinuierliche Rückmeldungen zur Verbesserung.

## Risiken im Projekt
- **Identifikation**: Erkennen potenzieller Probleme.
- **Bewertung**: Einschätzung der Auswirkungen und Wahrscheinlichkeiten.
- **Management**: Strategien zur Risikominderung (z. B. Vermeidung, Übertragung, Akzeptanz).

## Erfolgskriterien
- **Zielerreichung**: Wurden die Projektziele erreicht?
- **Termintreue**: Wurde der Zeitrahmen eingehalten?
- **Budgeteinhaltung**: Wurde das Budget eingehalten?
- **Qualität**: Entspricht das Ergebnis den Qualitätsanforderungen?



**1. Definition von Projektrisiken:**
- Projektrisiken sind **potenzielle Ereignisse oder Umstände**, die **negative Auswirkungen auf die Projektziele** haben können, wie Zeit, Kosten, Qualität oder Umfang.

**2. Identifikation von Risiken:**
- **Interne Risiken:**
    - Technische Probleme, Ressourcenengpässe, Widerstand im Team.
- **Externe Risiken:**
    - Marktveränderungen, rechtliche Anforderungen, Lieferantenprobleme.

**3. Analyse der Risiken:**
- **Wahrscheinlichkeit und Auswirkungen:**
    - Bewerten Sie die Wahrscheinlichkeit des Eintretens und die potenziellen Auswirkungen auf das Projekt.
- **Priorisierung:**
    - Risiken nach ihrer Bedeutung priorisieren, um gezielt Maßnahmen zu entwickeln.

**4. Entwicklung von Maßnahmen:**
- **Risikovermeidung:**
    - Strategien entwickeln, um Risiken zu vermeiden (z. B. alternative Technologien).
- **Risikominderung:**
    - Maßnahmen zur Reduzierung der Auswirkungen (z. B. Schulungen, Backup-Systeme).
- **Risikotransfer:**
    - Risiken an Dritte übertragen (z. B. durch Versicherungen oder Outsourcing).

**5. Monitoring und Anpassung:**
- **Regelmäßige Überprüfung:**
    - Risiken kontinuierlich überwachen und bewerten.
- **Anpassung der Strategien:**
    - Maßnahmen basierend auf neuen Informationen oder Veränderungen im Projektumfeld anpassen.

Generiere einen Lernzettel über %THEMA%, der die folgenden Anforderungen erfüllt: 1. Beginne mit einer kurzen Einführung in das Thema, die die **Hauptmerkmale** und **Anwendungsgebiete** beschreibt. 2. Verwende eine flexible Struktur, die je nach Thema sinnvoll ist. 3. Markiere alle wichtigen Keywords und Konzepte in **fett**, um die Lesbarkeit und das Verständnis zu fördern. 4. Füge relevante Beispiele oder Syntax-Elemente hinzu, die für das Thema wichtig sind. Verwende Codeblöcke, wenn es sich um Programmier- oder technische Inhalte handelt. 5. Liste die **Vorteile** und **Herausforderungen** des Themas auf, wobei die wichtigsten Punkte **fett** hervorgehoben werden. 6. Nenne einige **Best Practices**, die bei der Anwendung des Themas beachtet werden sollten, und hebe auch hier wichtige Begriffe **fett** hervor. 7. Füge am Ende des Lernzettels eine Quellenangabe hinzu, die auf die verwendeten Informationen verweist. Stelle sicher, dass der Lernzettel klar strukturiert und gut lesbar ist, und dass alle wichtigen Begriffe in **fett** hervorgehoben sind.

- **Vermittler** zwischen einem Client und einem Server. Er **leitet Anfragen** des Clients weiter und kann dabei verschiedene Funktionen wie **Caching**, **Anonymisierung** und **Zugriffssteuerung** übernehmen.

## Arten von Proxy-Technologien
1. **HTTP Proxy:**
   - **Beschreibung:** Speziell für HTTP-Datenverkehr entwickelt. Verwendet, um Webinhalte zu cachen und den Internetzugang zu kontrollieren.
   - **Anwendungsfälle:** Caching von Webseiten, Zugangskontrolle in Unternehmensnetzwerken.
2. **HTTPS Proxy:**
   - **Beschreibung:** Arbeitet mit verschlüsseltem HTTPS-Datenverkehr. Erfordert spezielle Konfiguration, um den verschlüsselten Datenverkehr zu handhaben.
   - **Anwendungsfälle:** Sicherer Zugriff auf Webinhalte, Filterung von HTTPS-Seiten.
3. **SOCKS Proxy (SOCKS5):**
   - **Beschreibung:** Ein allgemeiner Proxy, der mit verschiedenen Netzwerkprotokollen (TCP, UDP) arbeiten kann. Unterstützt Authentifizierung und bietet mehr Flexibilität als HTTP-Proxys.
   - **Anwendungsfälle:** Anwendungen, die nicht HTTP-basiert sind, wie E-Mail, Torrenting oder Spiele.
4. **Transparent Proxy:**
   - **Beschreibung:** Leitet Anfragen weiter, ohne dass der Benutzer dies bemerkt. Ideal für Netzwerke, in denen der Datenverkehr überwacht oder gefiltert werden soll.
   - **Anwendungsfälle:** Schulen oder öffentliche WLANs, wo Überwachung erforderlich ist.
5. **Reverse Proxy:**
   - **Beschreibung:** Steht zwischen dem Internet und einem internen Netzwerk von Servern. Leitet Anfragen an die entsprechenden Backend-Server weiter.
   - **Anwendungsfälle:** Lastverteilung, SSL-Offloading, Schutz interner Server.

## Vorteile
- **Anonymität:** Schutz der Benutzeridentität durch Verschleierung der IP-Adresse.
- **Sicherheitsmaßnahmen:** Filterung von schädlichen Inhalten und Schutz vor Angriffen.
- **Leistungssteigerung:** Durch Caching und Lastverteilung wird die Netzwerkleistung verbessert.

## Nachteile

- **Komplexität:** Die Einrichtung und Verwaltung von Proxy-Servern kann komplex sein, insbesondere bei der Konfiguration von HTTPS-Proxys.
- **Leistungsengpässe:** Ein schlecht konfigurierter Proxy kann zu Leistungsengpässen führen, da er ein zusätzlicher Punkt im Datenverkehrsfluss ist.
- **Sicherheitsrisiken:** Wenn ein Proxy-Server nicht ordnungsgemäß gesichert ist, kann er selbst ein Ziel für Angriffe werden.
- **Abhängigkeit:** Die Nutzung von Proxy-Servern kann zu einer Abhängigkeit führen, insbesondere wenn sie für die Filterung und Überwachung des Datenverkehrs eingesetzt werden.
## Quellen

> Erstelle mir einen Lernzettel zum Thema "Proxy". Der Lernzettel soll zum Lernen für eine Fachinformatiker Abschlussprüfung sein 🔎 You.com | AI for workplace productivity. (2024, September 20). Retrieved from https://you.com/search?q=Erstelle+mir+einen+Lernzettel+zum+Thema+%22Proxy%22.+Der+Lernzettel+soll+zum+Lernen+f%C3%BCr+eine+Fachinformatiker+Abschlusspr%C3%BCfung+sein&fromSearchBar=true&tbm=youchat&cid=c0_f6bc29f9-fbde-43ec-9c73-d0a5e319e2e2&chatMode=custom

## Quantitative Bewertungsmethoden

### Kennzahlen und Metriken
- **Durchliaufzeit**: Messung der Zeit, die ein Prozess von der Antragstellung bis zur Genehmigung benötigt.
- **Fehlerrate**: Prozentualer Anteil fehlerhafter Anträge oder Verzögerungen im Prozess.
- **Produktivität**: Anzahl der bearbeiteten Urlaubsanträge pro Zeiteinheit oder Ressourceneinsatz.
- **Kosten pro Einheit**: Berechnung der Kosten für jeden Prozessschritt, z.B. Verwaltungskosten pro Urlaubsantrag.

### Statistische Verfahren
- Verwendung von Methoden wie **Propensity Score Matching** oder **Differenz-in-Differenzen** zur Analyse von Prozessveränderungen.
- **Regressionsanalysen** zur Identifikation von Einflussfaktoren auf die Prozessleistung, z.B. Zeit bis zur Genehmigung in Abhängigkeit von der Anzahl der Anträge.

## Qualitative Bewertungsmethoden

### Beschreibende Techniken
- Detaillierte Dokumentation der einzelnen Prozessschritte, einschließlich der Identifikation von Engpässen.
- Erfassung von Schnittstellen und Abhängigkeiten zwischen Prozessschritten, um die Interaktion zwischen den Beteiligten zu verstehen.

### Bewertende Techniken
- **Kundenzufriedenheitsumfragen**: Bewertung der Prozessergebnisse aus Sicht der Mitarbeiter, die Urlaub beantragen.
- **Mitarbeiterfeedback**: Einschätzungen zur Effizienz und Effektivität der einzelnen Prozessschritte, z.B. zur Unterschrift des Vorgesetzten.
- **Experteninterviews**: Qualitative Beurteilung durch Fachexperten, um Verbesserungspotenziale zu identifizieren.

## Kombinierte Ansätze

### Nutzwertanalyse
- Bewertung von Prozessalternativen anhand verschiedener Kriterien, z.B. Zeit, Kosten und Zufriedenheit.
- Gewichtung qualitativer und quantitativer Faktoren, um eine fundierte Entscheidungsbasis zu schaffen.

### Prozess-Benchmarking
- Vergleich eigener Prozesse mit Best Practices der Branche, um Verbesserungspotenziale zu erkennen.
- Kombination quantitativer Leistungsdaten (z.B. Durchlaufzeiten) mit qualitativen Einschätzungen (z.B. Mitarbeiterzufriedenheit).

## Anwendung in der Praxis
- Wahl der Methode abhängig von der Art des Prozesses, den verfügbaren Daten und dem Bewertungsziel.
- Oft Kombination qualitativer und quantitativer Methoden für eine ganzheitliche Bewertung des Urlaubsantragsprozesses.
- Berücksichtigung von Kosten-Nutzen-Aspekten bei der Methodenwahl, um die Effizienz und Effektivität des Prozesses zu maximieren.


Prozessindikatoren sind **spezifische, messbare Größen**, die den **Verlauf**, die **Effizienz** und die **Qualität von Prozessen** innerhalb einer Organisation darstellen. Sie ermöglichen die **Überwachung der Leistung** einzelner Abläufe und helfen, Optimierungspotenziale zu identifizieren.

## Bedeutung von Prozessindikatoren
- **Qualitätskontrolle**: Überwachung der Prozessqualität und Identifikation von Abweichungen.
- **Effizienzsteigerung**: Unterstützung bei der Identifikation von Engpässen und Ineffizienzen.
- **Transparenz**: Schaffung von Klarheit über Prozessabläufe und -ergebnisse.
- **Kontinuierliche Verbesserung**: Grundlage für die Implementierung von Verbesserungsmaßnahmen.

## Arten von Prozessindikatoren
1. **Input-Indikatoren**: 
   - Messen die Ressourcen, die in einen Prozess eingehen.
   - **Beispiele**: 
     - Zeitaufwand für die Vorbereitung eines Prozesses.
     - Materialverbrauch pro Produktionseinheit.
2. **Output-Indikatoren**: 
   - Messen die Ergebnisse eines Prozesses.
   - **Beispiele**: 
     - Anzahl der produzierten Einheiten pro Zeiteinheit.
     - Anzahl der erfolgreich abgeschlossenen Aufträge.
3. **Outcome-Indikatoren**: 
   - Bewerten die Auswirkungen eines Prozesses auf die Zielgruppe.
   - **Beispiele**: 
     - Kundenzufriedenheit nach Abschluss eines Prozesses.
     - Rücklaufquote von fehlerhaften Produkten.
4. **Prozessindikatoren**: 
   - Messen die Effizienz und Effektivität des Prozesses selbst.
   - **Beispiele**: 
     - Fehlerquote: Anteil der fehlerhaften Produkte oder Dienstleistungen im Verhältnis zur Gesamtproduktion.
     - Durchlaufzeit: Zeit, die benötigt wird, um einen Prozess von Anfang bis Ende abzuschließen.

## Merkmale guter Prozessindikatoren
- **Messbarkeit**: Indikatoren sollten quantifizierbar sein.
- **Relevanz**: Sie müssen für die Zielsetzung des Prozesses von Bedeutung sein.
- **Verfügbarkeit**: Daten sollten leicht und regelmäßig verfügbar sein.
- **Eindeutigkeit**: Klare Definition und Verständlichkeit der Indikatoren.

## Beispiele für spezifische Prozessindikatoren
- **Durchlaufzeit**: 
	- Definition: Zeit, die benötigt wird, um einen Prozess von Anfang bis Ende abzuschließen.
	- Anwendung: Identifikation von Verzögerungen und Optimierung der Prozessgeschwindigkeit.
- **Fehlerquote**: 
	- Definition: Anteil der fehlerhaften Produkte oder Dienstleistungen im Verhältnis zur Gesamtproduktion.
	- Anwendung: Überwachung der Qualität und Identifikation von Verbesserungsbereichen.
- **Ressourcenauslastung**: 
	- Definition: Verhältnis der tatsächlich genutzten Ressourcen zu den verfügbaren Ressourcen.
	- Anwendung: Analyse der Ressourcennutzung zur Steigerung der Effizienz.
- **Bearbeitungszeit**: 
	- Definition: Zeit, die benötigt wird, um eine Anfrage oder einen Auftrag zu bearbeiten.
	- Anwendung: Verbesserung der Reaktionszeiten und Kundenzufriedenheit.

## Anwendung von Prozessindikatoren
- **Prozessoptimierung**: Identifikation von Engpässen und Verbesserungspotenzialen.
- **Benchmarking**: Vergleich der eigenen Prozesse mit Best Practices oder Wettbewerbern.
- **Reporting**: Regelmäßige Berichterstattung über Prozessleistungen an Stakeholder.


- Darstellungsform der **Ablauforganisation** eines Unternehmens
- Was passiert **im** Unternehmen?
- nicht normiert

## Gliederung
1. **Leistungs-/ Kernprozesse**, Kundenanforderungen ermitteln, Entwicklung neuer Produkte, *Produktion* der Ware, ...
	1. erfüllen *externe* Kundenanforderungen
	2. Stellen die *Wertschöpfung* dar
2. **Führungs- / Managementprozesse**
	1. *steuern* das Gesamtunternehmen
	2. legen generelle Richtlinien fest
	3. Koordinieren alle Prozesse im Prozessmodell
3. **Unterstützungs- / Supportprozesse**
	1. Erfüllen *interne* Kundenanforderungen
	2. Schaffen erforderlicher Rahmenbedingungen (z.B. IT-Prozesse, Personal-Prozesse)
	3. erfüllen gesetzliche Auflagen (z.B. Rechnungswesen, ...)

![[Pasted image 20240917071136.png]]
![[Pasted image 20240917071528.png]]

## Quellen

> BPM&O GmbH. (2021, June 09). Prozesslandkarte (Definition | Darstellung | Beispiel). Youtube. Retrieved from https://www.youtube.com/watch?v=zuLm4jd-rK0
> caesar. academy. (2022, November 29). Prozesslandkarte - 👨🏼‍🎓 EINFACH ERKLÄRT 👩🏼‍🎓. Youtube. Retrieved from https://www.youtube.com/watch?v=dO4A359BTB8

- **definierte Übergabepunkte** zwischen verschiedenen Prozessen oder Systemen, die den Austausch von Informationen, Daten oder Materialien ermöglichen.
- Ermöglichen nahtlose Integration verschiedener Systeme und Prozesse
- Fördern Effizienz und Produktivität
- Reduzieren Fehler und Informationsverluste
- Verbessern die Zusammenarbeit zwischen Abteilungen und Teams

## Arten
1. **Technische Schnittstellen**
	- APIs (Application Programming Interfaces)
	- Datenbanken
	- Dateischnittstellen
	- Netzwerkprotokolle
2. **Organisatorische Schnittstellen**
	- Abteilungsübergänge
	- Zuständigkeitswechsel
	- Projektübergaben
3. **Menschliche Schnittstellen**
	- Kommunikation zwischen Mitarbeitern
	- Übergabe von Aufgaben
	- Meetings und Besprechungen

## Herausforderungen
- Kompatibilitätsprobleme zwischen Systemen
- Datensicherheit und Datenschutz
- Komplexität bei der Integration verschiedener Technologien
- Notwendigkeit klarer Definitionen und Standards

## Best Practices
1. Klare Dokumentation der Schnittstellen
2. Standardisierung von Datenformaten und Protokollen
3. Regelmäßige Überprüfung und Optimierung
4. Schulung der Mitarbeiter im Umgang mit Schnittstellen
5. Implementierung von Fehlerbehandlung und Logging

## Analyse von Prozessschnittstellen
1. Identifikation aller relevanten Schnittstellen
2. Bewertung der Effizienz und Effektivität
3. Erkennung von Engpässen und Schwachstellen
4. Entwicklung von Verbesserungsvorschlägen

## Werkzeuge für Schnittstellenmanagement
- [[BPMN]] (Business Process Model and Notation)
- [[UML|UML (Unified Modeling Language)]]
- [[eEPK]]
- API-Management-Tools
- Prozessmanagement-Software



## Parität
- **Parität**: Ein Verfahren zur **Überprüfung von Daten oder Prozessen**, um deren Korrektheit und Konsistenz sicherzustellen.

### Anwendung von Parität
- **Ziel**: Sicherstellen, dass zwei oder mehr Implementierungen eines Prozesses oder Algorithmus identische Ergebnisse liefern.
- **Kontext**: Besonders relevant in der Softwareentwicklung, wo unterschiedliche Programmieransätze oder -techniken verglichen werden.

### Vorgehensweise
- **Vergleich von Implementierungen**:
  - Zwei verschiedene Versionen eines Algorithmus werden entwickelt.
  - Die Ausgaben beider Versionen werden unter identischen Bedingungen getestet.
  - Abweichungen in den Ergebnissen werden analysiert und gegebenenfalls korrigiert.

### Vorteile der Parität
- **Fehleridentifikation**: Ermöglicht das frühzeitige Erkennen von Fehlern in der Implementierung.
- **Vertrauenswürdigkeit**: Erhöht das Vertrauen in die Ergebnisse durch unabhängige Überprüfung.
- **Konsistenz**: Stellt sicher, dass verschiedene Systeme oder Komponenten gleichwertige Ergebnisse liefern.

### Beispiele für Parität
- **Softwareentwicklung**: Vergleich von zwei Algorithmen zur Berechnung von Daten (z. B. Sortieralgorithmen).
- **Datenübertragung**: Überprüfung von Datenintegrität durch Vergleich von gesendeten und empfangenen Daten.

### Herausforderungen
- **Komplexität**: Der Vergleich kann bei komplexen Systemen zeitaufwendig und schwierig sein.
- **Ressourcen**: Erfordert zusätzliche Ressourcen für die Entwicklung und den Test mehrerer Implementierungen.

## Redundanz
- Einsatz **zusätzlicher Komponenten, Systeme oder Verfahren**, um die Zuverlässigkeit und Qualität von Produkten oder Dienstleistungen zu erhöhen.

### Anwendung von Redundanz
- **Ziel**: Minimierung von Fehlern und Ausfällen durch die Bereitstellung von Alternativen oder Backup-Systemen.
- **Kontext**: Häufig in kritischen Systemen, wo Ausfälle schwerwiegende Folgen haben können (z. B. in der Luftfahrt, Medizintechnik, IT).

### Vorgehensweise
- **Implementierung zusätzlicher Komponenten**:
  - Verwendung mehrerer Sensoren zur Messung eines Wertes (z. B. Temperatur, Druck).
  - Einsatz von Backup-Servern, um Datenverlust bei einem Systemausfall zu verhindern.
- **Datenredundanz**:
  - Speicherung von Daten an mehreren Orten (z. B. Cloud-Speicher, lokale Server), um Datenintegrität und -verfügbarkeit zu gewährleisten.

### Vorteile der Redundanz
- **Erhöhte Zuverlässigkeit**: Redundante Systeme können bei Ausfällen nahtlos übernehmen, was die Betriebszeit erhöht.
- **Fehlervermeidung**: Durch zusätzliche Prüfungen und Systeme können Fehler frühzeitig erkannt und behoben werden.
- **Sicherheit**: Schutz vor Datenverlust und Systemausfällen, was besonders in sicherheitskritischen Bereichen wichtig ist.

### Beispiele für Redundanz
- **IT-Systeme**: Verwendung von RAID (Redundant Array of Independent Disks) zur Sicherstellung der Datensicherheit.
- **Luftfahrt**: Doppelte oder dreifache Systeme in Flugzeugen (z. B. redundante Steuerungssysteme), um die Sicherheit zu erhöhen.
- **Telekommunikation**: Mehrere Kommunikationskanäle, um die Erreichbarkeit auch bei Ausfällen zu gewährleisten.

### Herausforderungen
- **Kosten**: Implementierung von Redundanz kann teuer sein, da zusätzliche Ressourcen benötigt werden.
- **Komplexität**: Redundante Systeme können die Komplexität erhöhen und die Wartung erschweren.
- **Management**: Erfordert sorgfältige Planung und Management, um sicherzustellen, dass redundante Systeme effektiv funktionieren.

## Grundlagen von Pseudocode
- **Definition**: Pseudocode ist eine i**nformelle, menschenlesbare Beschreibung eines Algorithmus** oder Programms, die **keine spezifische Programmiersprache** verwendet.
- **Zweck**: Dient dazu, die **Logik und Struktur eines Algorithmus klar und verständlich darzustellen**, bevor er in einer Programmiersprache implementiert wird.

## Wichtige Merkmale
- **Einfachheit**: Verwendet **einfache, klare Sprache**, um die Schritte eines Algorithmus zu beschreiben.
- **Struktur**: Nutzt gängige Programmierkonzepte wie **Schleifen, Bedingungen und Variablen**.
- **Unabhängigkeit**: Ist nicht an eine bestimmte Programmiersprache gebunden, was die Lesbarkeit und Verständlichkeit erhöht.

## Grundlegende Strukturen
- **Variablenzuweisung**: `SET variable TO value`
- **Bedingungen**: 
  - `IF condition THEN`
  - `ELSE`
  - `ENDIF`
  
- **Schleifen**:
  - `FOR each item IN collection DO`
  - `WHILE condition DO`
  
- **Funktionen**: 
  - `FUNCTION functionName(parameters)`

## Beispiel eines Pseudocodes
```
FUNCTION calculateSum(a, b)
    SET sum TO a + b
    RETURN sum
END FUNCTION

SET result TO calculateSum(5, 10)
PRINT result
```

## Vorteile von Pseudocode
- **Klarheit**: Erleichtert das Verständnis komplexer Algorithmen.
- **Planung**: Hilft bei der Planung und Strukturierung von Programmen, bevor sie codiert werden.
- **Kommunikation**: Ermöglicht die Kommunikation von Ideen zwischen Entwicklern, auch wenn sie unterschiedliche Programmiersprachen verwenden.

## Fazit
Pseudocode ist ein nützliches Werkzeug zur Darstellung von Algorithmen und zur Planung von Programmen. Ein grundlegendes Verständnis der Struktur und der Merkmale von Pseudocode ist wichtig, um die Logik von Programmen effektiv zu entwickeln und zu kommunizieren.


## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **hochgradig lesbare, interpretierte Programmiersprache**, die für ihre **Einfachheit und Vielseitigkeit** bekannt ist. Sie wird häufig in Webentwicklung, **Datenanalyse**, **künstlicher Intelligenz**, wissenschaftlichem Rechnen und Automatisierung eingesetzt.

## Merkmale von Python
- **Einfachheit**: Klare und leicht verständliche Syntax, die das Lernen und die Wartung von Code erleichtert.
- **Dynamische Typisierung**: Variablen müssen nicht deklariert werden, und der Datentyp wird zur Laufzeit bestimmt.
- **Umfangreiche Standardbibliothek**: Bietet viele Module und Funktionen, die die Entwicklung beschleunigen.
- **Plattformunabhängigkeit**: Python-Code kann auf verschiedenen Betriebssystemen (Windows, macOS, Linux) ausgeführt werden.

## Anwendungsgebiete
- **Webentwicklung**: Verwendung von Frameworks wie Django und Flask zur Erstellung von Webanwendungen.
- **Datenanalyse**: Einsatz von Bibliotheken wie Pandas, NumPy und Matplotlib zur Analyse und Visualisierung von Daten.
- **Künstliche Intelligenz und maschinelles Lernen**: Verwendung von Bibliotheken wie TensorFlow, Keras und scikit-learn zur Entwicklung von KI-Modellen.
- **Automatisierung und Skripting**: Automatisierung von Aufgaben und Prozessen durch Skripte.

## Grundlegende Syntax
- **Variablen**: 
  ```python
  x = 10
  name = "Alice"
  ```
- **Funktionen**:
  ```python
  def greet(name):
      return f"Hello, {name}!"
  ```
- **Kontrollstrukturen**:
  ```python
  if x > 5:
      print("x is greater than 5")
  else:
      print("x is 5 or less")
  ```
- **Schleifen**:
  ```python
  for i in range(5):
      print(i)
  ```

## Vorteile von Python
- **Lesbarkeit**: Klare Syntax fördert die Lesbarkeit und Wartbarkeit des Codes.
- **Große Community**: Eine aktive Community bietet Unterstützung, Tutorials und Bibliotheken.
- **Vielfältige Einsatzmöglichkeiten**: Von Webentwicklung über Datenanalyse bis hin zu KI und Automatisierung.

## Herausforderungen
- **Leistung**: Python kann in bestimmten Anwendungen langsamer sein als kompilierte Sprachen wie C oder C++.
- **Dynamische Typisierung**: Kann zu Laufzeitfehlern führen, die schwer zu debuggen sind.
- **Speicherverbrauch**: Python kann mehr Speicher benötigen als einige andere Programmiersprachen.

## Best Practices
- **Code-Dokumentation**: Verwendung von Docstrings und Kommentaren zur Dokumentation des Codes.
- **Modularität**: Aufteilung des Codes in Module und Funktionen zur Verbesserung der Struktur und Wiederverwendbarkeit.
- **Versionskontrolle**: Verwendung von Git zur Nachverfolgung von Änderungen und zur Zusammenarbeit mit anderen Entwicklern.
- **Testen**: Implementierung von Unit-Tests und Integrationstests zur Sicherstellung der Codequalität.

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Das quadratische Mittel, auch als RMS (Root Mean Square) bekannt, ist eine **statistische Maßzahl**, die häufig in der Mathematik und den Naturwissenschaften verwendet wird. Es wird verwendet, um den **durchschnittlichen Wert einer Menge von Zahlen** zu berechnen, wobei die Werte zuerst quadriert werden. Dies ist besonders nützlich, **wenn die Werte sowohl positive als auch negative Zahlen** umfassen, da das Quadrieren alle Werte positiv macht.

### Formel
$\bar{x}_{QM}=\sqrt{\dfrac{x^{2}_1 + x^{2}_2 + ... + x^{2}_n}{n}}$

### Anwendung
Das quadratische Mittel wird häufig in folgenden Bereichen verwendet:
- **Physik**: zur Berechnung von Durchschnittswerten von Wechselstrom (AC) Spannungen und Strömen.
- **Statistik**: zur Analyse von Daten, insbesondere wenn die Daten variieren und sowohl positive als auch negative Werte enthalten.
- **Ingenieurwesen**: zur Bewertung von Signalstärken und anderen Messwerten.

### Eigenschaften
- Das quadratische Mittel ist **immer größer oder gleich dem arithmetischen Mittel**.
- Es ist **empfindlich gegenüber Ausreißern**, da das Quadrieren der Werte große Abweichungen verstärkt.

### Beispiel
Gegeben seien die Werte: 3, 4, 5. Das quadratische Mittel wird wie folgt berechnet:

1. Quadriere die Werte: $3^2 = 9$, $4^2 = 16$, $5^2 = 25$
2. Berechne den Durchschnitt der quadrierten Werte: $\dfrac{9 + 16 + 25}{3} = \dfrac{50}{3} \approx 16.67$
3. Ziehe die Quadratwurzel: $\sqrt{16.67} \approx 4.08$

Das quadratische Mittel dieser Werte beträgt also etwa 4.08.

## Quellen

> By Daniel Jung, M. (2014, September 12). Quadratisches Mittel, Statistik | Mathe by Daniel Jung. Youtube. Retrieved from https://www.youtube.com/watch?v=rqJaaZrpGeQ
> DuckDuckGo. (2024, September 16). AI language model. Retrieved from https://duck.ai


## Qualitätskontrolle von Daten
Die Qualitätskontrolle ist ein **produktbezogener** Teil des Datenqualitätsmanagements, der sich auf die **Überprüfung verarbeiteter Daten** konzentriert.

### Hauptmerkmale
- Nachsorgend am Ende des Datenverarbeitungsprozesses
- Zielt auf die Gewährleistung der Qualität der verarbeiteten Daten
- Verwendet spezifische Prüfmechanismen für Daten

### Inhalte der Qualitätskontrolle
1. Überprüfung der Datengenauigkeit und -korrektheit
2. Stichprobenprüfung zur effizienten Überprüfung großer Datenmengen
3. Anwendung von Datenvalidierungsregeln
4. Vergleich der Daten mit festgelegten Qualitätsstandards
5. Identifizierung von Datenanomalien oder -fehlern

### Methoden
- Datenprofilierung
- Statistische Analysen
- Konsistenzprüfungen
- Datenbereinigungsprozesse

### Maßnahmen
- Verwendung standardisierter Testverfahren und -methoden
- Einhaltung gesetzlicher Vorgaben zum Datenschutz
- Detaillierter Abgleich zwischen Lasten- und Pflichtenheft
- Verwendung standardisierter Softwareentwicklungsmodelle wie z.B. SCRUM oder KANBAN
- Detaillierter und permanenter Abgleich des definierten Soll-Zustandes und dem Ist-Zustand
## Qualitätssicherung von Daten
Qualitätssicherung ist ein **prozessbezogener** Teil des Datenqualitätsmanagements, der alle **organisatorischen und technischen Maßnahmen** umfasst, um die Qualität der Daten langfristig zu gewährleisten.

### Hauptmerkmale
- Vorbeugend eingesetzt
- Fokussiert auf den gesamten Datenlebenszyklus
- Zielt auf die Schaffung von Vertrauen in die Erfüllung von Datenqualitätsanforderungen

### Aufgaben der Qualitätssicherung

#### Organisatorisch
- Beschreibung der Datenerfassungs- und -verarbeitungsprozesse
- Überprüfung von Dateneingabe- und -verarbeitungsschritten
- Festlegung von Datenqualitätsmetriken und -standards
- Durchführung von Mitarbeiterschulungen zur Datenqualität
- Erstellung von Richtlinien für Datenmanagement und -sicherheit
- Dokumentation von Datenqualitätsmaßnahmen

#### Technisch
- Überwachung von Datenverarbeitungsprozessen
- Implementierung von Datenvalidierungsregeln
- Durchführung von Datenqualitätstests
- Automatisierte Datenbereinigung und -anreicherung

#### Methoden
- Implementierung eines Datenqualitätsmanagementsystems
- Kontinuierliche Schulungen zur Datenqualität
- Datenqualitätskontrollen entlang des gesamten Datenlebenszyklus
- Einsatz von Datenqualitäts-Tools und -Frameworks

## Unterschiede
- Qualitätssicherung ist **prozessbezogen**, Qualitätskontrolle ist **produktbezogen**
- Qualitätssicherung wirkt vorbeugend, Qualitätskontrolle nachsorgend
- Qualitätssicherung umfasst den gesamten Datenlebenszyklus, Qualitätskontrolle konzentriert sich auf die verarbeiteten Daten

## Wirtschaftliche Aspekte bei der Auswahl von Datenqualitätsmaßnahmen

Bei der Behebung von Defiziten in der Datenqualität müssen wirtschaftliche Aspekte berücksichtigt werden:

- **Kosten-Nutzen-Analyse:** Abwägung zwischen den Kosten für Qualitätsverbesserungsmaßnahmen und dem erwarteten Nutzen
- **Ressourcenallokation:** Effiziente Verteilung von personellen und technischen Ressourcen für Datenqualitätsmaßnahmen
- **Priorisierung:** Fokussierung auf Maßnahmen mit dem größten wirtschaftlichen Nutzen oder zur Minimierung von Geschäftsrisiken
- **Return on Investment (ROI):** Berechnung des erwarteten Ertrags im Verhältnis zu den Investitionen in Datenqualitätsmaßnahmen
- **Opportunitätskosten:** Berücksichtigung der Kosten, die durch Nichthandeln oder alternative Maßnahmen entstehen würden
- **Langfristige Auswirkungen:** Bewertung der langfristigen wirtschaftlichen Vorteile verbesserter Datenqualität, wie erhöhte Effizienz und bessere Entscheidungsfindung


- **R**edundant **A**rray of **I**ndependent **D**isks
- RAID Controller wird benötigt

![[Pasted image 20240918094630.png]]

## RAID 0
- mind. 2 Festplatten
- teilt Daten in **gleichgroße Blöcke** auf
- Größe richtet sich nach **kleinster Festplatte**
- Blöcke sind i. d. R. **64 kByte** groß
- **Vorteile**
	- große Datenmengen verarbeiten
	- schnellere Lese- und Schreibprozesse
- **Nachteile**
	- Hohe Ausfallwahrscheinlichkeit
- **Formel**
	- $Kapazität=(Anzahl \space Festplatten) \times Festplattenkapazität$

## RAID 1
- mind. 2 Festplatten
- Daten werden parallel auf zwei Festplatten geschrieben
- Größe richtet sich nach **kleinster Festplatte**
- **Vorteile**
	- hohes Maß an Datensicherheit (ein Ausfall kann toleriert werden)
	- Lesegeschwindigkeit kann erhöht werden bei intelligentem RAID-Controller
- **Nachteile**
	- doppelte an Speicherkapazität wird benötigt
	- Kostenfaktor ist hoch
- **Formel**
	- $Kapazität=(\dfrac{Anzahl \space Festplatten}{2}) \times Festplattenkapazität$

## RAID 5
- mind. 3 Festplatten werden benötigt
- Kombination aus Striping mit **Paritätsinformation** (*XOR Verknüpfung*)
- **Vorteile**
	- hohes Maß an Datensicherheit
	- optimalere Speicherkapazitätnutzung als RAID 1
- **Nachteile**
	- Schreibvorgänge sind langsamer durch Paritätsinformationen
	- Paritätsinformationen nehmen zusätzlich Speicherplatz in Anspruch
- **Formel**
	- $Kapazität = (Anzahl \space Festplatten - 1) \times Festplattenkapazität \space kleinste \space Festplatte$
	- *bei RAID 6 $-2$*
		- $Kapazität = (Anzahl \space Festplatten - 2) \times Festplattenkapazität \space kleinste \space Festplatte$

## RAID und Redundanzkonzepte

### Hot-Spare
- **Definition**: Ein Hot-Spare ist eine zusätzliche Festplatte, die in einem RAID-System bereitgehalten wird, um im Falle eines Festplattenausfalls sofort einspringen zu können.
- **Vorteile**:
    - Automatischer Wechsel: Bei einem Ausfall wird die Hot-Spare-Festplatte automatisch aktiviert, was die Ausfallzeit minimiert.
    - Keine manuelle Intervention erforderlich.
- **Nachteile**:
    - Die Hot-Spare-Festplatte kann nicht für Daten verwendet werden, solange sie im Standby-Modus ist.
    - Erhöhte Kosten durch zusätzliche Hardware.
### Cold-Standby
- **Definition**: Ein Cold-Standby ist eine zusätzliche Festplatte, die nicht aktiv im RAID-System integriert ist, aber im Falle eines Ausfalls manuell hinzugefügt werden kann.
- **Vorteile**:
    - Kostengünstiger, da keine permanente Hardware benötigt wird.
    - Flexibilität, da die Festplatte bei Bedarf hinzugefügt werden kann.
- **Nachteile**:
    - Längere Ausfallzeiten, da eine manuelle Intervention erforderlich ist, um die Festplatte zu aktivieren.
    - Erhöhtes Risiko von Datenverlust, wenn der Ausfall nicht schnell genug behoben wird.

## Quellen 

> Coleman, L. (2024). PITS Globale Datenrettungsdienste. PITS Globale Datenrettungsdienste. Retrieved from https://www.pitsdatenrettung.de/blog/raid-level-
> Boekhoven, P. (2024, February 18). RAID-Systeme: Effiziente Speicherorganisation einfach erklärt! Youtube. Retrieved from https://www.youtube.com/watch?v=za8ZJgIWMKQ
> Formeln RAID - Fachinformatiker Systemintegration. (2024, September 18). Retrieved from https://www.karteikarte.com/lesson/69679/formeln-raid

- **leistungsstarker** und **vielseitiger** Algorithmus des [[Maschinelles Lernen|maschinellen Lernens]], der **mehrere** [[Entscheidungsbaum|Entscheidungsbäume]] kombiniert, um ein einzelnes Ergebnis zu erzielen
- Es handelt sich um einen **[[Überwachtes und nicht-überwachtes Lernen|überwachten Lernalgorithmus]]**, der sowohl für [[Klassifikation|Klassifikations-]] als auch für [[Regression|Regressionsprobleme]] eingesetzt werden kann## 

## Funktionsweise
- Random Forest baut mehrere Entscheidungsbäume auf und kombiniert deren Vorhersagen
- Jeder Baum wird mit einer zufälligen Teilmenge der Trainingsdaten (Bootstrap-Stichprobe) erstellt
- Bei jedem Split werden nur zufällig ausgewählte Merkmale berücksichtigt (Feature Bagging)
- Für die Vorhersage:
    - Bei Klassifikation: Mehrheitsentscheidung der Bäume
    - Bei Regression: Durchschnitt der Vorhersagen aller Bäume


## Vorteile
- Hohe Genauigkeit durch Ensemble-Lernen
- Reduziert Overfitting im Vergleich zu einzelnen Entscheidungsbäumen
- Kann mit hochdimensionalen Daten umgehen
- Gut parallelisierbar, da Bäume unabhängig voneinander erstellt werden

## Wichtige Hyperparameter
- **n_estimators**: Anzahl der Bäume im Wald
- **max_features**: Maximale Anzahl der Merkmale pro Split
- **min_samples_leaf**: Minimale Anzahl von Samples in einem Blatt
- **n_jobs**: Anzahl der zu verwendenden Prozessoren

## Anwendungsgebiete
- Finanzwesen: Kreditrisikobewertung, Betrugserkennung
- Gesundheitswesen: Krankheitsdiagnose, Vorhersage von Behandlungsergebnissen
- Marketing: Kundensegmentierung, Vorhersage von Kundenverhalten
- Ökologie: Vorhersage von Artenverteilungen

## Feature Importance
Random Forests können die **Wichtigkeit von Merkmalen bewerten**, was bei der Merkmalsselektion und Modellinterpretation hilft.

Durch die Kombination mehrerer unkorrellierter Bäume erzielt Random Forest oft **genauere und stabilere Ergebnisse** als einzelne Entscheidungsbäume.


- Art von **Malware**, die **Daten** auf einem Computer oder Netzwerk **verschlüsselt** und von den Opfern ein **Lösegeld** verlangt, um den Zugriff auf ihre Daten wiederherzustellen.

## Arten von Ransomware
- **Crypto-Ransomware**: Verschlüsselt Dateien auf dem Computer des Opfers und fordert ein Lösegeld für den Entschlüsselungsschlüssel.
- **Locker-Ransomware**: Sperrt den Zugriff auf das gesamte System, sodass der Benutzer nicht mehr auf seine Dateien oder Anwendungen zugreifen kann.
- **Scareware**: Täuscht vor, dass das System infiziert ist, und fordert das Opfer auf, eine Gebühr zu zahlen, um das Problem zu beheben, obwohl keine echte Bedrohung besteht.

## Verbreitungswege
- **Phishing-E-Mails**: Ransomware wird häufig über gefälschte E-Mails verbreitet, die schädliche Anhänge oder Links enthalten.
- **Drive-by-Downloads**: Malware wird automatisch heruntergeladen, wenn ein Benutzer eine kompromittierte Website besucht.
- **Remote Desktop Protocol (RDP)**: Angreifer nutzen unsichere RDP-Verbindungen, um in Systeme einzudringen und Ransomware zu installieren.

## Auswirkungen
- **Datenverlust**: Verlust von wichtigen Daten, wenn das Lösegeld nicht gezahlt wird oder die Entschlüsselung fehlschlägt.
- **Finanzielle Verluste**: Kosten für die Wiederherstellung von Daten, Systemen und potenzielle Lösegeldzahlungen.
- **Rufschädigung**: Vertrauensverlust bei Kunden und Partnern, insbesondere bei Unternehmen, die von einem Ransomware-Angriff betroffen sind.

## Vorbeugung
- **Regelmäßige Backups**: Erstellen von regelmäßigen, sicheren Backups wichtiger Daten, um im Falle eines Angriffs eine Wiederherstellung zu ermöglichen.
- **Sicherheitssoftware**: Einsatz von aktueller Antivirus- und Antimalware-Software, um Bedrohungen zu erkennen und zu blockieren.
- **Schulung der Mitarbeiter**: Sensibilisierung der Mitarbeiter für Phishing und andere Angriffsvektoren, um das Risiko einer Infektion zu verringern.
- **Sicherheitsupdates**: Regelmäßige Aktualisierung von Betriebssystemen und Software, um bekannte Sicherheitslücken zu schließen.

## Reaktion auf einen Ransomware-Angriff
- **Isolierung des betroffenen Systems**: Sofortige Trennung des infizierten Systems vom Netzwerk, um die Ausbreitung der Ransomware zu verhindern.
- **Meldung an die Behörden**: Informieren der zuständigen Behörden über den Vorfall.
- **Datenwiederherstellung**: Nutzung von Backups zur Wiederherstellung der Daten, anstatt das Lösegeld zu zahlen.
- **Analyse des Vorfalls**: Untersuchung, wie der Angriff erfolgt ist, um zukünftige Angriffe zu verhindern.


## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Redundante Systeme sind IT-Infrastrukturen, die **zusätzliche Komponenten oder Systeme enthalten**, um die **Verfügbarkeit** und **Zuverlässigkeit** zu erhöhen. Sie dienen dazu, Ausfälle zu vermeiden und die Kontinuität von Diensten sicherzustellen.

## Wichtige Aspekte redundanter Systeme
- **Verfügbarkeit**: Redundante Systeme erhöhen die Verfügbarkeit von Diensten, indem sie sicherstellen, dass im Falle eines Ausfalls einer Komponente eine andere einspringen kann.
- **Fehlertoleranz**: Sie ermöglichen es einem System, auch bei einem Fehler oder Ausfall weiterhin zu funktionieren.
- **Lastverteilung**: Redundante Systeme können auch zur Lastverteilung eingesetzt werden, um die Leistung zu optimieren.

## Arten von Redundanz
- **Hardware-Redundanz**: Einsatz von zusätzlichen physischen Komponenten, wie z. B. Servern, Festplatten oder Netzteilen, die im Falle eines Ausfalls aktiv werden.
- **Software-Redundanz**: Verwendung von Softwarelösungen, die bei einem Fehler in einer Anwendung oder einem Dienst automatisch auf eine alternative Instanz umschalten.
- **Daten-Redundanz**: Speicherung von Daten an mehreren Orten, um Datenverlust zu vermeiden (z. B. durch RAID-Systeme).

## Implementierung redundanter Systeme
- **Cluster-Systeme**: Mehrere Server arbeiten zusammen, um eine höhere Verfügbarkeit und Lastverteilung zu gewährleisten.
- **Hot-Swap-fähige Komponenten**: Hardware, die im laufenden Betrieb ausgetauscht werden kann, ohne dass das System heruntergefahren werden muss.
- **Georedundanz**: Daten und Systeme werden an mehreren geografisch verteilten Standorten gespeichert, um Ausfälle durch Naturkatastrophen oder regionale Störungen zu minimieren.

## Vorteile redundanter Systeme
- **Erhöhte Zuverlässigkeit**: Redundante Systeme minimieren das Risiko von Ausfallzeiten und erhöhen die Zuverlässigkeit von Diensten.
- **Schnelle Wiederherstellung**: Im Falle eines Ausfalls kann die Wiederherstellung schneller erfolgen, da alternative Systeme sofort zur Verfügung stehen.
- **Bessere Benutzererfahrung**: Durch die Minimierung von Ausfallzeiten wird die Benutzererfahrung verbessert, was zu höherer Kundenzufriedenheit führt.

## Herausforderungen und Risiken
- **Kosten**: Die Implementierung redundanter Systeme kann teuer sein, sowohl in Bezug auf Hardware als auch auf Wartung.
- **Komplexität**: Die Verwaltung und Überwachung redundanter Systeme kann komplex sein und erfordert spezialisiertes Wissen.
- **Fehleranfälligkeit**: Auch redundante Systeme können fehleranfällig sein, insbesondere wenn die Redundanz nicht richtig konfiguriert oder gewartet wird.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Übereinstimmung** von **Handlungen**, **Prozessen** oder **Systemen** mit **festgelegten Regeln, Normen und gesetzlichen Vorgaben**.

## Bedeutung
- **Rechtssicherheit:** Vermeidung von rechtlichen Konsequenzen.
- **Vertrauen:** Stärkung des Vertrauens von Kunden und Partnern.
- **Qualitätssicherung:** Gewährleistung von konsistenten und qualitativ hochwertigen Ergebnissen.

## Bereiche der Regelkonformität
1. **Rechtliche Regelkonformität:**
   - Einhaltung von Gesetzen (z.B. Datenschutz, Arbeitsrecht).
2. **Normative Regelkonformität:**
   - Befolgung von Standards und Normen (z.B. ISO, ITIL)
3. **Ethische Regelkonformität:**
   - Orientierung an ethischen Standards und Unternehmenswerten.

## Faktoren, die Regelkonformität beeinflussen
- **Unternehmenskultur:** Werte und Normen innerhalb der Organisation.
- **Schulung und Sensibilisierung:** Regelmäßige Trainings zur Förderung des Bewusstseins.
- **Kontrollmechanismen:** Audits und Überprüfungen zur Sicherstellung der Einhaltung.

## Maßnahmen zur Förderung der Regelkonformität
- **Dokumentation:** Klare und nachvollziehbare Dokumentation von Prozessen.
- **Compliance-Management:** Implementierung von Systemen zur Überwachung der Regelkonformität.
- **Feedback-Mechanismen:** Möglichkeiten zur Rückmeldung und Verbesserung.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

> [!WARNING]
> Multivarielle Regression -> Gradientenabstieg, wie konkrete Umsetzung?
> https://www.youtube.com/watch?v=YMTwWKPliLw

- gehört zum [[Überwachtes und nicht-überwachtes Lernen|überwachten Lernen]]
- ausgehend von **einer oder mehreren Variablen** (*Unabhängige Variablen* bzw. *Prädiktoren*) auf **eine weitere Variable** (*Abhängige Variable* bzw. *Kriterium*) zu schließen
	- **Messung** des **Einflusses** einer oder mehreren Variablen auf eine weitere Variable bzw. **Vorhersage** einer Variable durch eine oder mehrere andere Variablen

- **Prädikatoren** können metrisch, [[Ordinalskala|ordinal]] oder nominal sein

## Formen

### **Einfache lineare** / **Univariate** Regression
- Vorhersage **eines Kriteriums** anhand von **eines Prädikators** (1:1)
- **Formel:**
	- $\hat{y} = b \times x + a = \theta_0 + \theta_1 x$ 
	- Kriterium $\hat{y}$
	- Steigung $b/\theta_1$
	- Prädikator $x$
	- Aufpunkt/Achsenschnitt $a/\theta_0$
- **Berechnung**
	- $b/\theta_1 = r \dfrac{s_y}{s_x}$
		- [[Korrelationskoeffizient|Korrelation]] zwischen $x$ und $y$: $r$
		- [[Standardabweichung]] von $y$: $s_y$
		- [[Standardabweichung]] von $x$: $s_x$
	- $a/\theta_0 = \bar{y} - b \times \bar{x} = \bar{y} - \theta_1 \times \bar{x}$
		- [[Arithmetisches Mittel|Mittelwert]] von $y$: $\bar{y}$
		- [[Arithmetisches Mittel|Mittelwert]] von $x$: $\bar{x}$

### **Multiple lineare** / **Multivariate** Regression
- Vorhersage **eines Kriteriums** anhand **mehrerer Prädikatoren** (n:1)
- **Formel:** $\hat{y} = b_1 \times x_1 + b_2 \times x_2 + ... + b_k \times x_k + a = \theta_0+\theta_1x_2+\theta_2x_2+...+\theta_mx_m$
- Berechnung und Deutung ähnlich wie bei der [[#**Einfache lineare** Regression|einfachen linearen Regression]]

### **Logistische** Regression
- Vorhersage eines **Ja/Nein-Prädikators**, Kategorische Einordnung
- abhängige Variable ist eine **dichotome Variable** -> Variable mit nur *zwei Ausprägungen*
- **Formel:** $f(z) = \dfrac{1}{1 + e^{{\theta_0}_1 \times x_1 + ... {\theta_0}_k \times x_k + a}}$
- Wahrscheinlichkeit, ob abhängige Variable $z$ ist: $P(y=z|x_1,...,x_n) = \dfrac{1}{1 + e^{-({\theta_0}_1 \times x_1 + ... + {\theta_0}_k \times x_k +\theta_1)}}$
	- Eulersche Zahl $e$ (ungef. $2,71828$) 
- Berechnung von $\theta_0$ anhand vom [[#Gradientabstiegsverfahren]]
- Ableitung der Kostenfunktion identisch mit der für die [[#**Multiple lineare** / **Multivariate** Regression|lineare Regression]]
- Berechnung nach folgendem Schema:
	- Berechnung der [[#Multivariate Regression|multivariaten Regression]]
	- Anwendung der Sigmoidfunktion auf $\hat{y}$ 
## Kostenfunktion

### Univariate Regression

$$
J(\theta_0, \theta_1) = \dfrac{1}{2N} \sum^{N}_{n=1}
(\theta_0 + \theta_1 x_n - y_n)^2
$$

### Multivariate Regression

$$
J(\theta_0,\theta_1) = \dfrac{1}{2N} \sum^{N}_{n=1} (h_\theta(x_{n}) - y_{n})^2
$$
- $N$ Anzahl der Datenpunkte
- $h_0(x_{n})$ Vorhersagefunktion des Modells (z.B. $\hat{y} =...$)
- $y_n$ Zielwert
- $\sum^N_{n=1}(...)^2$ quadrierter Fehler aller Datenpunkte um Richtung des Fehlers zu eliminieren
- $\dfrac{1}{2N}$ Den Fehler über alle Datenpunkte mitteln

> [!Erklärung]-
> Die Formel
>
> $J(\theta_0, \theta_1) = \dfrac{1}{2N} \sum^{N}_{n=1} (h_\theta(x^{(n)}) - y^{(n)})^2$
>
> ist die **Kostenfunktion** (auch Fehlerfunktion genannt) der linearen Regression. Sie hilft dabei, zu messen, wie gut unsere Vorhersagen des Modells sind im Vergleich zu den tatsächlichen Werten. Um sie zu verstehen, erkläre ich sie in einfachen Schritten:
> 
> 1. **$N$**: Das ist die Anzahl der Datenpunkte, also wie viele Paare von Eingabe (x) und tatsächlichem Ergebnis (y) wir in unserem Trainingsdatensatz haben.
> 
> 2. **$h_\theta(x^{(n)})$**: Dies ist die Vorhersage unseres Modells für den n-ten Datenpunkt. Das Modell gibt uns eine Schätzung basierend auf den Werten von $x$ (den Eingabe-Features) und den Parametern **$\theta_0$ und $\theta_1$** (also die Geradengleichung).
>
> 3. **$y^{(n)}$**: Das ist der tatsächliche Wert (Zielwert) für den n-ten Datenpunkt. Es ist das, was wir „wirklich“ gemessen haben.
>
> 4. **$(h_\theta(x^{(n)}) - y^{(n)})^2$**: Hier berechnen wir den Unterschied zwischen der Vorhersage des Modells **$h_\theta(x^{(n)})$** und dem tatsächlichen Wert **$y^{(n)}$**. Der Unterschied wird quadriert, um sicherzustellen, dass sowohl positive als auch negative Abweichungen gleichermaßen bestraft werden (sonst würden sich Abweichungen möglicherweise gegenseitig aufheben).
> 
> 5. **Summe $\sum^{N}_{n=1}$**: Das bedeutet, dass wir diesen quadrierten Fehler für **alle** Datenpunkte berechnen und addieren. So messen wir den Gesamtfehler für den gesamten Datensatz.
> 6. **$\dfrac{1}{2N}$**: Zum Schluss teilen wir die Summe durch $2N$. Das sorgt dafür, dass der Fehlerwert nicht zu groß wird (wir mitteln die Fehler über alle Datenpunkte), und die $1/2$ erleichtert später die Ableitung, wenn wir die optimale Lösung für **$\theta_0$** und **$\theta_1$** berechnen.
>
> **Einfach erklärt**:
> Die Kostenfunktion sagt uns also, **wie weit unsere Vorhersagen vom tatsächlichen Ergebnis entfernt sind**. Je kleiner der Wert der Kostenfunktion, desto besser passen unsere Vorhersagen zum echten Ergebnis.


## Berechnung

### Nullstellen der Kostenfunktionsableitung
- **Berechnung** der **Nullstellen** der **Kostenfunktionsableitung**
	- *-> Nullstelle der Ableitung gibt Extrempunkt (in diesem Fall das Minimum) an*

- Ableitungen der Kostenfunktion (wobei $\sum x$ = $\sum^{N}_{n=1}x^{(n)}$):
$$
\dfrac{\partial}{\partial \theta_0}J(\theta_0,\theta_1) = 0 \Longleftrightarrow \theta_0 = \dfrac{(\sum y)(\sum {x^2}) - (\sum x)(\sum {xy})}{N\times\sum {x^2}-(\sum x)^2}
$$
> [!Code Äquivalent]-
> ```python
> theta0 = ( 
>	(sum(y) * sum(x ** 2) - sum(x) * sum(x * y)) / 
>	(n * sum(x ** 2) - sum(x) ** 2) 
 >)
> ```

$$
\dfrac{\partial}{\partial \theta_1}J(\theta_0,\theta_1) = 0 \Longleftrightarrow \theta_1 = \dfrac{(\sum y)(\sum {x^2}) - (\sum x)(\sum {xy})}{N \sum {x^2}-(\sum x)^2}
$$
> [!Code äquivalent]-
> ```python
> theta1 = ( 
> 	(n * sum(x * y) - sum(x) * sum(y)) / 
> 	(n * sum(x ** 2) - sum(x) **2 ) 
> )
> ```

- akkurater als Gradientabstiegsverfahren, daher keine **[[#^a7aff3|Feature-Skalierung]]**
- bessere Methode bei kleiner bis mittlerer Datenmenge

### Gradientabstiegsverfahren
- Minimierung der Kostenfunktion durch **schrittweise Anpassung** der Parameter $\theta_0$ (y-Achsenabschnitt) und $\theta_1$ (Steigung).
- Beginn mit zufälligen oder nullinitialisierten $\theta$-Werten.
- **Vorhersagefunktion**:
$$
h_\theta(x) = \theta_0 + \theta_1 \cdot x
$$
- **Kostenfunktion** (Mean Squared Error):
$$
J(\theta_0, \theta_1) = \frac{1}{2n} \sum_{i=1}^{n} \left( h_\theta(x^{(i)}) - y^{(i)} \right)^2
$$

#### Ableitungen der Kostenfunktion
- Die Ableitungen der Kostenfunktion zeigen, wie sich die Kostenfunktion verändert, wenn ($\theta_0$) und ( $\theta_1$) angepasst werden.
1. **Ableitung nach ($\theta_0$)**:
$$
\dfrac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) = \frac{-1}{n} \sum_{i=1}^{n} \left( y^{(i)} - h_\theta(x^{(i)}) \right)
$$
2. **Ableitung nach ($\theta_1$)**:
$$
\dfrac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) = \frac{-1}{n} \sum_{i=1}^{n} x^{(i)} \left( y^{(i)} - h_\theta(x^{(i)}) \right)
$$

#### Update-Regeln für die Parameter
- Um die Parameter zu aktualisieren, bewegen wir uns in die **entgegengesetzte Richtung der Ableitungen**:
- **Update für ($\theta_0$)**:
$$
\theta_0 \leftarrow \theta_0 - \alpha \cdot \frac{1}{n} \sum_{i=1}^{n} \left( h_\theta(x_{(i)}) - y_{(i)} \right)
$$

- **Update für ($\theta_1$)**:
$$
\theta_1 \leftarrow \theta_1 - \alpha \cdot \frac{1}{n} \sum_{i=1}^{n} x_{(i)} \left( h_\theta(x_{(i)}) - y_{(i)} \right)
$$
- Lernrate $\alpha$
	- Ist der Wert zu klein, dauert es sehr lange, bis der Gradientenabstieg konvergiert

#### Code-Äquivalent

```python
# Gradientenabstieg
for step in range(0, 1000): 
	# Berechne die vorhergesagten y-Werte (y_pred) basierend 
	# auf aktuellen theta-Werten
	y_pred = theta0 + x * theta1
	
    # Aktualisiere theta1: 
    # Subtrahiere den Gradienten der Kostenfunktion bezüglich theta1
	theta1_new = theta1 - learning_rate * (1 / n) * sum(x * (y_pred - y))
	
    # Aktualisiere theta0: 
    # Subtrahiere den Gradienten der Kostenfunktion bezüglich theta0
	theta0_new = theta0 - learning_rate * (1 / n) * sum(y_pred - y)
	
	# Setze die neuen theta-Werte für den nächsten Schritt
	theta0, theta1 = theta0_new, theta1_new 
	
	# Speichere die theta-Werte alle 50 Schritte zur späteren Analyse
	if step % 50 == 0: 
		theta0s.append(theta0)
		theta1s.append(theta1)
```

#### Pseudocode für den Gradientenabstieg
```pseudo
1. INITIALISIERUNG:    
    - Setze theta0 = 0 (y-Achsenabschnitt)
    - Setze theta1 = 0 (Steigung)
    - Setze learning_rate = α (z.B. 0.1)
    - Setze Anzahl der Schritte (iterations) = 1000
    - Lade die Datenpunkte (x, y) in Arrays
    - n = Anzahl der Datenpunkte

2. FÜR jede Iteration von 1 bis iterations WIEDERHOLE:    
    - Berechne die Vorhersage für jedes x: y_pred = theta0 + theta1 * x
    - Berechne den Fehler (Differenz zwischen y_pred und y): error = y_pred - y

    - Berechne die Anpassungen für theta1: sum_term_theta1 = SUMME(x * error) (für alle Datenpunkte) theta1 = theta1 - learning_rate * (1 / n) * sum_term_theta1
	
    - Berechne die Anpassungen für theta0: sum_term_theta0 = SUMME(error) (für alle Datenpunkte) theta0 = theta0 - learning_rate * (1 / n) * sum_term_theta0
	
3. ENDE der Schleife
    
4. AUSGABE:   
    - Gebe die finalen Werte von theta0 und theta1 aus.
```

- Der Gradientenabstieg ist besonders vorteilhaft bei großen Datenmengen.



## Feature-Skalierung
- Werte der Features werden auf einen bestimmten Bereich (z.B. 0 bis 1) skaliert, um die Konvergenz[^1:] zu beschleunigen:
  $x_{\text{scaled}}^{(n)} = \dfrac{x^{(n)} - \min(x)}{\max(x) - \min(x)}$
  - Wichtig: sofern die Features skaliert werden, müssen später auch die Eingabewerte gleichskaliert werden.

---
[^1:] In der Mathematik und beim maschinellen Lernen beschreibt Konvergenz den Prozess, bei dem ein Algorithmus Schritt für Schritt einer optimalen Lösung (z.B. minimaler Fehler) immer näher kommt.

- Das RM ist ein Schritt in der **Datenbankentwicklung** nach dem [[Entity Relationship Model|Entity-Relationship-Modell (ERM)]]
- Es überführt das ERM in eine Form, die in relationalen Datenbanken gespeichert werden kann

## Vergleich ERM und RM

| ERM              | RM                            |
| ---------------- | ----------------------------- |
| Entitytyp        | Relation (Tabelle)            |
| Entity           | Tupel (eindeutiger Datensatz) |
| Attribute        | Spaltenüberschriften          |
| Primärschlüssel  | Primärschlüssel               |
| Beziehung (ship) | Relation (Tabelle)            |


## Darstellung im Relationenmodell
Beispiel:
```
Lehrer (Personalnummer, Name, Vorname, Schulform, Fachgebiet)
Schüler (Schülernummer, Name, Vorname)
Klasse (Klassenbezeichnung, Raum)
Zeugnis (Zeugnis_ID, Ausgabedatum)
```
oder
```
T_Lehrer(P_Personalnummer, Name, Vorname, Schulform, Fachgebiet)
T_Schüler(P_Schülernummer, Name, Vorname),
Klasse(P_Klassenbezeichnung, F_Lehrernummer, F_Schülernummer, Raum)
Zeugnis(P_Zeugnis_ID, F_Schülernummer, Ausgabedateum)
```

## Wichtige Merkmale
- Attribute sind atomar und nicht weiter zerlegbar
- Primärschlüssel sind identifizierende Eigenschaften (unterstrichen dargestellt)
- Keine Duplikate in Datensätzen erlaubt[1]
## Quellen
> https://bildung4u.eu/relationenmodell-rm/

Der Return on Investment (ROI) ist eine **Kennzahl**, die verwendet wird, um die **Rentabilität einer Investition zu messen**. Er zeigt das Verhältnis zwischen dem Gewinn und den Kosten der Investition und hilft dabei, die Effizienz verschiedener Investitionen zu vergleichen.

## Berechnung des ROI
Die Formel zur Berechnung des ROI lautet:

$$
\text{ROI} = \frac{\text{Gewinn} - \text{Investitionskosten}}{\text{Investitionskosten}} \times 100
$$

### Beispiel:
- **Investitionskosten**: 10.000 €
- **Gewinn**: 15.000 €

$$
\text{ROI} = \frac{15.000 - 10.000}{10.000} \times 100 = 50\%
$$

## Bedeutung des ROI
- **Rentabilität**: Ein hoher ROI zeigt an, dass eine Investition profitabel war.
- **Vergleichbarkeit**: Der ROI ermöglicht den Vergleich von verschiedenen Investitionen oder Projekten.
- **Entscheidungsfindung**: Unternehmen nutzen den ROI, um fundierte Entscheidungen über zukünftige Investitionen zu treffen.

## Vorteile des ROI
- **Einfachheit**: Die Berechnung ist unkompliziert und leicht verständlich.
- **Flexibilität**: Kann auf verschiedene Arten von Investitionen angewendet werden (z.B. Marketing, Projekte, Maschinen).
- **Visualisierung**: Erlaubt eine schnelle visuelle Darstellung der Rentabilität.

## Nachteile des ROI
- **Kurzfristige Perspektive**: Berücksichtigt oft nicht langfristige Gewinne oder Verluste.
- **Vernachlässigung von Risiken**: Der ROI sagt nichts über das Risiko einer Investition aus.
- **Manipulationsgefahr**: Gewinne können durch kreative Buchführung beeinflusst werden.

## Anwendung des ROI in der Praxis
1. **Marketing**: Bewertung der Effektivität von Werbekampagnen.
2. **Projektmanagement**: Analyse der Rentabilität von Projekten vor der Umsetzung.
3. **Finanzanalyse**: Vergleich von Anlageoptionen zur Optimierung des Portfolios.


- Roll-out des Sollprozesses bezeichnet die **systematische Einführung** und **Umsetzung** eines neu definierten oder optimierten **Prozesses** in einer Organisation.

## Ziele des Prozess-Roll-outs
- Effiziente Implementierung neuer Arbeitsabläufe
- Minimierung von Widerständen und Störungen
- Sicherstellung einer einheitlichen Prozessausführung
- Erreichung der definierten Prozessziele

## Phasen des Roll-outs
1. Vorbereitung
2. Planung
3. Pilotierung
4. Schulung und Kommunikation
5. Umsetzung
6. Kontrolle und Nachbereitung

## Wichtige Elemente zur Unterstützung des Roll-outs
1. Change Management
	- Stakeholder-Analyse
	- Kommunikationsplan
	- Widerstandsmanagement
2. Schulungskonzept
	- Bedarfsanalyse
	- Schulungsmaterialien
	- Train-the-Trainer-Konzepte
3. Technische Unterstützung
	- IT-Systeme und Tools
	- Prozessdokumentation
	- Arbeitsanweisungen
4. Prozess-Governance
	- Rollen und Verantwortlichkeiten
	- Eskalationswege
	- Prozess-Controlling

## Erfolgsfaktoren für den Roll-out
- Klare Zielsetzung und Nutzendarstellung
- Unterstützung durch das Top-Management
- Frühzeitige Einbindung der Mitarbeiter
- Ausreichende Ressourcenbereitstellung
- Flexible Anpassung an Feedback und Erfahrungen

## Herausforderungen beim Roll-out
- Widerstand gegen Veränderungen
- Komplexität des neuen Prozesses
- Unzureichende Schulung und Kommunikation
- Technische Probleme bei der Umsetzung
- Mangelnde Akzeptanz der neuen Arbeitsweisen

## Best Practices für einen erfolgreichen Roll-out
1. Pilotierung in einem begrenzten Bereich
2. Schrittweise Einführung (wenn möglich)
3. Regelmäßige Feedbackschleifen
4. Klare Kommunikation von Meilensteinen und Erfolgen
5. Bereitstellung von Support und Ansprechpartnern
6. Kontinuierliche Verbesserung des Prozesses

### Messung des Roll-out-Erfolgs
- Prozess-KPIs (Key Performance Indicators)
- Mitarbeiterzufriedenheit
- Kundenrückmeldungen
- Effizienzsteigerungen
- Fehlerreduktion

### Nachbereitung und kontinuierliche Verbesserung
- Regelmäßige Prozessaudits
- Lessons Learned Workshops
- Anpassung und Optimierung des Prozesses
- Förderung einer kontinuierlichen Verbesserungskultur


- **S**elf-**M**onitoring, **A**nalysis and **R**eporting **T**echnology
	- *System zur Selbstüberwachung, Analyse und Statusmeldung*
- Prognose über **Ausfall** der HDD bzw. SSD, Grundlage sind eine Vielzahl von **Sensoren** vom **aktuellen Zustand** der Festplatte
- **BIOS**/**UEFI** erstellt Überblick über Parameter. Liegen Werte nicht im **Normbereich**, wird dies im **Fehlerprotokoll** festgehalten 

## Parameter
- Leserfehlerrate
- Beschleunigungszeit
- Anzahl der Betriebsstunden
- Suchfehlerrate
- Temperatur
- ...

## Quellen

> S.M.A.R.T. bei Windows-Festplatten: Was das bedeutet. (2024, September 19). Retrieved from https://praxistipps.chip.de/s-m-a-r-t-bei-windows-festplatten-was-das-bedeutet_114668
> Autoren der Wikimedia-Projekte. (2004, August 13). Self-Monitoring, Analysis and Reporting Technology – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Self-Monitoring,_Analysis_and_Reporting_Technology&oldid=248409170

IT-Sicherheitsvorfälle sind Ereignisse, die die **Vertraulichkeit, Integrität oder Verfügbarkeit** von Informationen und IT-Systemen **gefährden**. Die Einschätzung der Schadenspotenziale dieser Vorfälle ist entscheidend, um **geeignete Maßnahmen zur Schadensverhütung und -minimierung** zu ergreifen.

## Wichtige Schadenspotenziale

### Imageschaden
- **Beschreibung**: Ein Sicherheitsvorfall kann das Vertrauen von Kunden, Partnern und der Öffentlichkeit in ein Unternehmen erheblich beeinträchtigen. Ein negativer Ruf kann langfristige Auswirkungen auf die Kundenbindung und die Marktposition haben.
- **Präventionsmaßnahmen**:
  - **Transparente Kommunikation**: Offene und ehrliche Kommunikation über Sicherheitsvorfälle kann helfen, das Vertrauen wiederherzustellen.
  - **Proaktive Öffentlichkeitsarbeit**: Maßnahmen zur Verbesserung des Unternehmensimages, wie z. B. CSR-Initiativen, können helfen, den Imageschaden zu mindern.

### Wirtschaftlicher Schaden
- **Beschreibung**: IT-Sicherheitsvorfälle können zu direkten finanziellen Verlusten führen, z. B. durch Betriebsunterbrechungen, Kosten für die Wiederherstellung von Systemen oder rechtliche Konsequenzen. Indirekte Kosten, wie der Verlust von Kunden und Marktanteilen, können ebenfalls erheblich sein.
- **Präventionsmaßnahmen**:
  - **Risikomanagement**: Identifikation und Bewertung von Risiken, um geeignete Sicherheitsmaßnahmen zu implementieren.
  - **Versicherungen**: Abschluss von Cyber-Versicherungen, um finanzielle Risiken abzusichern.

### Datenverlust
- **Beschreibung**: Der Verlust von sensiblen oder geschäftskritischen Daten kann schwerwiegende Folgen haben, einschließlich rechtlicher Konsequenzen und Verlust von Wettbewerbsvorteilen. Datenverlust kann durch Cyberangriffe, menschliches Versagen oder technische Fehler verursacht werden.
- **Präventionsmaßnahmen**:
  - **Regelmäßige Backups**: Implementierung von Backup-Strategien, um Datenverluste zu minimieren und eine schnelle Wiederherstellung zu ermöglichen.
  - **Zugriffskontrollen**: Sicherstellen, dass nur autorisierte Personen Zugriff auf sensible Daten haben, um das Risiko von Datenverlusten zu verringern.

## Weitere Schadenspotenziale
- **Rechtliche Konsequenzen**: Nichteinhaltung von Datenschutzgesetzen kann zu hohen Geldstrafen und rechtlichen Auseinandersetzungen führen.
- **Betriebsunterbrechungen**: Sicherheitsvorfälle können den Betrieb eines Unternehmens erheblich stören, was zu Produktionsausfällen und Umsatzverlusten führt.
- **Verlust von geistigem Eigentum**: Die unbefugte Offenlegung oder der Diebstahl von geistigem Eigentum kann die Wettbewerbsfähigkeit eines Unternehmens gefährden.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


## Verfügbarkeit
  - **Definition:** Sicherstellen, dass Informationen und Systeme jederzeit zugänglich sind.
  - **Maßnahmen:**
    - Implementierung von Redundanz (z. B. Backup-Systeme).
    - Nutzung von Lastverteilung und Failover-Mechanismen.
    - Regelmäßige Wartung und Updates der Systeme.
## Integrität
  - **Definition:** Gewährleisten, dass Daten unverändert und korrekt sind.
  - **Maßnahmen:**
    - Einsatz von Prüfziffern und Hash-Funktionen zur Datenvalidierung.
    - Implementierung von Zugriffsrechten, um unautorisierte Änderungen zu verhindern.
    - Regelmäßige Audits und Überprüfungen der Datenintegrität.

## Vertraulichkeit
  - **Definition:** Sicherstellen, dass Informationen nur von autorisierten Personen eingesehen werden können.
  - **Maßnahmen:**
    - Verwendung von Verschlüsselung für Datenübertragungen und -speicherungen.
    - Implementierung von starken Authentifizierungsmechanismen (z. B. Zwei-Faktor-Authentifizierung).
    - Schulung der Mitarbeiter über den Umgang mit sensiblen Daten.

## Datenminimierung
  - **Definition:** Erhebung und Verarbeitung nur der notwendigen Daten.
  - **Maßnahmen:**
    - Überprüfung und Anpassung von Datenanforderungen in Prozessen.
    - Anonymisierung oder Pseudonymisierung von Daten, wenn möglich.
    - Regelmäßige Löschung nicht mehr benötigter Daten.

## Transparenz
  - **Definition:** Offenlegung von Datenverarbeitungsprozessen und -praktiken.
  - **Maßnahmen:**
    - Erstellung und Veröffentlichung von Datenschutzrichtlinien.
    - Durchführung von Informationsveranstaltungen für Betroffene.
    - Bereitstellung von klaren Informationen über Datenverarbeitungszwecke.

## Intervenierbarkeit
  - **Definition:** Möglichkeit, in Datenverarbeitungsprozesse einzugreifen.
  - **Maßnahmen:**
    - Implementierung von Verfahren zur Datenkorrektur und -löschung auf Anfrage.
    - Bereitstellung von Kontaktstellen für Betroffene zur Ausübung ihrer Rechte.
    - Regelmäßige Schulungen für Mitarbeiter über die Rechte der Betroffenen.

## Nichtverkettung
  - **Definition:** Verhindern der Verknüpfung von Daten, um Rückschlüsse auf Einzelpersonen zu vermeiden.
  - **Maßnahmen:**
    - Trennung von Datenbanken, die personenbezogene Daten enthalten, von anderen Daten.
    - Einsatz von Techniken zur Datenanonymisierung.
    - Überprüfung von Datenverarbeitungsprozessen auf mögliche Verkettungen.

- Systematische **Identifikation** und **Bewertung** von **Sicherheitslücken** in IT-Systemen, Anwendungen und Netzwerken.
- **Ziel**: Verbesserung der Sicherheit durch Erkennung und Behebung von Schwachstellen, um Angriffe zu verhindern.

## Bedeutung der Schwachstellenanalyse
- **Proaktive Sicherheit**: Identifikation von Schwachstellen, bevor sie ausgenutzt werden können.
- **Risikomanagement**: Bewertung der Auswirkungen von Schwachstellen auf die Organisation.
- **Compliance**: Erfüllung von gesetzlichen und branchenspezifischen Sicherheitsanforderungen.

## Schritte der Schwachstellenanalyse
1. **Identifikation**: Erfassung potenzieller Schwachstellen durch Scans, Audits und manuelle Überprüfungen.
2. **Bewertung**: Einschätzung der Risiken und Auswirkungen der identifizierten Schwachstellen.
3. **Priorisierung**: Festlegung, welche Schwachstellen zuerst behoben werden sollten.
4. **Behebung**: Implementierung von Maßnahmen zur Schließung der Schwachstellen.
5. **Überwachung**: Kontinuierliche Überprüfung und Anpassung der Sicherheitsmaßnahmen.

## IT-Sicherheitsmaßnahmen
- **Technische Maßnahmen**: Firewalls, Intrusion Detection Systems (IDS), Antivirus-Software.
- **Organisatorische Maßnahmen**: Sicherheitsrichtlinien, Schulungen, Notfallpläne.
- **Physische Maßnahmen**: Zugangskontrollen, Überwachungskameras, Schutz vor Umwelteinflüssen.

## Tools zur Überprüfung von IT-Sicherheitsmaßnahmen
- **Vulnerability Scanner**: Tools wie Nessus, OpenVAS oder Qualys zur automatisierten Identifikation von Schwachstellen.
- **Penetration Testing Tools**: Metasploit, Burp Suite oder OWASP ZAP zur Durchführung von simulierten Angriffen.
- **Sicherheitsaudits**: Tools zur Überprüfung von Sicherheitsrichtlinien und -praktiken (z.B. CIS-CAT).
- **Monitoring-Tools**: SIEM-Systeme (z.B. Splunk, ELK Stack) zur Überwachung von Sicherheitsereignissen und Anomalien.

## Best Practices zur Durchführung einer Schwachstellenanalyse
- **Regelmäßige Scans**: Durchführung von Schwachstellenscans in regelmäßigen Abständen.
- **Patch-Management**: Schnelle Behebung von identifizierten Schwachstellen durch Software-Updates.
- **Schulung der Mitarbeiter**: Sensibilisierung für Sicherheitsrisiken und Best Practices.
- **Dokumentation**: Führen von Protokollen über identifizierte Schwachstellen und durchgeführte Maßnahmen.

## Wichtige Begriffe
- **Vulnerability Assessment**: Prozess zur Identifikation und Bewertung von Schwachstellen.
- **Penetration Testing**: Simulierte Angriffe zur Überprüfung der Sicherheit eines Systems.
- **Risikomanagement**: Identifikation, Bewertung und Priorisierung von Risiken.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **agiles** Projektmanagement
	- **Selbstorganisation** von **interdisziplinären** Teams
	- statt Arbeitsanweisungen: **Aktivitäten**, wichtige **Dokumente** und feste **Rollen**
- Ziele
	- **schnell** auf Veränderungen reagieren
	- **effizient** Zusammenarbeiten
	- funktionsfähiges Zwischenprodukt nach jeder Etappe
- nur **wenige** Regeln

- man arbeitet **empirisch** *(erfahrungsbasiert)*, **inkrementell** *(inkrementell)* und **iterativ** *(wiederholend)*
- Projektlaufzeit in **zwei bis vierwöchige** **Sprints**
## Rollen
- alle Beteiligten erhalten eine Rolle
- **Product Owner**, für Produkt verantwortlich, Wertmaximierung, Blick auf *Kundenbedürfnisse*, halt *Projektanforderungen* im Blick, *entwickelt* selbst *nicht* mit. Anforderungen werden im **Product Backlog** festgehalten.
- **Team**, *entwickelt* Produkt, *drei bis neun* Mitglieder, selbstorganisiert
- **Scrum Master**, sorgt für effektive arbeit des Teams und *verhindert Störungen*, bei Problemen vermittelt Scrum Master als *Moderator*

## Artefakte
- zeigen *Anforderungen an Projekt*, *Verbesserungsbedarf*
- bieten **hohe Transparenz**
- **Product Backlog**, liste mit Anforderungen, wird vom **Product Owner** aktuell gehalten
- **Product Increment**, funktionsfähiges Zwischenprodukt
- **Sprint Backlog**, Aufgaben im (nächsten) Entwicklungsschritt

## Scrum Ablauf
- nach jedem **Sprint** ein **Product Increment**
1. **Sprint Planning**
	1. *Anforderungen* werden besprochen
	2. Aus Anforderungen werden *Tasks* erstellt
	3. Tasks werden *zugeteilt*
	4. Fertiger Plan: **Sprint Backlog**
2. **Daily Scrum**
	1. *tägliches Meeting* im Sprint
	2. *Fortschritte* werden besprochen
	3. nicht länger als *15min*, größeres übernimmt **Scrum Master**
3. **Sprint Review**
	1. Präsentation vom **Product Increment**
	2. *Product Owner + Anwender* geben *Feedback*
4. **Sprint Retrospective**
	1. Gab es *Hindernisse*/*Probleme* bei Zusammenarbeit
	2. *Verbesserungen*?

## Vorteile
- wenig Hilfsmittel
- **Aufwand** für Administration und Dokumentation **gering**
- **kontinuierliche Verbesserung**
## Nachteile
- viel Kommunikation
- **nicht** für alle **Branchen geeignet**

- ähnlich wie **[[PDCA]]**

1. **Standardize**, Lösung verstehen und in Standard überführen
2. **Do**, Testen mit schnellen und einfachen Mitteln
3. **Check**, Resultat mit der Erwartung überprüfen
4. **Act**, Umsetzung freigeben oder an Standardisierung weiterarbeiten

## Quellen
> SDCA-Zyklus. (2024, September 10). Retrieved from https://www.leanprinzip.de/woerterbuch/sdcazyklus

- **Konzept**, das darauf abzielt, **Sicherheitsaspekte von Anfang an** in den Entwicklungsprozess von Software und Systemen zu integrieren, anstatt sie nachträglich hinzuzufügen.

## Grundprinzipien
- **Frühe Integration**: Sicherheitsüberlegungen werden bereits in der Planungs- und Entwurfsphase berücksichtigt.
- **Risikoanalyse**: Identifikation und Bewertung potenzieller Sicherheitsrisiken während des gesamten Entwicklungszyklus.
- **Minimierung der Angriffsfläche**: Reduzierung der Anzahl der potenziellen Schwachstellen durch einfache und klare Designs.
- **Verteidigung in der Tiefe**: Implementierung mehrerer Sicherheitsebenen, um den Schutz zu erhöhen.

## Vorbeugung
- **Sichere Programmierung**: Verwendung sicherer Programmierpraktiken, um Schwachstellen wie SQL-Injection oder Cross-Site Scripting (XSS) zu vermeiden.
- **Regelmäßige Sicherheitsüberprüfungen**: Durchführung von Code-Reviews und Sicherheitstests während der Entwicklung.
- **Schulung der Entwickler**: Sensibilisierung der Entwickler für Sicherheitsrisiken und Best Practices.
- **Einsatz von Sicherheitswerkzeugen**: Verwendung von Tools zur statischen und dynamischen Codeanalyse, um Sicherheitslücken frühzeitig zu erkennen.
- **Dokumentation und Standards**: Erstellung von Sicherheitsrichtlinien und -standards, die während des gesamten Entwicklungsprozesses befolgt werden.

## Vorteile
- **Frühe Fehlererkennung**: Sicherheitsprobleme werden frühzeitig identifiziert und behoben, was die Kosten für nachträgliche Korrekturen senkt.
- **Erhöhte Sicherheit**: Systeme sind von Grund auf sicherer, was das Risiko von Sicherheitsvorfällen verringert.
- **Vertrauen der Benutzer**: Kunden und Benutzer haben mehr Vertrauen in Produkte, die mit einem Sicherheitsfokus entwickelt wurden.
- **Compliance**: Erleichterung der Einhaltung von gesetzlichen und regulatorischen Anforderungen an die Sicherheit.

## Herausforderungen
- **Kosten**: Höhere Anfangsinvestitionen in Schulung und Sicherheitsmaßnahmen.
- **Komplexität**: Integration von Sicherheitsaspekten kann den Entwicklungsprozess komplexer machen.
- **Widerstand gegen Veränderungen**: Entwickler und Stakeholder könnten sich gegen neue Sicherheitspraktiken sträuben.

## Quellen
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1


Selbstkonfigurierende Systeme sind IT-Systeme, die in der Lage sind, ihre **Konfiguration automatisch anzupassen** und zu optimieren, ohne dass menschliches Eingreifen erforderlich ist. Diese Systeme nutzen Algorithmen und Technologien, um sich an veränderte Bedingungen oder Anforderungen anzupassen.

## Wichtige Aspekte selbstkonfigurierender Systeme
- **Automatisierung**: Die Fähigkeit, Konfigurationen automatisch zu erstellen, zu ändern oder zu optimieren, basierend auf vordefinierten Regeln oder Machine-Learning-Algorithmen.
- **Adaptivität**: Selbstkonfigurierende Systeme können sich dynamisch an neue Anforderungen oder Umgebungen anpassen, um optimale Leistung zu gewährleisten.
- **Skalierbarkeit**: Diese Systeme können leicht skaliert werden, indem sie neue Ressourcen oder Komponenten hinzufügen, die automatisch konfiguriert werden.

## Technologien und Methoden
- **Orchestrierung**: Automatisierung der Bereitstellung, Verwaltung und Koordination von Software- und Hardware-Ressourcen.

## Vorteile selbstkonfigurierender Systeme
- **Reduzierter Verwaltungsaufwand**: Minimierung des Bedarfs an manueller Konfiguration und Wartung, was Zeit und Ressourcen spart.
- **Fehlerreduktion**: Automatisierte Konfigurationen verringern das Risiko menschlicher Fehler, die bei manuellen Prozessen auftreten können.
- **Schnellere Reaktionszeiten**: Systeme können schneller auf Änderungen in der Umgebung oder den Anforderungen reagieren, was die Gesamtleistung verbessert.

## Anwendungsbereiche
- **Cloud-Computing**: Selbstkonfigurierende Systeme werden häufig in Cloud-Umgebungen eingesetzt, um Ressourcen dynamisch zu verwalten und zu skalieren.
- **Netzwerkmanagement**: In Netzwerken können selbstkonfigurierende Systeme die Konfiguration von Routern, Switches und anderen Geräten automatisieren.
- **IoT (Internet der Dinge)**: Selbstkonfigurierende Systeme sind entscheidend für die Verwaltung und Optimierung von IoT-Geräten, die in verschiedenen Umgebungen eingesetzt werden.

## Herausforderungen und Risiken
- **Komplexität**: Die Implementierung und Verwaltung selbstkonfigurierender Systeme kann komplex sein und erfordert spezialisiertes Wissen.
- **Sicherheitsrisiken**: Automatisierte Systeme können anfällig für Sicherheitslücken sein, insbesondere wenn sie nicht ordnungsgemäß konfiguriert oder überwacht werden.
- **Abhängigkeit von Technologie**: Eine hohe Abhängigkeit von automatisierten Systemen kann zu Problemen führen, wenn diese Systeme ausfallen oder nicht wie erwartet funktionieren.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Einführung in die Shellprogrammierung
- **Shell**: Eine *Kommandozeilen-Schnittstelle*, die Benutzern ermöglicht, mit dem *Betriebssystem zu interagieren.
- **Shell-Skripte**: *Textdateien*, die eine *Reihe von Befehlen* enthalten, um *Aufgaben zu automatisieren* und Prozesse zu steuern.

## Typen von Shells
- **Unix/Linux-Shells**: 
  - **Bash (Bourne Again SHell)**: Weit verbreitet, unterstützt Skripting und Automatisierung.
  - **Zsh (Z Shell)**: Erweiterte Funktionen und Anpassungsmöglichkeiten.
- **Windows-Shells**:
  - **Command Prompt (CMD)**: Traditionelle Windows-Shell für grundlegende Befehle.
  - **PowerShell**: Leistungsstarke Shell, die auf .NET basiert und für Systemadministration und Automatisierung verwendet wird.

## Grundlagen der Shell-Skripterstellung
- **Shebang**: Erste Zeile eines Skripts (`#!/bin/bash` für Bash oder `@echo off` für CMD).
- **Dateirechte**: In Unix/Linux müssen Skripte ausführbar sein (`chmod +x script.sh`).

## Wichtige Shell-Befehle
- **Variablen**: 
  - Unix: `name="Wert"`; Zugriff: `echo $name`
  - Windows: `set name=Wert`; Zugriff: `echo %name%`
- **Bedingungen**: 
  - Unix: `if [ condition ]; then ... fi`
  - Windows: `if condition ( ... )`
- **Schleifen**: 
  - Unix: `for`, `while`, `until`
  - Windows: `for`, `do while`
- **Funktionen**: 
  - Unix: `function_name() { ... }`
  - Windows: `:function_name` und `goto function_name`

## Eingabe und Ausgabe
- **Standardausgabe**: 
  - Unix: `echo`
  - Windows: `echo`
- **Standardfehler**: 
  - Unix: `>&2`
  - Windows: `echo Error message > con`
- **Eingabe**: 
  - Unix: `read`
  - Windows: `set /p`

## Dateioperationen
- **Datei erstellen**: 
  - Unix: `touch datei.txt`
  - Windows: `type nul > datei.txt`
- **Datei lesen**: 
  - Unix: `cat datei.txt`
  - Windows: `type datei.txt`
- **Datei schreiben**: 
  - Unix: `echo "Text" > datei.txt`
  - Windows: `echo Text > datei.txt`
- **Datei löschen**: 
  - Unix: `rm datei.txt`
  - Windows: `del datei.txt`

## Nützliche Tipps
- **Debugging**: 
  - Unix: `bash -x script.sh`
  - Windows: `set -x` in PowerShell.
- **Kommentare**: 
  - Unix: `# Kommentar`
  - Windows: `rem Kommentar` oder `:: Kommentar`
- **Modularisierung**: Funktionen verwenden, um den Code übersichtlich und wartbar zu halten.

## Praktische Anwendungen
- Automatisierung von **Systemadministrationsaufgaben**.
- **Batch-Verarbeitung** von Dateien.
- Erstellung von **Installations-** und **Konfigurationsskripten**.
- Integration mit anderen Tools und APIs.

## Fazit
- Shellprogrammierung ist ein **vielseitiges Werkzeug** zur **Automatisierung** und **Verwaltung von Systemaufgaben** in verschiedenen Betriebssystemen. Ein solides Verständnis der Grundlagen ermöglicht effiziente und effektive Skripterstellung sowohl in Unix/Linux- als auch in Windows-Umgebungen.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- systematisches Vorgehen zur **Prozessoptimierung**
- **mathematische Herangehensweise**: Kennzahlen machen Performanz von Prozessen messbar 
- Feststellen von **Kausalzusammenhängen**, Prozesse mit verschiedenen **Methoden** verbessern und **Fehlerquote** reduzieren

## Vorteile
- **Nachhaltigkeit**: Nachhaltiger Erfolg, Prozesse sind klar strukturiert, Basis zur kontinuierlichen Korrektur und Anpassung an Markt
- **Kundenzufriedenheit**: Six Sigma legt großen Wert auf Kundenperspektive
- **Wertsteigerung**: Wert des Unternehmen für Kunden, Kundenwünsche können konkreter verstanden und gezielt erreicht werden
- **Unternehmenskultur**: bessere Kommunikation zwischen Managern und Mitarbeitern
- **Lernende Organisation**: lebenslanges Lernen spielt wichtige Rolle in Six Sigma

## Anwendung
- Vielzahl an verschiedener Management-Techniken zur Qualitäts- und Prozessoptimierung -> **Six Sigma Toolkit**

### DMAIC-Zyklus
1. **Define** *(Definieren)*
	- Identifikation des zu verbessernden Prozess
	- Dokumentation von Problem und Prozess
	- Zielgröße und Projektscope bestimmen, was Teil der Analyse und was nicht
2. **Measure** *(Messen)*
	- relevante Qualitätsmerkmale mit verschiedenen Methoden untersuchen
	- aktuelle Performanz erheben
3. **Analyze** *(Analysieren)*
	- Ursachen und kausale Kette herausarbeiten
4. **Improve** *(Verbessern) -- bei bereits existierenden Prozessen*
	- Prozess wird verbessert
	- auch außerhalb von Six Sigma angewandten Methoden
4. **Engineer** *(Entwickeln) -- bei neuen Prozessen* 
5. **Control** *(Überwachen)*
	- Prozess wird mit Hilfe statischer Auswertung überwacht
	- Nachhaltige Verbesserung sicherstellen

## Rollen
- **Gelber Gürtel**: Einstiegszertifizierung, Überblick über Grundlagen. Unterstützer von Projekten, Experten in einem Fachbereich oder Manager die zukünftig weitere Zertifizierung erwerben
- **Grüner Gürtel**: tiefgehende methodische Kenntnisse, Verantwortungsbereich in einem Projekt leiten
- **Schwarzer Gürtel**: leiten komplexe Projekte, tiefe fachliche Expertise, hohe Sozialkompetenz um große Veränderungsprozesse umzusetzen. Fungieren als Motivator, maßgeblich für Erfolg des Projekes
- **Schwarzer Meistergürtel**: Prozessverantwortung, strategische Ausrichtung von Six Sigma in der Organisation. Legt Six Sigma Standards im Unternehmen fest
- **Champion**: Mittleren/Oberen Management, nicht im Tagesgeschäft eingebunden. Wählt Projekte aus, initiiert und überwacht sie

## Quellen
> Redaktion, I. (2019). Six-Sigma-Methode: Wie sie funktioniert und was sie bewirkt. IONOS Startup Guide. Retrieved from https://www.ionos.de/startupguide/unternehmensfuehrung/six-sigma-methode

- Schreiben von Programmen in **Skriptsprachen**, die in der Regel **interpretiert** werden und häufig zur **Automatisierung von Aufgaben**, zur **Webentwicklung** oder zur **Datenverarbeitung** verwendet werden.

## Merkmale von Skriptsprachen
- **Interpretiert**: Skriptsprachen werden zur Laufzeit interpretiert, was bedeutet, dass der Code nicht vor der Ausführung kompiliert werden muss.
- **Dynamisch**: Viele Skriptsprachen unterstützen dynamische Typisierung, was die Entwicklung flexibler und schneller macht.
- **Einfachheit**: Skriptsprachen sind oft einfacher zu erlernen und zu verwenden als kompilierte Programmiersprachen, was sie ideal für schnelle Prototypen und kleinere Projekte macht.
- **Plattformunabhängigkeit**: Skripte können auf verschiedenen Plattformen ausgeführt werden, solange ein geeigneter Interpreter vorhanden ist.

## Beliebte Skriptsprachen
- **JavaScript**: Eine weit verbreitete Sprache für die Webentwicklung, die es ermöglicht, interaktive und dynamische Inhalte in Webseiten zu integrieren.
- **Python**: Eine vielseitige Sprache, die in vielen Bereichen eingesetzt wird, darunter Webentwicklung, Datenanalyse, maschinelles Lernen und Automatisierung.
- **Ruby**: Bekannt für seine Einfachheit und Lesbarkeit, wird häufig in der Webentwicklung (z.B. mit Ruby on Rails) verwendet.
- **PHP**: Eine serverseitige Skriptsprache, die hauptsächlich für die Webentwicklung verwendet wird, um dynamische Webseiten zu erstellen.

## Anwendungen der Skriptprogrammierung
- **Webentwicklung**: Erstellung von interaktiven Webseiten und Webanwendungen (z.B. mit JavaScript und PHP).
- **Automatisierung**: Automatisierung von Aufgaben und Prozessen, z.B. durch Skripte in Python oder Bash.
- **Datenanalyse**: Verarbeitung und Analyse von Daten, häufig mit Bibliotheken wie Pandas in Python.
- **Systemadministration**: Verwaltung und Automatisierung von Systemaufgaben durch Skripte.

## Vorteile der Skriptprogrammierung
- **Schnelligkeit**: Schnelle Entwicklung und Iteration von Code, was die Produktivität erhöht.
- **Flexibilität**: Skripte können leicht angepasst und erweitert werden, um sich ändernden Anforderungen gerecht zu werden.
- **Zugänglichkeit**: Viele Skriptsprachen haben eine große Community und umfangreiche Bibliotheken, die den Einstieg erleichtern.

## Herausforderungen
- **Leistung**: Skriptsprachen sind oft langsamer als kompilierte Sprachen, was in leistungskritischen Anwendungen problematisch sein kann.
- **Fehlende Typensicherheit**: Dynamische Typisierung kann zu Laufzeitfehlern führen, die schwer zu debuggen sind.
- **Sicherheitsrisiken**: Skripte, insbesondere in Webanwendungen, können anfällig für Sicherheitslücken wie SQL-Injection oder Cross-Site Scripting (XSS) sein.

## Best Practices
- **Code-Organisation**: Strukturierung des Codes in Module oder Funktionen, um die Lesbarkeit und Wartbarkeit zu verbessern.
- **Versionskontrolle**: Verwendung von Versionskontrollsystemen (z.B. Git), um Änderungen nachverfolgen und verwalten zu können.
- **Dokumentation**: Ausführliche Dokumentation des Codes, um die Verständlichkeit für andere Entwickler zu erhöhen.
- **Testen**: Implementierung von Tests, um die Funktionalität und Stabilität des Codes sicherzustellen.
## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1



- **S**ervice **L**evel **A**greements
- formelles Dokument, das die **Erwartungen** und **Verpflichtungen** zwischen einem Dienstleister und einem Kunden festlegt. Es definiert die **Qualität**, **Verfügbarkeit** und **Verantwortlichkeiten** der **Dienstleistungen**.
- **Zweck**: **Sicherstellung**, dass beide Parteien **klare Erwartungen** haben und die vereinbarten Standards eingehalten werden.

## Wichtige Bestandteile eines SLA:
1. **Servicebeschreibung**: Detaillierte Beschreibung der angebotenen Dienstleistungen.
2. **Leistungskennzahlen (KPIs)**: Metriken zur Messung der Servicequalität (z. B. Verfügbarkeit, Reaktionszeiten).
3. **Verfügbarkeitsgarantien**: Zusicherungen über die Betriebszeiten (z. B. 99,9% Verfügbarkeit).
4. **Reaktionszeiten**: Zeitrahmen, innerhalb dessen der Dienstleister auf Anfragen oder Probleme reagieren muss.
5. **Berichterstattung**: Regelmäßige Berichte über die Serviceleistung.
6. **Strafen und Anreize**: Konsequenzen bei Nichteinhaltung der SLAs und mögliche Anreize für überdurchschnittliche Leistungen.

## Verschiedene Arten von SLAs
1. **Customer SLA (Kunden-SLA)**:
   - **Definition**: Vereinbarung zwischen einem Dienstleister und einem Endkunden.
   - **Zweck**: Festlegung der Erwartungen des Kunden an die Dienstleistungsqualität.
2. **Internal SLA (Internes SLA)**:
   - **Definition**: Vereinbarung zwischen verschiedenen Abteilungen innerhalb eines Unternehmens.
   - **Zweck**: Sicherstellung, dass interne Dienstleistungen die erforderlichen Standards erfüllen, um die Gesamtleistung des Unternehmens zu unterstützen.
3. **Operational Level Agreement (OLA)**:
   - **Definition**: Eine spezifische Art von internem SLA, das die Verpflichtungen zwischen verschiedenen internen Teams oder Abteilungen beschreibt.
   - **Zweck**: Unterstützung der Erfüllung von Kunden-SLAs durch Festlegung von Standards und Verantwortlichkeiten innerhalb des Unternehmens.
   - **Beispiel**: Ein OLA zwischen der IT-Abteilung und dem Kundenservice, das die Reaktionszeiten für technische Unterstützung definiert.
4. **Service Level Objective (SLO)**:
   - **Definition**: Ein spezifisches Ziel innerhalb eines SLA, das eine messbare Leistung beschreibt.
   - **Zweck**: Dient als Grundlage für die Bewertung der Servicequalität.
   - **Beispiel**: Ein SLO könnte festlegen, dass 95% der Supportanfragen innerhalb von 24 Stunden beantwortet werden.
5. **Service Level Management (SLM)**:
   - **Definition**: Der Prozess der Überwachung und Verwaltung von SLAs und SLOs.
   - **Zweck**: Sicherstellung, dass die vereinbarten Servicelevels eingehalten werden und kontinuierliche Verbesserungen stattfinden.

## Supportlevel
### Level 1 Support
- **Definition**: Erster Kontaktpunkt für Kundenanfragen und technische Probleme.
- **Aufgaben**:
  - Entgegennahme von Anrufen, E-Mails oder Chats.
  - Grundlegende Problemlösung und Beantwortung häufig gestellter Fragen (FAQs).
  - Erfassung von Kundeninformationen und Problembeschreibungen.
  - Weiterleitung komplexerer Probleme an Level 2 Support.
- **Beispiele**:
  - Passwort zurücksetzen.
  - Anleitungen zur Nutzung von Software bereitstellen.
  - Informationen zu Produkten und Dienstleistungen geben.

### Level 2 Support
- **Definition**: Technischer Support, der komplexere Probleme behandelt, die vom Level 1 Support nicht gelöst werden konnten.
- **Aufgaben**:
  - Detaillierte Analyse und Diagnose von technischen Problemen.
  - Nutzung von speziellen Tools und Ressourcen zur Problemlösung.
  - Unterstützung bei Software- und Hardwareproblemen.
  - Dokumentation von Lösungen und häufigen Problemen für zukünftige Referenz.
- **Beispiele**:
  - Fehlerbehebung bei Softwarefehlern.
  - Unterstützung bei Netzwerkproblemen.
  - Durchführung von Systemupdates oder -konfigurationen.

### Level 3 Support
- **Definition**: Höchster technischer Support, der sich mit den komplexesten und kritischsten Problemen befasst.
- **Aufgaben**:
  - Eingehende technische Analysen und Lösungen für schwerwiegende Probleme.
  - Zusammenarbeit mit Entwicklern oder Herstellern zur Lösung von Software- oder Hardwarefehlern.
  - Durchführung von Systemänderungen oder -upgrades.
  - Schulung und Unterstützung von Level 1 und Level 2 Supportmitarbeitern.
- **Beispiele**:
  - Entwicklung von Patches für Softwarefehler.
  - Analyse von Systemarchitekturen und -designs.
  - Unterstützung bei der Implementierung neuer Technologien.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- in [[Block Chain]] **gespeichertes Programm**
- **digitaler Vertrag**
- Bedingungen werden in **Wenn-Dann-Aussagen** formuliert
- **Selbstausführend**
- **Vorteile**
	- Nicht manipulierbar
	- Dezentralität
	- Effizienz
	- Eindeutigkeit
- **Nachteile**
	- Programmierfehler
	- Hintertüren
	- Keine Rechtssicherheit
	- Nachvollziehbarkeit?
	- Gute Infrastruktur nötig
- **Anwendungsgebiete**
	- **Kryptowährungen**, Ethereum + Solidity

## Quellen

> Dalwigk, F. (2021, November 19). SMART CONTRACTS: Was sind SCHLAUE VERTRÄGE? (Einfach erklärt). Youtube. Retrieved from https://www.youtube.com/watch?v=Rs4hsrIu1QI

- modernes elektrisches Versorgungsnetz, das **digitale Kommunikationstechnologien** und **intelligente Geräte** integriert, um die **Effizienz, Zuverlässigkeit und Nachhaltigkeit** der Energieversorgung zu verbessern.

## Komponenten des Smart Grid
- **Intelligente Zähler**: Geräte, die den Energieverbrauch in Echtzeit messen und Daten an Versorgungsunternehmen und Verbraucher übermitteln.
- **Energie-Management-Systeme**: Softwarelösungen, die den Energieverbrauch optimieren und die Integration erneuerbarer Energien unterstützen.
- **Dezentrale Energieerzeugung**: Nutzung von erneuerbaren Energiequellen wie Solar- und Windenergie, die lokal erzeugt und ins Netz eingespeist werden.
- **Kommunikationsinfrastruktur**: Netzwerke, die den Austausch von Daten zwischen Verbrauchern, Erzeugern und Versorgungsunternehmen ermöglichen.

## Vorteile des Smart Grid
- **Erhöhte Effizienz**: Optimierung des Energieverbrauchs und Reduzierung von Verlusten im Stromnetz.
- **Zuverlässigkeit**: Schnellere Identifizierung und Behebung von Störungen, was die Netzstabilität erhöht.
- **Integration erneuerbarer Energien**: Erleichterung der Einspeisung von Solar- und Windenergie in das Netz.
- **Kosteneinsparungen**: Langfristige Reduzierung der Betriebskosten für Versorgungsunternehmen und Verbraucher.

## Herausforderungen
- **Sicherheitsrisiken**: Erhöhte Anfälligkeit für Cyberangriffe aufgrund der Vernetzung und Digitalisierung.
- **Investitionskosten**: Hohe Anfangsinvestitionen für die Implementierung der erforderlichen Technologien und Infrastruktur.
- **Standardisierung**: Mangel an einheitlichen Standards und Protokollen, die die Interoperabilität zwischen verschiedenen Systemen gewährleisten.
- **Akzeptanz der Verbraucher**: Notwendigkeit, Verbraucher über die Vorteile und Funktionsweise des Smart Grid aufzuklären, um deren Akzeptanz zu fördern.

## Anwendungen des Smart Grid
- **Lastmanagement**: Anpassung des Energieverbrauchs in Echtzeit, um Spitzenlasten zu vermeiden und die Netzstabilität zu gewährleisten.
- **E-Mobilität**: Integration von Elektrofahrzeugen in das Stromnetz, um die Ladeinfrastruktur zu optimieren und die Energieverteilung zu steuern.
- **Demand Response**: Programme, die Verbraucher anregen, ihren Energieverbrauch in Zeiten hoher Nachfrage zu reduzieren.
- **Intelligente Gebäude**: Nutzung von Smart-Home-Technologien zur Optimierung des Energieverbrauchs in Wohn- und Geschäftsgebäuden.

## Quellen
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **Definition**: SMB steht für **Server Message Block** und ist ein Standard-Filesharing-Protokoll, das hauptsächlich für Windows-Betriebssysteme verwendet wird. Es ermöglicht Anwendungen, auf Dateien und Drucker über ein Netzwerk zuzugreifen.

- **Funktionsweise**:
  - **Client-Server-Architektur**: SMB funktioniert in einer **Client-Server-Architektur**, bei der **Clients Anfragen an den Server senden**, um auf Dateien, Drucker und andere Ressourcen zuzugreifen.
  - **Kommunikation**: SMB verwendet ein **Anfrage-Antwort-Modell**, bei dem der Client eine Anfrage an den Server sendet, der die Anfrage verarbeitet und eine Antwort zurücksendet.
  - **Netzwerkprotokolle**: SMB kann über verschiedene Netzwerkprotokolle wie [[TCP-IP-Modell|TCP/IP]], NetBEUI und IPX/SPX betrieben werden, wobei [[TCP-IP-Modell|TCP/IP]] am häufigsten verwendet wird.

- **Funktionen**:
  - **Dateizugriff**: Ermöglicht den Zugriff auf Dateien und Verzeichnisse auf einem Remote-Server, als wären sie lokal gespeichert.
  - **Druckdienste**: Unterstützt den Zugriff auf Netzwerkdrucker und ermöglicht das Drucken von Dokumenten über das Netzwerk.
  - **Authentifizierung**: Bietet Mechanismen zur Authentifizierung und Autorisierung von Benutzern, um den Zugriff auf Ressourcen zu steuern.
  - **Dateisperren**: Ermöglicht das Sperren von Dateien, um gleichzeitige Schreibzugriffe zu koordinieren und Dateninkonsistenzen zu vermeiden.

- **Vorteile von SMB**:
  - **Einfache Integration**: Nahtlose Integration in Windows-Umgebungen und Unterstützung für andere Betriebssysteme wie Linux und macOS.
  - **Benutzerfreundlichkeit**: Einfache Nutzung für Endbenutzer durch grafische Benutzeroberflächen zur Navigation und zum Zugriff auf Netzwerkressourcen.
  - **Flexibilität**: Unterstützt verschiedene Arten von Netzwerkressourcen, einschließlich Dateien, Drucker und andere Dienste.

## Quellen
> Seite „Server Message Block“. In: Wikipedia – Die freie Enzyklopädie. Bearbeitungsstand: 8. Januar 2024, 20:36 UTC. URL: [https://de.wikipedia.org/w/index.php?title=Server_Message_Block&oldid=240987303](https://de.wikipedia.org/w/index.php?title=Server_Message_Block&oldid=240987303) (Abgerufen: 18. September 2024, 11:38 UTC)


- Simple Network Management Protocol
- Protokoll zur **Überwachung** und **Steuerung** von Netzwerkgeräten (z.B. Router, Switches, Server, Drucker, etc.) indem Daten von diesen Geräten abgefragt und konfiguriert werden können.
- SNMP arbeitet auf der **Anwendungsschicht** (Layer 7).

## Protokollarchitektur
- **Manager**: Zentrale Instanz, die Informationen von Netzwerkgeräten sammelt.
- **Agent**: Software, die auf den Netzwerkgeräten installiert ist, um auf Anfragen des Managers zu reagieren.
- **MIB (Management Information Base)**: Eine Datenbank, die Informationen über die Netzwerkgeräte in einer strukturierten Form speichert.
  
## Hauptaufgaben
  - **Überwachen**: Erfassung von Netzwerkdaten, z.B. Bandbreitennutzung, Verfügbarkeit, CPU-Auslastung.
  - **Steuern**: Änderungen an den Geräteeinstellungen vornehmen, z.B. Neustart eines Geräts oder Ändern von IP-Adressen.
  - **Alarmierung**: SNMP kann Alarme auslösen, wenn ein Fehler oder eine Auffälligkeit auftritt (z.B. zu hohe CPU-Auslastung).

## Nachrichtenarten
  - **GET**: Anforderung bestimmter Informationen von einem Agenten.
  - **SET**: Ändert den Wert einer Variablen auf einem Agenten.
  - **TRAP**: Unaufgeforderte Nachricht von einem Agenten an den Manager, z.B. wenn ein Problem erkannt wird.
  - **GETNEXT**: Ruft die nächste Variable in der MIB ab.
  - **GETBULK**: Fordert mehrere Daten auf einmal an.

## Versionen
  - **SNMPv1**: Die erste Version, relativ einfach, aber sicherheitsanfällig.
  - **SNMPv2c**: Verbesserungen in der Leistung, aber noch immer mit Sicherheitslücken.
  - **SNMPv3**: Fügt **Sicherheitsmechanismen** wie Authentifizierung und Verschlüsselung hinzu.

## Vorteile
  - **Zentrale Verwaltung** von Netzwerken
  - **Skalierbarkeit** für große Netzwerke
  - **Automatisierte Benachrichtigungen** bei Problemen (z.B. Traps)

## Nachteile
  - Ältere Versionen (v1 und v2c) haben **Sicherheitsprobleme** (fehlende Verschlüsselung, einfache Authentifizierung).
  - Kann bei vielen Geräten oder großen Datenmengen zu **Netzwerkbelastungen** führen.

## Anwendungsbeispiele
  - Überwachung von **Servern** und **Routern** in einem Unternehmensnetzwerk.
  - Automatisierte **Alarmierungen** bei Netzwerkausfällen oder Ressourcenüberlastung.
  
## Einsatzbereiche
  - In IT-Infrastrukturen von kleinen bis großen Unternehmen zur **Netzwerkverwaltung** und Fehlerdiagnose.
## Quellen

> Thomas-Krenn. A. G. (2024, September 20). SNMP Grundlagen – Thomas-Krenn-Wiki. Retrieved from [https://www.thomas-krenn.com/de/wiki/SNMP_Grundlagen](https://www.thomas-krenn.com/de/wiki/SNMP_Grundlagen)


## Änderbarkeit
- **Definition**: Änderbarkeit beschreibt, wie einfach es ist, Software nach ihrer Fertigstellung zu modifizieren.
- **Wichtige Aspekte**:
  - Modularer Aufbau: Erleichtert Anpassungen und Erweiterungen.
  - Dokumentation: Klare und umfassende Dokumentation unterstützt zukünftige Änderungen.
  - Testbarkeit: Änderungen sollten durch Tests validiert werden können.

## Benutzbarkeit
- **Definition**: Benutzbarkeit bezieht sich auf die Benutzerfreundlichkeit der Software.
- **Wichtige Aspekte**:
  - Intuitive Benutzeroberfläche: Einfache Navigation und klare Anweisungen.
  - Zugänglichkeit: Berücksichtigung von Nutzern mit unterschiedlichen Fähigkeiten.
  - Feedback: Schnelles und hilfreiches Feedback an den Benutzer.

## Effizienz
- **Definition**: Effizienz beschreibt, wie gut die Software Ressourcen (z.B. Zeit, Speicher) nutzt.
- **Wichtige Aspekte**:
  - Reaktionszeit: Schnelle Antwortzeiten auf Benutzeraktionen.
  - Ressourcennutzung: Minimierung des Verbrauchs von CPU und Speicher.
  - Optimierung: Regelmäßige Überprüfung und Optimierung des Codes.

## Funktionalität
- **Definition**: Funktionalität bezieht sich auf die spezifischen Funktionen und Features, die die Software bereitstellt.
- **Wichtige Aspekte**:
  - Anforderungsanalyse: Klare Definition der benötigten Funktionen.
  - Vollständigkeit: Alle definierten Funktionen sollten implementiert sein.
  - Korrektheit: Funktionen müssen wie spezifiziert arbeiten.

## Übertragbarkeit
- **Definition**: Übertragbarkeit beschreibt, wie gut die Software auf verschiedenen Plattformen oder Umgebungen funktioniert.
- **Wichtige Aspekte**:
  - Plattformunabhängigkeit: Software sollte auf verschiedenen Betriebssystemen lauffähig sein.
  - Installationsprozess: Einfache Installation und Konfiguration auf neuen Systemen.
  - Migration: Unterstützung beim Wechsel von einer Umgebung zur anderen.

## Zuverlässigkeit
- **Definition**: Zuverlässigkeit beschreibt die Fähigkeit der Software, unter definierten Bedingungen konsistent zu funktionieren.
- **Wichtige Aspekte**:
  - Fehlertoleranz: Fähigkeit, Fehler zu erkennen und zu beheben, ohne den Betrieb zu unterbrechen.
  - Verfügbarkeit: Software sollte jederzeit verfügbar sein, wenn sie benötigt wird.
  - Wartbarkeit: Einfache Identifikation und Behebung von Problemen.

## Normen anwenden
- **Definition**: Die Anwendung von Normen bezieht sich auf die Einhaltung von Standards und Richtlinien in der Softwareentwicklung.
- **Wichtige Aspekte**:
  - Qualitätsstandards: Einhaltung von ISO-Standards oder anderen relevanten Normen.
  - Dokumentation: Alle Prozesse und Ergebnisse sollten dokumentiert werden, um die Nachverfolgbarkeit zu gewährleisten.
  - Best Practices: Anwendung bewährter Methoden zur Verbesserung der Softwarequalität.

- **Gestaltung von Softwareanwendungen**, um die **Benutzerfreundlichkeit**, **Effizienz** und **Zufriedenheit** der Nutzer zu maximieren. Sie berücksichtigt die Bedürfnisse, Fähigkeiten und Einschränkungen der Benutzer.
- **Ziel**: **Verbesserung der Interaktion zwischen Mensch und Computer**, um die Produktivität zu steigern und Fehler zu minimieren.

### Grundprinzipien der Softwareergonomie
- **Benutzerzentrierter Designansatz**: Die Bedürfnisse und Anforderungen der Benutzer stehen im Mittelpunkt des Entwicklungsprozesses.
- **Konsistenz**: Einheitliche Gestaltungselemente und Interaktionsmuster, um die Lernkurve zu verkürzen und Verwirrung zu vermeiden.
- **Feedback**: Bereitstellung von sofortigem und verständlichem Feedback auf Benutzeraktionen, um die Interaktion zu unterstützen.
- **Fehlertoleranz**: Gestaltung von Systemen, die Fehler erkennen und dem Benutzer helfen, diese zu korrigieren, anstatt sie zu bestrafen.
- **Flexibilität und Effizienz**: Anpassungsfähigkeit der Software an verschiedene Benutzerbedürfnisse und -fähigkeiten, um die Effizienz zu steigern.

### Anwendungsbereiche der Softwareergonomie
- **Webanwendungen**: Gestaltung von benutzerfreundlichen Websites und Online-Diensten.
- **Mobile Apps**: Optimierung der Benutzeroberflächen für Smartphones und Tablets.
- **Desktop-Anwendungen**: Entwicklung intuitiver Software für PCs und Laptops.
- **Spezialisierte Software**: Ergonomische Gestaltung von Software für spezifische Branchen (z.B. Medizintechnik, Ingenieurwesen).

### Methoden zur Verbesserung der Softwareergonomie
- **Usability-Tests**: Durchführung von Tests mit echten Benutzern, um Schwachstellen in der Benutzeroberfläche zu identifizieren.
- **Prototyping**: Erstellung von Prototypen, um Designideen zu visualisieren und frühzeitig Feedback von Benutzern zu erhalten.
- **Heuristische Evaluation**: Expertenbewertung der Benutzeroberfläche anhand von etablierten Usability-Heuristiken.
- **Benutzerbefragungen**: Erhebung von Benutzerfeedback zur Identifikation von Bedürfnissen und Problemen.

### Herausforderungen in der Softwareergonomie
- **Vielfalt der Benutzer**: Berücksichtigung unterschiedlicher Benutzergruppen mit variierenden Fähigkeiten, Erfahrungen und Bedürfnissen.
- **Technologische Entwicklungen**: Anpassung an neue Technologien und Plattformen, die die Benutzerinteraktion beeinflussen.
- **Ressourcenbeschränkungen**: Oftmals begrenzte Zeit und Budget für die Durchführung umfassender Usability-Studien.
### Wichtige Begriffe
- **Usability**: Maß für die Benutzerfreundlichkeit und Effizienz einer Softwareanwendung.
- **User Experience (UX)**: Gesamterlebnis eines Benutzers bei der Interaktion mit einem Produkt oder einer Dienstleistung.
- **Interaktionsdesign**: Gestaltung der Interaktion zwischen Benutzern und Systemen.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## User-Management
- **Definition**: Verwaltung von Benutzerkonten und deren Berechtigungen innerhalb eines Systems oder Netzwerks.
- **Wichtige Aspekte**:
  - **Benutzerkontenverwaltung**: Erstellung, Änderung und Löschung von Benutzerkonten.
  - **Rollenbasierte Zugriffskontrolle (RBAC)**: Zuweisung von Berechtigungen basierend auf den Rollen der Benutzer, um den Zugriff auf sensible Daten zu steuern.
  - **Starke Authentifizierung**: Implementierung von Multi-Faktor-Authentifizierung (MFA), um die Sicherheit der Benutzeranmeldungen zu erhöhen.
  - **Passwortrichtlinien**: Durchsetzung von Richtlinien für starke Passwörter (z. B. Mindestlänge, Komplexität) und regelmäßige Passwortänderungen.
  - **Überwachung und Protokollierung**: Nachverfolgung von Benutzeraktivitäten zur Erkennung von unbefugtem Zugriff oder verdächtigen Aktivitäten.

## Firewall/Webfilter
- **Definition**: Sicherheitslösungen, die den Datenverkehr zwischen einem internen Netzwerk und externen Netzwerken überwachen und steuern.
- **Wichtige Aspekte**:
  - **Firewall**: Hardware- oder Softwarelösung, die den ein- und ausgehenden Datenverkehr basierend auf vordefinierten Sicherheitsregeln filtert.
    - **Zugriffssteuerung**: Bestimmung, welche Verbindungen erlaubt oder blockiert werden.
    - **Intrusion Detection/Prevention Systems (IDS/IPS)**: Systeme zur Erkennung und Verhinderung von unbefugten Zugriffen oder Angriffen.
  - **Webfilter**: Software, die den Zugriff auf bestimmte Websites oder Inhalte basierend auf vordefinierten Richtlinien einschränkt.
    - **Inhaltsfilterung**: Blockierung von schädlichen oder unangemessenen Inhalten.
    - **Kategorisierung**: Klassifizierung von Websites in verschiedene Kategorien (z. B. soziale Medien, Glücksspiel), um den Zugriff zu steuern.

## Port-Security
- **Definition**: Sicherheitsmaßnahmen, die den Zugriff auf Netzwerkports steuern, um unbefugten Zugriff und Netzwerkangriffe zu verhindern.
- **Wichtige Aspekte**:
  - **Port-Security auf Switches**: Konfiguration von Switches, um nur autorisierte Geräte an bestimmten Ports zuzulassen.
    - **MAC-Adressfilterung**: Beschränkung des Zugriffs auf bestimmte MAC-Adressen, die an einem Port erlaubt sind.
    - **Maximale Anzahl von MAC-Adressen**: Festlegung einer maximalen Anzahl von MAC-Adressen, die an einem Port gleichzeitig aktiv sein dürfen.
  - **Alarmierung**: Benachrichtigung bei unbefugtem Zugriff oder wenn ein nicht autorisiertes Gerät versucht, sich mit dem Netzwerk zu verbinden.

## Verschlüsselung (TPM)
- **Definition**: Verschlüsselung ist der Prozess, bei dem Daten in ein unlesbares Format umgewandelt werden, um sie vor unbefugtem Zugriff zu schützen. TPM (Trusted Platform Module) ist ein Hardwarechip, der zur sicheren Speicherung von Verschlüsselungsschlüsseln verwendet wird.
- **Wichtige Aspekte**:
  - **Datenverschlüsselung**: Verschlüsselung von Daten sowohl im Ruhezustand (z. B. auf Festplatten) als auch während der Übertragung (z. B. über Netzwerke).
    - **Verschlüsselungsalgorithmen**: Verwendung starker Algorithmen wie AES (Advanced Encryption Standard) zur Sicherstellung der Datensicherheit.
  - **TPM**: Hardwarekomponente, die zur Generierung, Speicherung und Verwaltung von kryptografischen Schlüsseln verwendet wird.
    - **Sichere Schlüsselverwaltung**: Speicherung von Schlüsseln in einem geschützten Bereich, um sie vor unbefugtem Zugriff zu schützen.
    - **Plattformintegrität**: Überprüfung der Integrität des Systems beim Booten, um sicherzustellen, dass keine unbefugten Änderungen vorgenommen wurden.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

# Soll-Ist-Vergleich

## Definition
Der Soll-Ist-Vergleich ist ein **wichtiges Instrument im Controlling** und der Unternehmensplanung, um die geplanten (Soll-)Zustände mit den tatsächlich erreichten (Ist-)Zuständen zu vergleichen.

## Komponenten
- **Soll-Zustände**: 
	- Definierte Ziele und Vorgaben, die erreicht werden sollen.
	- Beispiel: Umsatzprognosen, Produktionsziele.
- **Ist-Zustände**: 
	 - Tatsächlich erreichte Werte und Ergebnisse.
	 - Beispiel: Tatsächlicher Umsatz, tatsächliche Produktionszahlen.
## Kennzahlen
- **Sollwerte**: 
	- Die angestrebten Werte, die in der Planung festgelegt wurden.
	- Beispiel: Geplante Verkaufszahlen pro Quartal.
- **Istwerte**: 
	- Die realisierten Werte, die während eines bestimmten Zeitraums erfasst werden.
	- Beispiel: Tatsächliche Verkaufszahlen pro Quartal.
## Analyse
- Eine Vielzahl von **Kennzahlen** (Soll- und Istwerte) wird gemessen und gegenübergestellt.
- Bei Abweichungen zwischen Soll- und Istwerten erfolgt eine detaillierte Ursachenanalyse.
  - Methoden zur Ursachenanalyse:
    - [[SWOT-Analyse|SWOT-Analyse Identifikation von Stärken, Schwächen, Chancen und Risiken.]]
    - Weitere Methoden: [[Ishikawa-Diagramm|Ursachen-Wirkungs-Diagramm]], 5-Why-Analyse.
## Ziel
- Der Soll-Ist-Vergleich dient dazu, Abweichungen frühzeitig zu erkennen, um geeignete Maßnahmen zur Optimierung und Anpassung der Planung zu ergreifen.
- Er unterstützt die Entscheidungsfindung und die strategische Ausrichtung des Unternehmens.


- **S**tandard **O**peration **P**rocedures 
- **dokumentierter Prozess**, der detaillierte **Anweisungen zur Durchführung spezifischer Aufgaben** oder Aktivitäten innerhalb einer Organisation bereitstellt. SOPs sind darauf ausgelegt, **Konsistenz**, **Effizienz** und **Qualität** in den **Arbeitsabläufen** zu gewährleisten.

## Zweck von SOPs
- **Konsistenz**: Sicherstellung, dass Aufgaben auf die gleiche Weise durchgeführt werden, unabhängig davon, wer sie ausführt.
- **Qualitätssicherung**: Minimierung von Fehlern und Abweichungen durch klare Anweisungen.
- **Schulung**: Bereitstellung eines Referenzdokuments für neue Mitarbeiter und zur Auffrischung des Wissens bestehender Mitarbeiter.
- **Compliance**: Unterstützung bei der Einhaltung von gesetzlichen und regulatorischen Anforderungen.
- **Effizienz**: Optimierung von Arbeitsabläufen durch klare und strukturierte Anweisungen.

## Bestandteile einer SOP
1. **Titel**: Klare Bezeichnung der SOP.
2. **Zweck**: Beschreibung des Ziels und der Bedeutung der SOP.
3. **Geltungsbereich**: Definition, auf welche Abteilungen oder Prozesse die SOP anwendbar ist.
4. **Verantwortlichkeiten**: Auflistung der Personen oder Rollen, die für die Durchführung und Einhaltung der SOP verantwortlich sind.
5. **Verfahren**: Detaillierte Schritt-für-Schritt-Anweisungen zur Durchführung der Aufgabe.
6. **Dokumentation**: Hinweise zur erforderlichen Dokumentation und Aufzeichnung von Ergebnissen.
7. **Referenzen**: Verweise auf relevante Richtlinien, Gesetze oder andere SOPs.
8. **Überprüfung und Aktualisierung**: Verfahren zur regelmäßigen Überprüfung und Aktualisierung der SOP.

## Arten von SOPs
1. **Administrative SOPs**: Beschreiben administrative Prozesse, wie z. B. Personalmanagement oder Budgetierung.
2. **Technische SOPs**: Detaillierte Anweisungen für technische oder spezialisierte Aufgaben, z. B. Laborverfahren oder Maschinenbedienung.
3. **Sicherheits-SOPs**: Verfahren zur Gewährleistung der Sicherheit am Arbeitsplatz, z. B. Notfallmaßnahmen oder Sicherheitsprotokolle.
4. **Qualitätsmanagement-SOPs**: Verfahren zur Sicherstellung der Qualität von Produkten oder Dienstleistungen, z. B. Prüf- und Testverfahren.

## Erstellung von SOPs
- **Identifikation**: Bestimmung der Prozesse, die dokumentiert werden müssen.
- **Zusammenstellung eines Teams**: Einbeziehung von Fachleuten, die mit dem Prozess vertraut sind.
- **Dokumentation**: Erstellung des SOP-Dokuments unter Berücksichtigung der oben genannten Bestandteile.
- **Überprüfung**: Prüfung des Entwurfs durch relevante Stakeholder.
- **Genehmigung**: Offizielle Genehmigung der SOP durch die zuständigen Personen.
- **Schulung**: Schulung der Mitarbeiter zur Anwendung der SOP.
- **Überwachung und Aktualisierung**: Regelmäßige Überprüfung der SOP auf Aktualität und Relevanz.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Soziale Stabilität bezieht sich auf den **Zustand einer Gesellschaft**, in dem soziale Strukturen, Beziehungen und Institutionen stabil und harmonisch funktionieren. Sie ist gekennzeichnet durch ein hohes Maß an sozialer Kohäsion, Gerechtigkeit und das Fehlen von Konflikten oder Unruhen.

### Wichtige Aspekte der sozialen Stabilität
- **Gleichheit und Gerechtigkeit**: Eine gerechte Verteilung von Ressourcen und Chancen trägt zur sozialen Stabilität bei, indem sie Ungleichheiten und Spannungen verringert.
- **Soziale Integration**: Die Einbeziehung aller gesellschaftlichen Gruppen, unabhängig von Herkunft, Geschlecht oder sozialem Status, fördert den sozialen Zusammenhalt.
- **Vertrauen in Institutionen**: Das Vertrauen der Bürger in politische, wirtschaftliche und soziale Institutionen ist entscheidend für die Stabilität einer Gesellschaft.

### Bedeutung der sozialen Stabilität in der IT
- **Zugang zu Informationen**: Der Zugang zu digitalen Informationen und Technologien kann die soziale Stabilität fördern, indem er Bildung und Teilhabe ermöglicht.
- **Digitale Inklusion**: Die Schaffung von inklusiven digitalen Räumen, in denen alle Menschen teilnehmen können, trägt zur sozialen Kohäsion bei.
- **Vermeidung von Konflikten**: Durch den Einsatz von Technologien zur Förderung des Dialogs und der Kommunikation können Missverständnisse und Konflikte reduziert werden.

### Maßnahmen zur Förderung der sozialen Stabilität
- **Bildung und Aufklärung**: Programme zur Förderung von Bildung und digitalen Kompetenzen, um Chancengleichheit zu gewährleisten.
- **Soziale Programme**: Initiativen zur Unterstützung benachteiligter Gruppen, um soziale Ungleichheiten abzubauen.
- **Partizipation**: Förderung der aktiven Teilnahme der Bürger an politischen und sozialen Prozessen, um das Vertrauen in Institutionen zu stärken.

### Herausforderungen und Risiken
- **Soziale Ungleichheit**: Ungleichheiten in Einkommen, Bildung und Zugang zu Ressourcen können die soziale Stabilität gefährden.
- **Digitale Kluft**: Der ungleiche Zugang zu digitalen Technologien kann bestehende soziale Spannungen verstärken und zu einer Fragmentierung der Gesellschaft führen.
- **Politische Instabilität**: Unzufriedenheit mit politischen Institutionen oder Entscheidungen kann zu sozialen Unruhen und Instabilität führen.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Die Spannweite ist ein **wichtiges Maß** in der Statistik, das die **Variabilität einer Datenreihe** beschreibt. Sie gibt an, wie **weit die Werte** einer Datenreihe **auseinander liegen**.

## Definition
- Teil der [[Streumaße]]
- Die Spannweite ist die Differenz zwischen dem größten (*Maximum*) und dem kleinsten (*Minimum*) Wert einer Datenreihe.
- Sie kann durch Ausreißer verzerrt werden, da nur die **Extremwerte** betrachtet werden.

## Formel
Die Spannweite $R$ wird wie folgt berechnet:

$$
R = x_{max} - x_{min}
$$


## Quellen
> Spannweite berechnen. (2022, September 19). Retrieved from https://studyflix.de/statistik/spannweite-berechnen-5401
> OpenAI. (2024, 16. September). _ChatGPT_. DuckDuckGo. Abgerufen von https://duck.ai



## Speichersysteme
![[Pasted image 20240917104333.png]]

### Direct Attached Storage (DAS)
- **kostengünstiger** Einstieg
- Speicher wird via **Punkt-zu-Punkt-Verbindung** Serial Attached SCSI direkt an Server angeschlossen
- **Stärken**
	- Niedriger Hardware-Aufwand
	- Niedrige Kosten
	- Kein zusätzlicher Protokollstack
	- Konzeptionell *sehr performant*
- **Schwächen**
	- Exklusiv an einem Host
	- Eingeschränkte Skalierbarkeit in Kapazität
	- Eingeschränkte Entfernung vom Host zum Storage (max. 10m)
- **Anwendungsgebiet**, bei hohen Anforderungen an Performance (Datenbankanwendungen, Caching)

### Storage Area Network (SAN)
- Anschluss meist über [[Fibre Channel|Fibre Channel]]
- Speicherserver haben eigene **Fibre-Channel-Infrastruktur**, analog zur Ethernet-Struktur aufgebaut
	- NIC -> Fibre-Channel-HBA (*Host-Bus-Adapter*)
	- Netzwerk Switch -> Fibre-Channel-Switch
- Server kann auf mehrere Storage-Systeme zugreifen 
- **Stärken**
	- Hohe Transferraten
	- Größere Distanzen möglich als DAS
	- Kosteneinsparungen durch Speicherkonsolidierung
	- Einfachere Administration durch Zentralisierung
- **Schwächen**
	- dedizierte Infrastrukturebene für Storage
	- Hochpreisige Hardware-Komponenten
	- Komplizierte Konfiguration
- **Anwendungsgebiete**, ähnlich wie beim DAS, Datenbank-Anwendungen, Caching, ...

### Network Attached Storage (NAS)
- Anschluss an bestehende IT-Infrastruktur via Ethernet-Switch
- **Stärken**
	- einfache Anbindung
	- Kompatibilität und Operabilität
	- Dank Networking-Filesystem einfacher konkurrierender Zugriff mehrer Clients
- **Schwächen**
	- TCP/IP-Protokoll nicht für Storage-Traffic optimiert
	- hohe Belastung des vorhandenen LANs
- **Anwendungsgebiete**, Produktiv-, Inhalts- und Archivdaten, Backups. Bei Flash-Basierten speicher auch für Datenbank-Anwendungen, Caching, ...


## Speichertechniken
![[Pasted image 20240917112006.png]]
### File Storage
![[Pasted image 20240917111323.png]]
- auch dateibasierter Speicher
- Informationen werden als **Dateien** gespeichert und in **Dateiordner** angelegt
- **Merkmale**
	1. hierarchische Verzeichnisstruktur, Ordner und Speicherortpfade
	2. Informationen/Daten werden als vollständige Dateien gespeichert
- **Protokolle**
	- Server Message Block (SMB) (Windows)
	- Network File System (NFS) (Linux)
- **Anwendungsgebiete**, PC, NAS und DAS
- **Vorteile**
	- Günstig
	- intuitive/leicht verständliche Handhabung
	- leicht (horizontal) skalierbar
- **Nachteile**
	- je mehr Daten(pfade)/Navigationskomplexität, desto langsamer der Zugriff
- **Verwendung**
	- NAS als Dateiserver in Unternehmen
	- File Storage Server in Unternehmen die auf dieselben Daten zugreifen
	- Archivierung
### Block Storage
![[Pasted image 20240917111611.png]]
- auch blockbasierter Speicher
- Informationen werden als **Blöcke** gespeichert, Speicherorte werden von Storage-Software bestimmt und verteilt, auch **über mehrere Umgebungen**
- **gleichmäßige Aufteilung** der Daten in Einheiten gleicher Blöcke
- Server setzt Dateien durch Block-Adressen zusammen
- **Anwendungsgebiete**, SAN
- **Vorteile**
	- Schnell
	- Niedrige Latenz
	- Redundanz
- **Nachteile**
	- SAN-Hardware ist Teuer
	- Keine Metadaten (jeder Block hat eigene Adresse)
- **Verwendung**
	- (Transaktionale) Datenbanken
	- Virtuelle Maschinen

### Object Storage
![[Pasted image 20240917111753.png]]
- auch objektbasierter Speicher
- **Objekte** beinhalten eindeutige ID, Daten, Metadaten und Attribute (Berechtigungen bezüglich Objekt RWX, ...)
- flache Hierarchie
- **Vorteile**
	- Hoch skalierbar
	- Flache Struktur
	- Viele Metadaten möglich, dadurch bessere Datenanalyse
- **Nachteile**
	- Langsame Umsetzung von Änderungen
- **Verwendung**
	- Clouds, Cloud-Storage

## Quellen

> Thomas-Krenn. A. G. (2022). Storage-Grundlagen: Ratgeber für IT-Interessierte zu DAS, NAS und SAN. TKmag. Retrieved from https://www.thomas-krenn.com/de/tkmag/expertentipps/storage-grundlagen-das-san-und-nas-im-ueberblick
> Was ist File Storage, Block Storage und Object Storage? (2024, September 17). Retrieved from https://serverhero.de/wissen/speicher-block-objekt-datei
> Technology, I. (2021, September 15). What is Object Storage? Youtube. Retrieved from https://www.youtube.com/watch?v=ZfTOQJlLsAs


- Daten in Tabellen mit fester Struktur
- Beziehungen zwischen Tabellen durch Schlüssel
- Verwendung von SQL
- Beispiele: MySQL, PostgreSQL, Oracle

## Datentypen in SQL
- **Boolean:** TRUE oder FALSE
- **Integer:** Ganzzahlen (z.B. INT, BIGINT)
- **Float/Double:** Gleitkommazahlen
- **Decimal/Numeric:** Festkommazahlen für präzise Berechnungen
- **Date/Time:** Datums- und Zeitwerte
- **Char/Varchar:** Texte fester bzw. variabler Länge
- **Text/CLOB:** Große Textmengen
- **BLOB:** Binäre Daten (z.B. Bilder)
- **Geometry:** Für Geodaten (nicht in allen DBMS)

## Integrität und Schlüssel

**Referenzielle Integrität:** Sicherstellung **gültiger Beziehungen** zwischen Tabellen

**Aktualisierungs-/Löschweitergabe:**
```sql
FOREIGN KEY (spalte) REFERENCES tabelle(spalte)
  ON UPDATE CASCADE
  ON DELETE CASCADE
```

**Primärschlüssel:** Eindeutige Identifikation von Datensätzen
```sql
PRIMARY KEY (spalte)
```

**Fremdschlüssel:** Verweis auf Primärschlüssel einer anderen Tabelle
```sql
FOREIGN KEY (spalte) REFERENCES tabelle(spalte)
```

## Datenbankoperationen

**Tabellenstruktur:**
```sql
CREATE TABLE tabelle (
  spalte1 datentyp,
  spalte2 datentyp,
  ...
);

ALTER TABLE tabelle ADD spalte datentyp;
```

**Index erstellen:**
```sql
CREATE INDEX idx_name ON tabelle (spalte);
```

**Datenmanipulation:**
```sql
INSERT INTO tabelle (spalte1, spalte2) VALUES (wert1, wert2);
UPDATE tabelle SET spalte = wert WHERE bedingung;
DELETE FROM tabelle WHERE bedingung;
```

**Datenabfrage:**
```sql
SELECT spalte1, spalte2 FROM tabelle WHERE bedingung;
```

**Sortieren und Gruppieren:**
```sql
SELECT spalte FROM tabelle ORDER BY spalte;
SELECT spalte, COUNT(*) FROM tabelle GROUP BY spalte HAVING COUNT(*) > 5;
```

## Komplexe Abfragen

**Unterabfragen:**
```sql
SELECT spalte FROM tabelle WHERE spalte IN (SELECT spalte FROM andere_tabelle);
```

**Tabellenverknüpfung (JOIN):**
```sql
SELECT t1.spalte, t2.spalte 
FROM tabelle1 t1
JOIN tabelle2 t2 ON t1.id = t2.fremdschluessel;
```
![[Pasted image 20241008081155.png]]
### INNER JOIN
- Gibt nur übereinstimmende Zeilen aus beiden Tabellen zurück.
- Syntax:
```sql
SELECT columns 
FROM table1 
INNER JOIN table2 
ON table1.column = table2.column;
```
### LEFT JOIN (oder LEFT OUTER JOIN)
- Gibt alle Zeilen aus der linken Tabelle und übereinstimmende Zeilen aus der rechten Tabelle zurück.
- Nicht übereinstimmende Zeilen aus der rechten Tabelle werden mit NULL-Werten gefüllt.
### RIGHT JOIN (oder RIGHT OUTER JOIN)
- Funktioniert wie LEFT JOIN, aber behält alle Zeilen aus der rechten Tabelle.
### FULL JOIN (oder FULL OUTER JOIN)
- Kombiniert Ergebnisse von LEFT und RIGHT JOIN.
- Gibt alle Zeilen aus beiden Tabellen zurück, mit NULL-Werten für nicht übereinstimmende Zeilen.
### CROSS JOIN
- Erzeugt das kartesische Produkt beider Tabellen.
- Jede Zeile aus der ersten Tabelle wird mit jeder Zeile aus der zweiten Tabelle kombiniert.

## Ausdrücke und Bedingungen

- Vergleichsoperatoren: =, <>, <, >, <=, >=
- Logische Operatoren: AND, OR, NOT
- LIKE für Textmuster: 'A%' (beginnt mit A), '%A%' (enthält A)
- BETWEEN für Wertebereiche
- IN für Mengenzugehörigkeit

## Aggregatfunktionen

### SUM()
- **Funktion:** Berechnet die Summe aller Werte in einer numerischen Spalte.
- **Beispiel:**
```SQL
SELECT SUM(verkaufspreis) AS Gesamteinnahmen 
FROM verkauf;
```
- Berechnet die gesamte Summe aller Verkaufspreise in der Tabelle "verkauf".

### AVG()
- **Funktion:** Berechnet den Durchschnitt aller Werte in einer numerischen Spalte.
- **Beispiel:**
```SQL
SELECT AVG(alter) AS Durchschnittsalter 
FROM kunden;
```
- Berechnet das durchschnittliche Alter aller Kunden.

### COUNT()
- **Funktion:** Zählt die Anzahl der Zeilen oder nicht-NULL-Werte in einer Spalte.
- **Beispiele:**
```SQL
SELECT COUNT(*) AS AnzahlKunden 
FROM kunden;
```    
- Zählt die gesamte Anzahl der Kunden.
```SQL
SELECT COUNT(bestellnummer) AS AnzahlBestellungen 
FROM bestellungen;
```  
- Zählt die Anzahl der Bestellungen, wobei NULL-Werte in der Spalte "bestellnummer" ignoriert werden.

### MAX()
- **Funktion:** Findet den größten Wert in einer Spalte.
- **Beispiel:**    
```SQL
SELECT MAX(gehalt) AS HoehestesGehalt 
FROM mitarbeiter;
```
- Findet das höchste Gehalt unter den Mitarbeitern.

### MIN()
- **Funktion:** Findet den kleinsten Wert in einer Spalte.
- **Beispiel:**
```SQL
SELECT MIN(geburtstag) AS JuengsterMitarbeiter 
FROM mitarbeiter;
```
- Findet das Geburtsdatum des jüngsten Mitarbeiters.

### Weitere Beispiele und Kombinationen

- **Mit GROUP BY:**
```SQL
SELECT land, AVG(verkaufspreis) AS DurchschnittlicherVerkaufspreis
FROM verkauf
GROUP BY land;
```
- Berechnet den durchschnittlichen Verkaufspreis für jedes Land.
- **Mit HAVING:**      
```SQL
SELECT abteilung, COUNT(*) AS AnzahlMitarbeiter
FROM mitarbeiter
GROUP BY abteilung
HAVING COUNT(*) > 10;
```
- Zählt die Mitarbeiter pro Abteilung und zeigt nur Abteilungen mit mehr als 10 Mitarbeitern an.
**Wichtige Hinweise:**
- Aggregatfunktionen werden häufig mit der `GROUP BY`-Klausel kombiniert, um Ergebnisse nach bestimmten Kriterien zu gruppieren.
- Die `HAVING`-Klausel wird verwendet, um Gruppen basierend auf einer Bedingung zu filtern.
- Aggregatfunktionen ignorieren normalerweise NULL-Werte, außer bei `COUNT(*)`, welches alle Zeilen zählt.
**Zusätzliche Funktionen:**
- **COUNT(DISTINCT):** Zählt die Anzahl eindeutiger Werte in einer Spalte.
- **SUM(CASE WHEN ... THEN ... ELSE ... END):** Ermöglicht bedingte Summierungen.

Beispiel:
```sql
SELECT AVG(gehalt) AS durchschnittsgehalt
FROM mitarbeiter
GROUP BY abteilung;
```


SQL steht für "**S**tructured **Q**uery **L**anguage" und bezieht sich auf relationale Datenbanksysteme, die ein **festes Schema** verwenden, um Daten zu speichern, abzurufen und zu verwalten. SQL-Datenbanken sind weit verbreitet und bieten robuste Funktionen für die Datenintegrität und -konsistenz.

## Charakteristika
- **Relationales Modell**: Daten werden in Tabellen gespeichert, die durch Beziehungen miteinander verbunden sind.
- **Festes Schema**: Strukturiertes Datenmodell mit vordefinierten Tabellen, Spalten und Datentypen.
- **ACID-Eigenschaften**: Gewährleistet Atomarität, Konsistenz, Isolation und Dauerhaftigkeit von Transaktionen.
- **Standardisierte Abfragesprache**: SQL ist eine standardisierte Sprache zur Abfrage und Manipulation von Daten.

## SQL-Datenbanktypen

### 1. Traditionelle relationale Datenbanken
- Speichern Daten in Tabellen mit festem Schema.
- **Beispiele**: MySQL, PostgreSQL, Oracle Database, Microsoft SQL Server
- **Anwendung**: Transaktionsverarbeitung, geschäftliche Anwendungen

### 2. NewSQL-Datenbanken
- Kombinieren die Vorteile von SQL mit der Skalierbarkeit von NoSQL.
- **Beispiele**: Google Spanner, CockroachDB
- **Anwendung**: Hochverfügbare, skalierbare Systeme mit SQL-Kompatibilität

## ACID-Eigenschaften
- **Atomicity (Atomarität)**: Eine Transaktion wird entweder vollständig ausgeführt oder gar nicht.
- **Consistency (Konsistenz)**: Die Datenbank bleibt in einem konsistenten Zustand, auch nach Transaktionen.
- **Isolation (Isolation)**: Transaktionen werden isoliert durchgeführt, um Konflikte zu vermeiden.
- **Durability (Dauerhaftigkeit)**: Einmal abgeschlossene Transaktionen bleiben auch bei Systemausfällen bestehen.

## Vergleich zu NoSQL-Datenbanken

| Aspekt | SQL | NoSQL |
|--------|-----|-------|
| Schema | Starr | Flexibel |
| Skalierung | Vertikal | Horizontal |
| Konsistenz | ACID | Eventual |
| Abfragesprache | SQL | Datenbankspezifisch |

## Vor- und Nachteile von SQL-Datenbanken

### Vorteile
- **Datenintegrität**: Starke Konsistenz und Integrität durch das relationale Modell und ACID-Eigenschaften.
- **Standardisierte Abfragen**: SQL ist eine weit verbreitete und gut dokumentierte Sprache, die eine einfache Datenmanipulation ermöglicht.
- **Komplexe Abfragen**: Unterstützt komplexe Abfragen, Joins und Transaktionen.

### Nachteile
- **Eingeschränkte Skalierbarkeit**: Vertikale Skalierung kann teuer sein und hat ihre Grenzen.
- **Festes Schema**: Änderungen am Datenmodell können aufwendig sein, insbesondere bei großen Datenmengen.
- **Leistungseinbußen bei großen Datenmengen**: Bei sehr großen Datensätzen kann die Leistung unter der Komplexität leiden.

## Anwendungsfälle
- Geschäftsanwendungen
- Finanztransaktionen
- Content Management Systeme (CMS)
- Kundenbeziehungsmanagement (CRM)

## Herausforderungen
- Schemaänderungen bei bestehenden Daten
- Handhabung von großen Datenmengen und Hochlastanfragen
- Integrationsprobleme mit modernen, agilen Entwicklungsmethoden

## Praxisrelevante Konzepte

### Normalisierung
Der Prozess zur Organisation von Daten, um Redundanz zu minimieren und Datenintegrität zu gewährleisten. Dabei werden Daten in separate, verknüpfte Tabellen aufgeteilt.

### Indexierung
Das Erstellen von Indizes zur Verbesserung der Abfragegeschwindigkeit und der Datenzugriffsleistung.

### Transaktionen
Ein Satz von Operationen, die als eine einzige Einheit betrachtet werden, um sicherzustellen, dass die ACID-Eigenschaften eingehalten werden.


**1. Definition von Stakeholdern:**
- Stakeholder sind Personen oder Gruppen, die ein Interesse an einem Projekt haben oder von dessen Ergebnissen betroffen sind. Sie können intern (z. B. Mitarbeiter, Management) oder extern (z. B. Kunden, Lieferanten) sein.

**2. Identifikation der Stakeholder:**
- **Interne Stakeholder:**
	- Mitarbeiter, Management, Abteilungen (z. B. IT, Personal).
- **Externe Stakeholder:**
    - Kunden, Lieferanten, Aufsichtsbehörden, Investoren.

**3. Analyse der Interessen und Befürchtungen:**
- **Interessen:**
    - Verstehen Sie, was Stakeholder von dem Projekt erwarten (z. B. Effizienz, Sicherheit, Kostenreduktion).
- **Befürchtungen:**
    - Identifizieren Sie mögliche Ängste oder Widerstände (z. B. Verlust von Arbeitsplätzen, erhöhte Arbeitsbelastung).

**4. Entwicklung von Gegenmaßnahmen:**
- **Kommunikation:**
    - Offene und transparente Kommunikation über Projektziele und -fortschritte.
- **Einbindung:**
    - Stakeholder in den Entscheidungsprozess einbeziehen, um Akzeptanz zu fördern.
- **Schulungen:**
    - Schulungsprogramme anbieten, um Ängste abzubauen und das Verständnis zu fördern.

**5. Monitoring und Feedback:**
- **Regelmäßige Überprüfung:**
    - Stakeholder-Feedback einholen und die Analyse regelmäßig aktualisieren.
- **Anpassung der Strategien:**
    - Maßnahmen basierend auf dem Feedback der Stakeholder anpassen.

- Maß wie stark **Daten um Mittelwert streuen**

## Formel
$\sigma$ = Standardabweichung  
$n$ = Anzahl an Daten  
$x_i$ = Daten  
$\bar{x}$ = [[Quadratisches Mittel|Mittelwert]] der Daten  

### Gesamtheit
$$
\sigma = \sqrt{\dfrac{1}{n}\sum^{n}_{i=1}(x_i-\bar{x})^2}
$$
**Wurzel** der **Summe** der **quadrierten Abweichungen** durch die **Anzahl der Werte** geteilt

### Stichprobe
- für Schätzungen, Stichproben, ...
$$
s = \sqrt{\dfrac{1}{n - 1}\sum^{n}_{i=1}(x_i-\bar{x})^2}
$$

## Vergleich zwischen Standardabweichung und Varianz

| Merkmal                     | Varianz ($v$)                                      | Standardabweichung ($\sigma$ oder $s$)               |
|-----------------------------|----------------------------------------------------|------------------------------------------------------|
| Definition                   | Durchschnitt der quadrierten Abweichungen          | Quadratwurzel der Varianz                             |
| Einheit                      | Quadrat der Einheit der Daten                       | Gleiche Einheit wie die Daten                         |
| Interpretation              | Gibt die Streuung in quadrierten Einheiten an      | Gibt die Streuung in den gleichen Einheiten wie die Daten an |
| Empfindlichkeit gegenüber    | Empfindlich gegenüber Ausreißern                    | Empfindlich gegenüber Ausreißern                      |
| Verwendung                   | Oft in der Theorie und bei der Berechnung von Tests | Häufiger in der Praxis verwendet, da leichter zu interpretieren |

## Quellen

> Datatab. (2021, November 28). Varianz (Einfach erklärt). Youtube. Retrieved from https://www.youtube.com/watch?v=iPjXpiB6w9E  
> Duck.ai. (2024, September 16). Anonymisierte AI-Interaktionen. Retrieved from https://duck.ai  


- **Ziel**: Zusammenfassung und Darstellung von Informationen aus großen Datensätzen.
- **Wichtigkeit**: Erleichtert das Verständnis von Daten durch repräsentative
- Geben die **Streuung von Verteilungen um das Zentrum** an.
  
### Wichtige Streumaße
- **[[Spannweite]]**: Differenz zwischen dem größten und dem kleinsten Wert.
- **[[Varianz]]**: Maß für die durchschnittliche quadratische Abweichung der Werte vom Mittelwert.
- **[[Standardabweichung]]**: Quadratwurzel der Varianz; gibt an, wie stark die Werte im Durchschnitt um den Mittelwert streuen.

## Gemeinsamkeiten mit Lagemaße
- Fassen Informationen aus großen Datensätzen zusammen.
- Stellen die Daten **übersichtlich** dar.
- Der zusammengefasste Wert **repräsentiert** den gesamten **Datensatz**.

## Unterschiede mit Lagemaße
- Streuungsmaße konzentrieren sich auf die **Variation der Werte um das Zentrum** 

## Quellen
> Streuungsmaß: Übersicht, Definition & Berechnen | StudySmarter. (2024, September 16). Retrieved from [StudySmarter](https://www.studysmarter.de/schule/mathe/stochastik/streuungsmass)


- auch **Nassi-Shneiderman-Diagramm** genannt
- Zerlegung von **Gesamtproblemen** in **kleinere Teilprobleme**
- Vorgehensweise: **Top-down-Programmierung** (Gesamtkonzept → Verfeinerung)

## Elemente
![[Pasted image 20240919065518.png]]
- **Anweisungen**
![[Pasted image 20240919065537.png]]![[Pasted image 20240919065543.png]]![[Pasted image 20240919065551.png]]
- **Bedingungen**
![[Pasted image 20240919065608.png]]
- **Case-Statement**
![[Pasted image 20240919065624.png]]
- **Iteration**
![[Pasted image 20240919065751.png]]
- **Kopfgesteuerte Schleife**
![[Pasted image 20240919065802.png]]
- **Fußgesteurte** Schleife
![[Pasted image 20240919065722.png]]
- **Break**, Beendigung eines Programmteils
![[Pasted image 20240919065645.png]]
- **Blockaufrauf**, Aufruf eines Unterprogramms, o. Ä.
![[Pasted image 20240919065703.png]]
- **Parallelausführung**, nebenläufige Abläufe

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1
> Autoren der Wikimedia-Projekte. (2004, February 17). Nassi-Shneiderman-Diagramm – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Nassi-Shneiderman-Diagramm&oldid=245429298

- **Support Vector Machine** (SVM) ist ein **[[Überwachtes und nicht-überwachtes Lernen|überwachter Lernalgorithmus]]**, der zur **[[Klassifikation]]** von Objekten verwendet wird. 
- Hauptsächlich eingesetzt für **Text-** und **Bildklassifizierung**.
- Besonders gut geeignet für **kleinere Datensätze mit klarer Trennbarkeit**.

### Vorteile
- **Effizientes Training**: Schneller trainierbar im Vergleich zu [[Neural Network|Neural Networks]]. 
- **Gute Leistung** mit **wenigen Trainingsdaten**. 
- Kann auf lineare und nicht-lineare Daten angewendet werden (mit Hilfe des Kernel-Tricks). 

### Nachteile 
- Funktioniert standardmäßig nur mit **linear separierbaren Daten**.
- Bei nicht-linearen Daten muss eine **Kernel-Funktion** verwendet werden, was die Berechnung aufwendiger macht.

## Funktionsweise

### Lineare Klassifikation
- Ziel der SVM: Einen **Hyperplane** zu finden, der zwei Klassen von Datenpunkten optimal trennt.
- Der **Hyperplane** ist eine **Trennlinie** (in 2D) oder eine **Trennebene** (in höherdimensionalen Räumen), die die Daten so trennt, dass der **Abstand** (Gap) zwischen den **nächsten Punkten jeder Klasse** und dem Hyperplane **maximal** ist.

#### Begriffe:
- **Hyperplane**: Im p-dimensionalen Raum ist dies ein flacher Unterraum mit p-1 Dimensionen:
	 - 1D: Ein Punkt
	 - 2D: Eine Linie
	- 3D: Eine Ebene
	- **Formel**: $w^Tx+b=0$
		- Gewichtungsvektor $w$
		- Datenpunkte $x$
		- Bias $b$
		- Transponierte $^T$ (Abflachung des Vektors $w$)
- **Support Vectors**: Die Punkte, die **am nächsten** zum Hyperplane liegen und seine Lage bestimmen. Sie haben die größte Bedeutung für die Berechnung des Hyperplanes und helfen dabei, **Overfitting** zu vermeiden.
- **Maximaler Gap**: Der Abstand der **nächsten Punkte** von jeder Klasse zum Hyperplane. Je größer der Gap, desto besser ist die Trennung der Klassen.
	- Abstand ist proportinal zu $\dfrac{1}{||w||}$ -> kleines $w$, max. Abstand

![[Pasted image 20240919112516.png]]

### Nicht-lineare Klassifikation
- Wenn Daten **nicht linear trennbar** sind, reicht ein einfacher Hyperplane nicht aus.
- Hier kommt der **Kernel-Trick** ins Spiel.

## Kernel-Trick
- Der **Kernel-Trick** ermöglicht es, Datenpunkte in einen **höherdimensionalen Raum** zu transformieren, wo sie durch einen **linearen Hyperplane** trennbar werden.
- Anstatt die Daten direkt in diesen höherdimensionalen Raum zu übertragen, verwendet der Kernel-Trick eine **mathematische Funktion**, um die **inneren Produkte** der Datenpunkte im neuen Raum zu berechnen, ohne die tatsächliche Transformation durchzuführen. Dies spart **Rechenaufwand**.

#### Häufig verwendete Kernel-Funktionen:
- **Linearer Kernel**: Für linear trennbare Daten.
![[Pasted image 20240919114509.png]]  - **Polynomieller Kernel**: Für nicht-lineare Daten, die durch eine polynomiale Trennung separiert werden können.
![[Pasted image 20240919114310.png]]
- **Radial Basis Function (RBF)**: Ein häufig verwendeter Kernel, um Daten mit nicht-linearen Mustern zu klassifizieren. Transformiert die Daten in einen sehr hohen (theoretisch unendlichen) dimensionalen Raum.
![[Pasted image 20240919114601.png]]
*(rechtes bild)*


### Vorteile des Kernel-Tricks:
- **Effiziente Transformation**: Der Trick führt zu einer Transformation ohne den tatsächlichen Aufwand der Berechnung eines höherdimensionalen Raums.
- **Anwendung auf komplexe Daten**: Selbst bei hochkomplexen und nicht-linearen Daten können durch den Kernel-Trick gute Ergebnisse erzielt werden.

### Nachteile des Kernel-Tricks:
- **Erhöhter Rechenaufwand**: Für große Datensätze und komplexe Kernel-Funktionen kann der Berechnungsaufwand erheblich steigen.
- **Auswahl des richtigen Kernels**: Es kann schwierig sein, den geeigneten Kernel und dessen Parameter auszuwählen, um optimale Ergebnisse zu erzielen.

## Zusammenfassung
- **SVM** ist ein leistungsstarker **Klassifikationsalgorithmus**, der sich besonders gut für **lineare Daten** eignet.
- Bei nicht-linearen Daten wird der **Kernel-Trick** verwendet, um die Daten trennbar zu machen.
- **Support Vectors** sind dabei die Schlüssel, die die Lage des **Hyperplanes** bestimmen und Overfitting vermeiden.
- Der **Gap** wird maximiert, um eine möglichst klare Trennung zwischen den Klassen zu erzielen.
  
## Quellen

> Support Vector Machine (SVM) - einfach erklärt! | Data Basecamp. (2024, September 19). Retrieved from https://databasecamp.de/ki/support-vector-machine-svm
> Science, P. D. (2018, July 09). Einführung in die Datenanalyse: Support Vector Machine. Youtube. Retrieved from https://www.youtube.com/watch?v=Xn1-0it0f5g 
> Explained, V. (2022, May 09). The Kernel Trick in Support Vector Machine (SVM). Youtube. Retrieved from https://www.youtube.com/watch?v=Q7vT0--5VII
> Explained, V. (2021, September 09). Support Vector Machine (SVM) in 2 minutes. Youtube. Retrieved from https://www.youtube.com/watch?v=_YPScrckx28&t=77s

- quasi wie [[TCP-IP-Modell#^b4a03f|Routing]], bloß auf [[OSI-Modell|Ebene 2]] bzw. [[TCP-IP-Modell|Netzzugangsschicht]]

## Ablauf
1. eingehendes **Ethernet-Frame** wird **analyisiert**
2. MAC-Adressen und Port Nummern von Sender um Empfänger werden in *MAC-Tabelle* (FDB, Forwarding Database) gespeichert (Einträge werden regelmäßig erneuert da Port-Nummer sich ändern kann)
3. Ethernet-Frame wird an Ziel Port Nummer weitergeleitet

## Quellen

> Switching. (2024, September 17). Retrieved from https://www.elektronik-kompendium.de/sites/net/0907141.htm

- **strategisches Instrument** zur Beurteilung der internen und externen Faktoren eines Unternehmens.

## Kategorien

- **Stärken** (_Strengths_): Interne Vorteile, die eine Organisation auszeichnet.
- **Schwächen** (_Weaknesses_): Interne Nachteile, die den Erfolg der Organisation hemmen.
- **Chancen** (_Opportunities_): Externe Möglichkeiten zur Verbesserung.
- **Risiken** (_Threats_): Externe Gefahren, die den Erfolg beeinträchtigen könnten.

## Kombinationen entwickeln

| extern/intern | Stärken                                                                               | Schwächen                                                                          |
| ------------- | ------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| Chancen       | *S-O-Strategie (Matching)*<br>**Stärken nutzen, um Chancen zu ergreifen**             | *W-O-Strategie (Umwandlung)*<br>**Schwächen ausbessern, um Chancen zu nutzen**     |
| Risiken       | *S-T-Strategie (Neutralisierung)*<br>**Stärken nutzen, um Risiken zu neutralisieren** | *W-T-Strategie (Verteidigung)*<br>**Schwächen reduzieren, um Risiken zu entgehen** |

## Vorteile
- Einfach durchzuführen.
- Liefert eine **umfassende Analyse** der **internen** und **externen** Faktoren.
- Flexibel anwendbar auf verschiedene Bereiche.

## Nachteile
- Subjektivität kann zu einer verzerrten Bewertung führen.
- Keine **quantitative** Analyse.
- Kann **komplexe Zusammenhänge** nicht vollständig abbilden.

## Quellen
>Bundesministerium des Innern und für Heimat. (2024). SWOT Analyse. Bundesministerium des Innern und für Heimat. Retrieved from https://www.orghandbuch.de/Webs/OHB/DE/OrganisationshandbuchNEU/4_MethodenUndTechniken/Methoden_A_bis_Z/SWOT_Analyse/swot_analyse_node.html%3Bjsessionid=A9EC8CF14A322DA22146DA463549ADD9.live882
>ChatGPT. (2024, September 19). Retrieved from https://chatgpt.com/c/66ebd0b5-9cac-800b-aea4-b8fedad5efac

- **Untersuchung** und **Bewertung** der **Auslastung** von Systemressourcen (z. B. CPU, RAM, Festplattenspeicher, Netzwerkbandbreite) in einem IT-System, um die Leistung, Stabilität und Effizienz zu überwachen und zu optimieren.

## Ziele der Systemlastanalyse
- **Leistungsüberwachung**: Identifizierung von Engpässen und Überlastungen, die die Systemleistung beeinträchtigen können.
- **Kapazitätsplanung**: Unterstützung bei der Planung zukünftiger Ressourcenanforderungen basierend auf aktuellen und prognostizierten Lasten.
- **Fehlerdiagnose**: Erkennung von Anomalien oder Problemen, die zu Systemausfällen oder Leistungsabfällen führen können.
- **Optimierung**: Verbesserung der Ressourcennutzung und der Gesamtleistung des Systems.

## Anwendung von Monitoringsystemen
- **Monitoring-Tools**: Verwendung von Softwarelösungen (z. B. Nagios, Zabbix, Prometheus, Grafana), die Systemressourcen in Echtzeit überwachen und analysieren.
- **Metriken**: Erfassung relevanter Leistungskennzahlen (KPIs), wie z. B.:
  - **CPU-Auslastung**: Prozentsatz der CPU-Zeit, die für die Verarbeitung von Aufgaben verwendet wird.
  - **Speicherauslastung**: Menge des verwendeten und verfügbaren RAM.
  - **Festplattenspeicher**: Verfügbarer und verwendeter Speicherplatz auf Festplatten.
  - **Netzwerkauslastung**: Bandbreite und Datenverkehr, der über das Netzwerk fließt.

## Durchführung der Systemlastanalyse
1. **Daten sammeln**: Konfiguration des Monitoringsystems zur Erfassung von Leistungsdaten über einen bestimmten Zeitraum.
2. **Datenvisualisierung**: Verwendung von Dashboards und Grafiken zur Darstellung der gesammelten Daten, um Trends und Muster zu erkennen.
3. **Schwellenwerte festlegen**: Definition von Grenzwerten für die verschiedenen Metriken, um zu bestimmen, wann eine Warnung oder ein Alarm ausgelöst werden sollte.

## Interpretation der Ergebnisse
- **Normalbetrieb**: Identifizierung von normalen Betriebsbedingungen und typischen Lastmustern, um eine Basislinie für die Analyse zu schaffen.
- **Engpässe erkennen**: Analyse der Daten, um Zeiten hoher Auslastung zu identifizieren, die auf Engpässe hinweisen (z. B. CPU-Auslastung über 80% für längere Zeit).
- **Anomalien identifizieren**: Erkennung von plötzlichen Änderungen oder Spitzen in der Systemlast, die auf Probleme oder Sicherheitsvorfälle hinweisen könnten.
- **Kapazitätsengpässe**: Bewertung, ob die aktuelle Infrastruktur den Anforderungen entspricht oder ob eine Erweiterung erforderlich ist.
- **Optimierungsmöglichkeiten**: Identifizierung von Bereichen, in denen die Ressourcennutzung verbessert werden kann (z. B. durch Lastverteilung, Optimierung von Anwendungen oder Upgrades der Hardware).

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Gruppe von **Netzwerkprotokollen**
- **T**ransmission **C**ontrol **P**rotocol *(TCP)* **I**nternet **P**rotocol *(IP)*
- Zuständig für **Vermittlung** und **Transport** innerhalb eines dezentralen Netzwerkes

## Aufgaben
 - logische Adressierung / **logical Addressing**: Aufteilung großer Netzwerke in kleinere *Segmente*
 - Wegfindung / **Routing**: auf jedem *Netzwerkknoten* wird der nächste Knoten für ein Datenpaket ermittelt. Wegfindung von Paketen *über Netzwerksegmente hinaus* ^b4a03f
 - Fehlerbehandlung und Flusssteuerung / **Error and Flow Control**: *verbindungsorientierte* Kommunikation, bei Fehler *erneute Übertragung* von Paketen
 - Anwendungsunterstützung / **Application Support**: Adressierung von Diensten über *TCP/UDP-Ports*
 - Namensauflösung / **Name Resolution**: Auflösung von *Domänenamen* in IPv4/IPv6 Adressen

## Schichten

4. **Anwendungsschicht**: *Anwendungen* die über das Netzwerk kommunizieren, Protokolle: *HTTP*, *FTP*, *POP*, *SMTP*, *TLS*, *SOCK5*
3. **Transportschicht**: Aufrechthaltung *zuverlässiger End-to-End-Kommunikation*, Protokoll: *TCP*, *UDP*
2. **Internetschicht**: Weiterleitung/*Routing* von Paketen, Protokolle: *IP*, *ICMP*
1. **Netzzugangsschicht**: *physische Verbindung* von Subnetzen, Protokolle: *Ethernet* (Kabel), *IEEE 802.11* (Funk)

## Vorteile
- Datenübertragung ist **standort-** und **herstellerunabhängig**
- **Anwender** benötigt ausschließlich **Zieladresse** - Verbindung kontrolliert TCP/IP
- Anwendungen sind vom **Übertragungssystem unabhängig**

## Nachteile
- **ineffizient** bei niedrigen Datenmengen
- **spezielle Anforderungen** an Übertragungssystem nur **schwer realisierbar**

## Quellen
> TCP/IP. (2022, November 13). Retrieved from https://studyflix.de/informatik/tcp-ip-5692

- Protokolle auf **Transportschicht** [[OSI-Modell|4. Transportschicht (OSI-Modell)]] / [[TCP-IP-Modell|3. Transportschicht (TCP/IP-Modell)]]

## TCP
- **T**ransmission **C**ontrol **P**rotocol, **20-Byte** Header
- **verbindugsorientiertes** Protokoll, *3-Wege-Handshake (SYN,SYN-ACK,ACK)*
- Übermittlung von Daten **garantiert** und **Einhaltung der Reihenfolge**
- **umfangreiche** Fehlererkennung (Congestion Control, Flow Control)
- **langsamer**, aber **sicherer** als UDP
- **Sequenzierung** (richtige Reihenfolge)
- **Retransimission**
- **Anwendungsgebiete**
	- E-Mail, Messaging, Downloads
	- HTTP, HTTPS, FTP, Telnet, SMTP

## UDP
- **U**ser **D**atagram **P**rotocol, **8-Byte** Header
- **verbindungsloses** Protokoll, kein Overhead dafür
- sehr gut für **broad-** und **multicast**
- Übermittlung von Daten **nicht garantiert**
- **schwache** Fehlererkennung (Checksumme)
- **schneller, einfacher, effizienter** als UDP
- **keine** Sequenzierung der Daten
- **keine** Retransmission
- **Anwendungsgebiete**, 
	- Videostreaming, Online-Spiele, ...
	- DHCP, TFTP, SNMP, DNS, RIP, VoIP

## Quellen
> Dalwigk, F. (2019, January 20). TCP vs. UDP | Die Unterschiede der beiden Protokolle | Netzwerktechnik. Youtube. Retrieved from https://www.youtube.com/watch?v=v8_mM7zq8GE
> TCP 3-Wege-Handshake (SYN, SYN-ACK, ACK). (2024, June 27). Retrieved from https://www.guru99.com/de/tcp-3-way-handshake.html


Die technische Verfügbarkeit von Daten bezieht sich auf die **Fähigkeit, Daten jederzeit und ohne Unterbrechung zugänglich zu machen**. Dies umfasst die Sicherstellung, dass Daten in den erforderlichen Formaten und innerhalb der festgelegten Zeitrahmen bereitgestellt werden können, um die Bedürfnisse der Benutzer und Anwendungen zu erfüllen.

## Wichtige Aspekte der technischen Verfügbarkeit von Daten
- **Zugänglichkeit**: Daten müssen für autorisierte Benutzer und Systeme jederzeit verfügbar sein, unabhängig von Standort oder Gerät.
- **Zuverlässigkeit**: Die Systeme, die die Daten speichern und bereitstellen, müssen stabil und fehlerfrei arbeiten, um Ausfallzeiten zu minimieren.
- **Wiederherstellbarkeit**: Im Falle eines Datenverlusts oder eines Systemausfalls müssen Mechanismen vorhanden sein, um die Daten schnell wiederherzustellen.

## Maßnahmen zur Realisierung der technischen Verfügbarkeit von Daten

### Redundante Systeme
- **Beschreibung**: Implementierung von redundanten Servern, Datenbanken oder Speichersystemen, um sicherzustellen, dass im Falle eines Ausfalls eines Systems ein anderes System die Daten weiterhin bereitstellen kann.
- **Vorteil**: Erhöht die Verfügbarkeit und minimiert Ausfallzeiten.

### Backup-Strategien
- **Beschreibung**: Regelmäßige Sicherung von Daten, um sicherzustellen, dass im Falle eines Datenverlusts eine aktuelle Kopie der Daten vorhanden ist.
- **Vorteil**: Ermöglicht eine schnelle Wiederherstellung der Daten im Falle eines Vorfalls.

### Lastverteilung
- **Beschreibung**: Einsatz von Lastverteilern, um den Datenverkehr gleichmäßig auf mehrere Server zu verteilen, wodurch die Belastung einzelner Systeme verringert wird.
- **Vorteil**: Verbessert die Reaktionszeiten und die Verfügbarkeit von Daten.

### Monitoring und Alarmierung
- **Beschreibung**: Implementierung von Überwachungssystemen, die die Leistung und Verfügbarkeit von Daten und Systemen in Echtzeit überwachen und bei Problemen Alarm schlagen.
- **Vorteil**: Frühzeitige Erkennung von Problemen ermöglicht eine proaktive Reaktion und Minimierung von Ausfallzeiten.

### Cloud-Lösungen
- **Beschreibung**: Nutzung von Cloud-Diensten, die hohe Verfügbarkeit und Skalierbarkeit bieten. Cloud-Anbieter garantieren oft eine bestimmte Verfügbarkeit durch Service Level Agreements (SLAs).
- **Vorteil**: Flexibilität und Redundanz, die die Verfügbarkeit von Daten erhöhen.

## Herausforderungen bei der Sicherstellung der technischen Verfügbarkeit von Daten
- **Kosten**: Die Implementierung redundanter Systeme und Backup-Lösungen kann kostspielig sein.
- **Komplexität**: Die Verwaltung und Überwachung mehrerer Systeme kann komplex sein und erfordert spezialisiertes Wissen.
- **Sicherheitsrisiken**: Die Erhöhung der Verfügbarkeit kann auch Sicherheitsrisiken mit sich bringen, insbesondere wenn Daten über das Internet zugänglich sind.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

Teilhabe bezieht sich auf die aktive Teilnahme und **Mitgestaltung von Individuen oder Gruppen an gesellschaftlichen, wirtschaftlichen und politischen Prozessen**. Im Kontext der Informationstechnologie bedeutet Teilhabe, dass alle Menschen Zugang zu digitalen Technologien und Informationen haben und diese nutzen können.

## Wichtige Aspekte der Teilhabe
- **Zugang zu Technologie**: Sicherstellung, dass alle Menschen, unabhängig von sozialen, wirtschaftlichen oder geografischen Faktoren, Zugang zu digitalen Technologien haben.
- **Digitale Kompetenzen**: Förderung der Fähigkeiten und Kenntnisse, die erforderlich sind, um digitale Technologien effektiv zu nutzen.
- **Inklusion**: Berücksichtigung der Bedürfnisse von benachteiligten Gruppen, um sicherzustellen, dass sie an digitalen Prozessen und Entscheidungen teilnehmen können.

## Bedeutung der Teilhabe in der IT
- **Demokratische Teilhabe**: Digitale Technologien ermöglichen es Bürgern, an politischen Prozessen teilzunehmen, Informationen zu teilen und ihre Meinungen zu äußern.
- **Wirtschaftliche Teilhabe**: Zugang zu digitalen Märkten und Plattformen ermöglicht es Menschen, wirtschaftliche Chancen zu nutzen und ihre eigenen Unternehmen zu gründen.
- **Soziale Teilhabe**: Digitale Kommunikation fördert den Austausch und die Vernetzung zwischen Menschen, was zu einer stärkeren sozialen Integration führt.

## Maßnahmen zur Förderung der Teilhabe
- **Bildungsprogramme**: Initiativen zur Schulung und Weiterbildung in digitalen Kompetenzen, um Menschen zu befähigen, digitale Technologien zu nutzen.
- **Barrierefreiheit**: Entwicklung von Technologien und Plattformen, die für Menschen mit Behinderungen zugänglich sind.
- **Öffentliche Infrastruktur**: Bereitstellung von kostenlosem oder kostengünstigem Internetzugang in öffentlichen Einrichtungen, um den Zugang zu digitalen Ressourcen zu erleichtern.

## Herausforderungen und Risiken
- **Digitale Kluft**: Ungleichheiten im Zugang zu Technologie und digitalen Kompetenzen können bestehende soziale und wirtschaftliche Ungleichheiten verstärken.
- **Exklusion**: Bestimmte Gruppen, wie ältere Menschen oder Menschen mit Behinderungen, können von der digitalen Teilhabe ausgeschlossen werden, wenn ihre Bedürfnisse nicht berücksichtigt werden.
- **Datenschutz und Sicherheit**: Die Teilhabe an digitalen Prozessen kann auch Risiken in Bezug auf Datenschutz und Sicherheit mit sich bringen, insbesondere für vulnerable Gruppen.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Software-Tools oder -Programme, die **automatisch Testdaten** erstellen, die für die Durchführung von Softwaretests benötigt werden. Diese Daten sind entscheidend, um die Funktionalität, Leistung und Sicherheit von Softwareanwendungen zu überprüfen.

## Zweck
- **Automatisierung**: Reduzierung des manuellen Aufwands bei der Erstellung von Testdaten.
- **Vielfalt**: Generierung einer Vielzahl von Daten, um unterschiedliche Testfälle abzudecken.
- **Konsistenz**: Sicherstellung, dass die Testdaten reproduzierbar und konsistent sind.

## Arten von Testdatengeneratoren
1. **Zufallsbasierte Generatoren**:
	- Erstellen Testdaten basierend auf Zufallszahlen.
	- Beispiel: Generierung von Benutzernamen, E-Mail-Adressen oder Transaktionsdaten.
1. **Regelbasiertes Generieren**:
	- Erstellen von Testdaten basierend auf vordefinierten Regeln oder Mustern.
	- Beispiel: Generierung von Daten, die bestimmten Formaten oder Validierungsregeln entsprechen (z.B. Telefonnummern, Postleitzahlen).
2. **Datenbankbasierte Generatoren**:
	- Nutzen bestehende Datenbanken, um Testdaten zu extrahieren und zu modifizieren.
	- Beispiel: Kopieren von Datensätzen aus einer Produktionsdatenbank und Anpassen für Testzwecke.
3. **Spezialisierte Generatoren**:
	- Entwickelt für spezifische Anwendungen oder Branchen, z.B. Finanzdaten, medizinische Daten oder E-Commerce-Daten.

## Vorteile
- **Effizienz**: Spart Zeit und Ressourcen bei der Erstellung von Testdaten.
- **Skalierbarkeit**: Ermöglicht die Generierung großer Datenmengen für umfangreiche Tests.
- **Flexibilität**: Anpassung der Testdaten an verschiedene Testanforderungen und -szenarien.

## Nachteile
- **Datenqualität**: Generierte Daten müssen sorgfältig validiert werden, um sicherzustellen, dass sie realistisch und relevant sind.
- **Komplexität**: Einige Generatoren können komplex sein und erfordern eine Einarbeitungszeit.
- **Sicherheitsrisiken**: Bei der Verwendung von Produktionsdaten zur Generierung von Testdaten müssen Datenschutz- und Sicherheitsaspekte berücksichtigt werden.

Ein Testkonzept ist entscheidend, um die **Qualität** und **Funktionalität** der App sicherzustellen. Hier sind drei wesentliche Inhalte, die in ein Testkonzept aufgenommen werden sollten:

1. **Testziele und -umfang**: In diesem Abschnitt werden die *spezifischen Ziele des Tests definiert*, z. B. die Überprüfung der *Funktionalität*, *Benutzerfreundlichkeit*, *Leistung* und *Sicherheit* der App. Zudem sollte der Umfang des Tests festgelegt werden, also welche Funktionen und Komponenten der App getestet werden sollen. Dies hilft, den Fokus der Tests zu bestimmen und sicherzustellen, dass alle relevanten Aspekte abgedeckt werden.
2. **Testmethoden und -arten**: Hier werden die verschiedenen *Testmethoden beschrieben, die angewendet werden sollen*, um die App zu testen. Dazu gehören unter anderem:
   - **Funktionale Tests**: Überprüfung, ob die App die *definierten Anforderungen* erfüllt.
   - **Usability-Tests**: Bewertung der *Benutzerfreundlichkeit* und der Benutzererfahrung.
   - **Leistungstests**: Überprüfung der *Reaktionszeiten* und der *Stabilität* der App unter verschiedenen Lastbedingungen.
   - **Sicherheitstests**: Identifikation von *Sicherheitsanfälligkeiten* und *Überprüfung der Datensicherheit*.
3. **Testressourcen und -zeitplan**: In diesem Abschnitt werden die benötigten Ressourcen für die Durchführung der Tests festgelegt, einschließlich der Testumgebungen, Testwerkzeuge und der benötigten Testdaten. Zudem sollte ein *Zeitplan* erstellt werden, der die *verschiedenen Testphasen* und Meilensteine beschreibt, um sicherzustellen, dass die Tests rechtzeitig vor der Veröffentlichung der App abgeschlossen werden.

- Dokumente, die die **Durchführung von Softwaretests dokumentieren**. Sie enthalten **detaillierte Informationen über die Testaktivitäten**, die getesteten Funktionen, die verwendeten Testdaten, die Testergebnisse und alle aufgetretenen Probleme oder Fehler. Testprotokolle sind ein wichtiger Bestandteil des Testmanagements und der Qualitätssicherung.

## Zweck
- **Dokumentation**: Bereitstellung einer umfassenden Aufzeichnung der durchgeführten Tests und ihrer Ergebnisse.
- **Nachverfolgbarkeit**: Ermöglicht die Rückverfolgbarkeit von Testergebnissen und Fehlern, um sicherzustellen, dass alle Anforderungen erfüllt sind.
- **Kommunikation**: Dient als Kommunikationsmittel zwischen Testern, Entwicklern und Stakeholdern, um den Status der Tests und die Qualität der Software zu vermitteln.
- **Compliance**: Unterstützt die Einhaltung von Standards und Vorschriften, indem sie eine formale Dokumentation der Testaktivitäten bereitstellt.

## Inhalte eines Testprotokolls
1. **Testidentifikation**:
	- Name und Version des Tests.
	- Datum und Uhrzeit der Durchführung.
2. **Testumgebung**:
	- Beschreibung der Testumgebung, einschließlich Hardware, Software und Netzwerkkonfiguration.
3. **Testobjekt**:
	- Beschreibung der getesteten Software oder Funktionalität.
4. **Testdaten**:
	- Angaben zu den verwendeten Testdaten, einschließlich ihrer Herkunft und Struktur.
5. **Testschritte**:
	- Detaillierte Beschreibung der durchgeführten Testschritte und -methoden.
6. **Ergebnisse**:
	- Dokumentation der Testergebnisse, einschließlich erfolgreicher und fehlgeschlagener Tests.
	- Screenshots oder Protokolle von Fehlern, wenn relevant.
7. **Fehlerberichte**:
	- Auflistung aller gefundenen Fehler oder Probleme, einschließlich ihrer Schwere und Status (offen, behoben, getestet).
8. **Zusammenfassung**:
	- Zusammenfassung der Testergebnisse und Empfehlungen für weitere Maßnahmen.
## Vorteile
- **Transparenz**: Erhöht die Transparenz der Testaktivitäten und -ergebnisse.
- **Qualitätssicherung**: Unterstützt die Qualitätssicherung, indem sie eine klare Dokumentation der Tests bereitstellt.
- **Wissenserhalt**: Dient als Wissensdatenbank für zukünftige Tests und Projekte.
## Nachteile
- **Zeitaufwand**: Die Erstellung und Pflege von Testprotokollen kann zeitaufwendig sein.
- **Komplexität**: Bei umfangreichen Tests kann die Dokumentation komplex und unübersichtlich werden.
- **Veraltete Informationen**: Wenn Testprotokolle nicht regelmäßig aktualisiert werden, können sie veraltete oder ungenaue Informationen enthalten.

- **systematische Ansätze** zur **Überprüfung und Validierung** von Software, um sicherzustellen, dass sie den **Anforderungen entspricht** und **fehlerfrei funktioniert**. Es gibt verschiedene Testmethoden und -techniken, die je nach Ziel und Kontext eingesetzt werden.

## Testverfahren
### Statische Testverfahren
- **Beschreibung**: Überprüfung von Software-Artefakten ohne Ausführung des Codes
- **Ziele**:
    - Frühzeitige Fehlererkennung
    - Überprüfung von Dokumentation und Code
- **Methoden**:
    - **Review**: Systematische Überprüfung von Dokumenten oder Code durch Experten.
    - Statische Codeanalyse
    - Walkthrough
### Dynamische Testverfahren
- **Beschreibung**: Überprüfung der Software durch Ausführung des Codes
- **Ziele**:
    - Funktionsverhalten testen
    - Speicher-/CPU-Nutzung überprüfen
    - Gesamtleistung des Systems evaluieren
- **Methoden**:
    - Black-Box-Testing
    - White-Box-Testing
    - Graue-Box-Testing
### Übersicht
![[Pasted image 20240919142509.png]]

### 1. Black-Box-Testing
![[Pasted image 20240919142350.png]]
- **Beschreibung**: Bei dieser Methode wird die Software getestet, ohne dass der Tester Kenntnisse über die interne Funktionsweise hat. Der Fokus liegt auf den Eingaben und Ausgaben.
- **Vorteile**:
  - Unabhängigkeit von der Implementierung.
  - Tests basieren auf den Anforderungen und Spezifikationen.
- **Nachteile**:
  - Mangelnde Einsicht in die interne Logik kann zu unvollständigen Tests führen.

### 2. White-Box-Testing
![[Pasted image 20240919142448.png]]
- **Beschreibung**: Hierbei hat der Tester Zugang zum Quellcode und testet die internen Strukturen und Abläufe der Software. Es werden spezifische Code-Pfade und Logik überprüft.
- **Vorteile**:
  - Detaillierte Tests der internen Logik.
  - Identifikation von Sicherheitslücken und Codefehlern.
- **Nachteile**:
  - Erfordert tiefes technisches Wissen.
  - Kann zeitaufwendig sein.

### 3. Graue-Box-Testing
![[Pasted image 20240919142522.png]]
- **Beschreibung**: Eine Kombination aus Black-Box- und White-Box-Testing, bei der der Tester teilweise Kenntnisse über die interne Struktur hat, aber auch die externen Anforderungen berücksichtigt.
- **Vorteile**:
  - Bietet eine ausgewogene Sicht auf die Software.
  - Ermöglicht umfassendere Tests.

## Testarten

### 1. Unit-Tests
![[Pasted image 20240919142745.png]]
- **Beschreibung**: Tests, die auf die kleinsten testbaren Teile der Software (z.B. Funktionen oder Methoden) abzielen. Sie werden in der Regel von Entwicklern geschrieben.
- **Ziel**: Sicherstellen, dass jede Einheit wie erwartet funktioniert.
- **Beispiel**: Test einer Funktion zur Berechnung der Summe zweier Zahlen, um sicherzustellen, dass sie die korrekte Summe zurückgibt.

### 2. Komponenten-Tests
![[Pasted image 20240919142935.png]]
*(einzelnes Modul)*
- **Beschreibung**: Tests, die auf einzelne Komponenten oder Module der Software abzielen, um deren Funktionalität zu überprüfen.
- **Ziel**: Sicherstellen, dass die Komponenten korrekt zusammenarbeiten.
- **Beispiel**: Test eines Login-Formulars, um zu überprüfen, ob die Authentifizierung korrekt funktioniert und die Benutzeroberfläche die richtigen Fehlermeldungen anzeigt.

### 3. Integrationstests
![[Pasted image 20240919142933.png]]
*(Zusammenarbeit von Modulen)*
- **Beschreibung**: Tests, die die Interaktion zwischen verschiedenen Komponenten oder Systemen überprüfen.
- **Ziel**: Sicherstellen, dass die Integration der Komponenten reibungslos funktioniert.
- **Beispiel**: Test der Interaktion zwischen dem Authentifizierungsmodul und der Datenbank, um sicherzustellen, dass Benutzeranmeldungen korrekt verarbeitet werden.

### 4. Systemtests
![[Pasted image 20240919143005.png]]
- **Beschreibung**: Tests, die das gesamte System als Ganzes überprüfen, um sicherzustellen, dass es den Anforderungen entspricht.
- **Ziel**: Validierung der Software in einer produktionsähnlichen Umgebung.
- **Beispiel**: Test der gesamten Anwendung, um sicherzustellen, dass alle Funktionen (z.B. Registrierung, Login, Datenanzeige) wie erwartet zusammenarbeiten.

### 5. Akzeptanztests
![[Pasted image 20240919143017.png]]
- **Beschreibung**: Tests, die von Endbenutzern oder Stakeholdern durchgeführt werden, um zu überprüfen, ob die Software den Geschäftsanforderungen entspricht.
- **Ziel**: Sicherstellen, dass die Software bereit für den Einsatz ist.
- **Beispiel**: Durchführung eines Testszenarios, bei dem ein Benutzer ein Produkt kauft, um sicherzustellen, dass der gesamte Kaufprozess (Warenkorb, Zahlung, Bestellbestätigung) reibungslos funktioniert.



### 6. Extremwerttest
- **Beschreibung**: Überprüfung des Systemverhaltens bei Grenzwerten und extremen Eingaben.
- **Ziel**: Robustheit und Fehlertoleranz testen.
- **Beispiel**: Test einer Funktion zur Altersberechnung mit Werten wie -1, 0, 150 Jahre.
## Test-Pyramide
![[Pasted image 20240919142623.png]]
- **Beschreibung**: Ein Konzept, das die verschiedenen Testarten in einer Pyramide anordnet, um die Balance zwischen den verschiedenen Testebenen zu verdeutlichen.
  - **Basis**: Unit-Tests (viele Tests, schnelle Ausführung).
  - **Mitte**: Komponenten- und Integrationstests (weniger Tests, mittlere Ausführungsgeschwindigkeit).
  - **Spitze**: System- und Akzeptanztests (wenige Tests, langsame Ausführung).
- **Ziel**: Förderung einer effektiven Teststrategie, die schnelle Rückmeldungen und eine hohe Testabdeckung bietet.



- **T**echnische **o**rganisatorische **M**aßnahmen
- Sicherheitsvorkehrungen, zur **Sicherheit von Daten** und **Erfüllung des Datenschutz** 

## Technische Maßnahmen
Diese Maßnahmen beziehen sich auf die **technischen Aspekte** der Datensicherheit und den Schutz von IT-Systemen.

- **Zutrittskontrolle**
	- Alarmanlagen
	- Videoüberwachung
	- Besucherausweise
- **Zugangskontrolle**
	- Bildschirmschoner mit Passwortschutz
	- Biometrische Verfahren (z.B. Fingerabdruck, Gesichtserkennung)
	- Magnet- oder Chipkarten
- **Zugriffskontrolle**
	- Verschlüsselung von Datenträgern
	- Löschung von Datenträgern
	- User/Rollenkonzept
- **Netzwerksicherheit**
	- Firewalls
	- Intrusion Detection Systems (IDS)
	- [[VPN-Modelle|VPNs (Virtual Private Networks)]]
- **Datensicherung**
	- Regelmäßige Backups
	- Redundante Systeme

## Organisatorische Maßnahmen
Diese Maßnahmen betreffen die **organisatorischen Strukturen** und Prozesse innerhalb eines Unternehmens.

- **Richtlinien und Verfahren**
	- Datenschutzrichtlinien
	- Sicherheitsrichtlinien
	- Notfallpläne
- **Schulung und Sensibilisierung**
	- Schulungen für Mitarbeiter zu Datenschutz und IT-Sicherheit
	- Sensibilisierungskampagnen
- **Zugriffsmanagement**
	- Regelungen zur Vergabe von Zugriffsrechten
	- Überprüfung und Anpassung von Benutzerrechten
- **Audit und Kontrolle**
	- Regelmäßige Sicherheitsüberprüfungen
	- Compliance-Checks
- **Incident Management**
	- Verfahren zur Meldung und Bearbeitung von Sicherheitsvorfällen
	- Dokumentation von Vorfällen
- **Change Management**
	- Regelungen zur Änderung von IT-Systemen und Prozessen
	- Überprüfung von Änderungen auf Sicherheitsrelevanz

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- auch als **TQM** bezeichnet
- **ganzheitliches System** zur **Verankerung** von **Qualität** und **Qualitätszielen** -> **langfristiges** Umsetzen
- anwendbar in **allen Branchen** und **Unternehmensgrößen**
- Ziel: **Kundenzufriedenheit** auf **Höchstmaß** steigern

## Merkmale
- **Optimierung** der Qualität von **Produkten** und **Dienstleistungen**
- Streben nach dem **Höchstmaß an Kundenzufriedenheit**
- **Qualitätsvorsprung** und **hohe Kundenzufriedenheit** als **Wettbewerbsvorteil**
- Qualitätsziele bestimmen die **Ausrichtung aller Ebenen** und **Funktionen des Unternehmens**
- **Alle Mitarbeiter** sind motiviert und tragen aktiv zur Verbesserung bei

## Warum ist TQM wichtig?
- Qualität der Produkte ist das oberste Ziel für Unternehmen.
- Fehlerfreie Produkte sind Voraussetzung für den Verkauf in großen Stückzahlen.
- TQM fördert die Einbindung aller Unternehmensbereiche in den Produktionsprozess.
- Hauptziel: absolute Kundenzufriedenheit durch schlankes Management und permanentes Qualitätscontrolling.

## Prinzipien von TQM
1. **Neue Blickwinkel schaffen**: Kundenzufriedenheit als oberstes Gebot.
2. **Stärkerer Einsatz der Unternehmensleitung**: Aktive Gestaltung des Umstrukturierungsprozesses.
3. **Mitarbeiterorientierung**: Einbindung der Mitarbeiter in den Prozess, um Motivation und Kreativität zu fördern.
4. **Kundenorientierung**: Der Kunde definiert, was Qualität bedeutet; alle Prozesse orientieren sich an seinen Wünschen.
5. **Lean Management**: Schlankes Management fördert Kommunikation und Effizienz.
6. **Permanentes Qualitätscontrolling**: Ständige Überwachung der Qualität zur Sicherstellung der Zielvorgaben.

![[Pasted image 20240920063011.png]]

## Vor- und Nachteile von TQM

### Vorteile
- Das gesamte Unternehmen orientiert sich an neuen Qualitätsmaßstäben.
- Kosteneinsparungspotenziale nach der Umsetzung.
- Weniger Störungen in den Prozessabläufen führen zu höherer Ausbringungsmenge.
- Positive Auswirkungen auf Unternehmenszahlen: Umsatz- und Gewinnsteigerung.

### Nachteile
- TQM erfordert eine Veränderung der Unternehmenskultur, was mit Widerständen verbunden sein kann.
- Mangelnde Akzeptanz bei Mitarbeitern kann zu Konflikten führen.
- Strikte Einhaltung der Abläufe kann bei vielen involvierten Mitarbeitern schwierig sein.


> Wirtschaft, D. M. (2016, August 14). Total Quality Management (TQM & EFQM) einfach erklärt - Qualitätsmanagement in Unternehmen. Youtube. Retrieved from https://www.youtube.com/watch?v=nIXPrC_jfhU
> caesar. academy. (2022, December 05). Total-Quality-Management (Definition) - 👨🏼‍🎓 EINFACH ERKLÄRT 👩🏼‍🎓. Youtube. Retrieved from https://www.youtube.com/watch?v=vv9vL1jzRWo
> ▷ Total Quality Management (TQM) » Definition, Erklärung & Beispiele + Übungsfragen. (2022, May 10). Retrieved from https://www.bwl-lexikon.de/wiki/total-quality-management-tqm/#welche-prinzipien-verfolgt-tqm

- Methode, um **Daten über ein Netzwerk zu transportieren**, wobei Protokolle verwendet werden, die von diesem Netzwerk nicht unterstützt werden.
- Es funktioniert durch die **Einkapselung** von Paketen: das Einwickeln von Paketen in andere Pakete.
- Tunneling wird häufig in **virtuellen privaten Netzwerken (VPNs)** eingesetzt und ermöglicht effiziente und sichere Verbindungen zwischen Netzwerken.

## Funktionsweise der Einkapselung von Paketen
- Daten werden in **Pakete** aufgeteilt, die aus einem Header (Ziel und Protokoll) und einer Nutzlast (eigentliche Daten) bestehen.
- Ein eingekapseltes Paket ist ein Paket innerhalb eines anderen Pakets. Der Header und die Nutzlast des ursprünglichen Pakets befinden sich im Nutzlastbereich des umgebenden Pakets.

## Vorteile der Einkapselung
- Ermöglicht die Übertragung von Daten über Netzwerke, die nicht alle Protokolle unterstützen (z.B. IPv6 über IPv4).
- Nützlich für **verschlüsselte Verbindungen**, da verschlüsselte Pakete in unverschlüsselte Pakete eingekapselt werden können, um die Weiterleitung durch Router zu ermöglichen.

## Was ist ein VPN-Tunnel?
- Ein VPN ist eine sichere, verschlüsselte Verbindung über ein öffentlich zugängliches Netzwerk.
- Tunneling ist der Prozess, durch den VPN-Pakete ihr Ziel erreichen, typischerweise in einem privaten Netzwerk.
- Häufig verwendete Protokolle:
  - **IPsec**: Protokollsuite, die auf der Netzwerkebene arbeitet und den gesamten Netzwerk-Traffic verschlüsselt.
  - **Transport Layer Security (TLS)**: Arbeitet auf Ebene 6 oder 7 des OSI-Modells, bietet Sicherheit für Datenübertragungen.

## Was ist Split Tunneling?
- Split Tunneling ermöglicht es Nutzern, sich **mit zwei Netzwerken gleichzeitig** zu verbinden: einem öffentlichen und einem privaten.
- Ein Teil des Traffics wird durch den VPN-Tunnel geleitet, während der andere Teil außerhalb des Tunnels bleibt.

## Tunneling-Protokolle
- **Generic Routing Encapsulation (GRE)**: Kapselt Datenpakete eines Routing-Protokolls in die Pakete eines anderen Protokolls. Fügt jedem Paket einen GRE-Header und einen IP-Header hinzu.
- **IP-in-IP**: Kapselt IP-Pakete in anderen IP-Paketen, wird nicht für VPNs verwendet.
- **SSH-Tunneling**: Stellt verschlüsselte Verbindungen zwischen Client und Server her, arbeitet auf Ebene 7 des OSI-Modells.
- Weitere Tunneling-Protokolle:
	- **Point-to-Point Tunneling Protocol (PPTP)**
	- **Secure Socket Tunneling Protocol (SSTP)**
	- **Layer 2 Tunneling Protocol (L2TP)**
	- **Virtual Extensible Local Area Network (VXLAN)**

## Quellen

> Was ist Tunneling? | Tunneling in Netzwerken. (2024, September 20). Retrieved from https://www.cloudflare.com/de-de/learning/network-layer/what-is-tunneling

## Überwachtes Lernen
Überwachtes Lernen ist ein zentraler Ansatz im maschinellen Lernen, bei dem Modelle **anhand von gekennzeichneten Trainingsdaten** trainiert werden. Ziel ist es, **Muster und Zusammenhänge** zu erkennen, die auf **unbekannte Daten** angewendet werden können.

## Definition
- **Überwachtes Lernen**: Ein Lernansatz, bei dem ein Modell auf Basis von Eingabedaten (**Features**) und den zugehörigen Ausgabewerten (**Labels**) trainiert wird. Das Modell lernt, eine Funktion zu approximieren, die die Eingaben den Ausgaben zuordnet.

## Funktionsweise
1. **Datensammlung**: Ein Datensatz wird erstellt, der aus Eingabedaten und den entsprechenden Ausgabewerten besteht.
2. **Datenaufteilung**: Der Datensatz wird typischerweise in zwei Teile aufgeteilt:
    - **Trainingsdatensatz (70-80%)**: Wird verwendet, um das Modell zu trainieren. Hier lernt das Modell, die Beziehung zwischen den Eingaben und den Ausgaben zu erkennen.
    - **Testdatensatz (20-30%)**: Wird verwendet, um die Leistung des Modells zu evaluieren. Hier wird überprüft, wie gut das Modell auf unbekannte Daten generalisiert.
      In einigen Fällen kann auch ein **Validierungsdatensatz** (z. B. 10-15%) verwendet werden, um Hyperparameter zu optimieren, bevor das endgültige Modell auf dem Testdatensatz bewertet wird.
3. **Modelltraining**: Das Modell wird mit dem Trainingsdatensatz trainiert, indem es die Gewichtungen anpasst, um die Fehler zwischen den vorhergesagten und den tatsächlichen Ausgaben zu minimieren.
4. **Modellbewertung**: Nach dem Training wird das Modell mit dem Testdatensatz evaluiert. Wichtige Metriken zur Bewertung sind:
    - **Genauigkeit (Accuracy)**: Der Anteil der **korrekt klassifizierten** Beispiele.
    - **Präzision (Precision)**: Anteil der **korrekt als positiv** klassifizierten Instanzen an allen als positiv klassifizierten Instanzen. *wenige falsch-positive Vorhersagen*
    - **Recall (Sensitivität)**: Anteil der **korrekt identifizierten** relevanten Instanzen an allen relevanten Instanzen. *keine falschen Vorhersagen*
    - **F1-Score**: Das harmonische Mittel von Präzision und Recall, das ein ausgewogenes Maß für die Modellleistung bietet.

## Anwendungsbeispiele

- **Betrugserkennung**: Identifikation von betrügerischen Transaktionen in Finanzdaten durch Analyse von Mustern in historischen Transaktionen.
- **Bilderkennung**: Klassifizierung von Bildern in verschiedene Kategorien, z. B. Erkennung von Objekten oder Gesichtern in Bildern.
- **Vorhersagemodelle**: Prognose von zukünftigen Ereignissen, wie z. B. Verkaufszahlen oder Wetterbedingungen, basierend auf historischen Daten.

## Herausforderungen
- **Overfitting**: Wenn das Modell zu gut auf den Trainingsdatensatz passt und dadurch die Fähigkeit verliert, auf neuen, unbekannten Daten gut zu generalisieren. Techniken wie Regularisierung, Cross-Validation und die Verwendung eines Testdatensatzes helfen, Overfitting zu vermeiden.
- **Datenqualität**: Die Leistung des Modells hängt stark von der Qualität der Daten ab. Rauschen, fehlende Werte oder unausgewogene Klassenverteilungen können die Ergebnisse negativ beeinflussen.
- **Feature Engineering**: Die Auswahl und Transformation der Eingabedaten (Features) ist entscheidend für den Erfolg des Modells. Gut gestaltete Features können die Leistung erheblich verbessern.

## Unüberwachtes Lernen
Unüberwachtes Lernen ist ein Ansatz im maschinellen Lernen, bei dem Algorithmen **Muster und Strukturen in unbeschrifteten Daten erkennen**, ohne dass vorherige Labels oder Ausgaben bereitgestellt werden.

## Definition
- **Unüberwachtes Lernen**: Ein Lernansatz, bei dem ein Modell auf Basis von Eingabedaten trainiert wird, um eigenständig Muster, Gruppen oder Strukturen zu identifizieren.

## Funktionsweise
1. **Datensammlung**: Ein Datensatz wird erstellt, der nur Eingabedaten (**Features**) enthält, ohne zugehörige Ausgabewerte (Labels).
2. **Mustererkennung**: Der Algorithmus analysiert die Daten und identifiziert Muster, Strukturen oder Gruppen.

## Algorithmen
- **Clusteranalyse**: Gruppiert ähnliche Datenpunkte in Cluster. Beispiele:
    - **K-Means**: Teilt die Daten in K Cluster basierend auf der Ähnlichkeit.
    - **Hierarchische Clusteranalyse**: Erstellt eine Baumstruktur von Clustern, die die Beziehungen zwischen den Datenpunkten zeigt.
- **Dimensionsreduktion**: Reduziert die Anzahl der Merkmale in den Daten, während die wesentlichen Informationen erhalten bleiben. Beispiele:
    - **Principal Component Analysis (PCA)**: Transformiert die Daten in eine niedrigdimensionale Darstellung, die die Varianz maximiert.
    - **t-Distributed Stochastic Neighbor Embedding (t-SNE)**: Visualisiert hochdimensionale Daten in zwei oder drei Dimensionen, indem es ähnliche Punkte nahe beieinander anordnet.
## Anwendungsbeispiele
- **Kundensegmentierung**: Identifikation von Kundengruppen in Marketingdaten, um gezielte Kampagnen zu entwickeln.
- **Anomalieerkennung**: Erkennung von ungewöhnlichen Mustern in Daten, z. B. bei der Betrugserkennung.
- **Bildkompression**: Reduzierung der Datenmenge in Bildern durch Dimensionsreduktion, um Speicherplatz zu sparen.

## Herausforderungen
- **Interpretation der Ergebnisse**: Da es keine Labels gibt, kann es schwierig sein, die gefundenen Muster zu interpretieren und zu bewerten.
- **Wahl des Algorithmus**: Die Auswahl des richtigen Algorithmus und der Parameter kann die Ergebnisse erheblich beeinflussen.
- **Skalierbarkeit**: Einige Algorithmen können bei großen Datensätzen ineffizient sein.

## Vergleich

| Aspekt                 | Überwachtes Lernen (Supervised Learning)                                     | Unüberwachtes Lernen (Unsupervised Learning)                                  |
| ---------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **Definition**         | Modell wird mit gekennzeichneten Daten trainiert, um Vorhersagen zu treffen. | Modell erkennt Muster in unbeschrifteten Daten ohne vorherige Labels.         |
| **Ziel**               | Vorhersage von Ausgaben basierend auf Eingaben.                              | Entdeckung von Mustern, Strukturen oder Gruppen in den Daten.                 |
| **Daten**              | Benötigt gekennzeichnete Daten (Eingaben und Ausgaben).                      | Arbeitet mit unbeschrifteten Daten (nur Eingaben).                            |
| **Beispiele**          | - Betrugserkennung<br>- Bilderkennung<br>- Vorhersagemodelle                 | - Clusteranalyse<br>- Dimensionsreduktion<br>- Anomalieerkennung              |
| **Algorithmen**        | - Entscheidungsbäume<br>- Support Vector Machines (SVM)<br>- Neuronale Netze | - K-Means<br>- Hierarchische Clusteranalyse<br>- PCA, t-SNE                   |
| **Leistungsbewertung** | Metriken wie Genauigkeit, Präzision, Recall, F1-Score.                       | Metriken wie Silhouette-Score, Davies-Bouldin-Index (für Cluster).            |
| **Herausforderungen**  | - Overfitting<br>- Datenqualität<br>- Feature Engineering                    | - Interpretation der Ergebnisse<br>- Wahl des Algorithmus<br>- Skalierbarkeit |
| **Anwendungsgebiete**  | - Medizinische Diagnosen<br>- Finanzprognosen<br>- Spam-Erkennung            | - Marktforschung<br>- Kundensegmentierung<br>- Explorative Datenanalyse       |

## Quellen
> datasolut. (2020, August 27). Überwachtes Lernen (Supervised Learning) einfach erklärt! - Machine Learning Grundlagen. Youtube. Retrieved from https://www.youtube.com/watch?v=BkDUDi6YDaU
> datasolut. (2020, August 29). Unüberwachtes Lernen (Unsupervised Learning) einfach erklärt! - Machine Learning Grundlagen. Youtube. Retrieved from https://www.youtube.com/watch?v=XSOi9MKfEHQ
> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Familie an Modellierungssprachen

## Arten
- [[UML-Sequenzdiagramm]]
- [[UML-Klassendiagramm]]
- [[UML-Zustandsdiagramm]]
- [[UML-Aktivitätsdiagramm]]
- [[UML-Anwendungsfalldiagramm]]

- hilft **bestimmten Anwendungsfall** auf **detaillierteren Ebene** zu visualisieren
- **Fluss der Aktivitäten** durch ein System

## Elemente
![[Pasted image 20240910081403.png]]
- **Anfangsknoten**, stellt *Anfangszustand der Aktivität* dar
![[Pasted image 20240910081554.png]]
- **Aktivität**, Darstellung einer Aktivität des Prozesses
![[Pasted image 20240910081751.png]]
- **Aktion**, ausführbarer **Teilbereich** einer Aktivität
![[Pasted image 20240910081954.png]]
- **Kontrollfluss**, eine Aktion zu einer anderen
![[Pasted image 20240910082546.png]]
- **Objektfluss**, Weg von Objekten die sich durch Aktivität bewegen
![[Pasted image 20240910082625.png]]
- **Aktivität Endknoten**, Ende aller Kontrollflüsse
![[Pasted image 20240910082812.png]]
- **Fluss-Endknoten**, Ende eines einzelnen Kontrollflusses
![[Pasted image 20240910082832.png]]
- **Entscheidungs-Knotenpunkt** / **Knoten verschmelzen**, bedingter Verzweigungspunkt; Ein Eingang, mehrere Ausgänge / Zusammenfließen von Strömen; mehrere Eingänge, ein Ausgang
![[Pasted image 20240910082952.png]]
- **Gabel**, Fluss, der sich in zwei oder mehr parallele Ströme verzweigt
![[Pasted image 20240910083034.png]]
- **Zusammenführen**, Fluss, der zwei oder mehr parallele Ströme verzweigt
![[Pasted image 20240910083103.png]]
- **Senden von Signalen**, an eine annehmende Aktivität
![[Pasted image 20240910083218.png]]
- **Signal-Empfang**, von einer sendenen Aktivität
![[Pasted image 20240910083244.png]]
- **Anmerkung/Kommentar**
![[Pasted image 20240910083302.png]]
- **Swimlanes**, Partitionen. Aktionen werden anhand ihrer Akteure getrennt
	- **Vorteile**: macht lineare Prozesse leichter lesbar, jedoch nicht mehr als 5 Swimlanes

## Beispiel

![[Pasted image 20240910083408.png]]

## Quellen

> Siriwardhana, S. (2022). Aktivitätsdiagramm UML: Symbol, Beispiele & Erstellung [Leitfaden]. Creately Blog. Retrieved from https://creately.com/blog/de/diagramme/aktivitatsdiagramm-uml

- Modellierung der **Struktur** und des **Verhaltens** von **Software** und anderen Systemen
- **Anwendungsfälle** und **Akteure** mit **jeweiligen Abhängigkeiten** und **Beziehungen zueinander**
- dazu geeignet Kommunikation zwischen *Auftraggeber* und *Entwickler* zu unterstützen

## Einsatzgebiete
- Modellierung eines Geschäftsprozesses
- Aufzeigen des Systemverhaltens aus der Sicht des Anwenders

## Elemente
![[Pasted image 20240909122259.png]]
- **Systemkontext** / *Systemgrenzen*
![[Pasted image 20240909122548.png]]
- Personen wie Kunden, Administratoren oder ein System
![[Pasted image 20240909122725.png]]
- **Anwendungsfälle werden** in Kommentar oder eigener Datei beschrieben werden
## Beziehungen
![[Pasted image 20240909122922.png]]
- **Assoziation / Kommunikation**
![[Pasted image 20240909122940.png]]
- **Multiplizität** von Akteur und Anwendungsfall
![[Pasted image 20240909123034.png]]
- **Generalisierung** von Anwendungsfällen
![[Pasted image 20240909123051.png]]
- **Generalisierung** von Akteuren
![[Pasted image 20240909123112.png]]
- **Include-Beziehung**, Anwendungsfall A beinhaltet Anwendungsfall B
![[Pasted image 20240909123155.png]]
- **Extend-Beziehung**, Anwendungsfall A erweitert Anwendungsfall B
![[Pasted image 20240909123220.png]]
- **Extend-Beziehung**, Anwendungsfall A erweitert Anwendungsfall B unter bestimmter Erweiterung
![[Pasted image 20240909123258.png]]
- **Anwendungsfall** mit Erweiterungsstellen

- veranschaulicht Systeme der **objektorientierten Programmierung**
- zeigt **Zustände von Systemen** und beschreibt **Interaktionen zwischen Systemelementen**

## Elemente
![[Pasted image 20240911135337.png]]
- **Klassen** (**+** public, **-** private, **#** protected), *Schlüselwörter* sind optional
![[Pasted image 20240911135649.png]]
- **Generalisierung**, Wärmesensor *spezialisiert* ISensor
![[Pasted image 20240911135753.png]]
- binäre **Assoziation**
![[Pasted image 20240911135810.png]]
- reflexive **Assoziation**
![[Pasted image 20240911135837.png]]
- **Aggregation**, leerer Pfeil, Teil-Ganzes-Beziehung mit *selbständigen* Teil *(Student existiert ohne Vorlesung)*
- **Komposition**, ausgefüllter Pfeil, Teil-Ganzes-Beziehung mit *unselbständigen* Teil *(Raum existiert nicht ohne Gebäude)*


## Quellen

> Redaktion, I. (2019). Klassendiagramme mit UML erstellen. IONOS Digital Guide. Retrieved from https://www.ionos.at/digitalguide/websites/web-entwicklung/klassendiagramme-mit-uml-erstellen
> Macke, S. (2023, August 18). UML-Klassendiagramm für AP1 der IT-Berufe. Youtube. Retrieved from https://www.youtube.com/watch?v=F3RDwz-uoX8
> Autoren der Wikimedia-Projekte. (2003, December 20). Klassendiagramm – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=Klassendiagramm&oldid=247765241

- stellt **Ereignisauftritte chronologisch** dar
- beschreibt wie **Objekte Nachrichten** in **bestimmter Reihenfolge austauschen**
- **genaue Reihenfolge** ist wichtiger als spezifische Zeitpunkte
- **Lebenslinien** repräsentiert **Zeitverlauf eines Prozesses**

- Sequenzdiagramm umfasst **Gruppe von Objekten**, die mit **Lebenslinien** dargestellt werden und die **Nachrichten** die sie während der **Interaktion** austauschen

## Elemente
![Objekt-Symbol](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-object-symbol.svg)
- **Objekt**, wie in UML, *ohne* Klassenattribute
![Aktivitätsbalken](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-activation-box-symbol.svg)
- **Aktivitätsbalken**, Zeit, die ein Objekt zum *Abschluss* einer *Aufgabe* benötigt
![Akteur-Symbol](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-actor-symbol.svg)
- **Akteur**, Entitäten die mit dem *System interagieren* bzw. systemintern sind 
![Lebenslinien-Symbol](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-lifeline-symbol.svg)
- **Lebenslinien**, aufeinanderfolgende Ereignisse die einem 
![Symbol für synchrone Nachrichten](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-synchronous-message-symbol.svg)
- **synchrone Nachrichten**, Absender muss auf Antwort warten
![Symbol für asynchrone Nachrichten](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-asynchronous-message-symbol.svg)
- **asynchrone Nachrichten**, keine Antwort erforderlich
![Symbol für asynchrone Antwortnachrichten](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-return-message-symbol.svg)
- **(asynchrone) Antwortnachrichten**, Antwort vom Empfänger
![Symbol für asynchrone Nachrichtenerstellung](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-create-message-symbol.svg)
- **asynchrone Nachrichtenerstellung**, Erstellung eines neuen Objekts
![Symbol für Löschnachrichten](https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/discovery/UML/UML-Sequence/uml-deleted-message-symbol.svg)
- **Löschnachrichten**, Zerstörung eines Objektes

## Beispiel
![[Pasted image 20240913065132.png]]

![[Pasted image 20240913072326.png]]
## Quellen

> Redaktion, I. (2018). Sequenzdiagramme: Den Nachrichtenaustausch in einem System mit UML darstellen. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/websites/web-entwicklung/sequenzdiagramme-mit-uml-erstellen
> Rational Application Developer for WebSphere Software 9.7.0. (2021, March 03). Retrieved from https://www.ibm.com/docs/de/radfws/9.7?topic=diagrams-sequence
> UML Sequenzdiagramm. (2024, September 13). Retrieved from https://www.lucidchart.com/pages/de/uml-sequenzdiagramme

- Visualisierung von Zuständen eines endlichen Automaten
- Darstellung des Lebenszyklus einzelner Objekte

## Diagrammstruktur
- Jedes Diagramm hat:
  - **Anfangszustand**
  - **Endzustand**
  - Mindestens einen **Zwischenzustand**

## Zustände
- **Darstellung**: Rechtecke
- **Pseudozustände**:
  - **Startzustand**: 
    - Keine eingehende Transition
    - Exakt eine ausgehende Transition
  - **Endzustand**: 
    - Keine ausgehende Transition
    - Ende der Verhaltensabfolge
  - **Gabelung**: 
    - Aufspaltung in parallele Zustände
  - **Synchronisation**: 
    - Vereinigung mehrerer paralleler Zustände
  - **Kreuzung**: 
    - Knotenpunkt für mehrere Transitionen
  - **Entscheidung**: 
    - Alternative Transitionen basierend auf vorheriger Entscheidung
  - **Eintrittspunkt**: 
    - Zusammenfassung gleichartiger Transitionen in einen zusammengesetzten Zustand
  - **Austrittspunkt**: 
    - Zusammenfassung gleichartiger Transitionen aus einem zusammengesetzten Zustand
  - **Flache Historie**: 
    - Speicherung des letzten aktiven Unterzustands eines zusammengesetzten Zustands
  - **Tiefe Historie**: 
    - Speicherung des letzten aktiven Unterzustands aller Hierarchie-Ebenen eines zusammengesetzten Zustands

## Ereignisse
- Beschreiben Bedingungen für den Zustandwechsel:
  - **entry**: Automatisches Auslösen beim Eintritt in den Zustand
  - **exit**: Auslösen beim Verlassen des Zustands
  - **do**: Wiederholtes Auslösen, solange der Zustand nicht wechselt

## Transitionen
- Zustandsübergänge, ausgelöst durch Ereignisse
- **Innere Transitionen**: 
  - Nicht unbedingt Bestandteil des Diagramms
- **Äußere Transitionen**: 
  - Obligatorisch, Zustand wechselt

## Elemente
![[Pasted image 20240913091756.png]]

## Beispiele
![[Pasted image 20240913090611.png]]
![[Pasted image 20240913090635.png]]
![[Pasted image 20240913091809.png]]

## Quellen

> Redaktion, I. (2020). UML-Zustandsdiagramme: Folgen von Objektzuständen sichtbar machen. IONOS Digital Guide. Retrieved from https://www.ionos.de/digitalguide/websites/web-entwicklung/uml-zustandsdiagramm

## Einführung in das Urheberrecht
- Das Urheberrecht schützt die kreativen Leistungen von Autoren, Künstlern und Entwicklern.
- Es regelt die Nutzung, Verbreitung und Vervielfältigung von geschützten Werken.

## Relevante Aspekte für die Fachinformatik
- **Schutz von Software**: Programme, Quellcodes und Algorithmen sind urheberrechtlich geschützt.
- **Datenbanken**: Auch Datenbanken können urheberrechtlichen Schutz genießen, wenn sie eine eigene schöpferische Höhe erreichen.
- **Grafiken und Designs**: Bilder, Logos und Designs sind ebenfalls urheberrechtlich geschützt.

## Rechte des Urhebers
- **Vervielfältigungsrecht**: Das Recht, Kopien des Werkes herzustellen.
- **Verbreitungsrecht**: Das Recht, das Werk zu verkaufen oder anderweitig zu verbreiten.
- **Bearbeitungsrecht**: Das Recht, das Werk zu verändern oder zu bearbeiten.

## Nutzungsrechte
- **Lizenzen**: Urheber können Lizenzen vergeben, die Dritten die Nutzung ihrer Werke erlauben (z.B. Open Source Lizenzen).
- **Creative Commons**: Lizenzen, die eine flexible Nutzung von Werken unter bestimmten Bedingungen ermöglichen.

## Verletzungen des Urheberrechts
- **Plagiat**: Unrechtmäßige Aneignung von urheberrechtlich geschützten Inhalten.
- **Illegale Vervielfältigung**: Kopieren und Verteilen von Software oder Medien ohne Erlaubnis.
- **Rechtsfolgen**: Abmahnungen, Schadensersatzforderungen und Unterlassungsklagen.

## Praktische Anwendung in der Fachinformatik
- **Softwareentwicklung**: Sicherstellen, dass verwendete Bibliotheken und Frameworks ordnungsgemäß lizenziert sind.
- **Content Creation**: Bei der Erstellung von Inhalten (z.B. Webseiten, Apps) die Urheberrechte Dritter respektieren.
- **Schulung und Sensibilisierung**: Mitarbeiter über Urheberrecht und Lizenzfragen informieren.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Gerät, das eine **kontinuierliche Stromversorgung** für kritische Systeme sicherstellt, selbst bei **Stromausfällen** oder **Spannungsschwankungen**. Sie **überbrückt Stromausfälle** und **schützt Geräte** vor Datenverlust oder Beschädigungen durch unerwartete Abschaltungen.

## USV-Arten
![[Pasted image 20240920091305.png]]
### Offline / Standby-USV
- **Funktionsweise**: Die USV lädt im Normalbetrieb ihre Batterien und schaltet im Falle eines Stromausfalls in wenigen Millisekunden auf Batteriebetrieb um.
- **Einsatzgebiet**: Geeignet für weniger kritische Systeme, bei denen kurze Umschaltzeiten tolerierbar sind (z. B. Büro-PCs).
- **Vorteile**:
    - Kostengünstig.
    - Einfacher Aufbau.
- **Nachteile**:
    - Umschaltzeit, die zu kurzen Spannungsverlusten führen kann.
    - Kein Schutz vor Spannungsspitzen oder -einbrüchen im Normalbetrieb.

### Line-Interactive-USV
- **Funktionsweise**: Diese USV verwendet einen Spannungsregler (AVR, Automatic Voltage Regulator), um Spannungsschwankungen im Netzbetrieb auszugleichen. Bei einem Stromausfall schaltet sie auf Batteriebetrieb um.
- **Einsatzgebiet**: Geeignet für Systeme, die häufig Spannungsprobleme haben (z. B. Netzschwankungen).
- **Vorteile**:
    - Besserer Schutz vor Spannungsschwankungen als eine Offline-USV.
    - Kürzere Umschaltzeit.
- **Nachteile**:
    - Umschaltzeit vorhanden.
    - Höhere Kosten als bei einer Offline-USV.

### Online / Doppelwandler-USV
- **Funktionsweise**: Wandelt die Netzspannung kontinuierlich in Gleichstrom und dann wieder in Wechselstrom um. Dadurch wird eine konstante und unterbrechungsfreie Stromversorgung ohne Umschaltzeiten gewährleistet.
- **Einsatzgebiet**: Für kritische Systeme (Server, Rechenzentren), die eine kontinuierliche Stromversorgung und Schutz vor allen Arten von Spannungsstörungen benötigen.
- **Vorteile**:
    - Kein Umschaltvorgang (0 ms Umschaltzeit).
    - Schutz vor allen Arten von Netzstörungen.
- **Nachteile**:
    - Teurer als Offline- und Line-Interactive-USVs.
    - Höherer Energieverbrauch (wegen ständiger Umwandlung).

## Quellen

> ChatGPT. (2024, September 20). Retrieved from https://chatgpt.com/c/66ed1d06-5424-800b-bc26-8455a49771b1
> mueller – Ihre USV-Beratung. (2024, September 20). Retrieved from https://www.usv-beratung.de

- wie stark **streuen Daten um den Mittelwert**

## Formel
$v$ = Varianz
$n$ = Anzahl
$x_i$ = Daten
$\bar{x}$ = [[Quadratisches Mittel|Mittelwert]] der Daten

### Gesamtheit
$$
v = \dfrac{1}{n} \sum^{n}_{i=1}(x_i - \bar{x})^2
$$
### Stichprobe
$$
v = \dfrac{1}{n-1} \sum^{n}_{i=1} (x_i - \bar{x})^2
$$

## Vor- und Nachteile der Varianz

### Vorteile
- **Mathematische Grundlage**: Die Varianz ist eine fundamentale Kennzahl in der Statistik, die auf der Differenz zwischen den Datenpunkten und dem Mittelwert basiert.
- Empfindlichkeit gegenüber Ausreißern: Sie **berücksichtigt alle Datenpunkte** und ist daher empfindlich gegenüber Ausreißern, was in bestimmten Analysen nützlich sein kann.
- **Basis für weitere Analysen**: Die Varianz ist die Grundlage für viele statistische Tests und Modelle, einschließlich der Standardabweichung und der Normalverteilung.

### Nachteile
- **schwieriger** zu interpretieren
- Einheitlichkeit: Die Varianz hat eine **andere Einheit als die ursprünglichen Daten** (z. B. Quadrat der Einheit), was die Interpretation erschwert.
- Empfindlichkeit gegenüber Ausreißern: Während dies ein Vorteil sein kann, kann es auch ein Nachteil sein, da **Ausreißer die Varianz stark beeinflussen** und zu verzerrten Ergebnissen führen können.
- **Nicht robust**: Die Varianz ist nicht robust gegenüber nicht-normalverteilten Daten, was zu ungenauen Schätzungen führen kann.


## Vergleich zwischen Standardabweichung und Varianz

| Merkmal                     | Varianz ($v$)                                      | Standardabweichung ($\sigma$ oder $s$)               |
|-----------------------------|----------------------------------------------------|------------------------------------------------------|
| Definition                   | Durchschnitt der quadrierten Abweichungen          | Quadratwurzel der Varianz                             |
| Einheit                      | Quadrat der Einheit der Daten                       | Gleiche Einheit wie die Daten                         |
| Interpretation              | Gibt die Streuung in quadrierten Einheiten an      | Gibt die Streuung in den gleichen Einheiten wie die Daten an |
| Empfindlichkeit gegenüber    | Empfindlich gegenüber Ausreißern                    | Empfindlich gegenüber Ausreißern                      |
| Verwendung                   | Oft in der Theorie und bei der Berechnung von Tests | Häufiger in der Praxis verwendet, da leichter zu interpretieren |


## Quellen

> Datatab. (2021, November 28). Varianz (Einfach erklärt). Youtube. Retrieved from https://www.youtube.com/watch?v=iPjXpiB6w9E  
> Duck.ai. (2024, September 16). Anonymisierte AI-Interaktionen. Retrieved from https://duck.ai

## Begriffsdefinitionen
- **Vernetzung**: Verbindung von verschiedenen Geräten, Systemen oder Netzwerken, um den Austausch von Daten und Ressourcen zu ermöglichen.

## Arten der Vernetzung
- **LAN (Local Area Network)**: Netzwerk, das Geräte in einem begrenzten geografischen Bereich verbindet, z. B. in einem Büro oder einem Gebäude.
- **WAN (Wide Area Network)**: Netzwerk, das größere geografische Bereiche abdeckt, z. B. Städte oder Länder, oft über das Internet.
- **MAN (Metropolitan Area Network)**: Netzwerk, das eine Stadt oder ein großes geografisches Gebiet abdeckt.
- **VPN (Virtual Private Network)**: Sicherer, verschlüsselter Zugang zu einem Netzwerk über das Internet.

## Vernetzungstechnologien
- **Ethernet**: Standard für kabelgebundene Netzwerke, der die Kommunikation zwischen Geräten ermöglicht.
- **Wi-Fi**: Drahtlose Technologie zur Vernetzung von Geräten über Funkwellen.
- **Bluetooth**: Kurzstreckenkommunikation zwischen Geräten, ideal für persönliche Netzwerke.
- **IP (Internet Protocol)**: Protokoll, das die Adressierung und den Austausch von Daten über Netzwerke regelt.
- **MQTT (Message Queuing Telemetry Transport)**: Leichtgewichtiges Protokoll für die Nachrichtenübertragung, ideal für IoT-Anwendungen, das eine effiziente Kommunikation zwischen Geräten ermöglicht.
- **Zigbee**: Drahtloses Kommunikationsprotokoll, das für die Vernetzung von Geräten in der Heimautomatisierung und im IoT entwickelt wurde, mit niedrigem Energieverbrauch und hoher Reichweite.
- **Z-Wave**: Ein weiteres Protokoll für die Heimautomatisierung, das eine zuverlässige Kommunikation zwischen Geräten mit geringem Energieverbrauch ermöglicht.

## Vorteile der Vernetzung
- **Ressourcenteilung**: Gemeinsame Nutzung von Druckern, Speicher und Internetverbindungen.
- **Zugänglichkeit**: Daten und Anwendungen sind von verschiedenen Standorten aus zugänglich, was die Zusammenarbeit fördert.
- **Skalierbarkeit**: Netzwerke können leicht erweitert werden, um neue Geräte oder Benutzer hinzuzufügen.
- **Zentralisierte Verwaltung**: Erleichtert die Überwachung und Verwaltung von Geräten und Benutzern.

## Nachteile der Vernetzung
- **Sicherheitsrisiken**: Vernetzte Systeme sind anfälliger für Cyberangriffe und Datenlecks.
- **Komplexität**: Die Verwaltung und Konfiguration von Netzwerken kann komplex sein und erfordert Fachwissen.
- **Abhängigkeit von Infrastruktur**: Ein Ausfall der Netzwerkverbindung kann den Zugriff auf wichtige Ressourcen und Daten verhindern.
- **Kosten**: Die Einrichtung und Wartung eines Netzwerks kann kostspielig sein, insbesondere bei großen oder komplexen Systemen.

## Best Practices für die Vernetzung
- **Sicherheitsmaßnahmen**: Implementierung von Firewalls, Antivirenprogrammen und Verschlüsselung.
- **Regelmäßige Wartung**: Überprüfung und Aktualisierung von Netzwerkhardware und -software.
- **Dokumentation**: Führen von Aufzeichnungen über Netzwerkarchitektur, Konfigurationen und Änderungen.
- **Monitoring**: Überwachung des Netzwerkverkehrs zur Erkennung von Anomalien und zur Sicherstellung der Leistung.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Symmetrische Verschlüsselung
- **derselbe Schlüssel** für Ver- und Entschlüsselung
- muss über sicheren Weg zwischen Sender und Empfänger ausgetauscht werden
- große Datenmengen können schnell ver- und entschlüsselt werden
- **Einsatzbereich**: Ideal für die Verschlüsselung großer Datenmengen, z.B. bei Dateiübertragungen oder Datenbanken, wo Geschwindigkeit und Effizienz wichtig sind.

## Asymmetrische Verschlüsselung
- **ein gemeinsamer**, **ein privater** Schlüssel -> **Schlüsselpaar**
	- **Public Key**, Verschlüsseln von Nachrichten, Identifikation [[Digitale Signatur|digitaler Signaturen]]
	- **Private Key**, Entschlüsseln verschlüsselter Nachrichten, Erstellung [[Digitale Signatur|digitaler Signaturen]]
- **Einsatzbereich**: Besonders geeignet für den Austausch von Schlüsseln oder für die Sicherstellung der Identität, z.B. bei E-Mail-Verschlüsselung oder digitalen Signaturen, wo Sicherheit und Authentifizierung wichtig sind.

## Auswahl der Verschlüsselungsart
- **Symmetrische Verschlüsselung**: 
	- **Datenmenge**: Hoch (z.B. große Dateien)
	- **Schutzbedarf**: Mittel bis hoch (wenn der Schlüssel sicher ausgetauscht werden kann)
- **Asymmetrische Verschlüsselung**: 
	- **Datenmenge**: Niedrig (z.B. kurze Nachrichten oder Schlüssel)
	- **Schutzbedarf**: Hoch (z.B. bei sensiblen Informationen, wo Identität und Integrität wichtig sind)
- **Hybride Verschlüsselung**: 
	- Kombination aus symmetrischer und asymmetrischer Verschlüsselung
	- **Einsatzbereich**: Optimal für sichere Kommunikation, z.B. bei SSL/TLS, wo asymmetrische Verschlüsselung für den Schlüsselaustausch und symmetrische Verschlüsselung für die Datenübertragung verwendet wird.
	- **Datenmenge**: Variabel (kann sowohl große als auch kleine Datenmengen effizient verarbeiten)
	- **Schutzbedarf**: Hoch (bietet sowohl Geschwindigkeit als auch Sicherheit)

## Quellen

> Arten der Verschlüsselung. (2024, September 18). Retrieved from https://www.bsi.bund.de/DE/Themen/Verbraucherinnen-und-Verbraucher/Informationen-und-Empfehlungen/Onlinekommunikation/Verschluesselt-kommunizieren/Arten-der-Verschluesselung/arten-der-verschluesselung_node.html

Versionsmanagement ist der Prozess der **Verwaltung und Nachverfolgung von Änderungen an Dateien und Projekten** über die Zeit. Es ermöglicht mehreren Benutzern, an denselben Dateien zu arbeiten, ohne dass es zu Konflikten kommt, und bietet die Möglichkeit, frühere Versionen wiederherzustellen.

## Wichtige Aspekte des Versionsmanagements
- **Nachverfolgbarkeit**: Jede Änderung an einem Projekt wird dokumentiert, einschließlich Informationen über den Autor, das Änderungsdatum und eine Beschreibung der Änderung.
- **Zusammenarbeit**: Mehrere Entwickler können gleichzeitig an einem Projekt arbeiten, ohne sich gegenseitig in die Quere zu kommen.
- **Wiederherstellung**: Bei Bedarf können frühere Versionen von Dateien oder des gesamten Projekts wiederhergestellt werden.

## Beliebte Versionsmanagement-Systeme
- **Git**: Ein verteiltes Versionskontrollsystem, das es Entwicklern ermöglicht, lokal zu arbeiten und Änderungen einfach zu synchronisieren. Git ist bekannt für seine Flexibilität und Leistungsfähigkeit.
- **SVN (Subversion)**: Ein zentrales Versionskontrollsystem, das eine zentrale Repository-Struktur verwendet. Es ist einfach zu bedienen und eignet sich gut für Projekte mit einer klaren Hierarchie.
- **Mercurial**: Ein weiteres verteiltes Versionskontrollsystem, das ähnlich wie Git funktioniert, jedoch eine einfachere Benutzeroberfläche bietet.

## Grundlegende Konzepte
- **Repository**: Der Speicherort, an dem alle Versionen eines Projekts gespeichert sind.
- **Commit**: Eine Aktion, bei der Änderungen an Dateien in das Repository gespeichert werden. Jeder Commit hat eine eindeutige ID und enthält Metadaten.
- **Branching**: Die Möglichkeit, von der Hauptentwicklungslinie (Master-Branch) abzuweichen, um neue Funktionen oder Änderungen zu entwickeln, ohne die Hauptversion zu beeinträchtigen.
- **Merging**: Der Prozess, bei dem Änderungen von einem Branch in einen anderen integriert werden, um die Arbeit zusammenzuführen.

## Vorteile des Versionsmanagements
- **Fehlerbehebung**: Durch die Möglichkeit, frühere Versionen wiederherzustellen, können Fehler schnell identifiziert und behoben werden.
- **Kollaboration**: Teams können effizienter zusammenarbeiten, da sie Änderungen nachverfolgen und Konflikte leicht lösen können.
- **Dokumentation**: Die Historie der Änderungen bietet eine wertvolle Dokumentation des Entwicklungsprozesses und der Entscheidungsfindung.

## Herausforderungen und Risiken
- **Komplexität**: Die Verwendung von Versionsmanagement-Systemen kann anfangs komplex sein, insbesondere für neue Benutzer.
- **Konflikte**: Bei gleichzeitigen Änderungen an denselben Dateien können Konflikte auftreten, die manuell gelöst werden müssen.
- **Schulung**: Teams müssen geschult werden, um die besten Praktiken im Umgang mit Versionsmanagement-Systemen zu verstehen und anzuwenden.

## Quellen

> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Normalverteilung
- **Gauß-Verteilung**, wichtigste Verteilung der Statistik
- fast jeder Mittelwert folgt Normalverteilung
- symmetrisch
- Mittelwert, Median, Modus = 0
- Varianz = 1
![[Pasted image 20240916111802.png]]

## Diskrete Gleichverteilung
- bei **diskreter** (*endliche Zahlen mit selben Wahrscheinlichkeit*) Zufallsvariable
- Bspw. Wurf eines nicht-gezinkten Würfels

## T-Verteilung
- breiter als Normalverteilung
- Mittelwert, Median, Modus = 0
- Varianz > 1
![[Pasted image 20240916112026.png]]

## Chi-Quadrat-Verteilung
- **steilen** Anstieg, abflachende Kurven Ausprägung
- asymmetrisch
- ausschließlich positive Werte
![[Pasted image 20240916112137.png]]

## F-Verteilung
- Spitzere Ausprägung als Chi-Quadrat-Verteilung
- F-Test: Test auf identische Grundgesamtheit
![[Pasted image 20240916112557.png]]

## Quellen

> Studyflix. (2019, January 22). Normalverteilung / Gaußverteilung - Stochastik einfach erklärt mit Rechenbeispiel! Youtube. Retrieved from https://www.youtube.com/watch?v=JHQB5lmo0XQ
> wirtconomy. (2022, June 26). Statistische Verteilungen | Überblick | Standardnormalverteilung | Chi-Quadrat-Verteilung | ... Youtube. Retrieved from https://www.youtube.com/watch?v=MyLEF1dNfVs&t=99s

### 1. Kaufen
**Vorteile:**
- **Eigentum:** Der Käufer wird Eigentümer des Objekts und kann es nach Belieben nutzen und verändern.
- **Wertsteigerung:** Mögliche Wertsteigerung des Objekts über die Zeit (z.B. Immobilien).
- **Keine laufenden Kosten:** Keine monatlichen Zahlungen nach dem Kauf, außer für Wartung und Betrieb.
- **Steuerliche Vorteile:** In einigen Fällen können Kosten steuerlich absetzbar sein.
**Nachteile:**
- **Hohe Anfangsinvestition:** Hohe Anschaffungskosten, die sofort aufgebracht werden müssen.
- **Wertverlust:** Bei vielen Gütern (z.B. Autos) sinkt der Wert schnell.
- **Risiko:** Der Käufer trägt das Risiko für Schäden oder Wertverluste.

### 2. Leasing
**Vorteile:**
- **Geringe monatliche Raten:** Oft niedrigere monatliche Zahlungen im Vergleich zum Kauf.
- **Neueste Modelle:** Möglichkeit, regelmäßig auf neuere Modelle oder Technologien umzusteigen.
- **Wartung:** Oft sind Wartung und Reparaturen im Leasingvertrag enthalten.

**Nachteile:**
- **Kein Eigentum:** Am Ende der Laufzeit gehört das Objekt nicht dem Leasingnehmer.
- **Laufzeitbindung:** Verträge sind oft langfristig und können schwer vorzeitig beendet werden.
- **Nutzungsbeschränkungen:** Oft gibt es Kilometerbegrenzungen oder andere Nutzungsbedingungen.

### 3. Mieten
**Vorteile:**
- **Flexibilität:** Kurze Mietverträge ermöglichen eine schnelle Anpassung an Veränderungen.
- **Geringe Anfangskosten:** Oft nur eine Kaution und die erste Monatsmiete erforderlich.
- **Keine Instandhaltungskosten:** Vermieter ist in der Regel für Reparaturen und Wartung verantwortlich.
**Nachteile:**
- **Kein Eigentum:** Mieter erwerben kein Eigentum am Objekt.
- **Langfristige Kosten:** Auf lange Sicht können Mietzahlungen höher sein als Kaufpreise.
- **Eingeschränkte Kontrolle:** Mieter haben oft weniger Kontrolle über das Objekt (z.B. Renovierungen).


- **V**irtual **P**rivate **N**etwork
- **sichere** und **zuverlässige** Verbindung über ein unsicheres Netzwerk (z.B. Internet)
- Schützt Internetaktivitäten und verschleiert Identität

## Funktionsweise
- **Tunneling**: VPNs erstellen einen verschlüsselten Tunnel zwischen dem Endgerät und dem VPN-Server. Dies schützt die Daten vor Dritten.
- **Verschlüsselung**: Daten werden mit Protokollen wie AES (Advanced Encryption Standard) verschlüsselt, um die Vertraulichkeit zu gewährleisten.
- **Authentifizierung**: Nutzer müssen sich oft mit Benutzernamen und Passwort oder durch Zertifikate authentifizieren, um Zugang zum VPN zu erhalten.

## Protokolle
- **PPTP (Point-to-Point Tunneling Protocol)**: Einfach zu konfigurieren, aber weniger sicher.
- **L2TP/IPsec (Layer 2 Tunneling Protocol)**: Bietet bessere Sicherheit durch Kombination mit IPsec, jedoch langsamer.
- **OpenVPN**: Open-Source-Protokoll, sehr sicher und flexibel, unterstützt verschiedene Verschlüsselungsmethoden.
- **IKEv2/IPsec (Internet Key Exchange Version 2)**: Bietet hohe Sicherheit und Stabilität, besonders bei mobilen Geräten.
- **WireGuard**: Modernes, einfaches und schnelles VPN-Protokoll, das eine hohe Sicherheit bei geringem Overhead bietet. Es verwendet kryptografische Methoden, die als sicher gelten und ist einfach zu implementieren.

## Modelle
- **End-to-End VPN**: Verbindet zwei Endgeräte direkt miteinander, sodass die Kommunikation zwischen diesen Geräten verschlüsselt ist. Ideal für private Kommunikation.
![[Pasted image 20240920074753.png]]
- **End-to-Site VPN**: Verbindet ein einzelnes Endgerät (z.B. Laptop) mit einem Netzwerk (z.B. Unternehmensnetzwerk). Dies ermöglicht dem Benutzer, auf Ressourcen im Unternehmensnetzwerk zuzugreifen, als wäre er vor Ort.
![[Pasted image 20240920074952.png]]
- **Site-to-Site VPN**: Verbindet zwei oder mehr Netzwerke miteinander, z.B. die Büros eines Unternehmens an verschiedenen Standorten. Dies ermöglicht eine sichere Kommunikation zwischen den Netzwerken.
![[Pasted image 20240920074905.png]]

## Vorteile
- **Datenschutz**: Anonymität im Internet durch Verschleierung der IP-Adresse.
- **Sicherheit**: Schutz vor Man-in-the-Middle-Angriffen und Abhörmaßnahmen.
- **Zugriff auf gesperrte Inhalte**: Umgehung von Geoblocking und Zensur, z.B. Zugriff auf Streaming-Dienste oder Webseiten, die in bestimmten Ländern blockiert sind.

## Nachteile
- **Geschwindigkeit**: VPNs können die Internetgeschwindigkeit verringern, da die Daten durch den VPN-Server geleitet werden.
- **Kosten**: Viele zuverlässige VPN-Dienste sind kostenpflichtig.
- **Vertrauenswürdigkeit des Anbieters**: Nutzer müssen darauf achten, einen seriösen Anbieter zu wählen, da dieser möglicherweise Protokolle der Internetaktivitäten speichert.

## Anwendungsgebiete
- **Fernzugriff**: Mitarbeiter können sicher auf Unternehmensressourcen zugreifen, während sie sich außerhalb des Büros befinden.
- **Öffentliche WLAN-Netzwerke**: Schutz der Datenübertragung in unsicheren Netzwerken, z.B. in Cafés oder Flughäfen.
- **Umgehung von Zensur**: Zugang zu Informationen und Plattformen, die in bestimmten Ländern eingeschränkt sind.

## Rechtliche Aspekte
- **Nutzungsbedingungen**: Einige Dienste verbieten die Nutzung von VPNs, was zu einem Verstoß gegen die Nutzungsbedingungen führen kann.
- **Datenschutzgesetze**: Nutzer sollten sich über die Datenschutzbestimmungen des VPN-Anbieters informieren, insbesondere in Bezug auf die Speicherung von Nutzerdaten.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

## Grundbegriffe

- **Stochastik**: Teilgebiet der Mathematik, das sich mit der Analyse von Zufallsexperimenten befasst
- **Wahrscheinlichkeit**: Maß für die Chance des Eintretens eines Ereignisses, liegt zwischen 0 und 1 (oder 0% und 100%)
- **Fairness**: Bei fairen Zufallsexperimenten ist die Wahrscheinlichkeit für jedes gleichartige Ereignis identisch

## Mengen und Ereignisse

- **Ergebnismenge** $\Omega$ (Omega): Menge aller möglichen Ergebnisse eines Zufallsexperiments
  - Beispiel: Würfel $\Omega = \{1,2,3,4,5,6\}$
- **Ereignis** $A$: Teilmenge von $\Omega$, also $A \subseteq \Omega$
- **Vereinigungsmenge** $A \cup B$: Enthält alle Elemente, die in A oder B (oder beiden) vorkommen
  - Beispiel: $A = \{1\}$, $B = \{2,4,6\}$, $A \cup B = \{1,2,4,6\}$

## Berechnung von Wahrscheinlichkeiten

1. **Einzelereignisse**: 
	- $P(A) = \frac{\text{günstige Fälle}}{\text{mögliche Fälle}}$
	- Beispiel: $P(\text{Würfel zeigt 3}) = \frac{1}{6}$

3. **Additionsregel** für sich gegenseitig ausschließende Ereignisse:
	- $P(A \text{ oder } B) = P(A) + P(B)$
	- Beispiel: $P(2 \text{ oder } 4 \text{ oder } 6) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{1}{2}$

4. **Multiplikationsregel** für unabhängige Ereignisse:
	- $P(A \text{ und } B) = P(A) \cdot P(B)$
	- Beispiel: $P(\text{zweimal Kopf}) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}$

5. **Gegenwahrscheinlichkeit**: $P(\text{nicht } A) = 1 - P(A)$
	- Beispiel: $P(\text{mindestens einmal Kopf in zwei Würfen}) = 1 - P(\text{zweimal Zahl}) = 1 - \frac{1}{4} = \frac{3}{4}$

## Abhängigkeit und Unabhängigkeit
- **Stochastisch unabhängige Ereignisse**: Das Eintreten des einen Ereignisses beeinflusst nicht die Wahrscheinlichkeit des anderen
	- $P(A \cap B) = P(A) \cdot P(B)$
	- $P(A|B) = P(A)$ und $P(B|A) = P(B)$
- **Stochastisch abhängige Ereignisse**: Das Eintreten des einen Ereignisses beeinflusst die Wahrscheinlichkeit des anderen
	- Berechnung mit bedingter Wahrscheinlichkeit: $P(A \cap B) = P(A) \cdot P(B|A)$

## Bedingte Wahrscheinlichkeit
- $P(A|B) = \frac{P(A \cap B)}{P(B)}$, für $P(B) > 0$
- Beschreibt die Wahrscheinlichkeit von A unter der Bedingung, dass B eingetreten ist



## Grundlagen von Webservern
- **Definition**: Webserver sind Systeme, die Webseiten hosten und über das Internet bereitstellen.
- **Zweck**: Ermöglichen den Zugriff auf Webseiten und Webanwendungen durch Clients (z. B. Browser).

## Wichtige Protokolle
- **HTTP (Hypertext Transfer Protocol)**: Protokoll für die Übertragung von Webseiten.
- **[[HTTPS]] (HTTP Secure)**: Sichere Version von HTTP, die Daten verschlüsselt.

## Komponenten eines Webservers
- **Webserver-Software**: Software, die Anfragen verarbeitet und Webseiten ausliefert (z. B. Apache, Nginx).
- **Datenbank**: Speichert dynamische Inhalte (z. B. MySQL, PostgreSQL).

## Funktionsweise
- **Anfrage-Antwort-Modell**: Der Client sendet eine Anfrage an den Webserver, der die angeforderte Webseite zurücksendet.
- **Statische vs. Dynamische Inhalte**: Statische Inhalte sind unverändert (z. B. HTML-Dateien), während dynamische Inhalte zur Laufzeit generiert werden (z. B. durch Skripte).

## Sicherheit
- **SSL/TLS**: Verschlüsselung für sichere Datenübertragung.
- **Firewall**: Schutz vor unbefugtem Zugriff und Angriffen.

## Fazit
Webserver sind entscheidend für die Bereitstellung von Webseiten und Webanwendungen. Ein grundlegendes Verständnis der Protokolle, der Funktionsweise und der Sicherheitsmaßnahmen ist wichtig, um die Verfügbarkeit und Sicherheit von Webdiensten zu gewährleisten.

## Quellen

> AI Chat. (2024, September 18). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- veranschaulicht die **einzelnen Schritte**, die ein **Produkt durchlaufen** muss um mit **Mehrwert verkauft** zu werden

![[Pasted image 20240928181316.png]]
- **Primäraktivitäten**, alle Tätigkeiten die **direkt mit der Erstellung** des Produktes/der Dienstleistung zusammenhängen (vgl. [[Haupt- und Teilprozesse|Hauptprozesse]])
	- Eingangslogistik
	- Operationen
	- Marketing und Vertrieb
	- Ausgangslogistik
	- Kundendienst
- **Unterstützungsaktivitäten**, alle Tätigkeiten, die die **Voraussetzung zur Ausführung** der primären Aktivitäten benötigt werden (vgl. [[Haupt- und Teilprozesse|Teilprozesse]])
	- Unternehmensinfrastruktur
	- Personalwirtschaft
	- Technologieentwicklung
	- Beschaffung
- **Gewinnspanne**, Umsatz wird den angefallenen Kosten gegenübergestellt

## Anwendung der Wertschöpfungskettenanalyse

1. **Identifikation von Verbesserungspotenzialen**: Durch den Vergleich der eigenen Wertschöpfungskette mit der von Wettbewerbern können Unternehmen Bereiche identifizieren, in denen sie sich verbessern können.
2. **Kostenoptimierung**: Die Analyse hilft, Aktivitäten zu identifizieren, die hohe Kosten verursachen, aber wenig zum Kundennutzen beitragen.
3. **Strategieentwicklung**: Basierend auf den Erkenntnissen der Analyse können Unternehmen ihre Kernkompetenzen erkennen und darauf aufbauend Wettbewerbsstrategien entwickeln.
4. **Branchenspezifische Anwendungen**:
	- In der Industrie: Zur Verbesserung von Produktionsprozessen und Maximierung des Produktwerts.
	- Im Dienstleistungssektor: Zur Optimierung von Kundenservice-Prozessen und Evaluierung von Marketingstrategien.
	- In der Landwirtschaft: Zur Effizienzsteigerung in der Nahrungsmittelproduktion, von der Aussaat bis zur Vermarktung.
5. **Prozessoptimierung**: Die Analyse hilft bei der Gestaltung unternehmensinterner Prozesse und der Identifikation von Optimierungspotenzialen.
6. **Wettbewerbsanalyse**: Durch die Visualisierung in einer Matrix können Unternehmen ihre Position im Vergleich zu Wettbewerbern einschätzen und Prioritäten für Verbesserungen setzen.



- **Ziel**: **Effizienzsteigerung** und **Fehlerreduktion** durch **Automatisierung** wiederkehrender Aufgaben.  
- Vorteile: **Zeitersparnis**, **Konsistenz**, **Entlastung** von **Routineaufgaben**.

## Skripting-Sprachen
- **[[Bash]]**: Ideal für Unix/Linux-Systeme, einfache Automatisierung von Shell-Befehlen.  
- **[[Python]]**: Vielseitig, umfangreiche Bibliotheken für Systemadministration und Automatisierung.  
- **[[PowerShell]]**: Speziell für Windows-Umgebungen, leistungsstark für Systemmanagement.

## Wichtige Konzepte
- **Skripterstellung**: Schreiben von Skripten zur Automatisierung von Aufgaben (z.B. Backup, Updates).  
- **Parameterübergabe**: Verwendung von Variablen und Argumenten zur Flexibilität der Skripte.  
- **Fehlerbehandlung**: Implementierung von Try-Catch-Mechanismen zur robusten Fehlerbehandlung.

## Überwachung von Skripten
- **Logging**: Protokollierung von Skriptausgaben und Fehlern zur späteren Analyse.  
- **Benachrichtigungen**: E-Mail- oder SMS-Benachrichtigungen bei Fehlern oder wichtigen Ereignissen.  
- **Monitoring-Tools**: Einsatz von Tools wie Nagios oder Zabbix zur Überwachung der Skriptausführung.

## Best Practices
- **Modularität**: Skripte in kleine, wiederverwendbare Module unterteilen.  
- **Dokumentation**: Skripte gut dokumentieren, um die Wartung zu erleichtern.  
- **Testen**: Skripte in einer Testumgebung prüfen, bevor sie in der Produktion eingesetzt werden.

## Anwendungsbeispiele
- Automatisierung von Systemupdates.  
- Regelmäßige Datensicherungen.  
- Überwachung von Systemressourcen und -diensten.

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- systematische Prozess der **Erfassung, Strukturierung, Speicherung, Verteilung und Nutzung von Wissen** innerhalb einer Organisation, um ihre Ziele effizienter zu erreichen.

## Ziele
- **Verbesserung** der **Wettbewerbsfähigkeit**
- Förderung von **Innovation**
- Effizienzsteigerung
- Vermeidung von Wissensverlust
- Unterstützung des organisationalen Lernens

## Kernprozesse des Wissensmanagements
1. Wissensidentifikation
2. Wissenserwerb
3. Wissensentwicklung
4. Wissens(ver)teilung
5. Wissensnutzung
6. Wissensbewahrung

## Arten von Wissen
1. Explizites Wissen
	- Dokumentiertes, leicht zu teilendes Wissen
1. Implizites Wissen (Tacit Knowledge)
	- Erfahrungsbasiertes, schwer zu formalisierendes Wissen

## Wissensmanagement-Methoden und -Tools
- Wissensdatenbanken
- Expertenverzeichnisse
- Communities of Practice
- Mentoring-Programme
- Wikis und Intranets
- Storytelling
- Lessons Learned
- After Action Reviews

## Barrieren im Wissensmanagement
- Mangelnde Bereitschaft zur Wissensteilung
- Unzureichende technische Infrastruktur
- Fehlende Unterstützung durch das Management
- Zeitdruck und Ressourcenmangel
- Kulturelle Hindernisse

## Erfolgsfaktoren
- Unterstützung durch die Führungsebene
- Schaffung einer Wissenskultur
- Anreizsysteme für Wissensteilung
- Nutzerfreundliche Technologien
- Integration in bestehende Geschäftsprozesse

## Trends im Wissensmanagement
- Künstliche Intelligenz und Machine Learning
- Social Learning Plattformen
- Gamification-Ansätze
- Microlearning
- Augmented und Virtual Reality für Wissensvermittlung

## Best Practices
- Regelmäßige Wissensaudits durchführen
- Wissensmanagement in die Unternehmensstrategie integrieren
- Kontinuierliche Schulung und Sensibilisierung der Mitarbeiter
- Feedback-Mechanismen etablieren
- Wissensmanagement-Erfolge messen und kommunizieren

Ein Workshop ist eine interaktive Veranstaltung, die darauf abzielt, **Wissen zu vermitteln, Fähigkeiten zu entwickeln oder Probleme zu lösen**. Workshops fördern die aktive Teilnahme der Teilnehmer und ermöglichen den Austausch von Ideen und Erfahrungen.

#### Ziele von Workshops
1. **Information und Aufklärung**
   - Vermittlung von Wissen über spezifische Themen oder Veränderungen.
   - Klärung von Fragen und **Beseitigung** von Missverständnissen.
   - Förderung des Verständnisses für die Notwendigkeit von Veränderungen.
2. **Einbindung und Mitgestaltung**
   - Aktive Beteiligung der Teilnehmer am Prozess.
   - Sammlung von Meinungen, Bedenken und Ideen der Mitarbeiter.
   - Förderung von Kreativität und Innovation durch Gruppenarbeit und Diskussionen.
3. **Teambildung und Stärkung des Zusammenhalts**
   - Förderung des Teamgeists und der Zusammenarbeit.
   - Stärkung der Beziehungen zwischen den Teilnehmern.
   - Schaffung eines positiven und unterstützenden Arbeitsumfelds.
#### Struktur eines Workshops
1. **Vorbereitung**
   - Festlegung der Ziele und Themen des Workshops.
   - Auswahl der Teilnehmer und der geeigneten Methoden.
   - Erstellung eines Zeitplans und der benötigten Materialien.
2. **Durchführung**
   - Einleitung: Vorstellung der Ziele und Agenda.
   - Interaktive Aktivitäten: Gruppenarbeiten, Diskussionen, Brainstorming.
   - Zusammenfassung: Präsentation der Ergebnisse und Erkenntnisse.
3. **Nachbereitung**
   - Dokumentation der Ergebnisse und Feedback der Teilnehmer.
   - Evaluation des Workshops: Was lief gut? Was kann verbessert werden?
   - Umsetzung der Ergebnisse in die Praxis.
#### Methoden und Techniken
- **Brainstorming**: Kreative Ideenfindung in Gruppen.
- **Gruppenarbeit**: Zusammenarbeit in kleinen Teams zur Lösung von Aufgaben.
- **Diskussionen**: Austausch von Meinungen und Erfahrungen.
- **Rollenspiele**: Simulation von Situationen zur Förderung des Verständnisses.
#### Vorteile von Workshops
- Förderung der aktiven Teilnahme und des Engagements.
- Verbesserung der Kommunikation und des Teamworks.
- Möglichkeit zur direkten Rückmeldung und Anpassung von Ideen.
- Stärkung des Zusammenhalts und der Motivation der Teilnehmer.
#### Herausforderungen
- Widerstände gegen Veränderungen können auftreten.
- Unterschiedliche Meinungen und Konflikte müssen moderiert werden.
- Zeitmanagement ist entscheidend, um alle Themen abzudecken.

- **Zentralisierung**: In der IT bezieht sich Zentralisierung auf die **Konzentration von IT-Ressourcen**, **Daten und Entscheidungsprozessen** in einer zentralen Einheit oder Infrastruktur. Dies bedeutet, dass alle wichtigen IT-Funktionen und -Daten an einem Ort verwaltet werden.
- **Dezentralisierung**: Dezentralisierung in der IT bedeutet, dass IT-Ressourcen, Daten und Entscheidungsprozesse auf mehrere Standorte oder Einheiten verteilt sind. Jede Einheit hat die Autonomie, ihre eigenen IT-Entscheidungen zu treffen und Ressourcen zu verwalten.

### Wichtige Merkmale

#### Zentralisierung in der IT
- **Datenmanagement**: Alle Daten werden in einer zentralen Datenbank oder einem Rechenzentrum gespeichert und verwaltet.
- **IT-Support**: Ein zentrales IT-Team kümmert sich um den technischen Support und die Wartung aller Systeme.
- **Sicherheitskontrolle**: Einheitliche Sicherheitsrichtlinien und -maßnahmen werden zentral festgelegt und durchgesetzt.
- **Kosteneffizienz**: Mögliche Kosteneinsparungen durch die Bündelung von Ressourcen und die Vermeidung redundanter Systeme.

#### Dezentralisierung in der IT
- **Datenverteilung**: Daten werden lokal gespeichert und verwaltet, oft in mehreren Rechenzentren oder Cloud-Umgebungen.
- **Autonomie der Abteilungen**: Verschiedene Abteilungen oder Standorte haben die Freiheit, ihre eigenen IT-Lösungen und -Strategien zu wählen.
- **Flexibilität**: Schnellere Anpassung an lokale Anforderungen und Veränderungen im Geschäftsumfeld.
- **Innovationsförderung**: Ermutigung zur Entwicklung neuer Lösungen und Technologien auf lokaler Ebene.

### Anwendungsbereiche

#### Zentralisierung
- **Unternehmens-IT**: Zentrale Verwaltung von Servern, Netzwerken und Datenbanken in großen Unternehmen.
- **Cloud-Computing**: Nutzung zentralisierter Cloud-Dienste, bei denen alle Daten und Anwendungen in einem Rechenzentrum gehostet werden.
- **IT-Sicherheitsmanagement**: Implementierung zentraler Sicherheitslösungen, um Bedrohungen effizient zu überwachen und zu bekämpfen.

#### Dezentralisierung
- **Verteilte Systeme**: Nutzung von verteilten Datenbanken und Cloud-Diensten, die Daten an mehreren Standorten speichern.
- **Edge Computing**: Verarbeitung von Daten an der Quelle (z.B. IoT-Geräte), um Latenzzeiten zu reduzieren und lokale Entscheidungen zu ermöglichen.
- **Agile Entwicklung**: Teams, die autonom arbeiten und ihre eigenen Technologien und Tools wählen, um schnell auf Marktveränderungen zu reagieren.

### Vor- und Nachteile

#### Zentralisierung in der IT
- **Vorteile**:
  - Einheitliche Verwaltung und Kontrolle über IT-Ressourcen.
  - Einfachere Implementierung von Sicherheitsrichtlinien.
  - Kosteneinsparungen durch reduzierte Redundanz.

- **Nachteile**:
  - Geringere Flexibilität und Anpassungsfähigkeit an lokale Bedürfnisse.
  - Risiko von Engpässen und Überlastungen in der zentralen IT-Abteilung.
  - Mögliche Verzögerungen bei der Entscheidungsfindung.

#### Dezentralisierung in der IT
- **Vorteile**:
  - Höhere Flexibilität und Anpassungsfähigkeit an spezifische Anforderungen.
  - Schnellere Reaktionszeiten auf lokale Probleme und Chancen.
  - Förderung von Innovation und Kreativität durch lokale Autonomie.

- **Nachteile**:
  - Mögliche Inkonsistenzen in Sicherheitsrichtlinien und Datenmanagement.
  - Höhere Komplexität in der Verwaltung und Koordination.
  - Risiko von Ressourcenverschwendung durch redundante Systeme.

### Wichtige Begriffe
- **Cloud-Computing**: Bereitstellung von IT-Ressourcen über das Internet, oft zentralisiert in großen Rechenzentren.
- **Edge Computing**: Verarbeitung von Daten an der Quelle, um Latenzzeiten zu reduzieren.
- **Verteilte Systeme**: Systeme, die Daten und Anwendungen über mehrere Standorte oder Einheiten verteilen.

## Quellen
> AI Chat. (2024, September 20). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- Funktion, die den Ergebnissen einer Zufallsexperiments reelle Zahlen zuordnet
	- **-> Ergebnis eines Zufallsexperiments** werden beschrieben

## Diskrete Zufallsvariable
- nehmen **endlich viele** oder **abzählbar unendlich** viele Werte an
	- Ausprägungen können durchnummeriert werden
- **Beispiel**: wie viele Liter Bier pro Jahr werden getrunken (theoretisch unendlich, jedoch abzählbar) 

## Stetige Zufallsvariable
- überabzählbar, **unendlich viele**, nicht abzählbare Werte
- z.B. bei Messvorgängen wie Zeiten, Längen oder Temperaturen
- kein exaktes Ergebnis möglich, lediglich Intervalle
- **Beispiel:** mit welcher Wahrscheinlichkeit ist eine Studentin zwischen 160cm und 175cm groß, in welcher Wahrscheinlichkeit läuft ein Sprinter 100m unter 12 Sekunden

- Bildung einer **Rangfolge** der betrachteten Objekte anhand **Priorisierung** vorgenommen und **Handlungsstrategien** abgeleitet werden können
- Wesentliches vom Unwesentlichen trennen, Schwerpunkte setzen, unwirtschaftliche Anstrengungen vermeiden

## Klassifizierung

1. Klasse **A**, **sehr** wichtig bzw. dringlich
2. Klasse **B**, wichtig oder dringlich
3. Klasse **C**, **weniger** wichtig oder dringlich


| Kategorie | Wertanteile der Aufgabe | Mengenanteil |
| --------- | ----------------------- | ------------ |
| A         | 60 - 85%                | 10 - 20%     |
| B         | 10 - 25%                | 20 - 40%     |
| C         | 5 - 15%                 | 40 - 60%     |

## Vorteile
- Analyse **komplexer Probleme** mit einem **vertretbaren Aufwand** durch Einschränkung auf **wesentliche Faktoren**
- universelle, einfache Anwendbarkeit
- vom Untersuchungsgegenstand unabhängig
- Übersichtliche, graphische Darstellung möglich

## Nachteile
- sehr **grobe Klasseneinteilung**
- konsistente Daten sind vorausgesetzt

## Quellen
> Bundesministerium des Innern und für Heimat. (2024, September 19). Retrieved from https://www.orghandbuch.de/Webs/OHB/DE/Organisationshandbuch/6_MethodenTechniken/63_Analysetechniken/631_ABC-Analyse/abc-analyse_inhalt.html%3Bjsessionid=A9EC8CF14A322DA22146DA463549ADD9.live882?nn=21098996

> **Unabhängige Daten** sind **Eingabevariablen**. Abhängige Daten repräsentieren das Ergebnis oder die zu erklärende Variable, die von den unabhängigen Daten beeinflusst wird. **Abhängige Daten** können auch als **Ergebnisvariablen** bezeichnet werden.

**Abhängige und unabhängige Daten** sind zentrale Begriffe in der Statistik, insbesondere bei der Planung und Auswertung von Experimenten. Sie beschreiben, wie verschiedene Datensätze miteinander in Beziehung stehen.

## (Un-)abhängige Variablen
- **Abhängige Variable:** Dies ist die Variable, deren Wert man vorhersagen möchte. Im Beispiel ist die _Anzahl der verkauften Masken_ (oder der Erfolg/Misserfolg) die abhängige Variable, da sie von anderen Faktoren abhängt.
- **Unabhängige Variablen:** Dies sind die Variablen, die Einfluss auf die abhängige Variable haben. Im Beispiel sind _Datum_, _Event_, _Ort_, _Zielgruppe_, _Werbemittel_ und _Kosten_ unabhängige Variablen.

## Unabhängige Daten
- **Definition:** Unabhängige Daten sind Datensätze, die **keinerlei Zusammenhang** miteinander haben. Die Werte einer Datenmenge beeinflussen nicht die Werte einer anderen.
- **Beispiel:**
    - Die Ergebnisse zweier Münzwürfe sind unabhängig voneinander.
    - Die Körpergröße von zufällig ausgewählten Personen ist unabhängig von ihrer Postleitzahl.
- **Merkmale:**
    - Jeder Datensatz kann separat betrachtet werden.
    - Statistische Tests für unabhängige Stichproben werden verwendet.

## Abhängige Daten
- **Definition:** Abhängige Daten weisen einen **Zusammenhang** auf. Die Werte in einer Datenmenge beeinflussen oder sind korreliert mit den Werten in einer anderen.
- **Beispiel:**
    - Die Körpergröße von Eltern und ihren Kindern ist abhängig.
    - Die Testergebnisse einer Person vor und nach einer Behandlung sind abhängig.
- **Merkmale:**
    - Die Datensätze sind oft paarweise verknüpft (z.B. Vorher-Nachher-Messungen).
    - Statistische Tests für abhängige Stichproben werden verwendet.

## Warum ist die Unterscheidung wichtig?
Die Unterscheidung zwischen abhängigen und unabhängigen Daten ist entscheidend für die Wahl der richtigen statistischen Verfahren. Denn:

- **Falsche Wahl:** Die Verwendung falscher Tests kann zu falschen Schlussfolgerungen führen.
- **Abhängigkeit:** Abhängige Daten haben oft eine größere Varianz innerhalb der Gruppen, was die statistische Power verringern kann.

### Visuelle Darstellung

| Merkmal                | Unabhängige Daten                         | Abhängige Daten                                               |
| ---------------------- | ----------------------------------------- | ------------------------------------------------------------- |
| **Beziehung**          | Kein Zusammenhang                         | Zusammenhang (Korrelation, Paarung)                           |
| **Beispiel**           | Ergebnisse zweier verschiedener Gruppen   | Ergebnisse derselben Gruppe zu verschiedenen Zeitpunkten      |
| **Statistische Tests** | t-Test für unabhängige Stichproben, ANOVA | t-Test für abhängige Stichproben, gepaarte Stichproben t-Test |

### Anwendungsbeispiele
- **Medizin:** VerglZusammenhangeich der Wirksamkeit eines Medikaments bei zwei verschiedenen Patientengruppen (unabhängig) vs. Vergleich der Wirksamkeit eines Medikaments bei denselben Patienten vor und nach der Behandlung (abhängig).
- **Psychologie:** Vergleich der Leistungsfähigkeit von zwei verschiedenen Lerngruppen (unabhängig) vs. Vergleich der Leistungsfähigkeit derselben Lerngruppe unter verschiedenen Bedingungen (abhängig).
- **Soziologie:** Vergleich der Einkommen in zwei verschiedenen Städten (unabhängig) vs. Vergleich des Einkommens von Ehepartnern (abhängig).



- Gestaltung der Abläufe
- **dynamisch** und **prozessorientiert**
- **Ziele**
	- Arbeiten mit **geringsten Aufwand** erledigen
	- **Bearbeitungs- und Durchlaufkosten** minimieren
	- **Bearbeitungszeiten und -fehler** minimieren
	- **Termine** einhalten
	- **Kapazitäten** optimal nutzen

## Arbeitsanalyse
- **Zerlegung** der *Gesamtaufgabe* in *Teilaufgaben*
- Arbeitsverteilung

## Arbeitssynthese
-  Zusammenfassung der Teilaufgaben zu **Abläufen**
- Zuordnung von **Arbeitsmitteln**
- **Arbeitspensum** und **Mitarbeiter**
- **Arbeitsablauf** festlegen

## Darstellung
- [[Flussdiagramm]]

## Quellen

> Ausbilderwelt. (2021, March 19). Ablauforganisation einfach erklärt für die IHK-Prüfung. Youtube. Retrieved from https://www.youtube.com/watch?v=ImnadIPICmA


- Technik zur **Überwachung und Analyse des Programmablaufs**, um Fehler zu identifizieren und den Programmfluss zu verstehen.
- **Ziel**: Verbesserung der Softwarequalität durch frühzeitige Fehlererkennung und -behebung.

## Bedeutung
- **Fehleridentifikation**: Hilft dabei, die Ursachen von Fehlern zu finden, indem der Programmfluss dokumentiert wird.
- **Performance-Analyse**: Ermöglicht die Identifikation von Engpässen und ineffizienten Code-Pfaden.

## Methoden
- **Manuelle Ablaufverfolgung**:
  - Einfügen von Debugging-Anweisungen (z.B. `print`-Statements) im Code.
  - Nachverfolgen von Variablenwerten und Programmzuständen.
- **Automatisierte Ablaufverfolgung**:
  - Verwendung von Debugging-Tools (z.B. GDB, Visual Studio Debugger) zur Echtzeitüberwachung.
  - Einsatz von Profiler-Tools zur Analyse der Performance.
- **Tracing-Frameworks**:
  - Nutzung von speziellen Bibliotheken (z.B. Log4j, SLF4J) zur strukturierten Protokollierung.
  - Unterstützung von verschiedenen Log-Leveln (DEBUG, INFO, WARN, ERROR).

## Best Practices
- **Konsistente Protokollierung**: Einheitliche Formatierung und Struktur der Log-Ausgaben.
- **Wahl der Log-Level**: Angemessene Verwendung von Log-Leveln zur Vermeidung von Informationsüberflutung.
- **Regelmäßige Überprüfung**: Analyse der Log-Dateien und Traces zur kontinuierlichen Verbesserung.
- **Dokumentation**: Festhalten von Erkenntnissen aus der Ablaufverfolgung zur Wissenssicherung.

## Tools und Technologien
- **Debugging-Tools**: GDB, Visual Studio Debugger, Eclipse Debugger.
- **Tracing-Tools**: Jaeger, Zipkin, OpenTelemetry.
- **Logging-Frameworks**: Log4j, SLF4J, Winston (für Node.js).

Ein Abnahmeprotokoll ist ein **formelles Dokument**, das den erfolgreichen Abschluss eines Projekts oder die Übergabe eines Produkts dokumentiert[^1]. Es dient als **rechtliche und vertragliche Absicherung für beide Parteien** - den Auftragnehmer und den Auftraggeber.

### Inhalt eines Abnahmeprotokolls
**Grundlegende Informationen:**
- Projektname und -nummer
- Datum der Abnahme
- Namen und Funktionen der beteiligten Personen
**Detaillierte Angaben:**
- Beschreibung des abzunehmenden Objekts oder der Leistung
- Liste der durchgeführten Tests und deren Ergebnisse
- Festgestellte Mängel und deren Klassifizierung
- Vereinbarte Nachbesserungen mit Terminen
- Bestätigung der Funktionalität und Vollständigkeit
**Abschluss:**
- Erklärung zur Abnahme (vollständig, teilweise, unter Vorbehalt)
- Unterschriften aller Beteiligten

### Bedeutung für das Projektmanagement
- Markiert den offiziellen Projektabschluss
- Überträgt die Verantwortung und Risiken auf den Auftraggeber
- Löst oft die Schlusszahlung aus
- Beginnt Gewährleistungsfristen

### Arten der Abnahme
1. **Vollständige Abnahme:** Projekt wird ohne Einschränkungen akzeptiert
2. **Teilabnahme:** Nur bestimmte Teile werden abgenommen
3. **Abnahme unter Vorbehalt:** Mit Auflagen zur Nachbesserung

### Best Practices
- Klare Abnahmekriterien im Vorfeld definieren
- Alle Beteiligten zur Abnahme einladen
- Gründliche Tests vor der Abnahme durchführen
- Mängel präzise beschreiben und kategorisieren
- Nachbesserungstermine realistisch setzen

### Rechtliche Aspekte
- Das Abnahmeprotokoll hat Beweiskraft bei rechtlichen Auseinandersetzungen
- Es beendet die Erfüllungsphase und leitet die Gewährleistungsphase ein
- Verjährungsfristen für Mängelansprüche beginnen mit der Abnahme

## Quellen

>[^1:] https://www.youtube.com/watch?v=XxijMDva5sk
>[^2:] https://blog.christianeirich.de/lernzettel-sql-zur-gap2-fuer-fachinformatiker-anwendungsentwicklung/
>[^3:] https://it-berufe-podcast.de/vorbereitung-auf-die-ihk-abschlusspruefung-der-it-berufe/moegliche-themen-von-teil-2-der-gestreckten-abschlusspruefung-gap-fuer-fachinformatiker-anwendungsentwicklung/
>[^4:] https://www.u-form-shop.de/lernkarten/lernkarten-papierversion/it-berufe/fachinformatiker-fachinformatikerin-systemintegration-lernkarten-abschlusspruefung-teil-nbsp-2
>[^5:] https://www.u-form-shop.de/lernkarten/lernkarten-papierversion/it-berufe
>[^6:] https://www.amazon.de/Lernkarten-Fachinformatiker-Anwendungsentwicklung-Pr%C3%BCfung-Pr%C3%BCfungsvorbereitung/dp/3943608522
>[^7:] https://www.fachinformatiker.de/topic/174802-pr%C3%BCfungsvorbereitung-ap2/
>[^8:] https://www.reddit.com/r/fachinformatiker/comments/1dqe7wu/lernzettel_fisi_ap2/

- **Definition**: Vorformulierte **Vertragsbedingungen**, die eine Partei der anderen bei Abschluss eines Vertrages stellt.
- **Zweck**: Vereinheitlichung von Vertragsbedingungen und Vereinfachung des Vertragsabschlusses.

## Rechtsgrundlagen
- **BGB § 305-310**: Regelungen zu AGB im Bürgerlichen Gesetzbuch.
- **AGB-Gesetz**: Teil des BGB, das die Verwendung und Kontrolle von AGB regelt.

## Voraussetzungen für die Gültigkeit
- **Inhaltliche Kontrolle**: AGB dürfen n*icht gegen gesetzliche Vorschriften* verstoßen.
- **Transparenzgebot**: Klauseln müssen *klar und verständlich* formuliert sein.
- **Einbeziehung**: AGB müssen wirksam in den Vertrag einbezogen werden (z.B. durch Hinweis).

## Unwirksamkeit von Klauseln
- **Gesetzliche Verbote**: Klauseln, die gegen gesetzliche Bestimmungen verstoßen, sind unwirksam.
- **Überraschende Klauseln**: Unerwartete oder unklare Klauseln können unwirksam sein.
- **Benachteiligung**: Klauseln, die den Vertragspartner unangemessen benachteiligen, sind nicht zulässig.

## Besondere Regelungen
- **Verbraucherschutz**: Besondere Schutzvorschriften für Verbraucher (z.B. Informationspflichten).
- **Individualabreden**: Abweichungen von AGB durch individuelle Vereinbarungen sind möglich.

## Quellen

> AI Chat. (2024, September 19). Retrieved from https://duckduckgo.com/?q=DuckDuckGo+AI+Chat&ia=chat&duckai=1

- **A**usfallrate **n**ach **R**eparatur (engl. *After Repair Failure Rate*)
- Kennzahl im **Risikomanagement** und der **Zuverlässigkeitsanalyse**
- Misst die **Wahrscheinlichkeit eines erneuten Ausfalls** kurz nach einer Reparatur

## Bedeutung im Risikomanagement
- Hilft bei der Identifikation von Schwachstellen in Systemen/Prozessen
- Ermöglicht gezielte Maßnahmenplanung zur Verbesserung der Zuverlässigkeit 
- Dient als Indikator im [[PDCA]]-Zyklus (Plan-Do-Check-Act)

## Zusammenhang mit anderen Konzepten
- Eng verbunden mit [[MTBF]] (Mean Time Between Failures)
- Wichtiger Bestandteil von Notfallkonzepten 
- Trägt zur Berechnung von Ausfallwahrscheinlichkeiten bei

## Anwendung
- Risikoidentifikation: Aufdecken von Schwachstellen
- Maßnahmenplanung: Entwicklung gezielter Verbesserungsstrategien
- Notfallplanung: Hinweis auf Notwendigkeit robusterer Pläne
- Zuverlässigkeitsanalyse: Verfeinerung von Berechnungen

## Berechnung
$$
ANR = \dfrac{Anzahl \space der \space Ausfälle \space nach \space Reparatur \space innerhalb \space eines \space bestimmten \space Zeitraums}{Gesamtzahl \space der \space Reparaturen \space im \space selben \space Zeitraum}
$$

## Vorteile
- Verbessert die Genauigkeit der Risikoanalyse
- Unterstützt die Optimierung von Wartungs- und Reparaturprozessen
- Erhöht die Gesamtzuverlässigkeit von Systemen

## Beachtung bei der Anwendung
- Sollte in Kombination mit anderen Metriken wie [[MTBF]] betrachtet werden
- Regelmäßige Überprüfung und Aktualisierung erforderlich
- Berücksichtigung bei der Entwicklung von Risikomanagementstrategien



- **grundlegende Trennung** verschiedener Beschreibungsebenen für **Datenbankschemata**
- 
![[Pasted image 20240911121738.png]]
## Ebenen
1. **externe Ebene**, stellt Anwendungen und Benutzern individuelle Benutzersichten bereit, Benutzeroberflächen, Schnittstellen
2. **konzeptionelle Ebene**, welche Daten werden gespeichert, Beziehung zwischen den Daten, Designziel ist vollständige und redundanzfreie Darstellung (Normalisierung)
3. **interne/physische Ebene**, wie und wo werden die Daten in Datenbank gespeichert, Designziel ist effizienter Zugriff

## Vorteile
- **physische Unabhängigkeit**, Änderungen an physischer Ebene (*wechsel Speichermedium*) beeinflussen nicht externe Ebene oder konzeptionelle Ebene
- **logische Datenunabhängigkeit**, Änderungen an Datenbankstruktur (hinzufügen *neuer Attribute, Entitäten*) keine Auswirkungen auf externe Ebene
- **höhere Robustheit** gegenüber Änderungen
- **einfachere Wartung** und **Anpassung**

## Quellen

> Autoren der Wikimedia-Projekte. (2004, July 29). ANSI-SPARC-Architektur – Wikipedia. Retrieved from https://de.wikipedia.org/w/index.php?title=ANSI-SPARC-Architektur&oldid=236727164
> DuckDuckGo AI Chat (2023). Anfrage zur Verbesserung des Lernzettels über ANSI-SPARC-Architektur.